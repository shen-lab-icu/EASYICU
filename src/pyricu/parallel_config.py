"""
æ™ºèƒ½å¹¶è¡Œé…ç½®æ¨¡å—

æ ¹æ®ç³»ç»Ÿå†…å­˜å’ŒCPUæ ¸å¿ƒæ•°è‡ªåŠ¨è°ƒæ•´å¹¶è¡ŒåŠ è½½ç­–ç•¥ã€‚
ç”¨äºä»£ç ç«¯å’ŒWebç«¯ç»Ÿä¸€çš„å¹¶è¡Œé…ç½®ã€‚

Usage:
    from pyricu.parallel_config import get_parallel_config, ParallelConfig
    
    config = get_parallel_config()
    print(f"Max workers: {config.max_workers}")
    print(f"Buckets per batch: {config.buckets_per_batch}")
"""

import os
import logging
from dataclasses import dataclass
from typing import Optional

logger = logging.getLogger(__name__)


@dataclass
class ParallelConfig:
    """å¹¶è¡Œé…ç½®ç±»"""
    
    # ç³»ç»Ÿä¿¡æ¯
    total_memory_gb: float  # æ€»å†…å­˜ (GB)
    available_memory_gb: float  # å¯ç”¨å†…å­˜ (GB)
    cpu_count: int  # CPU æ ¸å¿ƒæ•°
    
    # å¹¶è¡Œç­–ç•¥
    max_workers: int  # æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
    buckets_per_batch: int  # æ¯æ‰¹è¯»å–çš„åˆ†æ¡¶æ•°
    memory_per_concept_mb: int  # é¢„ä¼°æ¯ä¸ªæ¦‚å¿µçš„å†…å­˜å ç”¨ (MB)
    
    # ä¼˜åŒ–æ ‡å¿—
    use_duckdb_aggregation: bool  # æ˜¯å¦ä½¿ç”¨DuckDBå±‚èšåˆ
    enable_concept_cache: bool  # æ˜¯å¦å¯ç”¨æ¦‚å¿µç¼“å­˜
    
    @property
    def performance_tier(self) -> str:
        """è¿”å›æ€§èƒ½ç­‰çº§æè¿°"""
        if self.total_memory_gb >= 128:
            return "high-performance"
        elif self.total_memory_gb >= 64:
            return "server"
        elif self.total_memory_gb >= 32:
            return "workstation"
        elif self.total_memory_gb >= 16:
            return "standard"
        else:
            return "limited"


def get_system_memory() -> tuple:
    """è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯
    
    Returns:
        (total_memory_gb, available_memory_gb)
    """
    try:
        import psutil
        mem = psutil.virtual_memory()
        total_gb = mem.total / (1024 ** 3)
        available_gb = mem.available / (1024 ** 3)
        return total_gb, available_gb
    except ImportError:
        # psutil æœªå®‰è£…ï¼Œä½¿ç”¨ç³»ç»Ÿå‘½ä»¤
        try:
            with open('/proc/meminfo', 'r') as f:
                lines = f.readlines()
                mem_info = {}
                for line in lines:
                    parts = line.split(':')
                    if len(parts) == 2:
                        key = parts[0].strip()
                        value = parts[1].strip().split()[0]  # å–ç¬¬ä¸€ä¸ªæ•°å­—
                        mem_info[key] = int(value)
                
                total_kb = mem_info.get('MemTotal', 16 * 1024 * 1024)
                available_kb = mem_info.get('MemAvailable', 
                                           mem_info.get('MemFree', 8 * 1024 * 1024))
                return total_kb / (1024 ** 2), available_kb / (1024 ** 2)
        except Exception:
            # é»˜è®¤å‡è®¾ 16GB å†…å­˜ï¼Œ8GB å¯ç”¨
            return 16.0, 8.0


def get_cpu_count() -> int:
    """è·å–CPUæ ¸å¿ƒæ•°"""
    try:
        import psutil
        return psutil.cpu_count(logical=True) or os.cpu_count() or 4
    except ImportError:
        return os.cpu_count() or 4


def get_parallel_config(
    override_memory_gb: Optional[float] = None,
    override_workers: Optional[int] = None,
) -> ParallelConfig:
    """
    è·å–æ™ºèƒ½å¹¶è¡Œé…ç½®
    
    æ ¹æ®ç³»ç»Ÿèµ„æºè‡ªåŠ¨è®¡ç®—æœ€ä¼˜çš„å¹¶è¡Œç­–ç•¥ã€‚
    
    Args:
        override_memory_gb: æ‰‹åŠ¨æŒ‡å®šå†…å­˜å¤§å° (GB)ï¼Œç”¨äºæµ‹è¯•
        override_workers: æ‰‹åŠ¨æŒ‡å®šæœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        
    Returns:
        ParallelConfig é…ç½®å¯¹è±¡
        
    Examples:
        # è‡ªåŠ¨æ£€æµ‹
        config = get_parallel_config()
        
        # æ‰‹åŠ¨æŒ‡å®š (ç”¨äºæµ‹è¯•æˆ–é™åˆ¶èµ„æº)
        config = get_parallel_config(override_memory_gb=8, override_workers=2)
    """
    # è·å–ç³»ç»Ÿä¿¡æ¯
    total_mem, available_mem = get_system_memory()
    cpu_count = get_cpu_count()
    
    if override_memory_gb is not None:
        total_mem = override_memory_gb
        available_mem = override_memory_gb * 0.7  # å‡è®¾70%å¯ç”¨
    
    # è®¡ç®—å¹¶è¡Œç­–ç•¥
    # åŸºäºå†…å­˜çš„ç­–ç•¥ï¼ˆä¿å®ˆä¼°è®¡ï¼Œæ¯ä¸ªå¹¶è¡Œä»»åŠ¡éœ€è¦çº¦2GBå†…å­˜ï¼‰
    memory_based_workers = max(1, int(available_mem / 2))
    
    # åŸºäºCPUçš„ç­–ç•¥ï¼ˆä¸è¶…è¿‡CPUæ ¸å¿ƒæ•°çš„ä¸€åŠï¼Œé¿å…è¿‡åº¦ç«äº‰ï¼‰
    cpu_based_workers = max(1, cpu_count // 2)
    
    # å–è¾ƒå°å€¼ï¼Œç¡®ä¿ä¸ä¼šOOM
    max_workers = min(memory_based_workers, cpu_based_workers)
    
    # ğŸš€ æ ¹æ®å†…å­˜å¤§å°åŠ¨æ€è°ƒæ•´ä¸Šé™
    # 16GB: æœ€å¤š8ä¸ªworkers
    # 32GB: æœ€å¤š16ä¸ªworkers
    # 64GB: æœ€å¤š32ä¸ªworkers
    # 128GB+: æœ€å¤š64ä¸ªworkers
    if total_mem >= 128:
        max_workers_limit = 64
    elif total_mem >= 64:
        max_workers_limit = 32
    elif total_mem >= 32:
        max_workers_limit = 16
    else:
        max_workers_limit = 8
    
    max_workers = min(max_workers, max_workers_limit)
    
    if override_workers is not None:
        max_workers = override_workers
    
    # æ¯æ‰¹è¯»å–çš„åˆ†æ¡¶æ•°
    # 16GB: 1ä¸ªåˆ†æ¡¶/æ‰¹
    # 32GB: 2ä¸ªåˆ†æ¡¶/æ‰¹
    # 64GB+: 4ä¸ªåˆ†æ¡¶/æ‰¹
    # 128GB+: 8ä¸ªåˆ†æ¡¶/æ‰¹
    if total_mem >= 128:
        buckets_per_batch = 8
    elif total_mem >= 64:
        buckets_per_batch = 4
    elif total_mem >= 32:
        buckets_per_batch = 2
    else:
        buckets_per_batch = 1
    
    # æ¯ä¸ªæ¦‚å¿µçš„é¢„ä¼°å†…å­˜å ç”¨
    # åŸºäºç»éªŒå€¼ï¼šMIIV hr çº¦200MBï¼ŒAUMC numericitems çº¦1GB
    if total_mem >= 64:
        memory_per_concept_mb = 500
    elif total_mem >= 32:
        memory_per_concept_mb = 300
    else:
        memory_per_concept_mb = 200
    
    # æ˜¯å¦å¯ç”¨DuckDBå±‚èšåˆï¼ˆå§‹ç»ˆå¯ç”¨ï¼Œè¿™æ˜¯å…³é”®ä¼˜åŒ–ï¼‰
    use_duckdb_aggregation = True
    
    # æ˜¯å¦å¯ç”¨æ¦‚å¿µç¼“å­˜ï¼ˆå†…å­˜å……è¶³æ—¶å¯ç”¨ï¼‰
    enable_concept_cache = available_mem >= 8
    
    config = ParallelConfig(
        total_memory_gb=total_mem,
        available_memory_gb=available_mem,
        cpu_count=cpu_count,
        max_workers=max_workers,
        buckets_per_batch=buckets_per_batch,
        memory_per_concept_mb=memory_per_concept_mb,
        use_duckdb_aggregation=use_duckdb_aggregation,
        enable_concept_cache=enable_concept_cache,
    )
    
    logger.info(
        f"ğŸ”§ å¹¶è¡Œé…ç½®: {config.performance_tier} "
        f"(å†…å­˜: {total_mem:.1f}GB, CPU: {cpu_count}æ ¸, "
        f"workers: {max_workers}, buckets/batch: {buckets_per_batch})"
    )
    
    return config


def get_recommended_batch_size(
    config: Optional[ParallelConfig] = None,
    num_concepts: int = 1,
    database: str = 'miiv',
) -> int:
    """
    è·å–æ¨èçš„æ‚£è€…æ‰¹å¤„ç†å¤§å°
    
    ç”¨äºå†…å­˜å—é™ç¯å¢ƒä¸‹çš„åˆ†æ‰¹å¤„ç†ã€‚
    
    Args:
        config: å¹¶è¡Œé…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨è·å–
        num_concepts: è¦åŠ è½½çš„æ¦‚å¿µæ•°é‡
        database: æ•°æ®åº“ç±»å‹
        
    Returns:
        æ¨èçš„ batch_size
    """
    if config is None:
        config = get_parallel_config()
    
    # åŸºç¡€æ‰¹å¤§å°
    # æ ¹æ® AGENTS.md: 12GB å†…å­˜ä¸Š 30000 æ‚£è€…æ˜¯å®‰å…¨ä¸Šé™
    if config.available_memory_gb >= 32:
        base_batch = 50000
    elif config.available_memory_gb >= 16:
        base_batch = 30000
    elif config.available_memory_gb >= 8:
        base_batch = 10000
    else:
        base_batch = 5000
    
    # æ ¹æ®æ¦‚å¿µæ•°é‡è°ƒæ•´
    # å¤šä¸ªæ¦‚å¿µä¼šå¢åŠ å†…å­˜å ç”¨
    concept_factor = max(0.3, 1.0 - (num_concepts - 1) * 0.1)
    
    # æŸäº›æ•°æ®åº“çš„æ•°æ®é‡æ›´å¤§ï¼Œéœ€è¦æ›´å°çš„æ‰¹æ¬¡
    db_factors = {
        'aumc': 0.7,  # AUMC è¡Œæ•°å¤š
        'hirid': 0.6,  # HiRID é«˜é¢‘æ•°æ®
        'miiv': 1.0,
        'eicu': 1.2,  # eICU ç›¸å¯¹è¾ƒå°
        'mimic': 1.0,
        'sic': 1.0,
    }
    db_factor = db_factors.get(database, 1.0)
    
    recommended = int(base_batch * concept_factor * db_factor)
    
    # ç¡®ä¿è‡³å°‘1000
    return max(1000, recommended)


# å…¨å±€é…ç½®ç¼“å­˜
_cached_config: Optional[ParallelConfig] = None


def get_global_config() -> ParallelConfig:
    """è·å–å…¨å±€å¹¶è¡Œé…ç½®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    global _cached_config
    if _cached_config is None:
        _cached_config = get_parallel_config()
    return _cached_config


def reset_global_config():
    """é‡ç½®å…¨å±€é…ç½®ç¼“å­˜"""
    global _cached_config
    _cached_config = None
