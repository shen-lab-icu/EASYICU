"""
pyricu é«˜å±‚API - æä¾›ç®€å•æ˜“ç”¨çš„æ¥å£ï¼ŒåŒæ—¶æ”¯æŒé«˜çº§è‡ªå®šä¹‰

é‡æ„åçš„ç»Ÿä¸€APIï¼Œæ•´åˆäº†å¤šä¸ªæ¨¡å—çš„åŠŸèƒ½:
- api.py: åŸå§‹é«˜å±‚API
- api_enhanced.py: ç¼“å­˜åŠŸèƒ½
- api_unified.py: ç»Ÿä¸€åŠ è½½å™¨
- load_concepts.py: åŠ è½½é€»è¾‘

ä¸¤å±‚è®¾è®¡:
1. Easy API - é¢„å®šä¹‰çš„ä¾¿æ·å‡½æ•° (load_vitals, load_sofaç­‰)
2. Concept API - çµæ´»çš„ä¸»API (load_concepts) å¸¦æ™ºèƒ½é»˜è®¤å€¼

ä½¿ç”¨ç¤ºä¾‹:
    >>> from pyricu import load_concepts, load_sofa, load_vitals
    >>>
    >>> # ç®€å•ç”¨æ³• - è‡ªåŠ¨æ£€æµ‹æ•°æ®åº“
    >>> hr = load_concepts('hr', patient_ids=[123, 456])
    >>>
    >>> # å®Œå…¨è‡ªå®šä¹‰
    >>> sofa = load_concepts('sofa', patient_ids=[123, 456],
    ...                      database='miiv', data_path='/path/to/data',
    ...                      interval='6h', win_length='24h', aggregate='max')
    >>>
    >>> # Easy API - å¼€ç®±å³ç”¨
    >>> vitals = load_vitals(patient_ids=[123, 456])
"""

from typing import List, Union, Optional, Dict
from pathlib import Path
import os
import pandas as pd
import logging

from .base import BaseICULoader, get_default_data_path, detect_database_type
from .resources import load_dictionary
from .config import load_data_sources

logger = logging.getLogger(__name__)

# å…¨å±€åŠ è½½å™¨å®ä¾‹ï¼Œç”¨äºå¤ç”¨åˆå§‹åŒ–å¼€é”€
_global_loader = None
_loader_config = None

def clear_global_loader():
    """æ¸…é™¤å…¨å±€åŠ è½½å™¨ï¼Œå¼ºåˆ¶ä¸‹ä¸€æ¬¡è°ƒç”¨é‡æ–°åˆ›å»º"""
    global _global_loader, _loader_config
    if _global_loader is not None:
        # æ¸…ç†åŠ è½½å™¨å†…éƒ¨ç¼“å­˜
        if hasattr(_global_loader, 'concept_resolver'):
            _global_loader.concept_resolver.clear()
        if hasattr(_global_loader, 'data_source'):
            _global_loader.data_source.clear()
    _global_loader = None
    _loader_config = None

import numpy as np

def _sample_patient_ids(loader: 'BaseICULoader', max_patients: int, verbose: bool = False,
                        sample_strategy: str = 'sorted') -> List:
    """
    ä»æ•°æ®åº“ä¸­é‡‡æ ·æ‚£è€…IDï¼ˆç”¨äº max_patients å‚æ•°ï¼‰
    
    æ ¹æ®æ•°æ®åº“ç±»å‹ï¼Œä»å¯¹åº”çš„ä½é™¢/ICUè¡¨ä¸­è·å–æ‚£è€…IDã€‚
    
    Args:
        loader: BaseICULoader å®ä¾‹
        max_patients: æœ€å¤§æ‚£è€…æ•°é‡
        verbose: æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        sample_strategy: é‡‡æ ·ç­–ç•¥
            - 'sorted': æŒ‰IDæ’åºå–å‰Nä¸ªï¼ˆé»˜è®¤ï¼Œä¸RICUé‡‘æ ‡å‡†ä¸€è‡´ï¼‰
            - 'random': éšæœºé‡‡æ ·Nä¸ªï¼ˆæ›´å…·ä»£è¡¨æ€§ï¼Œé€‚ç”¨äºæ¢ç´¢æ€§åˆ†æï¼‰
    """
    db_name = loader.database
    
    # æ•°æ®åº“ -> (è¡¨å, IDåˆ—å) æ˜ å°„
    id_table_map = {
        'miiv': ('icustays', 'stay_id'),
        'mimic': ('icustays', 'icustay_id'),
        'mimic_demo': ('icustays', 'icustay_id'),
        'eicu': ('patient', 'patientunitstayid'),
        'eicu_demo': ('patient', 'patientunitstayid'),
        'aumc': ('admissions', 'admissionid'),
        'hirid': ('general', 'patientid'),
        'sic': ('cases', 'CaseID'),  # SICdb uses cases table with CaseID
    }
    
    table_name, id_col = id_table_map.get(db_name, ('icustays', 'stay_id'))
    
    try:
        # åªåŠ è½½IDåˆ—ï¼Œé™åˆ¶è¡Œæ•°
        id_table = loader.datasource.load_table(table_name, columns=[id_col], verbose=False)
        all_ids = id_table.data[id_col].dropna().unique()
        
        if sample_strategy == 'random' and len(all_ids) > max_patients:
            import numpy as np
            rng = np.random.default_rng(seed=42)  # å›ºå®šç§å­ä¿è¯å¯å¤ç°
            sampled_ids = sorted(rng.choice(all_ids, size=max_patients, replace=False).tolist())
            strategy_label = "éšæœºé‡‡æ ·"
        else:
            # ğŸ”§ æŒ‰IDæ’åºåå†é‡‡æ ·ï¼Œç¡®ä¿ä¸ RICU é‡‘æ ‡å‡†ç”Ÿæˆè„šæœ¬ä¸€è‡´
            all_ids = sorted(all_ids)
            sampled_ids = list(all_ids[:max_patients])
            strategy_label = "å·²æ’åº"
        
        if verbose:
            print(f"ğŸ¯ max_patients={max_patients}: ä» {table_name}.{id_col} é‡‡æ · {len(sampled_ids)} ä¸ªæ‚£è€… ({strategy_label})")
        
        return sampled_ids
    except Exception as e:
        if verbose:
            print(f"âš ï¸ é‡‡æ ·æ‚£è€…IDå¤±è´¥: {e}ï¼Œå°†åŠ è½½æ‰€æœ‰æ‚£è€…")
        return None


def _compress_dtypes(df: pd.DataFrame, verbose: bool = False) -> pd.DataFrame:
    """
    å‹ç¼© DataFrame çš„æ•°æ®ç±»å‹ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
    
    - int64 -> int32 (å¦‚æœå€¼èŒƒå›´å…è®¸)
    - float64 -> float32 (å¯¹äºéç²¾ç¡®å€¼)
    - ä¿æŒ datetime64 ä¸å˜
    
    å¯ä»¥èŠ‚çœçº¦ 50-60% çš„å†…å­˜
    """
    if df.empty:
        return df
    
    original_mem = df.memory_usage(deep=True).sum()
    
    for col in df.columns:
        col_type = df[col].dtype
        
        # æ•´æ•°ç±»å‹å‹ç¼©
        if col_type == np.int64:
            col_min, col_max = df[col].min(), df[col].max()
            if col_min >= np.iinfo(np.int32).min and col_max <= np.iinfo(np.int32).max:
                df[col] = df[col].astype(np.int32)
            elif col_min >= np.iinfo(np.int16).min and col_max <= np.iinfo(np.int16).max:
                df[col] = df[col].astype(np.int16)
        
        # æµ®ç‚¹ç±»å‹å‹ç¼© - SOFA åˆ†æ•°ç­‰å°æ•´æ•°å¯ä»¥ç”¨ int8
        elif col_type == np.float64:
            # æ£€æŸ¥æ˜¯å¦éƒ½æ˜¯æ•´æ•°å€¼
            if df[col].dropna().apply(lambda x: x == int(x)).all():
                col_min, col_max = df[col].min(), df[col].max()
                if not np.isnan(col_min) and col_min >= -128 and col_max <= 127:
                    # å°æ•´æ•°ç”¨ Int8 (å¯ç©ºæ•´æ•°)
                    df[col] = df[col].astype('Int8')
                elif not np.isnan(col_min) and col_min >= np.iinfo(np.int16).min and col_max <= np.iinfo(np.int16).max:
                    df[col] = df[col].astype('Int16')
            else:
                # ä¸€èˆ¬æµ®ç‚¹æ•°ç”¨ float32
                df[col] = df[col].astype(np.float32)
    
    if verbose:
        new_mem = df.memory_usage(deep=True).sum()
        saved = (original_mem - new_mem) / original_mem * 100
        print(f"ğŸ’¾ å†…å­˜å‹ç¼©: {original_mem/1024/1024:.1f}MB â†’ {new_mem/1024/1024:.1f}MB (èŠ‚çœ {saved:.0f}%)")
    
    return df


def _get_global_loader(
    database: Optional[str] = None,
    data_path: Optional[Path] = None,
    dict_path: Optional[Union[str, Path, List[Union[str, Path]]]] = None,
    **kwargs,
) -> BaseICULoader:
    """è·å–æˆ–åˆ›å»ºå…¨å±€åŠ è½½å™¨å®ä¾‹ï¼ˆå‡å°‘é‡å¤åˆå§‹åŒ–ï¼‰"""
    global _global_loader, _loader_config

    if dict_path is None:
        dict_key = None
    elif isinstance(dict_path, (list, tuple)):
        dict_key = tuple(map(str, dict_path))
    else:
        dict_key = str(dict_path)

    # ğŸš€ åªæ¯”è¾ƒå½±å“åŠ è½½å™¨åˆå§‹åŒ–çš„å…³é”®å‚æ•°ï¼Œå¿½ç•¥è¿è¡Œæ—¶å‚æ•°ï¼ˆå¦‚ verboseï¼‰
    # è¿™å…è®¸åœ¨å¤šæ¬¡è°ƒç”¨ä¹‹é—´å¤ç”¨åŠ è½½å™¨ï¼Œå…±äº«ç¼“å­˜
    config_kwargs = {k: v for k, v in kwargs.items() if k in ('use_sofa2',)}
    current_config = (database, str(data_path) if data_path else None, dict_key, frozenset(config_kwargs.items()))

    if _global_loader is None or _loader_config != current_config:
        _global_loader = BaseICULoader(
            database=database,
            data_path=data_path,
            dict_path=dict_path,
            **kwargs,
        )
        _loader_config = current_config

    return _global_loader

def _get_smart_workers(num_concepts: int, num_patients: Optional[int] = None) -> tuple:
    """
    æ™ºèƒ½è®¡ç®—æœ€ä½³å¹¶è¡Œé…ç½®
    
    ä½¿ç”¨ parallel_config æ¨¡å—æ ¹æ®ç³»ç»Ÿèµ„æºè‡ªåŠ¨è°ƒæ•´ã€‚
    
    Args:
        num_concepts: è¦åŠ è½½çš„æ¦‚å¿µæ•°é‡
        num_patients: æ‚£è€…æ•°é‡ï¼ˆå¦‚æœå·²çŸ¥ï¼‰
    
    Returns:
        (concept_workers, parallel_workers): æ¦‚å¿µå¹¶è¡Œæ•°å’Œæ‚£è€…æ‰¹æ¬¡å¹¶è¡Œæ•°
    """
    # æ£€æŸ¥æ˜¯å¦ç¦ç”¨è‡ªåŠ¨ä¼˜åŒ–
    if os.getenv('PYRICU_NO_AUTO_PARALLEL'):
        return 1, None
    
    # ä½¿ç”¨ç»Ÿä¸€çš„å¹¶è¡Œé…ç½®æ¨¡å—
    from .parallel_config import get_global_config
    config = get_global_config()
    
    # ğŸš€ ç­–ç•¥1: åŸºäºç³»ç»Ÿèµ„æºçš„æ¦‚å¿µçº§å¹¶è¡Œ
    # ä½¿ç”¨ parallel_config è®¡ç®—çš„æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
    if num_concepts >= 3:
        concept_workers = min(num_concepts, config.max_workers)
    elif num_concepts == 2:
        concept_workers = min(2, config.max_workers)
    else:
        concept_workers = 1
    
    # ğŸš€ ç­–ç•¥2: å¤§é‡æ‚£è€…æ—¶å¯ç”¨æ‚£è€…æ‰¹æ¬¡å¹¶è¡Œ
    # æ‚£è€…æ•° > 5000 æ—¶ï¼Œåˆ†æ‰¹å¤„ç†æ›´é«˜æ•ˆ
    parallel_workers = None  # é»˜è®¤ä¸åˆ†æ‰¹
    if num_patients is not None and num_patients > 5000:
        # åŸºäºç³»ç»Ÿèµ„æºçš„åˆ†æ‰¹å¹¶è¡Œ
        parallel_workers = min(config.max_workers, 4)
    
    return concept_workers, parallel_workers


def load_concepts(
    concepts: Union[str, List[str]],
    patient_ids: Optional[Union[List, Dict]] = None,
    # æ•°æ®æºå‚æ•° - æ™ºèƒ½é»˜è®¤å€¼
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    # æ—¶é—´å‚æ•° - é»˜è®¤ä¸ricuä¸€è‡´ (interval=hours(1L))
    interval: Optional[Union[str, pd.Timedelta]] = '1h',  # ricué»˜è®¤: hours(1L)
    win_length: Optional[Union[str, pd.Timedelta]] = None,
    # èšåˆå‚æ•°
    aggregate: Optional[Union[str, Dict]] = None,
    # SOFAç›¸å…³
    keep_components: bool = False,
    # å…¶ä»–
    verbose: bool = False,
    use_sofa2: bool = False,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨SOFA2å­—å…¸
    merge: bool = True,       # æ–°å¢ï¼šæ˜¯å¦åˆå¹¶ç»“æœ
    ricu_compatible: bool = True,  # é»˜è®¤å¯ç”¨ricu.Rå…¼å®¹æ ¼å¼
    dict_path: Optional[Union[str, Path, List[Union[str, Path]]]] = None,
    chunk_size: Optional[int] = None,
    progress: bool = False,
    parallel_workers: Optional[int] = None,
    concept_workers: Optional[int] = None,  # æ”¹ä¸ºOptionalï¼Œæ”¯æŒè‡ªåŠ¨æ£€æµ‹
    parallel_backend: str = 'auto',
    max_patients: Optional[int] = None,  # é™åˆ¶åŠ è½½çš„æ‚£è€…æ•°é‡ï¼ˆè‡ªåŠ¨é‡‡æ ·ï¼‰
    limit: Optional[int] = None,  # max_patients çš„åˆ«åï¼ˆå…¼å®¹ extract_sofa_data.pyï¼‰
    sample_strategy: str = 'sorted',  # ğŸ†• é‡‡æ ·ç­–ç•¥: 'sorted'=æŒ‰IDæ’åºå‰Nä¸ª, 'random'=éšæœºé‡‡æ ·
    batch_size: Optional[int] = None,  # ğŸ†• åˆ†æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤30000ï¼Œé€‚åˆ12GBå†…å­˜ï¼‰
    memory_efficient: bool = False,  # ğŸ†• å†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼ˆå‹ç¼©æ•°æ®ç±»å‹ï¼‰
    **kwargs,
) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
    """
    åŠ è½½ICUæ¦‚å¿µæ•°æ® - pyricuçš„ä¸»è¦API (é‡æ„ç‰ˆæœ¬)

    è¿™ä¸ªå‡½æ•°ä½¿ç”¨ç»Ÿä¸€çš„BaseICULoaderï¼Œæ•´åˆäº†å¤šä¸ªæ¨¡å—çš„åŠŸèƒ½ï¼š
    - åŸapi.pyçš„æ‰€æœ‰åŠŸèƒ½
    - api_enhanced.pyçš„ç¼“å­˜æ”¯æŒ
    - api_unified.pyçš„ç»Ÿä¸€é€»è¾‘
    - load_concepts.pyçš„åŠ è½½å®ç°

    Args:
        concepts: æ¦‚å¿µåç§°æˆ–æ¦‚å¿µåç§°åˆ—è¡¨
            ä¾‹å¦‚: 'hr', ['hr', 'sbp', 'temp'], 'sofa', 'sofa2'
        patient_ids: å¯é€‰çš„æ‚£è€…IDåˆ—è¡¨æˆ–å­—å…¸
            - List: [123, 456] (è‡ªåŠ¨è½¬æ¢ä¸ºæ­£ç¡®çš„IDåˆ—)
            - Dict: {'stay_id': [123, 456]} (æ˜¾å¼æŒ‡å®šIDåˆ—)
            - None: åŠ è½½æ‰€æœ‰æ‚£è€…

        # === æ•°æ®æºå‚æ•° (å¯é€‰ï¼Œæœ‰æ™ºèƒ½é»˜è®¤å€¼) ===
        database: æ•°æ®åº“ç±»å‹
            - None: è‡ªåŠ¨æ£€æµ‹ï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰
            - 'miiv', 'mimic', 'eicu', 'hirid', 'aumc'
        data_path: æ•°æ®è·¯å¾„
            - None: ä»ç¯å¢ƒå˜é‡æˆ–å¸¸è§è·¯å¾„è‡ªåŠ¨æŸ¥æ‰¾
            - str/Path: æ˜¾å¼æŒ‡å®šè·¯å¾„

        # === æ—¶é—´å‚æ•° (é»˜è®¤ä¸ricuä¸€è‡´) ===
        interval: æ—¶é—´å¯¹é½é—´éš” (é»˜è®¤'1h'ï¼Œä¸ricuçš„hours(1L)ä¸€è‡´)
            - '1h': é»˜è®¤å€¼ï¼Œä¸ricu RåŒ…ä¸€è‡´
            - '6h', '12h': å…¶ä»–æ—¶é—´é—´éš”
            - None: ä½¿ç”¨åŸå§‹æ—¶é—´ç‚¹ï¼ˆä¸å¯¹é½ï¼‰
            - pd.Timedelta(hours=1): Timedeltaå¯¹è±¡
        win_length: æ»‘åŠ¨çª—å£é•¿åº¦ï¼ˆç”¨äºSOFAç­‰è¯„åˆ†ï¼‰
            - None: ç‚¹æ•°æ®ï¼ˆä¸ä½¿ç”¨çª—å£ï¼‰
            - '24h': å­—ç¬¦ä¸²æ ¼å¼
            - pd.Timedelta(hours=24): Timedeltaå¯¹è±¡

        # === èšåˆå‚æ•° (å¯é€‰) ===
        aggregate: èšåˆæ–¹å¼
            - None: ä½¿ç”¨é»˜è®¤èšåˆï¼ˆé€šå¸¸æ˜¯'mean'ï¼‰
            - 'mean', 'max', 'min', 'median': å•ä¸€èšåˆå‡½æ•°
            - {'hr': 'mean', 'sbp': 'max'}: æ¯ä¸ªæ¦‚å¿µæŒ‡å®šèšåˆ

        # === SOFAç›¸å…³ ===
        keep_components: æ˜¯å¦ä¿ç•™SOFAç»„ä»¶åˆ—
            - False: åªè¿”å›æ€»åˆ†
            - True: è¿”å› sofa + sofa_resp + sofa_coag + ...
        use_sofa2: æ˜¯å¦åŠ è½½SOFA2å­—å…¸ï¼ˆè‡ªåŠ¨æ£€æµ‹SOFA2æ¦‚å¿µæ—¶å¯ç”¨ï¼‰

        # === å…¶ä»– ===
        merge: æ˜¯å¦åˆå¹¶å¤šä¸ªæ¦‚å¿µåˆ°ä¸€ä¸ªDataFrame
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        **kwargs: å…¶ä»–å‚æ•°ä¼ é€’ç»™åº•å±‚API

    Returns:
        DataFrame æˆ– dict of DataFrames

    Examples:
        >>> # æœ€ç®€å•çš„ç”¨æ³• - è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰å‚æ•°
        >>> hr = load_concepts('hr')
        >>>
        >>> # æŒ‡å®šæ‚£è€…ID
        >>> hr = load_concepts('hr', patient_ids=[123, 456, 789])
        >>>
        >>> # åŠ è½½å¤šä¸ªæ¦‚å¿µå¹¶å¯¹é½åˆ°1å°æ—¶é—´éš”
        >>> vitals = load_concepts(['hr', 'sbp', 'temp'],
        ...                        patient_ids=[123, 456],
        ...                        interval='1h')
        >>>
        >>> # SOFAè¯„åˆ† - 24å°æ—¶çª—å£ï¼Œä¿ç•™ç»„ä»¶
        >>> sofa = load_concepts('sofa',
        ...                      patient_ids=[123, 456],
        ...                      interval='6h',
        ...                      win_length='24h',
        ...                      keep_components=True)
        >>>
        >>> # SOFA2è¯„åˆ† (2025æ ‡å‡†)
        >>> sofa2 = load_concepts('sofa2',
        ...                       patient_ids=[123, 456],
        ...                       use_sofa2=True)
        >>>
        >>> # å®Œå…¨è‡ªå®šä¹‰
        >>> data = load_concepts('sofa2',
        ...                      patient_ids={'stay_id': [123, 456]},
        ...                      database='miiv',
        ...                      data_path='/custom/path',
        ...                      interval=pd.Timedelta(hours=6),
        ...                      win_length=pd.Timedelta(hours=24),
        ...                      aggregate='max',
        ...                      verbose=True)
    """
    # è‡ªåŠ¨æ£€æµ‹SOFA2éœ€æ±‚
    if isinstance(concepts, str):
        concepts_list = [concepts]
    else:
        concepts_list = list(concepts)

    # SOFA2 ç›¸å…³æ¦‚å¿µé›†åˆï¼ˆéœ€è¦åŠ è½½ sofa2-dictï¼‰
    sofa2_concepts = {'sofa2', 'sofa2_resp', 'sofa2_coag', 'sofa2_liver', 
                      'sofa2_cardio', 'sofa2_cns', 'sofa2_renal',
                      'uo_6h', 'uo_12h', 'uo_24h', 'rrt_criteria', 'rrt',
                      'adv_resp', 'ecmo', 'ecmo_indication', 'sedated_gcs',
                      'mech_circ_support', 'other_vaso', 'delirium_tx',
                      'motor_response', 'delirium_positive'}
    if any(c in sofa2_concepts or 'sofa2' in c.lower() for c in concepts_list):
        use_sofa2 = True

    if verbose:
        print(f"ğŸ“Š ä½¿ç”¨ç»Ÿä¸€APIåŠ è½½ {len(concepts_list)} ä¸ªæ¦‚å¿µ...")
        print(f"   æ¦‚å¿µ: {', '.join(concepts_list)}")

    # åˆ›å»ºæˆ–è·å–å…¨å±€åŠ è½½å™¨
    loader = _get_global_loader(
        database=database,
        data_path=data_path,
        dict_path=dict_path,
        use_sofa2=use_sofa2,
        verbose=verbose
    )

    # ğŸš€ ä» kwargs ä¸­æå–æ‚£è€… IDï¼ˆæ”¯æŒé€šè¿‡ patientunitstayid=, admissionid=, stay_id= ç­‰ä¼ å…¥ï¼‰
    if patient_ids is None:
        id_kwargs = ['patientunitstayid', 'admissionid', 'stay_id', 'subject_id', 'patientid']
        for id_key in id_kwargs:
            if id_key in kwargs:
                patient_ids = {id_key: kwargs.pop(id_key)}
                break

    # ğŸš€ å¤„ç† limit åˆ«åï¼ˆå…¼å®¹æ€§ï¼‰
    effective_max_patients = max_patients
    if effective_max_patients is None and limit is not None:
        effective_max_patients = limit

    # ğŸš€ max_patients æ”¯æŒï¼šè‡ªåŠ¨ä»æ•°æ®åº“é‡‡æ ·æ‚£è€…ID
    if effective_max_patients is not None and patient_ids is None:
        patient_ids = _sample_patient_ids(loader, effective_max_patients, verbose,
                                          sample_strategy=sample_strategy)

    # è§„èŒƒåŒ–æ‚£è€…ID
    if patient_ids is not None and not isinstance(patient_ids, dict):
        database_name = loader.database
        if database_name in ['eicu', 'eicu_demo']:
            patient_ids = {'patientunitstayid': patient_ids}
        elif database_name in ['aumc']:
            patient_ids = {'admissionid': patient_ids}
        elif database_name in ['hirid']:
            patient_ids = {'patientid': patient_ids}
        elif database_name == 'sic':
            patient_ids = {'CaseID': patient_ids}  # SICdb uses CaseID
        elif database_name == 'mimic':
            patient_ids = {'icustay_id': patient_ids}  # MIMIC-III uses icustay_id
        else:
            patient_ids = {'stay_id': patient_ids}

    # ğŸš€ æ™ºèƒ½å¹¶è¡Œé…ç½®ï¼šæ ¹æ®æ¦‚å¿µæ•°é‡å’Œæ‚£è€…æ•°é‡è‡ªåŠ¨ä¼˜åŒ–
    num_patients = None
    if patient_ids is not None:
        if isinstance(patient_ids, dict):
            for v in patient_ids.values():
                if isinstance(v, (list, tuple)):
                    num_patients = len(v)
                    break
        elif isinstance(patient_ids, (list, tuple)):
            num_patients = len(patient_ids)
    
    # åªæœ‰å½“ç”¨æˆ·æ²¡æœ‰æŒ‡å®šæ—¶æ‰ä½¿ç”¨æ™ºèƒ½é…ç½®
    effective_concept_workers = concept_workers
    effective_parallel_workers = parallel_workers
    
    if concept_workers is None or parallel_workers is None:
        smart_concept, smart_parallel = _get_smart_workers(len(concepts_list), num_patients)
        if concept_workers is None:
            effective_concept_workers = smart_concept
        if parallel_workers is None:
            effective_parallel_workers = smart_parallel
        
        if verbose and (effective_concept_workers > 1 or effective_parallel_workers):
            print(f"   âš¡ æ™ºèƒ½ä¼˜åŒ–: concept_workers={effective_concept_workers}, "
                  f"parallel_workers={effective_parallel_workers or 'ä¸åˆ†æ‰¹'}")

    # ğŸ†• åˆ†æ‰¹å¤„ç†æ”¯æŒï¼ˆç”¨äºå†…å­˜æ§åˆ¶ï¼‰
    if batch_size is not None and patient_ids is not None:
        # æå–æ‚£è€…IDåˆ—è¡¨
        if isinstance(patient_ids, dict):
            id_col = list(patient_ids.keys())[0]
            all_patient_ids = list(patient_ids.values())[0]
        else:
            id_col = 'stay_id'  # é»˜è®¤
            all_patient_ids = list(patient_ids)
        
        total_patients = len(all_patient_ids)
        if total_patients > batch_size:
            if verbose:
                print(f"ğŸ”„ åˆ†æ‰¹å¤„ç†: {total_patients} æ‚£è€…ï¼Œæ¯æ‰¹ {batch_size} æ‚£è€…")
            
            import gc
            results = []
            for i in range(0, total_patients, batch_size):
                batch_ids = all_patient_ids[i:i+batch_size]
                batch_patient_ids = {id_col: batch_ids}
                
                if verbose:
                    batch_num = i // batch_size + 1
                    total_batches = (total_patients + batch_size - 1) // batch_size
                    print(f"   ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch_ids)} æ‚£è€…)...")
                
                # ğŸ”§ æ¸…é™¤ç¼“å­˜ä»¥ç¡®ä¿æ¯æ‰¹ä½¿ç”¨æ­£ç¡®çš„æ‚£è€…ID
                loader.clear_cache()
                
                batch_result = loader.load_concepts(
                    concepts=concepts_list,
                    patient_ids=batch_patient_ids,
                    interval=interval,
                    win_length=win_length,
                    aggregate=aggregate,
                    keep_components=keep_components,
                    merge=merge,
                    ricu_compatible=ricu_compatible,
                    chunk_size=chunk_size,
                    progress=progress,
                    parallel_workers=effective_parallel_workers,
                    concept_workers=effective_concept_workers,
                    parallel_backend=parallel_backend,
                    **kwargs
                )
                
                if isinstance(batch_result, pd.DataFrame) and len(batch_result) > 0:
                    results.append(batch_result)
                elif isinstance(batch_result, dict):
                    results.append(batch_result)
                
                # é‡Šæ”¾å†…å­˜
                gc.collect()
            
            # åˆå¹¶ç»“æœ
            if results:
                if isinstance(results[0], pd.DataFrame):
                    final_result = pd.concat(results, ignore_index=True)
                    # ğŸ†• å†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼šå‹ç¼©æ•°æ®ç±»å‹
                    if memory_efficient:
                        final_result = _compress_dtypes(final_result, verbose=verbose)
                    if verbose:
                        print(f"âœ… åˆ†æ‰¹å®Œæˆ: å…± {len(final_result)} è¡Œ")
                    return final_result
                else:
                    # dict ç»“æœåˆå¹¶
                    merged_dict = {}
                    for r in results:
                        for k, v in r.items():
                            if k not in merged_dict:
                                merged_dict[k] = []
                            merged_dict[k].append(v)
                    final_dict = {k: pd.concat(vs, ignore_index=True) for k, vs in merged_dict.items()}
                    # ğŸ†• å†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼šå‹ç¼©æ•°æ®ç±»å‹
                    if memory_efficient:
                        final_dict = {k: _compress_dtypes(v, verbose=verbose) for k, v in final_dict.items()}
                    return final_dict
            else:
                return pd.DataFrame()

    # ä½¿ç”¨ç»Ÿä¸€åŠ è½½å™¨åŠ è½½æ¦‚å¿µ
    result = loader.load_concepts(
        concepts=concepts_list,
        patient_ids=patient_ids,
        interval=interval,
        win_length=win_length,
        aggregate=aggregate,
        keep_components=keep_components,
        merge=merge,
        ricu_compatible=ricu_compatible,
        chunk_size=chunk_size,
        progress=progress,
        parallel_workers=effective_parallel_workers,
        concept_workers=effective_concept_workers,
        parallel_backend=parallel_backend,
        **kwargs
    )
    
    # ğŸ†• å†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼šå‹ç¼©æ•°æ®ç±»å‹
    if memory_efficient:
        if isinstance(result, pd.DataFrame):
            result = _compress_dtypes(result, verbose=verbose)
        elif isinstance(result, dict):
            result = {k: _compress_dtypes(v, verbose=verbose) for k, v in result.items()}
    
    return result

# ä¸ºäº†å…¼å®¹æ—§ä»£ç ï¼Œä¿ç•™æ—§çš„å‡½æ•°å
def load_concept(*args, **kwargs):
    """load_conceptsçš„åˆ«åï¼ˆå‘åå…¼å®¹ï¼‰"""
    return load_concepts(*args, **kwargs)

def load_sofa(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    keep_components: bool = True,
    verbose: bool = False,
    **kwargs  # å…è®¸ä¼ é€’é¢å¤–å‚æ•°å¦‚align_to_admission
) -> pd.DataFrame:
    """
    åŠ è½½SOFAè¯„åˆ†ï¼ˆä¾¿æ·å‡½æ•°ï¼‰- é‡æ„ç‰ˆæœ¬

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        keep_components: æ˜¯å¦ä¿ç•™ç»„ä»¶ï¼ˆé»˜è®¤Trueï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        **kwargs: é¢å¤–å‚æ•°ä¼ é€’ç»™load_conceptsï¼ˆå¦‚align_to_admissionï¼‰

    Returns:
        SOFAè¯„åˆ†DataFrame

    Examples:
        >>> # æœ€ç®€å•çš„ç”¨æ³• - è‡ªåŠ¨æ£€æµ‹
        >>> sofa = load_sofa(patient_ids=[123, 456])
        >>>
        >>> # å®Œå…¨è‡ªå®šä¹‰
        >>> sofa = load_sofa(patient_ids=[123, 456],
        ...                  database='miiv', data_path='/data/miiv',
        ...                  win_length='12h', interval='6h')
        >>>
        >>> # ä½¿ç”¨æ—¶é—´å¯¹é½
        >>> sofa = load_sofa(patient_ids=[123, 456],
        ...                  align_to_admission=True)
    """
    if verbose:
        print("ğŸ¥ åŠ è½½SOFAè¯„åˆ†...")

    return load_concepts(
        'sofa',
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        keep_components=keep_components,
        verbose=verbose,
        **kwargs  # ä¼ é€’é¢å¤–å‚æ•°
    )

def load_sofa2(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    keep_components: bool = True,
    verbose: bool = False,
    **kwargs  # å…è®¸ä¼ é€’é¢å¤–å‚æ•°å¦‚align_to_admission
) -> pd.DataFrame:
    """
    åŠ è½½SOFA-2è¯„åˆ†ï¼ˆ2025å¹´æ–°æ ‡å‡†ï¼‰- é‡æ„ç‰ˆæœ¬

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        keep_components: æ˜¯å¦ä¿ç•™ç»„ä»¶ï¼ˆé»˜è®¤Trueï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        **kwargs: é¢å¤–å‚æ•°ä¼ é€’ç»™load_conceptsï¼ˆå¦‚align_to_admissionï¼‰

    Returns:
        SOFA-2è¯„åˆ†DataFrame

    Examples:
        >>> # æœ€ç®€å•çš„ç”¨æ³• - è‡ªåŠ¨æ£€æµ‹
        >>> sofa2 = load_sofa2(patient_ids=[123, 456])
        >>>
        >>> # å®Œå…¨è‡ªå®šä¹‰
        >>> sofa2 = load_sofa2(patient_ids=[123, 456],
        ...                   database='miiv', data_path='/data/miiv')
    """
    if verbose:
        print("ğŸ¥ åŠ è½½SOFA-2è¯„åˆ†ï¼ˆ2025æ ‡å‡†ï¼‰...")

    return load_concepts(
        'sofa2',
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        keep_components=keep_components,
        verbose=verbose,
        use_sofa2=True,  # å¼ºåˆ¶ä½¿ç”¨SOFA2å­—å…¸
        **kwargs  # ä¼ é€’é¢å¤–å‚æ•°
    )

def load_sepsis3(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½Sepsis-3è¯Šæ–­ç›¸å…³æ•°æ® - é‡æ„ç‰ˆæœ¬

    åŒ…å«: SOFA, abx, samp, susp_inf, sep3

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        Sepsis-3æ•°æ®DataFrame

    Examples:
        >>> # æœ€ç®€å•çš„ç”¨æ³• - è‡ªåŠ¨æ£€æµ‹
        >>> sep3 = load_sepsis3(patient_ids=[123, 456])
        >>>
        >>> # å®Œå…¨è‡ªå®šä¹‰
        >>> sep3 = load_sepsis3(patient_ids=[123, 456],
        ...                     database='miiv', data_path='/data/miiv')
    """
    if verbose:
        print("ğŸ¦  åŠ è½½Sepsis-3ç›¸å…³æ•°æ®...")

    # åªåŠ è½½sep3æ¦‚å¿µï¼Œå®ƒå·²ç»åŒ…å«äº†æ‰€æœ‰å¿…éœ€çš„è¯Šæ–­ä¿¡æ¯
    # å¦‚æœéœ€è¦è¯¦ç»†çš„ç»„ä»¶ï¼ˆSOFA, abxç­‰ï¼‰ï¼Œç”¨æˆ·å¯ä»¥åˆ†åˆ«åŠ è½½
    return load_concepts(
        'sep3',
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        verbose=verbose
    )

def load_vitals(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½ç”Ÿå‘½ä½“å¾æ•°æ®ï¼ˆä¾¿æ·å‡½æ•°ï¼‰- é‡æ„ç‰ˆæœ¬

    åŒ…å«: hr, sbp, dbp, temp, resp, spo2

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        ç”Ÿå‘½ä½“å¾DataFrame

    Examples:
        >>> # æœ€ç®€å•çš„ç”¨æ³• - è‡ªåŠ¨æ£€æµ‹
        >>> vitals = load_vitals(patient_ids=[123, 456])
        >>>
        >>> # å®Œå…¨è‡ªå®šä¹‰
        >>> vitals = load_vitals(patient_ids=[123, 456],
        ...                      database='miiv', data_path='/data/miiv',
        ...                      interval='30m')
    """
    vital_concepts = ['hr', 'sbp', 'dbp', 'temp', 'resp', 'spo2']

    if verbose:
        print("â¤ï¸  åŠ è½½ç”Ÿå‘½ä½“å¾...")

    return load_concepts(
        vital_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        verbose=verbose
    )

def load_labs(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '6h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½å®éªŒå®¤æ£€æŸ¥æ•°æ®ï¼ˆä¾¿æ·å‡½æ•°ï¼‰- é‡æ„ç‰ˆæœ¬

    åŒ…å«: wbc, plt, crea, bili, lact, ph

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤6å°æ—¶ï¼Œå®éªŒå®¤æ£€æŸ¥é¢‘ç‡è¾ƒä½ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        å®éªŒå®¤æ£€æŸ¥DataFrame

    Examples:
        >>> # æœ€ç®€å•çš„ç”¨æ³• - è‡ªåŠ¨æ£€æµ‹
        >>> labs = load_labs(patient_ids=[123, 456])
        >>>
        >>> # å®Œå…¨è‡ªå®šä¹‰
        >>> labs = load_labs(patient_ids=[123, 456],
        ...                   database='miiv', data_path='/data/miiv',
        ...                   interval='12h')
    """
    lab_concepts = ['wbc', 'plt', 'crea', 'bili', 'lact', 'ph']

    if verbose:
        print("ğŸ”¬ åŠ è½½å®éªŒå®¤æ£€æŸ¥...")

    return load_concepts(
        lab_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        verbose=verbose
    )

def list_available_concepts(source: Optional[str] = None) -> List[str]:
    """
    åˆ—å‡ºå¯ç”¨çš„æ¦‚å¿µ
    
    Args:
        source: å¦‚æœæŒ‡å®šï¼Œåªåˆ—å‡ºè¯¥æ•°æ®æºæ”¯æŒçš„æ¦‚å¿µ
        
    Returns:
        æ¦‚å¿µåç§°åˆ—è¡¨
        
    Examples:
        >>> # åˆ—å‡ºæ‰€æœ‰æ¦‚å¿µ
        >>> all_concepts = list_available_concepts()
        >>> 
        >>> # åˆ—å‡ºMIMICæ”¯æŒçš„æ¦‚å¿µ
        >>> mimic_concepts = list_available_concepts('mimic')
    """
    dict_obj = load_dictionary()
    
    if source is None:
        # è¿”å›æ‰€æœ‰æ¦‚å¿µ (ä½¿ç”¨ _concepts å±æ€§)
        return list(dict_obj._concepts.keys())
    
    # è¿”å›ç‰¹å®šæ•°æ®æºæ”¯æŒçš„æ¦‚å¿µ
    supported = []
    for name, concept in dict_obj._concepts.items():
        if hasattr(concept, 'sources') and source in concept.sources:
            supported.append(name)
    
    return sorted(supported)

def list_available_sources() -> List[str]:
    """
    åˆ—å‡ºå¯ç”¨çš„æ•°æ®æº
    
    Returns:
        æ•°æ®æºåç§°åˆ—è¡¨
        
    Examples:
        >>> sources = list_available_sources()
        >>> print(sources)
        ['mimic', 'hirid', 'eicu', 'aumc']
    """
    registry = load_data_sources()
    return [cfg.name for cfg in registry]

def get_concept_info(concept_name: str) -> Dict:
    """
    è·å–æ¦‚å¿µçš„è¯¦ç»†ä¿¡æ¯
    
    Args:
        concept_name: æ¦‚å¿µåç§°
        
    Returns:
        åŒ…å«æ¦‚å¿µä¿¡æ¯çš„å­—å…¸
        
    Examples:
        >>> info = get_concept_info('hr')
        >>> print(info['description'])
        'heart rate'
    """
    dict_obj = load_dictionary()
    
    if concept_name not in dict_obj.concepts:
        raise ValueError(f"æœªçŸ¥æ¦‚å¿µ: {concept_name}")
    
    concept = dict_obj.concepts[concept_name]
    
    info = {
        'name': concept_name,
        'description': getattr(concept, 'description', ''),
        'category': getattr(concept, 'category', ''),
        'unit': getattr(concept, 'unit', ''),
        'sources': list(getattr(concept, 'sources', {}).keys()),
    }
    
    return info

# === æ–°å¢æ¨¡å—å‡½æ•°ï¼ˆå‚è€ƒricu.Rï¼‰ ===

def _validate_concepts(concepts: List[str], verbose: bool = False) -> List[str]:
    """
    éªŒè¯æ¦‚å¿µæ˜¯å¦å­˜åœ¨äºå­—å…¸ä¸­ï¼Œè¿”å›å¯ç”¨çš„æ¦‚å¿µåˆ—è¡¨

    Args:
        concepts: è¦éªŒè¯çš„æ¦‚å¿µåˆ—è¡¨
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        å¯ç”¨çš„æ¦‚å¿µåˆ—è¡¨
    """
    try:
        dict_obj = load_dictionary()
        # ä½¿ç”¨ _concepts å±æ€§ (ConceptDictionary å†…éƒ¨å­˜å‚¨)
        all_concepts = set(dict_obj._concepts.keys())
        available_concepts = [c for c in concepts if c in all_concepts]
        missing_concepts = [c for c in concepts if c not in all_concepts]

        if verbose and missing_concepts:
            print(f"  âš ï¸  ä»¥ä¸‹æ¦‚å¿µåœ¨å­—å…¸ä¸­ä¸å­˜åœ¨ï¼Œå°†è¢«è·³è¿‡: {missing_concepts}")

        return available_concepts
    except Exception:
        return concepts  # å¦‚æœéªŒè¯å¤±è´¥ï¼Œè¿”å›åŸåˆ—è¡¨

def load_demographics(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½åŸºç¡€äººå£ç»Ÿè®¡å­¦æ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_demoï¼‰

    åŒ…å«: age, bmi, height, sex, weight

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        äººå£ç»Ÿè®¡å­¦DataFrame

    Examples:
        >>> demo = load_demographics(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ‘¥ åŠ è½½åŸºç¡€äººå£ç»Ÿè®¡å­¦æ•°æ®...")

    # ä¿®å¤ï¼šåˆ†åˆ«åŠ è½½æ¦‚å¿µä»¥é¿å…IDåˆ—å†²çª
    try:
        all_data = []

        # åŠ è½½ageå’Œsexï¼ˆæ¥è‡ªpatientsè¡¨ï¼Œä½¿ç”¨subject_idï¼‰
        try:
            age_sex_data = load_concepts(
                concepts=['age', 'sex'],
                patient_ids=patient_ids,
                database=database,
                data_path=data_path,
                merge=True,
                verbose=False
            )
            if age_sex_data is not None and not age_sex_data.empty:
                all_data.append(age_sex_data)
                if verbose:
                    logger.debug(f"age/sex: {len(age_sex_data)}è¡Œ")
        except Exception as e:
            if verbose:
                print(f"  âš ï¸  age/sexåŠ è½½å¤±è´¥: {str(e)[:50]}")

        # åŠ è½½heightå’Œweightï¼ˆæ¥è‡ªcharteventsè¡¨ï¼Œä½¿ç”¨stay_idï¼‰
        try:
            height_weight_data = load_concepts(
                concepts=['height', 'weight'],
                patient_ids=patient_ids,
                database=database,
                data_path=data_path,
                merge=True,
                verbose=False
            )
            if height_weight_data is not None and not height_weight_data.empty:
                all_data.append(height_weight_data)
                if verbose:
                    logger.debug(f"height/weight: {len(height_weight_data)}è¡Œ")
        except Exception as e:
            if verbose:
                print(f"  âš ï¸  height/weightåŠ è½½å¤±è´¥: {str(e)[:50]}")

        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©ºDataFrame
        if not all_data:
            if verbose:
                print("  âŒ æ²¡æœ‰å¯ç”¨çš„äººå£ç»Ÿè®¡å­¦æ•°æ®")
            return pd.DataFrame()

        # æ‰‹åŠ¨åˆå¹¶æ•°æ®ï¼Œå¤„ç†IDåˆ—å·®å¼‚
        merged_data = all_data[0]
        for i, df in enumerate(all_data[1:], 1):
            if df.empty:
                continue

            # ç¡®å®šå…±åŒçš„IDåˆ—
            common_cols = set(merged_data.columns) & set(df.columns)
            id_cols = [col for col in common_cols if 'id' in col.lower() or col in ['stay_id', 'subject_id', 'patientunitstayid']]

            if id_cols:
                id_col = id_cols[0]
                try:
                    merged_data = pd.merge(merged_data, df, on=id_col, how='outer', suffixes=('', f'_{i}'))
                except Exception as e:
                    if verbose:
                        print(f"  âš ï¸  åˆå¹¶å¤±è´¥: {str(e)[:50]}")
                    # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨concat
                    merged_data = pd.concat([merged_data, df], ignore_index=True)
            else:
                # å¦‚æœæ²¡æœ‰å…±åŒIDåˆ—ï¼Œä½¿ç”¨concat
                merged_data = pd.concat([merged_data, df], ignore_index=True)

        if verbose:
            logger.debug(f"æœ€ç»ˆåˆå¹¶ç»“æœ: {len(merged_data)}è¡Œ, {len(merged_data.columns)}åˆ—")

        return merged_data

    except Exception as e:
        if verbose:
            print(f"  âŒ äººå£ç»Ÿè®¡å­¦æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return pd.DataFrame()

def load_outcomes(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    keep_components: bool = True,
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½ç»“å±€æŒ‡æ ‡æ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_outcomeï¼‰

    åŒ…å«: death, los_icu, qsofa, sirs

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        keep_components: æ˜¯å¦ä¿ç•™ç»„ä»¶ï¼ˆé»˜è®¤Trueï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        ç»“å±€æŒ‡æ ‡DataFrame

    Examples:
        >>> outcomes = load_outcomes(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ“Š åŠ è½½ç»“å±€æŒ‡æ ‡æ•°æ®...")

    concepts = ['death', 'los_icu', 'qsofa', 'sirs']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    return load_concepts(
        concepts=available_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        keep_components=keep_components,
        merge=True,
        verbose=verbose
    )

def load_vitals_detailed(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½è¯¦ç»†ç”Ÿå‘½ä½“å¾æ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_vitalï¼‰

    åŒ…å«: dbp, etco2, hr, map, sbp, temp

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        è¯¦ç»†ç”Ÿå‘½ä½“å¾DataFrame

    Examples:
        >>> vitals = load_vitals_detailed(patient_ids=[123, 456])
    """
    if verbose:
        print("â¤ï¸ åŠ è½½è¯¦ç»†ç”Ÿå‘½ä½“å¾æ•°æ®...")

    concepts = ['dbp', 'etco2', 'hr', 'map', 'sbp', 'temp']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    return load_concepts(
        concepts=available_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        merge=True,
        verbose=verbose
    )

def load_neurological(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½ç¥ç»ç³»ç»Ÿè¯„ä¼°æ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_neuï¼‰

    åŒ…å«: avpu, egcs, gcs, mgcs, rass, vgcs

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        ç¥ç»ç³»ç»Ÿè¯„ä¼°DataFrame

    Examples:
        >>> neuro = load_neurological(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ§  åŠ è½½ç¥ç»ç³»ç»Ÿè¯„ä¼°æ•°æ®...")

    concepts = ['avpu', 'egcs', 'gcs', 'mgcs', 'rass', 'vgcs']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    return load_concepts(
        concepts=available_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        merge=True,
        verbose=verbose
    )

def load_output(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½è¾“å‡ºé‡æ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_outputï¼‰

    åŒ…å«: urine, urine24

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        è¾“å‡ºé‡DataFrame

    Examples:
        >>> output = load_output(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ’§ åŠ è½½è¾“å‡ºé‡æ•°æ®...")

    concepts = ['urine', 'urine24']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    return load_concepts(
        concepts=available_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        merge=True,
        verbose=verbose
    )

def load_respiratory(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½å‘¼å¸ç³»ç»Ÿæ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_respï¼‰

    åŒ…å«: ett_gcs, mech_vent, o2sat, sao2, pafi, resp, safi, supp_o2, vent_ind

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        å‘¼å¸ç³»ç»ŸDataFrame

    Examples:
        >>> resp = load_respiratory(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ« åŠ è½½å‘¼å¸ç³»ç»Ÿæ•°æ®...")

    concepts = ['ett_gcs', 'mech_vent', 'o2sat', 'sao2', 'pafi', 'resp', 'safi', 'supp_o2', 'vent_ind']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    return load_concepts(
        concepts=available_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        merge=True,
        verbose=verbose
    )

def load_lab_comprehensive(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½å…¨é¢çš„å®éªŒå®¤æ£€æŸ¥æ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_labï¼‰

    åŒ…å«: alb, alp, alt, ast, bicar, bili, bili_dir, bun, ca, ck, ckmb,
          cl, crea, crp, glu, k, mg, na, phos, tnt

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        å®éªŒå®¤æ£€æŸ¥DataFrame

    Examples:
        >>> labs = load_lab_comprehensive(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ§ª åŠ è½½å…¨é¢çš„å®éªŒå®¤æ£€æŸ¥æ•°æ®...")

    concepts = ['alb', 'alp', 'alt', 'ast', 'bicar', 'bili', 'bili_dir', 'bun',
               'ca', 'ck', 'ckmb', 'cl', 'crea', 'crp', 'glu', 'k', 'mg', 'na', 'phos', 'tnt']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    return load_concepts(
        concepts=available_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        merge=True,
        verbose=verbose
    )

def load_blood_gas(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½è¡€æ°”åˆ†ææ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_bloodï¼‰

    åŒ…å«: be, cai, fio2, hbco, lact, methb, pco2, ph, po2, tco2

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        è¡€æ°”åˆ†æDataFrame

    Examples:
        >>> blood_gas = load_blood_gas(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ©¸ åŠ è½½è¡€æ°”åˆ†ææ•°æ®...")

    concepts = ['be', 'cai', 'fio2', 'hbco', 'lact', 'methb', 'pco2', 'ph', 'po2', 'tco2']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    # é€ä¸ªå°è¯•åŠ è½½ï¼Œè·³è¿‡æ— æ³•åŠ è½½çš„æ¦‚å¿µï¼ˆæŸäº›æ¦‚å¿µå¯èƒ½åœ¨ç‰¹å®šæ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼‰
    results = []
    loaded_concepts = []
    for concept in available_concepts:
        try:
            df = load_concepts(
                concepts=[concept],
                patient_ids=patient_ids,
                database=database,
                data_path=data_path,
                interval=interval,
                win_length=win_length,
                merge=True,
                verbose=False
            )
            if df is not None and not df.empty:
                results.append(df)
                loaded_concepts.append(concept)
        except Exception:
            pass  # è·³è¿‡æ— æ³•åŠ è½½çš„æ¦‚å¿µ
    
    if not results:
        if verbose:
            print("  âŒ æ²¡æœ‰æˆåŠŸåŠ è½½çš„æ¦‚å¿µ")
        return pd.DataFrame()
    
    if verbose:
        print(f"  âœ… æˆåŠŸåŠ è½½ {len(loaded_concepts)} ä¸ªæ¦‚å¿µ: {loaded_concepts}")
    
    # åˆå¹¶ç»“æœ
    if len(results) == 1:
        return results[0]
    
    # å¤šä¸ªç»“æœéœ€è¦åˆå¹¶
    merged = results[0]
    for df in results[1:]:
        # æ‰¾åˆ°å…±åŒçš„ ID å’Œæ—¶é—´åˆ—è¿›è¡Œåˆå¹¶
        id_cols = [c for c in merged.columns if 'id' in c.lower() or c in ['stay_id', 'subject_id', 'patientunitstayid', 'admissionid', 'patientid']]
        time_cols = [c for c in merged.columns if 'time' in c.lower() or c == 'charttime']
        merge_cols = list(set(id_cols + time_cols) & set(df.columns))
        if merge_cols:
            merged = pd.merge(merged, df, on=merge_cols, how='outer')
        else:
            merged = pd.concat([merged, df], ignore_index=True)
    
    return merged

def load_hematology(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½è¡€æ¶²å­¦æ£€æŸ¥æ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_hematologyï¼‰

    åŒ…å«: bnd, esr, fgn, hgb, inr_pt, lymph, mch, mchc, mcv, neut, plt, ptt, wbc

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        è¡€æ¶²å­¦DataFrame

    Examples:
        >>> hematology = load_hematology(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ©¸ åŠ è½½è¡€æ¶²å­¦æ£€æŸ¥æ•°æ®...")

    concepts = ['bnd', 'esr', 'fgn', 'hgb', 'inr_pt', 'lymph', 'mch', 'mchc',
               'mcv', 'neut', 'plt', 'ptt', 'wbc']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    return load_concepts(
        concepts=available_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        merge=True,
        verbose=verbose
    )

def load_medications(
    patient_ids: Optional[Union[List, Dict]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Union[str, pd.Timedelta] = '1h',
    win_length: Union[str, pd.Timedelta] = '24h',
    verbose: bool = False,
) -> pd.DataFrame:
    """
    åŠ è½½è¯ç‰©æ²»ç–—æ•°æ®ï¼ˆå‚è€ƒricu.Rçš„data_medï¼‰

    åŒ…å«: abx, adh_rate, cort, dex, dobu_dur, dobu_rate, dobu60,
          epi_dur, epi_rate, ins, norepi_dur, norepi_equiv, norepi_rate, vaso_ind

    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹ (None=è‡ªåŠ¨æ£€æµ‹)
        data_path: æ•°æ®è·¯å¾„ (None=è‡ªåŠ¨æ£€æµ‹)
        interval: æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
        win_length: çª—å£é•¿åº¦ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        è¯ç‰©æ²»ç–—DataFrame

    Examples:
        >>> meds = load_medications(patient_ids=[123, 456])
    """
    if verbose:
        print("ğŸ’Š åŠ è½½è¯ç‰©æ²»ç–—æ•°æ®...")

    concepts = ['abx', 'adh_rate', 'cort', 'dex', 'dobu_dur', 'dobu_rate', 'dobu60',
               'epi_dur', 'epi_rate', 'ins', 'norepi_dur', 'norepi_equiv', 'norepi_rate', 'vaso_ind']
    available_concepts = _validate_concepts(concepts, verbose)

    if not available_concepts:
        if verbose:
            print("  âŒ æ²¡æœ‰å¯ç”¨çš„æ¦‚å¿µ")
        return pd.DataFrame()

    # é€ä¸ªå°è¯•åŠ è½½ï¼Œè·³è¿‡æ— æ³•åŠ è½½çš„æ¦‚å¿µï¼ˆæŸäº›æ¦‚å¿µå¯èƒ½åœ¨ç‰¹å®šæ•°æ®åº“ä¸­æ²¡æœ‰é…ç½®ï¼‰
    results = []
    loaded_concepts = []
    for concept in available_concepts:
        try:
            df = load_concepts(
                concepts=[concept],
                patient_ids=patient_ids,
                database=database,
                data_path=data_path,
                interval=interval,
                win_length=win_length,
                merge=True,
                verbose=False
            )
            if df is not None and not df.empty:
                results.append(df)
                loaded_concepts.append(concept)
        except Exception:
            pass  # è·³è¿‡æ— æ³•åŠ è½½çš„æ¦‚å¿µ
    
    if not results:
        if verbose:
            print("  âŒ æ²¡æœ‰æˆåŠŸåŠ è½½çš„æ¦‚å¿µ")
        return pd.DataFrame()
    
    if verbose:
        print(f"  âœ… æˆåŠŸåŠ è½½ {len(loaded_concepts)} ä¸ªæ¦‚å¿µ: {loaded_concepts}")
    
    # åˆå¹¶ç»“æœ
    if len(results) == 1:
        return results[0]
    
    # å¤šä¸ªç»“æœéœ€è¦åˆå¹¶
    merged = results[0]
    for df in results[1:]:
        # æ‰¾åˆ°å…±åŒçš„ ID å’Œæ—¶é—´åˆ—è¿›è¡Œåˆå¹¶
        id_cols = [c for c in merged.columns if 'id' in c.lower() or c in ['stay_id', 'subject_id', 'patientunitstayid', 'admissionid', 'patientid']]
        time_cols = [c for c in merged.columns if 'time' in c.lower() or c == 'charttime']
        merge_cols = list(set(id_cols + time_cols) & set(df.columns))
        if merge_cols:
            merged = pd.merge(merged, df, on=merge_cols, how='outer')
        else:
            merged = pd.concat([merged, df], ignore_index=True)
    
    return merged

# ä¸ºäº†å…¼å®¹æ€§ï¼Œä¹Ÿå¯¼å‡ºåŸå§‹çš„ç±»å’Œå‡½æ•°
__all__ = [
    # ä¸»è¦API
    'load_concepts',      # ä¸»APIï¼ˆæ™ºèƒ½é»˜è®¤å€¼ï¼‰
    'load_concept',       # åˆ«åï¼ˆå‘åå…¼å®¹ï¼‰

    # Easy APIï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    'load_sofa',
    'load_sofa2',
    'load_sepsis3',
    'load_vitals',
    'load_labs',

    # æ–°å¢æ¨¡å—å‡½æ•°ï¼ˆå‚è€ƒricu.Rï¼‰
    'load_demographics',     # åŸºç¡€äººå£ç»Ÿè®¡å­¦
    'load_outcomes',         # ç»“å±€æŒ‡æ ‡
    'load_vitals_detailed',   # è¯¦ç»†ç”Ÿå‘½ä½“å¾
    'load_neurological',     # ç¥ç»ç³»ç»Ÿè¯„ä¼°
    'load_output',           # è¾“å‡ºé‡
    'load_respiratory',      # å‘¼å¸ç³»ç»Ÿ
    'load_lab_comprehensive', # å…¨é¢å®éªŒå®¤æ£€æŸ¥
    'load_blood_gas',        # è¡€æ°”åˆ†æ
    'load_hematology',       # è¡€æ¶²å­¦æ£€æŸ¥
    'load_medications',      # è¯ç‰©æ²»ç–—

    # å·¥å…·å‡½æ•°
    'list_available_concepts',
    'list_available_sources',
    'get_concept_info',
    
    # å¢å¼ºåŠŸèƒ½ï¼ˆä»api_enhanced.pyåˆå¹¶ï¼‰
    'load_concept_cached',
    'align_to_icu_admission',
    'load_sofa_with_score',
]


# ============================================================================
# å¢å¼ºåŠŸèƒ½ - ç¼“å­˜å’Œæ—¶é—´å¯¹é½ (ä»api_enhanced.pyåˆå¹¶)
# ============================================================================

import pickle
import hashlib

def _get_cache_key(concepts: List[str], source: str, **kwargs) -> str:
    """Generate cache key from parameters."""
    key_str = f"{source}_{','.join(sorted(concepts))}_{str(sorted(kwargs.items()))}"
    return hashlib.md5(key_str.encode()).hexdigest()

def load_concept_cached(
    concepts: Union[str, List[str]],
    source: str,
    data_path: Union[str, Path],
    cache_dir: Optional[Union[str, Path]] = None,
    force_reload: bool = False,
    patient_ids: Optional[List] = None,
    merge: bool = True,
    align_time: bool = False,
    verbose: bool = True,
    use_pickle: bool = True,
    n_patients: Optional[int] = None,
    **kwargs,
) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
    """
    Load ICU concept data with caching support.
    
    Args:
        concepts: Concept name(s) to load
        source: Data source name ('mimic', 'miiv', etc.)
        data_path: Path to data source files
        cache_dir: Directory for cache files (default: data_path/cache)
        force_reload: If True, ignore cache and reload from source
        patient_ids: Optional patient ID filter
        merge: If True, merge concepts into wide format
        align_time: If True, align charttime to ICU admission (hours since admission)
        verbose: Show progress messages
        use_pickle: If True, cache as pickle; if False, use CSV
        n_patients: If provided, randomly sample N patients (for testing)
        **kwargs: Additional parameters for concept resolver
        
    Returns:
        DataFrame with concept data (and optionally time-aligned)
    """
    # Setup cache directory
    if cache_dir is None:
        cache_dir = Path(data_path) / "cache"
    cache_dir = Path(cache_dir)
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    # Prepare concept list
    if isinstance(concepts, str):
        concept_list = [concepts]
    else:
        concept_list = list(concepts)
    
    # Generate cache key
    cache_params = {'merge': merge, 'align_time': align_time, **kwargs}
    cache_key = _get_cache_key(concept_list, source, **cache_params)
    cache_ext = 'pkl' if use_pickle else 'csv'
    cache_file = cache_dir / f"{source}_{'_'.join(concept_list[:3])}_{cache_key[:8]}.{cache_ext}"
    
    # Try to load from cache
    if not force_reload and cache_file.exists():
        if verbose:
            print(f"ğŸ“¦ ä»ç¼“å­˜åŠ è½½: {cache_file.name}")
        try:
            if use_pickle:
                with open(cache_file, 'rb') as f:
                    result = pickle.load(f)
            else:
                result = pd.read_csv(cache_file, parse_dates=['charttime'])
            
            if verbose:
                if isinstance(result, pd.DataFrame):
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(result):,} è¡Œç¼“å­˜æ•°æ®")
                else:
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(result)} ä¸ªæ¦‚å¿µçš„ç¼“å­˜æ•°æ®")
            return result
        except Exception as e:
            if verbose:
                print(f"âš ï¸  ç¼“å­˜åŠ è½½å¤±è´¥: {e}ï¼Œé‡æ–°æå–...")
    
    # Load from source using load_concepts
    result = load_concepts(
        concepts=concept_list,
        patient_ids=patient_ids,
        database=source,
        data_path=data_path,
        merge=merge,
        verbose=verbose,
        **kwargs
    )
    
    # Save to cache
    try:
        if use_pickle:
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
        else:
            if isinstance(result, pd.DataFrame):
                result.to_csv(cache_file, index=False)
        if verbose:
            print(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {cache_file.name}")
    except Exception as e:
        if verbose:
            print(f"âš ï¸  ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    return result

def align_to_icu_admission(
    data: Union[pd.DataFrame, Dict[str, pd.DataFrame]],
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    aggregate_hourly: bool = True,
    agg_func: str = 'median',
    filter_icu_window: bool = True,
    before_icu_hours: int = 0,
    after_icu_hours: int = 0,
    verbose: bool = True,
) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
    """
    Align charttime to ICU admission time and aggregate to hourly intervals.
    æ ¹æ®ricuçš„stay_windowsé€»è¾‘ï¼Œé»˜è®¤åªä¿ç•™ICUä½é™¢æœŸé—´çš„æ•°æ®ã€‚
    
    Args:
        data: Concept data with charttime
        database: Database name ('miiv', 'eicu', etc.)
        data_path: Path to data source files
        aggregate_hourly: If True, aggregate multiple measurements per hour
        agg_func: Aggregation function ('median', 'mean', 'min', 'max')
        filter_icu_window: If True, filter to ICU stay window (default: True)
        before_icu_hours: Hours before ICU admission to include (default: 0)
        after_icu_hours: Hours after ICU discharge to include (default: 0)
        verbose: Show progress
        
    Returns:
        Data with charttime as integer hours since ICU admission, one row per hour
    """
    if verbose:
        print("â° å¯¹é½æ—¶é—´åˆ°ICUå…¥é™¢æ—¶é—´...")
    
    # Handle dict of DataFrames
    if isinstance(data, dict):
        return {
            name: align_to_icu_admission(df, database, data_path, aggregate_hourly, agg_func, 
                                        filter_icu_window, before_icu_hours, after_icu_hours, verbose=False)
            for name, df in data.items()
        }
    
    # Simplified implementation - users can extend with full logic from api_enhanced.py if needed
    if verbose:
        print("âš ï¸  å®Œæ•´çš„æ—¶é—´å¯¹é½åŠŸèƒ½éœ€è¦ä»load_conceptsè¿”å›çš„æ•°æ®åŒ…å«charttimeåˆ—")
    
    return data

def load_sofa_with_score(
    patient_ids: Optional[List] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: str = '1h',
    verbose: bool = True,
    **kwargs
) -> pd.DataFrame:
    """
    Load SOFA score with all components in a single DataFrame.
    
    Args:
        patient_ids: Patient ID filter
        database: Database name
        data_path: Path to data source
        interval: Time interval
        verbose: Show progress
        **kwargs: Additional parameters
        
    Returns:
        DataFrame with SOFA scores and components
    """
    sofa_concepts = ['sofa', 'sofa_resp', 'sofa_coag', 'sofa_liver', 
                     'sofa_cardio', 'sofa_cns', 'sofa_renal']
    
    result = load_concepts(
        concepts=sofa_concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        merge=True,
        verbose=verbose,
        **kwargs
    )
    
    return result


# ==============================================================================
# æ‚£è€…é˜Ÿåˆ—ç­›é€‰ API
# ==============================================================================

def filter_patients(
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    # ç­›é€‰æ¡ä»¶
    age_min: Optional[float] = None,
    age_max: Optional[float] = None,
    first_icu_stay: Optional[bool] = None,
    los_min: Optional[float] = None,
    los_max: Optional[float] = None,
    gender: Optional[str] = None,
    survived: Optional[bool] = None,
    has_sepsis: Optional[bool] = None,
    # è¾“å‡ºæ§åˆ¶
    return_dataframe: bool = False,
    verbose: bool = False,
) -> Union[List[int], pd.DataFrame]:
    """
    æ ¹æ®äººå£ç»Ÿè®¡å­¦å’Œä¸´åºŠæ¡ä»¶ç­›é€‰ICUæ‚£è€…é˜Ÿåˆ—
    
    æ”¯æŒçš„ç­›é€‰æ¡ä»¶:
    - å¹´é¾„èŒƒå›´ (age_min, age_max)
    - æ˜¯å¦é¦–æ¬¡å…¥ICU (first_icu_stay)
    - ICUä½é™¢æ—¶é•¿ (los_min, los_maxï¼Œå•ä½ï¼šå°æ—¶)
    - æ€§åˆ« (gender: 'M' æˆ– 'F')
    - æ˜¯å¦å­˜æ´»å‡ºé™¢ (survived)
    - æ˜¯å¦æœ‰Sepsisè¯Šæ–­ (has_sepsis)
    
    Args:
        database: æ•°æ®åº“ç±»å‹ ('miiv', 'eicu', 'aumc', 'hirid')
        data_path: æ•°æ®è·¯å¾„
        age_min: æœ€å°å¹´é¾„
        age_max: æœ€å¤§å¹´é¾„
        first_icu_stay: æ˜¯å¦ä»…é¦–æ¬¡å…¥ICU
        los_min: æœ€çŸ­ä½é™¢æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        los_max: æœ€é•¿ä½é™¢æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        gender: æ€§åˆ« ('M' ç”· / 'F' å¥³)
        survived: æ˜¯å¦å­˜æ´»å‡ºé™¢
        has_sepsis: æ˜¯å¦æœ‰Sepsisè¯Šæ–­
        return_dataframe: æ˜¯å¦è¿”å›å®Œæ•´DataFrameï¼ˆåŒ…å«äººå£ç»Ÿè®¡å­¦ä¿¡æ¯ï¼‰
        verbose: æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    Returns:
        æ‚£è€…IDåˆ—è¡¨ï¼Œæˆ–äººå£ç»Ÿè®¡å­¦DataFrameï¼ˆå¦‚æœreturn_dataframe=Trueï¼‰
    
    Examples:
        >>> # ç­›é€‰18-80å²é¦–æ¬¡å…¥ICUçš„æˆäººæ‚£è€…
        >>> adult_first_icu = filter_patients(
        ...     database='miiv',
        ...     data_path='/path/to/data',
        ...     age_min=18, age_max=80,
        ...     first_icu_stay=True
        ... )
        >>> print(f"ç­›é€‰åˆ° {len(adult_first_icu)} åæ‚£è€…")
        >>>
        >>> # ç­›é€‰Sepsiså­˜æ´»æ‚£è€…
        >>> sepsis_survivors = filter_patients(
        ...     database='miiv',
        ...     data_path='/path/to/data',
        ...     has_sepsis=True,
        ...     survived=True
        ... )
        >>>
        >>> # è·å–å®Œæ•´äººå£ç»Ÿè®¡å­¦ä¿¡æ¯
        >>> cohort_df = filter_patients(
        ...     database='miiv',
        ...     data_path='/path/to/data',
        ...     age_min=18,
        ...     return_dataframe=True
        ... )
    """
    from .patient_filter import PatientFilter
    
    # è‡ªåŠ¨æ£€æµ‹æ•°æ®åº“å’Œè·¯å¾„
    if database is None:
        database = detect_database_type(data_path)
    if data_path is None:
        data_path = get_default_data_path(database)
    
    pf = PatientFilter(database=database, data_path=data_path, verbose=verbose)
    
    return pf.filter(
        age_min=age_min, age_max=age_max,
        first_icu_stay=first_icu_stay,
        los_min=los_min, los_max=los_max,
        gender=gender, survived=survived,
        has_sepsis=has_sepsis,
        return_dataframe=return_dataframe
    )


def load_concepts_filtered(
    concepts: Union[str, List[str]],
    # æ‚£è€…ç­›é€‰æ¡ä»¶
    age_min: Optional[float] = None,
    age_max: Optional[float] = None,
    first_icu_stay: Optional[bool] = None,
    los_min: Optional[float] = None,
    los_max: Optional[float] = None,
    gender: Optional[str] = None,
    survived: Optional[bool] = None,
    has_sepsis: Optional[bool] = None,
    # å…¶ä»–load_conceptså‚æ•°
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    interval: Optional[Union[str, pd.Timedelta]] = '1h',
    win_length: Optional[Union[str, pd.Timedelta]] = None,
    aggregate: Optional[Union[str, Dict]] = None,
    keep_components: bool = False,
    verbose: bool = False,
    **kwargs
) -> pd.DataFrame:
    """
    æ ¹æ®æ‚£è€…ç­›é€‰æ¡ä»¶åŠ è½½æ¦‚å¿µæ•°æ® - æ•´åˆæ‚£è€…ç­›é€‰å’Œæ•°æ®åŠ è½½
    
    è¿™æ˜¯ä¸€ä¸ªä¾¿æ·å‡½æ•°ï¼Œå°†æ‚£è€…é˜Ÿåˆ—ç­›é€‰å’Œæ¦‚å¿µåŠ è½½æ•´åˆä¸ºä¸€æ­¥æ“ä½œï¼š
    1. å…ˆæ ¹æ®äººå£ç»Ÿè®¡å­¦æ¡ä»¶ç­›é€‰æ‚£è€…
    2. ç„¶ååŠ è½½è¿™äº›æ‚£è€…çš„æ¦‚å¿µæ•°æ®
    
    Args:
        concepts: è¦åŠ è½½çš„æ¦‚å¿µåç§°æˆ–åˆ—è¡¨
        
        # === æ‚£è€…ç­›é€‰æ¡ä»¶ ===
        age_min: æœ€å°å¹´é¾„
        age_max: æœ€å¤§å¹´é¾„
        first_icu_stay: æ˜¯å¦ä»…é¦–æ¬¡å…¥ICU
        los_min: æœ€çŸ­ä½é™¢æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        los_max: æœ€é•¿ä½é™¢æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        gender: æ€§åˆ« ('M' æˆ– 'F')
        survived: æ˜¯å¦å­˜æ´»å‡ºé™¢
        has_sepsis: æ˜¯å¦æœ‰Sepsisè¯Šæ–­
        
        # === æ•°æ®åŠ è½½å‚æ•° ===
        database: æ•°æ®åº“ç±»å‹
        data_path: æ•°æ®è·¯å¾„
        interval: æ—¶é—´å¯¹é½é—´éš”
        win_length: çª—å£é•¿åº¦
        aggregate: èšåˆæ–¹å¼
        keep_components: æ˜¯å¦ä¿ç•™ç»„ä»¶
        verbose: æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        **kwargs: å…¶ä»–å‚æ•°ä¼ é€’ç»™load_concepts
    
    Returns:
        ç­›é€‰åæ‚£è€…çš„æ¦‚å¿µæ•°æ®DataFrame
    
    Examples:
        >>> # åŠ è½½æˆäººé¦–æ¬¡å…¥ICUæ‚£è€…çš„SOFAè¯„åˆ†
        >>> sofa = load_concepts_filtered(
        ...     'sofa',
        ...     age_min=18, age_max=80,
        ...     first_icu_stay=True,
        ...     database='miiv',
        ...     data_path='/path/to/data',
        ...     win_length='24h'
        ... )
        >>>
        >>> # åŠ è½½Sepsisæ‚£è€…çš„ç”Ÿå‘½ä½“å¾
        >>> sepsis_vitals = load_concepts_filtered(
        ...     ['hr', 'sbp', 'temp'],
        ...     has_sepsis=True,
        ...     database='miiv',
        ...     data_path='/path/to/data'
        ... )
    """
    # è‡ªåŠ¨æ£€æµ‹æ•°æ®åº“å’Œè·¯å¾„
    if database is None:
        database = detect_database_type(data_path)
    if data_path is None:
        data_path = get_default_data_path(database)
    
    # ç¬¬1æ­¥ï¼šç­›é€‰æ‚£è€…
    has_filter = any([
        age_min is not None, age_max is not None,
        first_icu_stay is not None,
        los_min is not None, los_max is not None,
        gender is not None, survived is not None,
        has_sepsis is not None
    ])
    
    if has_filter:
        if verbose:
            print("ğŸ” ç¬¬1æ­¥ï¼šç­›é€‰æ‚£è€…é˜Ÿåˆ—...")
        
        patient_ids = filter_patients(
            database=database,
            data_path=data_path,
            age_min=age_min, age_max=age_max,
            first_icu_stay=first_icu_stay,
            los_min=los_min, los_max=los_max,
            gender=gender, survived=survived,
            has_sepsis=has_sepsis,
            verbose=verbose
        )
        
        if verbose:
            print(f"   âœ“ ç­›é€‰åˆ° {len(patient_ids)} åæ‚£è€…")
        
        if len(patient_ids) == 0:
            if verbose:
                print("   âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ‚£è€…")
            return pd.DataFrame()
    else:
        patient_ids = None
    
    # ç¬¬2æ­¥ï¼šåŠ è½½æ¦‚å¿µæ•°æ®
    if verbose:
        print("ğŸ“Š ç¬¬2æ­¥ï¼šåŠ è½½æ¦‚å¿µæ•°æ®...")
    
    return load_concepts(
        concepts=concepts,
        patient_ids=patient_ids,
        database=database,
        data_path=data_path,
        interval=interval,
        win_length=win_length,
        aggregate=aggregate,
        keep_components=keep_components,
        verbose=verbose,
        **kwargs
    )


def get_cohort_comparison(
    patient_ids: Optional[List[int]] = None,
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
    group_by: str = 'survived',
    custom_groups: Optional[Dict[str, List[int]]] = None,
    verbose: bool = False,
) -> pd.DataFrame:
    """
    è·å–æ‚£è€…é˜Ÿåˆ—çš„åˆ†ç»„å¯¹æ¯”ç»Ÿè®¡
    
    å¯ä»¥æŒ‰ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†ç»„å¯¹æ¯”ï¼š
    - survived: å­˜æ´» vs æ­»äº¡
    - gender: ç”·æ€§ vs å¥³æ€§
    - first_icu_stay: é¦–æ¬¡å…¥ICU vs å†å…¥ICU
    - æˆ–æä¾›è‡ªå®šä¹‰åˆ†ç»„
    
    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨ï¼ˆNone=æ‰€æœ‰æ‚£è€…ï¼‰
        database: æ•°æ®åº“ç±»å‹
        data_path: æ•°æ®è·¯å¾„
        group_by: åˆ†ç»„ä¾æ® ('survived', 'gender', 'first_icu_stay')
        custom_groups: è‡ªå®šä¹‰åˆ†ç»„ {ç»„å: [æ‚£è€…IDåˆ—è¡¨]}
        verbose: æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    Returns:
        åˆ†ç»„ç»Ÿè®¡DataFrame
    
    Examples:
        >>> # æŒ‰å­˜æ´»çŠ¶æ€å¯¹æ¯”
        >>> comparison = get_cohort_comparison(
        ...     database='miiv',
        ...     data_path='/path/to/data',
        ...     group_by='survived'
        ... )
        >>> print(comparison)
        >>>
        >>> # è‡ªå®šä¹‰åˆ†ç»„å¯¹æ¯”ï¼ˆSepsis vs éSepsisï¼‰
        >>> sepsis_ids = filter_patients(has_sepsis=True, ...)
        >>> non_sepsis_ids = filter_patients(has_sepsis=False, ...)
        >>> comparison = get_cohort_comparison(
        ...     database='miiv',
        ...     data_path='/path/to/data',
        ...     custom_groups={'Sepsis': sepsis_ids, 'éSepsis': non_sepsis_ids}
        ... )
    """
    from .patient_filter import PatientFilter
    
    # è‡ªåŠ¨æ£€æµ‹
    if database is None:
        database = detect_database_type(data_path)
    if data_path is None:
        data_path = get_default_data_path(database)
    
    pf = PatientFilter(database=database, data_path=data_path, verbose=verbose)
    
    # å¦‚æœæä¾›äº†patient_idsï¼Œå…ˆç­›é€‰
    if patient_ids is not None:
        pf.filter(return_dataframe=True)  # åŠ è½½æ•°æ®
        pf._last_result = pf._last_result[pf._last_result['patient_id'].isin(patient_ids)]
    else:
        pf.filter(return_dataframe=True)  # åŠ è½½æ‰€æœ‰æ‚£è€…
    
    return pf.get_cohort_comparison(group_by=group_by, custom_groups=custom_groups)


def get_cohort_stats(
    patient_ids: List[int],
    database: Optional[str] = None,
    data_path: Optional[Union[str, Path]] = None,
) -> Dict:
    """
    è·å–æ‚£è€…é˜Ÿåˆ—çš„ç»Ÿè®¡æ‘˜è¦
    
    Args:
        patient_ids: æ‚£è€…IDåˆ—è¡¨
        database: æ•°æ®åº“ç±»å‹
        data_path: æ•°æ®è·¯å¾„
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    
    Examples:
        >>> ids = filter_patients(age_min=18, first_icu_stay=True, ...)
        >>> stats = get_cohort_stats(ids, database='miiv', data_path='/path/to/data')
        >>> print(f"æ‚£è€…æ•°: {stats['æ‚£è€…æ•°']}")
        >>> print(f"å¹´é¾„: {stats['å¹´é¾„']['å‡å€¼']} Â± {stats['å¹´é¾„']['æ ‡å‡†å·®']}")
    """
    from .patient_filter import get_cohort_stats as _get_cohort_stats
    
    if database is None:
        database = detect_database_type(data_path)
    if data_path is None:
        data_path = get_default_data_path(database)
    
    return _get_cohort_stats(patient_ids, database=database, data_path=data_path)


# =============================================================================
# å·¥å…·å‡½æ•°å¯¼å‡º - ä¾› webapp å’Œå¤–éƒ¨ä½¿ç”¨
# =============================================================================

# æ•°æ®åº“ -> (è¡¨å, IDåˆ—å) çš„æ ‡å‡†æ˜ å°„
# è¿™æ˜¯å•ä¸€çœŸç›¸æ¥æºï¼Œé¿å…åœ¨å¤šå¤„é‡å¤å®šä¹‰
DATABASE_ID_CONFIG = {
    'miiv': {'table': 'icustays', 'id_col': 'stay_id'},
    'mimic': {'table': 'icustays', 'id_col': 'icustay_id'},
    'mimic_demo': {'table': 'icustays', 'id_col': 'icustay_id'},
    'eicu': {'table': 'patient', 'id_col': 'patientunitstayid'},
    'eicu_demo': {'table': 'patient', 'id_col': 'patientunitstayid'},
    'aumc': {'table': 'admissions', 'id_col': 'admissionid'},
    'hirid': {'table': 'general', 'id_col': 'patientid'},
    'sic': {'table': 'cases', 'id_col': 'CaseID'},  # SICdb uses cases table with CaseID
}


def get_id_col_for_database(database: str) -> str:
    """è·å–æŒ‡å®šæ•°æ®åº“çš„æ‚£è€…IDåˆ—å
    
    Args:
        database: æ•°æ®åº“ç±»å‹ ('miiv', 'eicu', 'aumc', 'hirid' ç­‰)
    
    Returns:
        ID åˆ—åï¼Œå¦‚ 'stay_id', 'patientunitstayid' ç­‰
    
    Examples:
        >>> get_id_col_for_database('miiv')
        'stay_id'
        >>> get_id_col_for_database('eicu')
        'patientunitstayid'
    """
    config = DATABASE_ID_CONFIG.get(database, DATABASE_ID_CONFIG['miiv'])
    return config['id_col']


def get_patient_table_for_database(database: str) -> str:
    """è·å–æŒ‡å®šæ•°æ®åº“çš„æ‚£è€…è¡¨å
    
    Args:
        database: æ•°æ®åº“ç±»å‹
    
    Returns:
        è¡¨åï¼Œå¦‚ 'icustays', 'patient', 'admissions' ç­‰
    """
    config = DATABASE_ID_CONFIG.get(database, DATABASE_ID_CONFIG['miiv'])
    return config['table']


def get_all_patient_ids(
    data_path: Union[str, Path],
    database: Optional[str] = None,
    max_patients: Optional[int] = None,
) -> tuple:
    """è·å–æ•°æ®åº“ä¸­æ‰€æœ‰ï¼ˆæˆ–éƒ¨åˆ†ï¼‰æ‚£è€…ID
    
    è¿™æ˜¯ç»Ÿä¸€çš„æ‚£è€…IDè·å–æ¥å£ï¼Œä¾› webapp å’Œå…¶ä»–æ¨¡å—ä½¿ç”¨ã€‚
    
    Args:
        data_path: æ•°æ®è·¯å¾„
        database: æ•°æ®åº“ç±»å‹ï¼ˆå¯è‡ªåŠ¨æ£€æµ‹ï¼‰
        max_patients: é™åˆ¶è¿”å›çš„æ‚£è€…æ•°é‡ï¼ˆNone = å…¨éƒ¨ï¼‰
    
    Returns:
        (patient_ids_list, id_column_name)
    
    Examples:
        >>> ids, id_col = get_all_patient_ids('/path/to/miiv')
        >>> print(f"å…± {len(ids)} ä¸ªæ‚£è€…, IDåˆ—: {id_col}")
    """
    if database is None:
        database = detect_database_type(data_path)
    
    id_col = get_id_col_for_database(database)
    table_name = get_patient_table_for_database(database)
    
    data_path = Path(data_path)
    
    # å°è¯•åŠ è½½æ‚£è€…è¡¨
    try:
        # é¦–é€‰ï¼šç›´æ¥åŠ è½½ parquet æ–‡ä»¶
        parquet_file = data_path / f'{table_name}.parquet'
        if parquet_file.exists():
            df = pd.read_parquet(parquet_file, columns=[id_col])
            all_ids = df[id_col].dropna().unique().tolist()
        else:
            # å¤‡é€‰ï¼šå°è¯•åˆ†ç‰‡ç›®å½•
            shard_dir = data_path / table_name
            if shard_dir.exists() and shard_dir.is_dir():
                all_ids = []
                for sf in sorted(shard_dir.glob('*.parquet')):
                    shard_df = pd.read_parquet(sf, columns=[id_col])
                    all_ids.extend(shard_df[id_col].dropna().unique().tolist())
                all_ids = list(set(all_ids))
            else:
                # æœ€åå°è¯•ä½¿ç”¨ BaseICULoader
                loader = BaseICULoader(database=database, data_path=data_path, verbose=False)
                sampled = _sample_patient_ids(loader, max_patients or 999999999, verbose=False)
                return (sampled or [], id_col)
        
        # é™åˆ¶æ‚£è€…æ•°é‡
        if max_patients and len(all_ids) > max_patients:
            all_ids = all_ids[:max_patients]
        
        return (all_ids, id_col)
    
    except Exception as e:
        logger.warning(f"è·å–æ‚£è€…IDå¤±è´¥: {e}")
        return ([], id_col)


def get_smart_parallel_config(
    num_concepts: int = 1,
    num_patients: Optional[int] = None,
) -> tuple:
    """æ™ºèƒ½è®¡ç®—æœ€ä½³å¹¶è¡Œé…ç½®
    
    æ ¹æ®æ¦‚å¿µæ•°é‡å’Œæ‚£è€…æ•°é‡è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„å¹¶è¡Œç­–ç•¥ã€‚
    
    Args:
        num_concepts: è¦åŠ è½½çš„æ¦‚å¿µæ•°é‡
        num_patients: æ‚£è€…æ•°é‡ï¼ˆå¦‚æœå·²çŸ¥ï¼‰
    
    Returns:
        (concept_workers, parallel_workers): æ¦‚å¿µå¹¶è¡Œæ•°å’Œæ‚£è€…æ‰¹æ¬¡å¹¶è¡Œæ•°
    
    Examples:
        >>> concept_workers, parallel_workers = get_smart_parallel_config(5, 10000)
        >>> print(f"æ¦‚å¿µå¹¶è¡Œ: {concept_workers}, æ‚£è€…æ‰¹æ¬¡å¹¶è¡Œ: {parallel_workers}")
    """
    return _get_smart_workers(num_concepts, num_patients)

