"""EasyICU Streamlit ä¸»åº”ç”¨ã€‚

æœ¬åœ° ICU æ•°æ®åˆ†æå’Œå¯è§†åŒ–å¹³å°ã€‚
"""

import streamlit as st
from pathlib import Path
import pandas as pd
import numpy as np
import os
from typing import Dict, Any, Optional, List

# ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šç¦ç”¨è‡ªåŠ¨ç¼“å­˜æ¸…é™¤ï¼Œä¿æŒè¡¨ç¼“å­˜åœ¨å¤šæ¬¡åŠ è½½é—´å¤ç”¨
os.environ['PYRICU_AUTO_CLEAR_CACHE'] = 'False'

# å°è¯•å¯¼å…¥ç¾åŒ–ç»„ä»¶
try:
    from streamlit_extras.metric_cards import style_metric_cards
    HAS_EXTRAS = True
except ImportError:
    HAS_EXTRAS = False

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="EasyICU Data Explorer",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded",
)
# åˆå§‹åŒ–ä¾§è¾¹æ å±•å¼€çŠ¶æ€
if 'sidebar_expanded' not in st.session_state:
    st.session_state.sidebar_expanded = False

# ä¾§è¾¹æ å®½åº¦è®¾ç½® - æ ¹æ®å±•å¼€çŠ¶æ€åŠ¨æ€è°ƒæ•´
sidebar_width = "100vw" if st.session_state.sidebar_expanded else "450px"
sidebar_min_width = "100vw" if st.session_state.sidebar_expanded else "380px"
main_display = "none" if st.session_state.sidebar_expanded else "block"

st.markdown(f"""
<style>
    [data-testid="stSidebar"] {{
        min-width: {sidebar_min_width};
        max-width: {sidebar_width};
        width: {sidebar_width} !important;
        transition: all 0.3s ease;
    }}
    [data-testid="stSidebar"] > div {{
        width: 100% !important;
    }}
    /* éšè—ä¾§è¾¹æ æŠ˜å æŒ‰é’® */
    [data-testid="collapsedControl"] {{
        display: none !important;
    }}
    button[kind="headerNoPadding"] {{
        display: none !important;
    }}
    [data-testid="stSidebarCollapseButton"] {{
        display: none !important;
    }}
    /* å±•å¼€æ—¶éšè—å³ä¾§ä¸»å†…å®¹ */
    [data-testid="stMain"] {{
        display: {main_display} !important;
    }}
</style>
""", unsafe_allow_html=True)

# ğŸ¨ ç°ä»£åŒ– CSS æ ·å¼ç³»ç»Ÿ
st.markdown("""
<style>
    /* ============ å…¨å±€ä¸»é¢˜å˜é‡ ============ */
    :root {
        /* ä¸»è‰²è°ƒ */
        --primary-color: #667eea;
        --primary-dark: #5a67d8;
        --secondary-color: #764ba2;
        --gradient-primary: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        --gradient-success: linear-gradient(135deg, #10b981 0%, #059669 100%);
        --gradient-info: linear-gradient(135deg, #06b6d4 0%, #0891b2 100%);
        --gradient-warning: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
        --gradient-danger: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
        
        /* åŠŸèƒ½è‰² */
        --success-color: #10b981;
        --warning-color: #f59e0b;
        --danger-color: #ef4444;
        --info-color: #06b6d4;
        
        /* é˜´å½± */
        --shadow-soft: 0 4px 20px rgba(0, 0, 0, 0.08);
        --shadow-hover: 0 8px 30px rgba(0, 0, 0, 0.12);
        --shadow-card: 0 2px 12px rgba(0, 0, 0, 0.06);
        --shadow-glow: 0 4px 15px rgba(102, 126, 234, 0.35);
        
        /* åœ†è§’ */
        --radius-sm: 8px;
        --radius-md: 12px;
        --radius-lg: 16px;
        --radius-xl: 20px;
        
        /* åŠ¨ç”» */
        --transition-smooth: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        --transition-fast: all 0.15s ease;
        
        /* æµ…è‰²ä¸»é¢˜ */
        --card-bg-light: #ffffff;
        --text-primary-light: #1e1e1e;
        --text-secondary-light: #64748b;
        --border-light: rgba(102, 126, 234, 0.1);
        
        /* æ·±è‰²ä¸»é¢˜ */
        --card-bg-dark: rgba(30, 35, 45, 0.95);
        --text-primary-dark: #e0e0e0;
        --text-secondary-dark: #94a3b8;
        --border-dark: rgba(102, 126, 234, 0.2);
    }
    
    /* ============ é¡µé¢å¤´éƒ¨ ============ */
    .block-container {
        padding-top: 0.5rem !important;
        margin-top: 0 !important;
    }
    header[data-testid="stHeader"] {
        height: 0 !important;
        min-height: 0 !important;
        visibility: hidden !important;
    }
    
    /* ============ ç°ä»£åŒ–æ ‡ç­¾é¡µ ============ */
    div[data-baseweb="tab-list"] {
        gap: 10px !important;
        margin-top: 0 !important;
        padding: 12px !important;
        background: linear-gradient(180deg, rgba(102,126,234,0.05), transparent) !important;
        border-radius: var(--radius-lg) !important;
        border: 1px solid rgba(102, 126, 234, 0.08);
    }
    
    div[data-baseweb="tab-list"] button {
        font-size: 1.15rem !important;
        font-weight: 600 !important;
        padding: 12px 24px !important;
        border-radius: var(--radius-md) !important;
        transition: var(--transition-smooth) !important;
        border: 1px solid transparent !important;
        background: transparent !important;
    }
    
    div[data-baseweb="tab-list"] button:hover {
        background: rgba(102, 126, 234, 0.1) !important;
        border-color: rgba(102, 126, 234, 0.2) !important;
    }
    
    div[data-baseweb="tab-list"] button[aria-selected="true"] {
        background: var(--gradient-primary) !important;
        color: white !important;
        box-shadow: var(--shadow-glow) !important;
        border-color: transparent !important;
    }
    
    div[data-baseweb="tab-list"] button p {
        font-size: 1.15rem !important;
        font-weight: 600 !important;
    }
    
    /* ============ Metric å¡ç‰‡ç¾åŒ– ============ */
    div[data-testid="stMetric"] {
        background: linear-gradient(145deg, rgba(255,255,255,0.98), rgba(248,250,252,0.95));
        border: 1px solid var(--border-light);
        border-radius: var(--radius-lg);
        padding: 1.2rem 1.5rem;
        box-shadow: var(--shadow-card);
        transition: var(--transition-smooth);
        position: relative;
        overflow: hidden;
    }
    
    div[data-testid="stMetric"]::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        width: 4px;
        height: 100%;
        background: var(--gradient-primary);
        border-radius: 4px 0 0 4px;
    }
    
    div[data-testid="stMetric"]:hover {
        transform: translateY(-4px);
        box-shadow: var(--shadow-hover);
        border-color: rgba(102, 126, 234, 0.25);
    }
    
    div[data-testid="stMetric"] label {
        font-weight: 600 !important;
        color: var(--text-secondary-light) !important;
        font-size: 0.85rem !important;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    div[data-testid="stMetric"] div[data-testid="stMetricValue"] {
        font-size: 1.75rem !important;
        font-weight: 700 !important;
        background: var(--gradient-primary);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    /* æ·±è‰²æ¨¡å¼ Metric */
    @media (prefers-color-scheme: dark) {
        div[data-testid="stMetric"] {
            background: linear-gradient(145deg, rgba(30,35,45,0.98), rgba(40,45,55,0.95));
            border-color: var(--border-dark);
        }
        div[data-testid="stMetric"] label {
            color: var(--text-secondary-dark) !important;
        }
    }
    
    /* ============ ä¸»æ ‡é¢˜æ ·å¼ ============ */
    .main-header {
        font-size: 2.2rem;
        font-weight: 800;
        background: var(--gradient-primary);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        margin-top: 0;
        margin-bottom: 0.5rem;
        text-align: center;
        letter-spacing: -0.5px;
    }
    
    .sub-header {
        font-size: 1.1rem;
        color: var(--text-secondary-light);
        margin-bottom: 1.5rem;
        text-align: center;
        font-weight: 400;
    }
    
    @media (prefers-color-scheme: dark) {
        .sub-header { color: var(--text-secondary-dark); }
    }
    
    /* ============ åŠŸèƒ½å¡ç‰‡ ============ */
    .metric-card, .feature-card {
        background: linear-gradient(145deg, #ffffff, #f8f9ff);
        border-radius: var(--radius-lg);
        padding: 1.4rem;
        margin: 0.5rem 0;
        box-shadow: var(--shadow-card);
        border: 1px solid var(--border-light);
        transition: var(--transition-smooth);
        color: var(--text-primary-light);
    }
    
    .metric-card:hover, .feature-card:hover {
        transform: translateY(-3px);
        box-shadow: var(--shadow-hover);
        border-color: rgba(102, 126, 234, 0.3);
    }
    
    @media (prefers-color-scheme: dark) {
        .metric-card, .feature-card {
            background: linear-gradient(145deg, rgba(40,45,60,0.95), rgba(30,35,50,0.95));
            border-color: var(--border-dark);
            color: var(--text-primary-dark);
        }
    }
    
    .feature-card h4 {
        background: var(--gradient-primary);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        margin-bottom: 0.8rem;
        font-weight: 600;
    }
    
    /* ============ æŒ‰é’®æ ·å¼ ============ */
    .stButton > button[kind="primary"] {
        background: var(--gradient-primary) !important;
        border: none !important;
        border-radius: var(--radius-md) !important;
        padding: 0.75rem 2rem !important;
        font-weight: 600 !important;
        box-shadow: var(--shadow-glow) !important;
        transition: var(--transition-smooth) !important;
    }
    
    .stButton > button[kind="primary"]:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.45) !important;
    }
    
    /* ä¾§è¾¹æ æŒ‰é’® */
    [data-testid="stSidebar"] .stButton button {
        background: var(--gradient-primary) !important;
        color: white !important;
        border: none !important;
        font-weight: 600 !important;
        border-radius: var(--radius-md) !important;
    }
    
    [data-testid="stSidebar"] .stButton button:hover {
        box-shadow: var(--shadow-glow) !important;
        transform: translateY(-1px) !important;
    }
    
    /* ============ çŠ¶æ€æç¤ºæ¡† ============ */
    .success-box {
        background: rgba(16, 185, 129, 0.12);
        border-left: 4px solid var(--success-color);
        border-radius: 0 var(--radius-sm) var(--radius-sm) 0;
        padding: 12px 16px;
        margin: 10px 0;
        color: #065f46;
    }
    
    .warning-box {
        background: rgba(245, 158, 11, 0.12);
        border-left: 4px solid var(--warning-color);
        border-radius: 0 var(--radius-sm) var(--radius-sm) 0;
        padding: 12px 16px;
        margin: 10px 0;
        color: #92400e;
    }
    
    .info-box {
        background: rgba(6, 182, 212, 0.12);
        border-left: 4px solid var(--info-color);
        border-radius: 0 var(--radius-sm) var(--radius-sm) 0;
        padding: 12px 16px;
        margin: 10px 0;
        color: #0e7490;
    }
    
    @media (prefers-color-scheme: dark) {
        .success-box { color: #6ee7b7; background: rgba(16, 185, 129, 0.15); }
        .warning-box { color: #fcd34d; background: rgba(245, 158, 11, 0.15); }
        .info-box { color: #67e8f9; background: rgba(6, 182, 212, 0.15); }
    }
    
    /* ============ åˆ†éš”çº¿ ============ */
    .divider {
        height: 2px;
        background: linear-gradient(90deg, transparent, rgba(102, 126, 234, 0.3), transparent);
        margin: 1.5rem 0;
        border: none;
    }
    
    hr {
        border: none;
        height: 2px;
        background: linear-gradient(90deg, transparent, rgba(102, 126, 234, 0.2), transparent);
        margin: 1.5rem 0;
    }
    
    /* ============ ç»Ÿè®¡æ•°å­— ============ */
    .stat-number {
        font-size: 2.5rem;
        font-weight: 700;
        background: var(--gradient-primary);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .stat-label {
        font-size: 0.9rem;
        color: var(--text-secondary-light);
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    @media (prefers-color-scheme: dark) {
        .stat-label { color: var(--text-secondary-dark); }
    }
    
    /* ============ æ‚£è€…ä¿¡æ¯å¡ç‰‡ ============ */
    .patient-card {
        background: #f8f9fa;
        border-radius: var(--radius-md);
        padding: 1.5rem;
        border: 2px solid #e2e8f0;
        margin-bottom: 1rem;
        color: var(--text-primary-light);
        transition: var(--transition-smooth);
    }
    
    .patient-card:hover {
        border-color: rgba(102, 126, 234, 0.3);
        box-shadow: var(--shadow-soft);
    }
    
    @media (prefers-color-scheme: dark) {
        .patient-card {
            background: rgba(30, 40, 50, 0.9);
            border-color: rgba(255,255,255,0.15);
            color: var(--text-primary-dark);
        }
    }
    
    .patient-card.critical { border-color: var(--danger-color); background: rgba(239, 68, 68, 0.08); }
    .patient-card.warning { border-color: var(--warning-color); background: rgba(245, 158, 11, 0.08); }
    .patient-card.stable { border-color: var(--success-color); background: rgba(16, 185, 129, 0.08); }
    
    /* ============ ä¾§è¾¹æ ç¾åŒ– ============ */
    [data-testid="stSidebar"] {
        min-width: 450px !important;
        max-width: 55000px !important;
    }
    
    [data-testid="stSidebar"] > div:first-child {
        min-width: 450px !important;
        max-width: 55000px !important;
    }
    
    /* ä¾§è¾¹æ å¤´éƒ¨è£…é¥° */
    .sidebar-header {
        background: var(--gradient-primary);
        border-radius: var(--radius-md);
        padding: 1rem 1.5rem;
        text-align: center;
        margin-bottom: 1.5rem;
        color: white;
    }
    
    .sidebar-header h3 {
        margin: 0;
        font-weight: 700;
    }
    
    /* ============ SOFA2 ç‰¹æ®Šæ ‡è¯† ============ */
    .sofa2-badge {
        background: linear-gradient(135deg, #ff6b6b, #ffa500);
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 600;
        display: inline-block;
        margin-left: 8px;
        box-shadow: 0 2px 8px rgba(255, 107, 107, 0.3);
    }
    
    /* ============ æ•°æ®è¡¨æ ¼ä¼˜åŒ– ============ */
    .dataframe {
        border-radius: var(--radius-sm) !important;
        overflow: hidden;
    }
    
    /* ============ è¿›åº¦æ¡ç¾åŒ– ============ */
    .progress-bar {
        height: 8px;
        background: #e2e8f0;
        border-radius: 4px;
        overflow: hidden;
    }
    
    .progress-bar-fill {
        height: 100%;
        background: var(--gradient-primary);
        border-radius: 4px;
        transition: width 0.3s ease;
    }
    
    /* ============ é«˜äº®å¡ç‰‡ ============ */
    .highlight-card {
        background: linear-gradient(135deg, #f0f9ff, #e0f2fe);
        border: 2px solid #0ea5e9;
        border-radius: var(--radius-md);
        padding: 1.2rem;
        margin: 1rem 0;
        color: #0c4a6e;
    }
    
    .highlight-card h4 { color: #0369a1; margin-bottom: 0.8rem; }
    .highlight-card p, .highlight-card li { color: #0e7490; }
    .highlight-card b { color: #0284c7; }
    
    @media (prefers-color-scheme: dark) {
        .highlight-card {
            background: linear-gradient(135deg, #0c4a6e, #164e63);
            border-color: #06b6d4;
            color: #e0f2fe;
        }
        .highlight-card h4 { color: #67e8f9; }
        .highlight-card p, .highlight-card li { color: #a5f3fc; }
        .highlight-card b { color: #22d3ee; }
    }
    
    /* ============ åŠ¨ç”»æ•ˆæœ ============ */
    @keyframes fadeInUp {
        from {
            opacity: 0;
            transform: translateY(20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    .animate-fade-in {
        animation: fadeInUp 0.4s ease-out;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.6; }
    }
    
    .animate-pulse {
        animation: pulse 2s infinite;
    }
    
    /* ============ Tooltip ç¾åŒ– ============ */
    [data-baseweb="tooltip"] {
        border-radius: var(--radius-sm) !important;
        box-shadow: var(--shadow-soft) !important;
    }
</style>
""", unsafe_allow_html=True)


# æ•°æ®å­—å…¸å®šä¹‰ - ç‰¹å¾ç¼©å†™åŠå…¶å«ä¹‰
CONCEPT_DICTIONARY = {
    # ç”Ÿå‘½ä½“å¾
    'hr': ('Heart Rate', 'å¿ƒç‡', 'bpm'),
    'map': ('Mean Arterial Pressure', 'å¹³å‡åŠ¨è„‰å‹', 'mmHg'),
    'sbp': ('Systolic Blood Pressure', 'æ”¶ç¼©å‹', 'mmHg'),
    'dbp': ('Diastolic Blood Pressure', 'èˆ’å¼ å‹', 'mmHg'),
    'temp': ('Temperature', 'ä½“æ¸©', 'Â°C'),
    'etco2': ('End-Tidal CO2', 'å‘¼æ°”æœ«äºŒæ°§åŒ–ç¢³', 'mmHg'),
    'resp': ('Respiratory Rate', 'å‘¼å¸é¢‘ç‡', 'breaths/min'),
    
    # å‘¼å¸ç³»ç»Ÿ
    'pafi': ('PaO2/FiO2 Ratio', 'æ°§åˆæŒ‡æ•°', 'mmHg'),
    'safi': ('SpO2/FiO2 Ratio', 'è„‰æ°§/å¸æ°§æ¯”', ''),
    'supp_o2': ('Supplemental Oxygen', 'è¾…åŠ©å¸æ°§', 'boolean'),
    'vent_ind': ('Ventilation Duration Windows', 'æœºæ¢°é€šæ°”æ—¶é—´çª—', 'boolean'),
    'o2sat': ('Oxygen Saturation (SpO2)', 'è¡€æ°§é¥±å’Œåº¦', '%'),
    'sao2': ('Arterial Oxygen Saturation', 'åŠ¨è„‰è¡€æ°§é¥±å’Œåº¦', '%'),
    'mech_vent': ('Mechanical Ventilation', 'æœºæ¢°é€šæ°”', 'boolean'),
    'ett_gcs': ('Intubation/Tracheostomy Status', 'æ°”ç®¡æ’ç®¡/åˆ‡å¼€çŠ¶æ€', 'boolean'),
    'fio2': ('Fraction of Inspired Oxygen', 'å¸å…¥æ°§æµ“åº¦', '%'),
    
    # è¡€æ°”åˆ†æ
    'be': ('Base Excess', 'ç¢±å‰©ä½™', 'mEq/L'),
    'cai': ('Ionized Calcium', 'ç¦»å­é’™', 'mmol/L'),
    'hbco': ('Carboxyhemoglobin', 'ç¢³æ°§è¡€çº¢è›‹ç™½', '%'),
    'lact': ('Lactate', 'ä¹³é…¸', 'mmol/L'),
    'methb': ('Methemoglobin', 'é«˜é“è¡€çº¢è›‹ç™½', '%'),
    'pco2': ('Partial Pressure of CO2', 'äºŒæ°§åŒ–ç¢³åˆ†å‹', 'mmHg'),
    'ph': ('Blood pH', 'è¡€æ¶²pHå€¼', ''),
    'po2': ('Partial Pressure of O2', 'æ°§åˆ†å‹', 'mmHg'),
    'tco2': ('Total CO2', 'æ€»äºŒæ°§åŒ–ç¢³', 'mEq/L'),
    
    # å®éªŒå®¤æ£€æŸ¥
    'alb': ('Albumin', 'ç™½è›‹ç™½', 'g/dL'),
    'alp': ('Alkaline Phosphatase', 'ç¢±æ€§ç£·é…¸é…¶', 'IU/L'),
    'alt': ('Alanine Aminotransferase', 'è°·ä¸™è½¬æ°¨é…¶', 'IU/L'),
    'ast': ('Aspartate Aminotransferase', 'è°·è‰è½¬æ°¨é…¶', 'IU/L'),
    'bicar': ('Bicarbonate', 'ç¢³é…¸æ°¢æ ¹', 'mEq/L'),
    'bili': ('Total Bilirubin', 'æ€»èƒ†çº¢ç´ ', 'mg/dL'),
    'bili_dir': ('Direct Bilirubin', 'ç›´æ¥èƒ†çº¢ç´ ', 'mg/dL'),
    'bun': ('Blood Urea Nitrogen', 'è¡€å°¿ç´ æ°®', 'mg/dL'),
    'ca': ('Calcium', 'é’™', 'mg/dL'),
    'ck': ('Creatine Kinase', 'è‚Œé…¸æ¿€é…¶', 'IU/L'),
    'ckmb': ('CK-MB', 'è‚Œé…¸æ¿€é…¶åŒå·¥é…¶', 'ng/mL'),
    'cl': ('Chloride', 'æ°¯', 'mEq/L'),
    'crea': ('Creatinine', 'è‚Œé…', 'mg/dL'),
    'crp': ('C-Reactive Protein', 'Cååº”è›‹ç™½', 'mg/L'),
    'glu': ('Glucose', 'è¡€ç³–', 'mg/dL'),
    'k': ('Potassium', 'é’¾', 'mEq/L'),
    'mg': ('Magnesium', 'é•', 'mg/dL'),
    'na': ('Sodium', 'é’ ', 'mEq/L'),
    'phos': ('Phosphorus', 'ç£·', 'mg/dL'),
    'tnt': ('Troponin T', 'è‚Œé’™è›‹ç™½T', 'ng/mL'),
    
    # è¡€æ¶²å­¦
    'bnd': ('Band Neutrophils', 'æ†çŠ¶æ ¸ä¸­æ€§ç²’ç»†èƒ', '%'),
    'esr': ('Erythrocyte Sedimentation Rate', 'çº¢ç»†èƒæ²‰é™ç‡', 'mm/hr'),
    'fgn': ('Fibrinogen', 'çº¤ç»´è›‹ç™½åŸ', 'mg/dL'),
    'hgb': ('Hemoglobin', 'è¡€çº¢è›‹ç™½', 'g/dL'),
    'inr_pt': ('INR (Prothrombin Time)', 'å›½é™…æ ‡å‡†åŒ–æ¯”å€¼', ''),
    'lymph': ('Lymphocytes', 'æ·‹å·´ç»†èƒ', '%'),
    'mch': ('Mean Corpuscular Hemoglobin', 'å¹³å‡çº¢ç»†èƒè¡€çº¢è›‹ç™½å«é‡', 'pg'),
    'mchc': ('Mean Corpuscular Hemoglobin Concentration', 'å¹³å‡çº¢ç»†èƒè¡€çº¢è›‹ç™½æµ“åº¦', 'g/dL'),
    'mcv': ('Mean Corpuscular Volume', 'å¹³å‡çº¢ç»†èƒä½“ç§¯', 'fL'),
    'neut': ('Neutrophils', 'ä¸­æ€§ç²’ç»†èƒ', '%'),
    'plt': ('Platelets', 'è¡€å°æ¿', 'Ã—10Â³/Î¼L'),
    'ptt': ('Partial Thromboplastin Time', 'éƒ¨åˆ†å‡è¡€æ´»é…¶æ—¶é—´', 'sec'),
    'wbc': ('White Blood Cells', 'ç™½ç»†èƒ', 'Ã—10Â³/Î¼L'),
    
    # è¯ç‰©æ²»ç–—
    'abx': ('Antibiotics', 'æŠ—ç”Ÿç´ ä½¿ç”¨', 'boolean'),
    'adh_rate': ('Vasopressin Rate', 'è¡€ç®¡åŠ å‹ç´ é€Ÿç‡', 'units/min'),
    'cort': ('Corticosteroids', 'ç³–çš®è´¨æ¿€ç´ ', 'boolean'),
    'dex': ('Dextrose (D10)', 'è‘¡è„ç³–ï¼ˆ10%ï¼‰', 'mL/hr'),
    'dobu_dur': ('Dobutamine Duration', 'å¤šå·´é…šä¸èƒºæŒç»­æ—¶é—´', 'hours'),
    'dobu_rate': ('Dobutamine Rate', 'å¤šå·´é…šä¸èƒºé€Ÿç‡', 'mcg/kg/min'),
    'dobu60': ('Dobutamine >60min', 'å¤šå·´é…šä¸èƒº>60åˆ†é’Ÿ', 'boolean'),
    'epi_dur': ('Epinephrine Duration', 'è‚¾ä¸Šè…ºç´ æŒç»­æ—¶é—´', 'hours'),
    'epi_rate': ('Epinephrine Rate', 'è‚¾ä¸Šè…ºç´ é€Ÿç‡', 'mcg/kg/min'),
    'ins': ('Insulin', 'èƒ°å²›ç´ ', 'units/hr'),
    'norepi_dur': ('Norepinephrine Duration', 'å»ç”²è‚¾ä¸Šè…ºç´ æŒç»­æ—¶é—´', 'hours'),
    'norepi_equiv': ('Norepinephrine Equivalent', 'å»ç”²è‚¾ä¸Šè…ºç´ å½“é‡', 'mcg/kg/min'),
    'norepi_rate': ('Norepinephrine Rate', 'å»ç”²è‚¾ä¸Šè…ºç´ é€Ÿç‡', 'mcg/kg/min'),
    'vaso_ind': ('Vasopressor Indicator', 'è¡€ç®¡æ´»æ€§è¯ç‰©æŒ‡ç¤º', 'boolean'),
    
    # å°¿é‡
    'urine': ('Urine Output', 'å°¿é‡', 'mL'),
    'urine24': ('24h Urine Output', '24å°æ—¶å°¿é‡', 'mL/24h'),
    
    # ç¥ç»ç³»ç»Ÿ
    'avpu': ('AVPU Scale', 'AVPUæ„è¯†è¯„åˆ†', ''),
    'egcs': ('Eye Component of GCS', 'GCSçœ¼ç›è¯„åˆ†', ''),
    'gcs': ('Glasgow Coma Scale', 'æ ¼æ‹‰æ–¯å“¥æ˜è¿·è¯„åˆ†', ''),
    'mgcs': ('Motor Component of GCS', 'GCSè¿åŠ¨è¯„åˆ†', ''),
    'rass': ('Richmond Agitation-Sedation Scale', 'RASSé•‡é™è¯„åˆ†', ''),
    'tgcs': ('Total GCS', 'GCSæ€»åˆ†', ''),
    'vgcs': ('Verbal Component of GCS', 'GCSè¯­è¨€è¯„åˆ†', ''),
    
    # äººå£ç»Ÿè®¡
    'age': ('Age', 'å¹´é¾„', 'years'),
    'bmi': ('Body Mass Index', 'ä½“é‡æŒ‡æ•°', 'kg/mÂ²'),
    'height': ('Height', 'èº«é«˜', 'cm'),
    'sex': ('Sex', 'æ€§åˆ«', ''),
    'weight': ('Weight', 'ä½“é‡', 'kg'),
    
    # SOFA-1 è¯„åˆ†
    'sofa': ('SOFA Score (Total)', 'SOFAæ€»åˆ†', '0-24'),
    'sofa_resp': ('SOFA Respiratory', 'SOFAå‘¼å¸è¯„åˆ†', '0-4'),
    'sofa_coag': ('SOFA Coagulation', 'SOFAå‡è¡€è¯„åˆ†', '0-4'),
    'sofa_liver': ('SOFA Liver', 'SOFAè‚è„è¯„åˆ†', '0-4'),
    'sofa_cardio': ('SOFA Cardiovascular', 'SOFAå¿ƒè¡€ç®¡è¯„åˆ†', '0-4'),
    'sofa_cns': ('SOFA Central Nervous System', 'SOFAç¥ç»è¯„åˆ†', '0-4'),
    'sofa_renal': ('SOFA Renal', 'SOFAè‚¾è„è¯„åˆ†', '0-4'),
    'qsofa': ('Quick SOFA', 'å¿«é€ŸSOFAè¯„åˆ†', '0-3'),
    'sirs': ('SIRS Criteria', 'SIRSæ ‡å‡†', '0-4'),
    'mews': ('Modified Early Warning Score', 'æ”¹è‰¯æ—©æœŸé¢„è­¦è¯„åˆ†', '0-14'),
    'news': ('National Early Warning Score', 'å›½å®¶æ—©æœŸé¢„è­¦è¯„åˆ†', '0-20'),
    'death': ('In-hospital Mortality', 'é™¢å†…æ­»äº¡', 'boolean'),
    'los_icu': ('ICU Length of Stay', 'ICUä½é™¢æ—¶é•¿', 'days'),
    'los_hosp': ('Hospital Length of Stay', 'ä½é™¢æ—¶é•¿', 'days'),
    
    # SOFA-2 è¯„åˆ† (2025å¹´æ–°æ ‡å‡†)
    'sofa2': ('SOFA-2 Score (Total)', 'SOFA-2æ€»åˆ† (2025æ–°æ ‡å‡†)', '0-24'),
    'sofa2_resp': ('SOFA-2 Respiratory', 'SOFA-2å‘¼å¸è¯„åˆ†', '0-4'),
    'sofa2_coag': ('SOFA-2 Coagulation', 'SOFA-2å‡è¡€è¯„åˆ†', '0-4'),
    'sofa2_liver': ('SOFA-2 Liver', 'SOFA-2è‚è„è¯„åˆ†', '0-4'),
    'sofa2_cardio': ('SOFA-2 Cardiovascular', 'SOFA-2å¿ƒè¡€ç®¡è¯„åˆ†', '0-4'),
    'sofa2_cns': ('SOFA-2 Central Nervous System', 'SOFA-2ç¥ç»è¯„åˆ†', '0-4'),
    'sofa2_renal': ('SOFA-2 Renal', 'SOFA-2è‚¾è„è¯„åˆ†', '0-4'),
    
    # Sepsis è¯Šæ–­
    'sep3': ('Sepsis-3 Diagnosis (Default)', 'Sepsis-3è¯Šæ–­ (é»˜è®¤)', 'boolean'),
    'sep3_sofa1': ('Sepsis-3 (SOFA-1 based)', 'Sepsis-3è¯Šæ–­ (åŸºäºä¼ ç»ŸSOFA)', 'boolean'),
    'sep3_sofa2': ('Sepsis-3 (SOFA-2 based)', 'Sepsis-3è¯Šæ–­ (åŸºäºSOFA-2, 2025æ–°æ ‡å‡†)', 'boolean'),
    'susp_inf': ('Suspected Infection', 'ç–‘ä¼¼æ„ŸæŸ“', 'boolean'),
    'infection_icd': ('ICD Infection Diagnosis', 'ICDæ„ŸæŸ“è¯Šæ–­ (Angusæ ‡å‡†)', 'boolean'),
    
    # å‘¼å¸ç³»ç»Ÿ (æ‰©å±•)
    'spo2': ('Peripheral Oxygen Saturation', 'è„‰æè¡€æ°§é¥±å’Œåº¦', '%'),
    'vent_start': ('Ventilation Start Time', 'é€šæ°”å¼€å§‹æ—¶é—´', 'datetime'),
    'vent_end': ('Ventilation End Time', 'é€šæ°”ç»“æŸæ—¶é—´', 'datetime'),
    'ecmo': ('ECMO in Use', 'ECMOä½¿ç”¨ä¸­', 'boolean'),
    'ecmo_indication': ('ECMO Indication', 'ECMOé€‚åº”ç—‡ (å‘¼å¸/å¿ƒè¡€ç®¡)', ''),
    'adv_resp': ('Advanced Respiratory Support', 'é«˜çº§å‘¼å¸æ”¯æŒ (IMV/NIV/HFNC)', 'boolean'),
    
    # å‘¼å¸æœºå‚æ•° (Ventilator Parameters)
    'peep': ('Positive End-Expiratory Pressure', 'å‘¼æ°”æœ«æ­£å‹', 'cmH2O'),
    'tidal_vol': ('Tidal Volume (Observed)', 'æ½®æ°”é‡ï¼ˆå®æµ‹ï¼‰', 'mL'),
    'tidal_vol_set': ('Tidal Volume (Set)', 'æ½®æ°”é‡ï¼ˆè®¾å®šï¼‰', 'mL'),
    'pip': ('Peak Inspiratory Pressure', 'å¸æ°”å³°å‹', 'cmH2O'),
    'plateau_pres': ('Plateau Pressure', 'å¹³å°å‹', 'cmH2O'),
    'mean_airway_pres': ('Mean Airway Pressure', 'å¹³å‡æ°”é“å‹', 'cmH2O'),
    'minute_vol': ('Minute Ventilation', 'åˆ†é’Ÿé€šæ°”é‡', 'L/min'),
    'vent_rate': ('Ventilator Respiratory Rate', 'å‘¼å¸æœºé¢‘ç‡', '/min'),
    'compliance': ('Static Compliance', 'é™æ€è‚ºé¡ºåº”æ€§', 'mL/cmH2O'),
    'driving_pres': ('Driving Pressure', 'é©±åŠ¨å‹', 'cmH2O'),
    'ps': ('Pressure Support', 'å‹åŠ›æ”¯æŒ', 'cmH2O'),
    
    # è¡€æ¶²å­¦ (æ‰©å±•)
    'basos': ('Basophils', 'å—œç¢±æ€§ç²’ç»†èƒ', '%'),
    'eos': ('Eosinophils', 'å—œé…¸æ€§ç²’ç»†èƒ', '%'),
    'hba1c': ('Hemoglobin A1C', 'ç³–åŒ–è¡€çº¢è›‹ç™½', '%'),
    'hct': ('Hematocrit', 'çº¢ç»†èƒå‹ç§¯', '%'),
    'pt': ('Prothrombin Time', 'å‡è¡€é…¶åŸæ—¶é—´', 'sec'),
    'rbc': ('Red Blood Cell Count', 'çº¢ç»†èƒè®¡æ•°', 'Ã—10â¶/Î¼L'),
    'rdw': ('Red Cell Distribution Width', 'çº¢ç»†èƒåˆ†å¸ƒå®½åº¦', '%'),
    
    # ç”ŸåŒ– (æ‰©å±•)
    'tri': ('Troponin I', 'è‚Œé’™è›‹ç™½I', 'ng/mL'),
    
    # è¯ç‰© (æ‰©å±•)
    'dopa_rate': ('Dopamine Rate', 'å¤šå·´èƒºé€Ÿç‡', 'mcg/kg/min'),
    'dopa_dur': ('Dopamine Duration', 'å¤šå·´èƒºæŒç»­æ—¶é—´', 'hours'),
    'dopa60': ('Dopamine >60min', 'å¤šå·´èƒº>60åˆ†é’Ÿ', 'boolean'),
    'norepi60': ('Norepinephrine >60min', 'å»ç”²è‚¾ä¸Šè…ºç´ >60åˆ†é’Ÿ', 'boolean'),
    'epi60': ('Epinephrine >60min', 'è‚¾ä¸Šè…ºç´ >60åˆ†é’Ÿ', 'boolean'),
    'phn_rate': ('Phenylephrine Rate', 'å»æ°§è‚¾ä¸Šè…ºç´ é€Ÿç‡', 'mcg/kg/min'),
    
    # è‚¾è„ä¸å°¿é‡ç‡
    'rrt': ('Renal Replacement Therapy', 'è‚¾è„æ›¿ä»£æ²»ç–—', 'boolean'),
    'rrt_criteria': ('RRT Criteria Met', 'æ»¡è¶³RRTæ ‡å‡†', 'boolean'),
    'uo_6h': ('Average Urine Output Rate (past 6h)', 'è¿‡å»6å°æ—¶å¹³å‡å°¿é‡ç‡', 'mL/kg/h'),
    'uo_12h': ('Average Urine Output Rate (past 12h)', 'è¿‡å»12å°æ—¶å¹³å‡å°¿é‡ç‡', 'mL/kg/h'),
    'uo_24h': ('Average Urine Output Rate (past 24h)', 'è¿‡å»24å°æ—¶å¹³å‡å°¿é‡ç‡', 'mL/kg/h'),
    
    # KDIGO AKI (æ€¥æ€§è‚¾æŸä¼¤) - ğŸ”§ 2026-02-04: ç§»é™¤é‡å¤çš„ kdigo_aki/kdigo_creat/kdigo_uo
    'aki': ('Acute Kidney Injury', 'æ€¥æ€§è‚¾æŸä¼¤', 'boolean'),
    'aki_stage': ('AKI Stage (KDIGO)', 'AKIåˆ†æœŸï¼ˆKDIGOæ ‡å‡†ï¼‰', '0-3'),
    'aki_stage_creat': ('AKI Stage (Creatinine)', 'AKIåˆ†æœŸï¼ˆè‚Œé…ï¼‰', '0-3'),
    'aki_stage_uo': ('AKI Stage (Urine Output)', 'AKIåˆ†æœŸï¼ˆå°¿é‡ï¼‰', '0-3'),
    'aki_stage_rrt': ('AKI Stage (RRT)', 'AKIåˆ†æœŸï¼ˆRRTï¼‰', '0-3'),
    # ğŸ”§ 2026-02-12: æ·»åŠ è§„èŒƒåŒ–åçš„ KDIGO æ‰©å±•åˆ—
    'creat_low_past_48hr': ('Lowest Creatinine in Past 48h', 'è¿‡å»48å°æ—¶å†…æœ€ä½è‚Œé…', 'mg/dL'),
    'creat_low_past_7day': ('Baseline Creatinine (7-day lowest)', 'åŸºçº¿è‚Œé…ï¼ˆ7å¤©å†…æœ€ä½å€¼ï¼‰', 'mg/dL'),
    'uo_rt_6hr': ('Urine Output Rate (6h rolling window)', 'å°¿é‡ç‡ï¼ˆ6å°æ—¶æ»šåŠ¨çª—å£ï¼‰', 'mL/kg/h'),
    'uo_rt_12hr': ('Urine Output Rate (12h rolling window)', 'å°¿é‡ç‡ï¼ˆ12å°æ—¶æ»šåŠ¨çª—å£ï¼‰', 'mL/kg/h'),
    'uo_rt_24hr': ('Urine Output Rate (24h rolling window)', 'å°¿é‡ç‡ï¼ˆ24å°æ—¶æ»šåŠ¨çª—å£ï¼‰', 'mL/kg/h'),
    
    # ç¥ç» (æ‰©å±•)
    'sedated_gcs': ('GCS Before Sedation', 'é•‡é™å‰GCS', ''),
    
    # å¿ƒè¡€ç®¡ (æ‰©å±•)
    'mech_circ_support': ('Mechanical Circulatory Support', 'æœºæ¢°å¾ªç¯æ”¯æŒ (IABP/LVAD/Impella)', 'boolean'),
    'other_vaso': ('Other Vasopressors', 'å…¶ä»–è¡€ç®¡æ´»æ€§è¯ç‰©', 'boolean'),
    'circ_failure': ('Circulatory Failure', 'å¾ªç¯è¡°ç«­', 'boolean'),
    'circ_event': ('Circulatory Failure Event Level', 'å¾ªç¯è¡°ç«­äº‹ä»¶ç­‰çº§', '0-3'),
    
    # ç¥ç»ç³»ç»Ÿ SOFA-2 æ‰©å±•
    'motor_response': ('GCS Motor Response', 'GCSè¿åŠ¨ååº”', '1-6'),
    'delirium_positive': ('Delirium Positive (CAM-ICU)', 'è°µå¦„é˜³æ€§ï¼ˆCAM-ICUï¼‰', 'boolean'),
    'delirium_tx': ('Delirium Treatment', 'è°µå¦„æ²»ç–—', 'boolean'),
    
    # äººå£ç»Ÿè®¡ (æ‰©å±•)
    'adm': ('Admission Type', 'å…¥é™¢ç±»å‹', ''),
    
    # å¾®ç”Ÿç‰©
    'samp': ('Body Fluid Sampling', 'ä½“æ¶²é‡‡æ ·', 'boolean'),
}

# ç‰¹å¾è¯¦ç»†æè¿°ï¼ˆè‹±æ–‡å’Œä¸­æ–‡ï¼‰
CONCEPT_DESCRIPTIONS = {
    # SOFA-2
    'sofa2': ('Total SOFA-2 score (2025 new standard), sum of 6 organ systems (0-24)', 'SOFA-2æ€»åˆ†ï¼ˆ2025å¹´æ–°æ ‡å‡†ï¼‰ï¼Œ6ä¸ªå™¨å®˜ç³»ç»Ÿè¯„åˆ†ä¹‹å’Œï¼ˆ0-24åˆ†ï¼‰'),
    'sofa2_resp': ('Respiratory: PaO2/FiO2 (or SpO2/FiO2 if unavailable), scores 3-4 require advanced respiratory support (IMV/NIV/HFNC) or ECMO', 'å‘¼å¸ç³»ç»Ÿï¼šåŸºäºæ°§åˆæŒ‡æ•°ï¼Œ3-4åˆ†éœ€è¦é«˜çº§å‘¼å¸æ”¯æŒï¼ˆIMV/NIV/HFNCï¼‰æˆ–ECMO'),
    'sofa2_coag': ('Coagulation: platelet count with updated thresholds (â‰¤50â†’4, â‰¤80â†’3, â‰¤100â†’2, â‰¤150â†’1)', 'å‡è¡€ç³»ç»Ÿï¼šåŸºäºè¡€å°æ¿è®¡æ•°ï¼Œä½¿ç”¨æ›´æ–°çš„é˜ˆå€¼ï¼ˆâ‰¤50â†’4åˆ†ï¼Œâ‰¤80â†’3åˆ†ï¼Œâ‰¤100â†’2åˆ†ï¼Œâ‰¤150â†’1åˆ†ï¼‰'),
    'sofa2_liver': ('Liver: bilirubin with relaxed 1-point threshold (>1.2 mg/dL instead of >1.9)', 'è‚è„ï¼šåŸºäºèƒ†çº¢ç´ ï¼Œ1åˆ†é˜ˆå€¼æ”¾å®½ï¼ˆ>1.2 mg/dLï¼ŒåŸä¸º>1.9ï¼‰'),
    'sofa2_cardio': ('Cardiovascular: combined NE+Epi dose, other vasopressors/inotropes, or mechanical circulatory support (IABP/LVAD/Impella)', 'å¿ƒè¡€ç®¡ï¼šåŸºäºå»ç”²è‚¾+è‚¾ä¸Šè…ºç´ è”åˆå‰‚é‡ã€å…¶ä»–è¡€ç®¡æ´»æ€§è¯ç‰©æˆ–æœºæ¢°å¾ªç¯æ”¯æŒ'),
    'sofa2_cns': ('Neurological: GCS score, with delirium (CAM-ICU+ or treatment) adding 1 point if GCS=15', 'ç¥ç»ç³»ç»Ÿï¼šåŸºäºGCSè¯„åˆ†ï¼Œè‹¥GCS=15ä½†æœ‰è°µå¦„ï¼ˆCAM-ICUé˜³æ€§æˆ–æ¥å—æ²»ç–—ï¼‰åˆ™åŠ 1åˆ†'),
    'sofa2_renal': ('Renal: creatinine and urine output (6h/12h/24h windows), score 4 for RRT or meeting RRT criteria', 'è‚¾è„ï¼šåŸºäºè‚Œé…å’Œå°¿é‡ï¼ˆ6h/12h/24hçª—å£ï¼‰ï¼Œæ¥å—RRTæˆ–æ»¡è¶³RRTæ ‡å‡†åˆ™ä¸º4åˆ†'),
    
    # Sepsis
    'sep3_sofa2': ('Sepsis-3 diagnosis: suspected infection + SOFA-2 â‰¥2 point increase from baseline', 'åŸºäºSOFA-2çš„Sepsis-3è¯Šæ–­ï¼šç–‘ä¼¼æ„ŸæŸ“ + SOFA-2è¾ƒåŸºçº¿å‡é«˜â‰¥2åˆ†'),
    'sep3_sofa1': ('Sepsis-3 diagnosis: suspected infection + traditional SOFA â‰¥2 point increase', 'åŸºäºä¼ ç»ŸSOFAçš„Sepsis-3è¯Šæ–­ï¼šç–‘ä¼¼æ„ŸæŸ“ + SOFAè¾ƒåŸºçº¿å‡é«˜â‰¥2åˆ†'),
    'susp_inf': ('Suspected infection: antibiotics started within 72h of culture OR culture within 24h of antibiotics', 'ç–‘ä¼¼æ„ŸæŸ“ï¼šåŸ¹å…»å72å°æ—¶å†…å¼€å§‹æŠ—ç”Ÿç´  æˆ– æŠ—ç”Ÿç´ å24å°æ—¶å†…è¿›è¡ŒåŸ¹å…»'),
    'infection_icd': ('Infection diagnosis based on Angus ICD criteria (explicit infection codes)', 'åŸºäºAngus ICDæ ‡å‡†çš„æ„ŸæŸ“è¯Šæ–­ï¼ˆæ˜¾æ€§æ„ŸæŸ“ç¼–ç ï¼‰'),
    
    # Vitals
    'hr': ('Heart rate in beats per minute', 'æ¯åˆ†é’Ÿå¿ƒè·³æ¬¡æ•°'),
    'map': ('Mean arterial pressure = (SBP + 2Ã—DBP) / 3', 'å¹³å‡åŠ¨è„‰å‹ = (æ”¶ç¼©å‹ + 2Ã—èˆ’å¼ å‹) / 3'),
    'sbp': ('Systolic blood pressure (peak pressure during heartbeat)', 'æ”¶ç¼©å‹ï¼ˆå¿ƒè„æ”¶ç¼©æ—¶çš„æœ€é«˜å‹åŠ›ï¼‰'),
    'dbp': ('Diastolic blood pressure (pressure between heartbeats)', 'èˆ’å¼ å‹ï¼ˆå¿ƒè„èˆ’å¼ æ—¶çš„æœ€ä½å‹åŠ›ï¼‰'),
    'temp': ('Body temperature in Celsius', 'ä½“æ¸©ï¼ˆæ‘„æ°åº¦ï¼‰'),
    'resp': ('Respiratory rate (breaths per minute)', 'å‘¼å¸é¢‘ç‡ï¼ˆæ¯åˆ†é’Ÿå‘¼å¸æ¬¡æ•°ï¼‰'),
    
    # Respiratory
    'pafi': ('PaO2/FiO2 ratio - key oxygenation index for ARDS/SOFA scoring', 'æ°§åˆæŒ‡æ•° - ARDS/SOFAè¯„åˆ†çš„å…³é”®æŒ‡æ ‡'),
    'safi': ('SpO2/FiO2 ratio - non-invasive alternative to PaFi (used when SpO2<98%)', 'è„‰æ°§/å¸æ°§æ¯” - PaFiçš„éä¾µå…¥æ€§æ›¿ä»£ï¼ˆå½“SpO2<98%æ—¶ä½¿ç”¨ï¼‰'),
    'fio2': ('Fraction of inspired oxygen (21-100%)', 'å¸å…¥æ°§æµ“åº¦ï¼ˆ21-100%ï¼‰'),
    'vent_ind': ('Mechanical ventilation indicator (boolean)', 'æœºæ¢°é€šæ°”æŒ‡ç¤ºï¼ˆå¸ƒå°”å€¼ï¼‰'),
    'ecmo_indication': ("ECMO indication type: 'respiratory' (for lung failure, auto-scores 4 in SOFA-2 resp) or 'cardiovascular' (for heart failure, scores in SOFA-2 cardio as mech_circ_support)", "ECMOé€‚åº”ç—‡ç±»å‹ï¼š'respiratory'ï¼ˆè‚ºè¡°ç«­ï¼ŒSOFA-2å‘¼å¸è¯„åˆ†è‡ªåŠ¨ä¸º4åˆ†ï¼‰æˆ–'cardiovascular'ï¼ˆå¿ƒè¡°ï¼Œè®¡å…¥SOFA-2å¿ƒè¡€ç®¡çš„æœºæ¢°å¾ªç¯æ”¯æŒï¼‰"),
    'adv_resp': ('Advanced respiratory support indicator: IMV (invasive mechanical ventilation), NIV (non-invasive ventilation), HFNC (high-flow nasal cannula), CPAP, or BiPAP - required for SOFA-2 respiratory scores 3-4', 'é«˜çº§å‘¼å¸æ”¯æŒæŒ‡ç¤ºï¼šIMVï¼ˆæœ‰åˆ›æœºæ¢°é€šæ°”ï¼‰ã€NIVï¼ˆæ— åˆ›é€šæ°”ï¼‰ã€HFNCï¼ˆç»é¼»é«˜æµé‡ï¼‰ã€CPAPæˆ–BiPAP - SOFA-2å‘¼å¸è¯„åˆ†3-4åˆ†çš„å¿…è¦æ¡ä»¶'),
    
    # Blood gas
    'lact': ('Lactate - marker of tissue hypoperfusion and shock', 'ä¹³é…¸ - ç»„ç»‡ä½çŒæ³¨å’Œä¼‘å…‹çš„æ ‡å¿—ç‰©'),
    'ph': ('Blood acidity/alkalinity (normal 7.35-7.45)', 'è¡€æ¶²é…¸ç¢±åº¦ï¼ˆæ­£å¸¸7.35-7.45ï¼‰'),
    'pco2': ('Partial pressure of CO2 in arterial blood', 'åŠ¨è„‰è¡€ä¸­äºŒæ°§åŒ–ç¢³åˆ†å‹'),
    'po2': ('Partial pressure of O2 in arterial blood', 'åŠ¨è„‰è¡€ä¸­æ°§åˆ†å‹'),
    
    # Labs
    'crea': ('Serum creatinine - kidney function marker, key for SOFA renal scoring', 'è¡€æ¸…è‚Œé… - è‚¾åŠŸèƒ½æ ‡å¿—ç‰©ï¼ŒSOFAè‚¾è„è¯„åˆ†å…³é”®æŒ‡æ ‡'),
    'bili': ('Total bilirubin - liver function marker, key for SOFA liver scoring', 'æ€»èƒ†çº¢ç´  - è‚åŠŸèƒ½æ ‡å¿—ç‰©ï¼ŒSOFAè‚è„è¯„åˆ†å…³é”®æŒ‡æ ‡'),
    'plt': ('Platelet count - coagulation marker, key for SOFA coagulation scoring', 'è¡€å°æ¿è®¡æ•° - å‡è¡€åŠŸèƒ½æ ‡å¿—ç‰©ï¼ŒSOFAå‡è¡€è¯„åˆ†å…³é”®æŒ‡æ ‡'),
    'wbc': ('White blood cell count - infection/inflammation marker', 'ç™½ç»†èƒè®¡æ•° - æ„ŸæŸ“/ç‚ç—‡æ ‡å¿—ç‰©'),
    
    # Vasopressors
    'norepi_rate': ('Norepinephrine infusion rate in Î¼g/kg/min (weight-adjusted)', 'å»ç”²è‚¾ä¸Šè…ºç´ è¾“æ³¨é€Ÿç‡ï¼ˆÎ¼g/kg/minï¼Œä½“é‡æ ¡æ­£ï¼‰'),
    'norepi_equiv': ('Norepinephrine equivalent dose - standardized vasopressor potency', 'å»ç”²è‚¾ä¸Šè…ºç´ å½“é‡ - æ ‡å‡†åŒ–è¡€ç®¡æ´»æ€§è¯ç‰©æ•ˆä»·'),
    'vaso_ind': ('Any vasopressor use indicator (boolean)', 'ä»»ä½•è¡€ç®¡æ´»æ€§è¯ç‰©ä½¿ç”¨æŒ‡ç¤ºï¼ˆå¸ƒå°”å€¼ï¼‰'),
    'other_vaso': ('Other vasopressors/inotropes: vasopressin, phenylephrine, milrinone (combined with dobutamine in SOFA-2 cardio scoring as "has_other_vaso")', 'å…¶ä»–è¡€ç®¡æ´»æ€§è¯ç‰©ï¼šè¡€ç®¡åŠ å‹ç´ ã€å»æ°§è‚¾ä¸Šè…ºç´ ã€ç±³åŠ›å†œï¼ˆåœ¨SOFA-2å¿ƒè¡€ç®¡è¯„åˆ†ä¸­ä¸å¤šå·´é…šä¸èƒºåˆå¹¶ä¸º"has_other_vaso"ï¼‰'),
    
    # Neurological
    'gcs': ('Glasgow Coma Scale total score (3-15), key for SOFA CNS scoring', 'æ ¼æ‹‰æ–¯å“¥æ˜è¿·è¯„åˆ†æ€»åˆ†ï¼ˆ3-15åˆ†ï¼‰ï¼ŒSOFAç¥ç»è¯„åˆ†å…³é”®æŒ‡æ ‡'),
    
    # Outcomes
    'death': ('In-hospital mortality (0=survived, 1=died)', 'é™¢å†…æ­»äº¡ï¼ˆ0=å­˜æ´»ï¼Œ1=æ­»äº¡ï¼‰'),
    'los_icu': ('ICU length of stay in days', 'ICUä½é™¢æ—¶é•¿ï¼ˆå¤©ï¼‰'),
    'los_hosp': ('Hospital length of stay in days', 'æ€»ä½é™¢æ—¶é•¿ï¼ˆå¤©ï¼‰'),
    
    # AKI
    'aki': ('Acute Kidney Injury (KDIGO Stage â‰¥1)', 'æ€¥æ€§è‚¾æŸä¼¤ï¼ˆKDIGOåˆ†æœŸâ‰¥1ï¼‰'),
    'aki_stage': ('KDIGO AKI stage (0-3): max of creatinine and urine output criteria', 'KDIGO AKIåˆ†æœŸï¼ˆ0-3ï¼‰ï¼šè‚Œé…å’Œå°¿é‡æ ‡å‡†çš„æœ€å¤§å€¼'),
    'aki_stage_creat': ('AKI stage based on creatinine: â‰¥1.5x baseline or â‰¥0.3 mg/dL increase in 48h', 'åŸºäºè‚Œé…çš„AKIåˆ†æœŸï¼šè¾ƒåŸºçº¿å‡é«˜â‰¥1.5å€ æˆ– 48hå†…å‡é«˜â‰¥0.3 mg/dL'),
    'aki_stage_uo': ('AKI stage based on urine output: <0.5 mL/kg/h for 6h (Stage 1), 12h (Stage 2), or <0.3 for 24h (Stage 3)', 'åŸºäºå°¿é‡çš„AKIåˆ†æœŸï¼š<0.5 mL/kg/hæŒç»­6h(1æœŸ)ã€12h(2æœŸ) æˆ– <0.3æŒç»­24h(3æœŸ)'),
    
    # Circulatory failure
    'circ_failure': ('Circulatory failure (circEWS definition): lactate â‰¥2 mmol/L with hypotension/vasopressors', 'å¾ªç¯è¡°ç«­ï¼ˆcircEWSå®šä¹‰ï¼‰ï¼šä¹³é…¸â‰¥2 mmol/Lä¼´ä½è¡€å‹æˆ–è¡€ç®¡æ´»æ€§è¯ç‰©'),
    'circ_event': ('Circulatory failure event level (0-3): based on lactate, MAP, and vasopressor tier', 'å¾ªç¯è¡°ç«­äº‹ä»¶ç­‰çº§ï¼ˆ0-3ï¼‰ï¼šåŸºäºä¹³é…¸ã€MAPå’Œè¡€ç®¡æ´»æ€§è¯ç‰©ç­‰çº§'),
    
    # Other scores
    'qsofa': ('Quick SOFA (0-3): RRâ‰¥22 + altered mental status + SBPâ‰¤100', 'å¿«é€ŸSOFAï¼ˆ0-3åˆ†ï¼‰ï¼šå‘¼å¸é¢‘ç‡â‰¥22 + æ„è¯†æ”¹å˜ + æ”¶ç¼©å‹â‰¤100'),
    'sirs': ('SIRS criteria (0-4): temp + HR + RR/PaCO2 + WBC/bands', 'SIRSæ ‡å‡†ï¼ˆ0-4åˆ†ï¼‰ï¼šä½“æ¸© + å¿ƒç‡ + å‘¼å¸/PaCO2 + ç™½ç»†èƒ/æ†çŠ¶æ ¸'),
}

# å…¨å±€ç‰¹å¾åˆ†ç»„å®šä¹‰ - ä¾›ä¾§è¾¹æ å’Œæ•°æ®å­—å…¸å…±ç”¨
# ä½¿ç”¨è‹±æ–‡keyï¼Œå¹¶æä¾›åŒè¯­æ˜¾ç¤ºåç§°
CONCEPT_GROUPS_INTERNAL = {
    'sofa2_score': ['sofa2', 'sofa2_resp', 'sofa2_coag', 'sofa2_liver', 'sofa2_cardio', 'sofa2_cns', 'sofa2_renal'],
    'sofa1_score': ['sofa', 'sofa_resp', 'sofa_coag', 'sofa_liver', 'sofa_cardio', 'sofa_cns', 'sofa_renal'],
    'sepsis3_sofa2': ['sep3_sofa2'],  # ğŸ”§ å…±äº«æ¦‚å¿µç§»åˆ°å•ç‹¬çš„ sepsis_shared æ¨¡å—
    'sepsis3_sofa1': ['sep3_sofa1'],  # ğŸ”§ å…±äº«æ¦‚å¿µç§»åˆ°å•ç‹¬çš„ sepsis_shared æ¨¡å—
    'sepsis_shared': ['sep3', 'susp_inf', 'infection_icd', 'samp'],  # åŒ…å«sep3é»˜è®¤è¯Šæ–­
    'vitals': ['hr', 'map', 'sbp', 'dbp', 'temp', 'spo2', 'resp'],  # ğŸ”§ etco2 ç§»åˆ° ventilator
    'respiratory': ['pafi', 'safi', 'fio2', 'supp_o2', 'vent_ind', 'vent_start', 'vent_end', 'o2sat', 'sao2', 'mech_vent', 'ett_gcs', 'ecmo', 'ecmo_indication', 'adv_resp'],
    'ventilator': ['peep', 'tidal_vol', 'tidal_vol_set', 'pip', 'plateau_pres', 'mean_airway_pres', 'minute_vol', 'vent_rate', 'etco2', 'compliance', 'driving_pres', 'ps'],
    'blood_gas': ['be', 'cai', 'hbco', 'lact', 'methb', 'pco2', 'ph', 'po2', 'tco2'],
    'chemistry': ['alb', 'alp', 'alt', 'ast', 'bicar', 'bili', 'bili_dir', 'bun', 'ca', 'ck', 'ckmb', 'cl', 'crea', 'crp', 'glu', 'k', 'mg', 'na', 'phos', 'tnt', 'tri'],
    'hematology': ['bnd', 'basos', 'eos', 'esr', 'fgn', 'hba1c', 'hct', 'hgb', 'inr_pt', 'lymph', 'mch', 'mchc', 'mcv', 'neut', 'plt', 'pt', 'ptt', 'rbc', 'rdw', 'wbc'],
    'vasopressors': ['norepi_rate', 'norepi_dur', 'norepi_equiv', 'norepi60', 'epi_rate', 'epi_dur', 'epi60', 'dopa_rate', 'dopa_dur', 'dopa60', 'dobu_rate', 'dobu_dur', 'dobu60', 'adh_rate', 'phn_rate', 'vaso_ind', 'other_vaso'],
    'medications': ['abx', 'cort', 'dex', 'ins'],
    # ğŸ”§ 2026-02-04: ç§»é™¤é‡å¤çš„ kdigo_aki/kdigo_creat/kdigo_uoï¼Œåªä¿ç•™ aki_* è§„èŒƒå
    'renal': ['urine', 'urine24', 'uo_6h', 'uo_12h', 'uo_24h', 'rrt', 'rrt_criteria', 'aki', 'aki_stage', 'aki_stage_creat', 'aki_stage_uo', 'aki_stage_rrt',
              # è§„èŒƒåŒ–åçš„åˆ—åï¼ˆä» kdigo_* å±•å¼€åˆ—è§„èŒƒåŒ–è€Œæ¥ï¼‰
              'creat_low_past_48hr', 'creat_low_past_7day', 'uo_rt_6hr', 'uo_rt_12hr', 'uo_rt_24hr'],
    'neurological': ['avpu', 'egcs', 'gcs', 'mgcs', 'rass', 'tgcs', 'vgcs', 'sedated_gcs', 'motor_response', 'delirium_positive', 'delirium_tx'],
    'circulatory': ['mech_circ_support', 'circ_failure', 'circ_event'],  # ğŸ”§ æ·»åŠ å¾ªç¯è¡°ç«­ç‰¹å¾
    'demographics': ['age', 'bmi', 'height', 'sex', 'weight', 'adm'],
    'other_scores': ['qsofa', 'sirs', 'mews', 'news'],
    'outcome': ['death', 'los_icu', 'los_hosp'],
}

# åŒè¯­æ˜¾ç¤ºåç§°æ˜ å°„ï¼ˆä¼˜åŒ–ï¼šæ›´æ¸…æ™°çš„å‘½ååŒºåˆ†è¯„åˆ†vsè¯Šæ–­ï¼ŒåŒ…å«å‡†ç¡®ç‰¹å¾æ•°é‡ï¼‰
CONCEPT_GROUP_NAMES = {
    'sofa2_score': ('â­ SOFA-2 Scores', 'â­ SOFA-2 è¯„åˆ†'),
    'sofa1_score': ('ğŸ“Š SOFA-1 Scores', 'ğŸ“Š SOFA-1 è¯„åˆ†'),
    'sepsis3_sofa2': ('ğŸ¦  Sepsis-3 (SOFA-2 based)', 'ğŸ¦  Sepsis-3 (åŸºäºSOFA-2)'),
    'sepsis3_sofa1': ('ğŸ¦  Sepsis-3 (SOFA-1 based)', 'ğŸ¦  Sepsis-3 (åŸºäºSOFA-1)'),
    'sepsis_shared': ('ğŸ¦  Sepsis Shared Concepts', 'ğŸ¦  Sepsis å…±äº«æ¦‚å¿µ'),
    'vitals': ('â¤ï¸ Vital Signs', 'â¤ï¸ ç”Ÿå‘½ä½“å¾'),
    'respiratory': ('ğŸ’¨ Respiratory System', 'ğŸ’¨ å‘¼å¸ç³»ç»Ÿ'),
    'ventilator': ('ğŸŒ¬ï¸ Ventilator Parameters', 'ğŸŒ¬ï¸ å‘¼å¸æœºå‚æ•°'),
    'blood_gas': ('ğŸ©¸ Blood Gas Analysis', 'ğŸ©¸ è¡€æ°”åˆ†æ'),
    'chemistry': ('ğŸ§ª Lab - Chemistry', 'ğŸ§ª å®éªŒå®¤-ç”ŸåŒ–'),
    'hematology': ('ğŸ”¬ Lab - Hematology', 'ğŸ”¬ å®éªŒå®¤-è¡€æ¶²å­¦'),
    'vasopressors': ('ğŸ’‰ Vasopressors', 'ğŸ’‰ è¡€ç®¡æ´»æ€§è¯ç‰©'),
    'medications': ('ğŸ’Š Other Medications', 'ğŸ’Š å…¶ä»–è¯ç‰©'),
    'renal': ('ğŸš° Renal & Urine Output', 'ğŸš° è‚¾è„ä¸å°¿é‡'),
    'neurological': ('ğŸ§  Neurological', 'ğŸ§  ç¥ç»ç³»ç»Ÿ'),
    'circulatory': ('â¤ï¸â€ğŸ©¹ Circulatory System', 'â¤ï¸â€ğŸ©¹ å¾ªç¯ç³»ç»Ÿ'),
    'demographics': ('ğŸ‘¤ Demographics', 'ğŸ‘¤ äººå£ç»Ÿè®¡'),
    'other_scores': ('ğŸ“ˆ Other Scores', 'ğŸ“ˆ å…¶ä»–è¯„åˆ†'),
    'outcome': ('ğŸ¯ Outcome', 'ğŸ¯ ç»“å±€'),
}

# ç”¨äºæ—¶åºåˆ†æé¡µé¢çš„æ˜¾ç¤ºåç§°æ˜ å°„ï¼ˆè‹±æ–‡ç‰ˆæœ¬ï¼‰
CONCEPT_GROUPS_DISPLAY = {
    'sofa2_score': 'â­ SOFA-2 Scores',
    'sofa1_score': 'ğŸ“Š SOFA-1 Scores',
    'sepsis3_sofa2': 'ğŸ¦  Sepsis-3 (SOFA-2)',
    'sepsis3_sofa1': 'ğŸ¦  Sepsis-3 (SOFA-1)',
    'sepsis_shared': 'ğŸ¦  Sepsis Shared',
    'vitals': 'â¤ï¸ Vital Signs',
    'respiratory': 'ğŸ’¨ Respiratory',
    'ventilator': 'ğŸŒ¬ï¸ Ventilator',
    'blood_gas': 'ğŸ©¸ Blood Gas',
    'chemistry': 'ğŸ§ª Chemistry',
    'hematology': 'ğŸ”¬ Hematology',
    'vasopressors': 'ğŸ’‰ Vasopressors',
    'medications': 'ğŸ’Š Medications',
    'renal': 'ğŸš° Renal',
    'neurological': 'ğŸ§  Neurological',
    'circulatory': 'â¤ï¸â€ğŸ©¹ Circulatory',
    'demographics': 'ğŸ‘¤ Demographics',
    'other_scores': 'ğŸ“ˆ Other Scores',
    'outcome': 'ğŸ¯ Outcome',
}

# ğŸ”§ ADD (2026-02-05): æ”¯æŒæ—¶åºåˆ†æçš„æ¨¡å—ï¼ˆæ’é™¤é™æ€æ•°æ®æ¨¡å—ï¼‰
# é™æ€æ•°æ®æ¨¡å—ï¼ˆdemographics, outcomeï¼‰çš„å€¼ä¸æ˜¯è¿ç»­å˜åŒ–çš„ï¼Œä¸é€‚åˆæ—¶åºåˆ†æ
TIME_SERIES_COMPATIBLE_MODULES = {
    'sofa2_score',      # SOFAè¯„åˆ†éšæ—¶é—´å˜åŒ–
    'sofa1_score',
    'sepsis3_sofa2',    # SepsisçŠ¶æ€éšæ—¶é—´å˜åŒ–
    'sepsis3_sofa1',
    'sepsis_shared',
    'vitals',           # ç”Ÿå‘½ä½“å¾ï¼ˆå¿ƒç‡ã€è¡€å‹ç­‰ï¼‰
    'respiratory',      # å‘¼å¸ç³»ç»Ÿ
    'ventilator',       # å‘¼å¸æœºå‚æ•°
    'blood_gas',        # è¡€æ°”åˆ†æ
    'chemistry',        # ç”ŸåŒ–æ£€éªŒ
    'hematology',       # è¡€æ¶²å­¦
    'vasopressors',     # è¡€ç®¡æ´»æ€§è¯ç‰©
    'medications',      # è¯ç‰©
    'renal',            # è‚¾è„ä¸å°¿é‡
    'neurological',     # ç¥ç»ç³»ç»Ÿï¼ˆGCSç­‰ï¼‰
    'circulatory',      # å¾ªç¯ç³»ç»Ÿ
    'other_scores',     # å…¶ä»–è¯„åˆ†
    # æ’é™¤: 'demographics' - é™æ€æ•°æ®ï¼ˆå¹´é¾„ã€æ€§åˆ«ã€èº«é«˜ã€ä½“é‡ç­‰ï¼‰
    # æ’é™¤: 'outcome' - é™æ€æ•°æ®ï¼ˆæ­»äº¡ã€ä½é™¢æ—¶é•¿ç­‰ï¼‰
}

def get_concept_groups():
    """æ ¹æ®å½“å‰è¯­è¨€è¿”å›å¸¦æ­£ç¡®æ˜¾ç¤ºåç§°çš„ç‰¹å¾åˆ†ç»„ã€‚"""
    lang = st.session_state.get('language', 'en')
    result = {}
    for key, concepts in CONCEPT_GROUPS_INTERNAL.items():
        en_name, zh_name = CONCEPT_GROUP_NAMES.get(key, (key, key))
        display_name = en_name if lang == 'en' else zh_name
        result[display_name] = concepts
    return result


# ğŸ”§ åˆ—åè§„èŒƒåŒ–æ˜ å°„ï¼šå°†é‡å¤çš„å±•å¼€åˆ—åç»Ÿä¸€ä¸ºç®€çŸ­çš„è§„èŒƒåç§°
# è¿™äº›åˆ—æ¥è‡ª kdigo_aki, kdigo_creat, kdigo_uo ç­‰å¤åˆæ¦‚å¿µçš„å±•å¼€
# è§„èŒƒåŒ–åæ¯ä¸ªå”¯ä¸€çš„æ•°æ®åˆ—åªä¿ç•™ä¸€ä»½ï¼Œé¿å…é‡å¤
COLUMN_NORMALIZATION_MAP = {
    # kdigo_aki_ å‰ç¼€çš„åˆ— -> è§„èŒƒå
    'kdigo_aki_aki': 'aki',
    'kdigo_aki_aki_stage': 'aki_stage',
    'kdigo_aki_aki_stage_creat': 'aki_stage_creat',
    'kdigo_aki_aki_stage_uo': 'aki_stage_uo',
    'kdigo_aki_crea': 'crea',  # æ³¨æ„ï¼šcrea åœ¨ chemistry æ¨¡å—ä¹Ÿæœ‰ï¼Œéœ€è¦åŒºåˆ†
    'kdigo_aki_creat_low_past_48hr': 'creat_low_past_48hr',
    'kdigo_aki_creat_low_past_7day': 'creat_low_past_7day',
    'kdigo_aki_rrt': 'rrt',
    'kdigo_aki_uo_rt_6hr': 'uo_rt_6hr',
    'kdigo_aki_uo_rt_12hr': 'uo_rt_12hr',
    'kdigo_aki_uo_rt_24hr': 'uo_rt_24hr',
    # kdigo_creat_ å‰ç¼€çš„åˆ— -> è§„èŒƒåï¼ˆä¸ kdigo_aki_ é‡å¤ï¼‰
    'kdigo_creat_aki_stage_creat': 'aki_stage_creat',
    'kdigo_creat_crea': 'crea',
    'kdigo_creat_creat_low_past_48hr': 'creat_low_past_48hr',
    'kdigo_creat_creat_low_past_7day': 'creat_low_past_7day',
    # kdigo_uo_ å‰ç¼€çš„åˆ— -> è§„èŒƒåï¼ˆä¸ kdigo_aki_ é‡å¤ï¼‰
    'kdigo_uo_aki_stage_uo': 'aki_stage_uo',
    'kdigo_uo_uo_rt_6hr': 'uo_rt_6hr',
    'kdigo_uo_uo_rt_12hr': 'uo_rt_12hr',
    'kdigo_uo_uo_rt_24hr': 'uo_rt_24hr',
}

# ğŸ”§ åå‘æ˜ å°„ï¼šè§„èŒƒå -> æ‰€æœ‰åŸå§‹åˆ—åï¼ˆç”¨äºæŸ¥æ‰¾æ•°æ®ï¼‰
NORMALIZED_TO_ORIGINAL_MAP = {}
for orig, norm in COLUMN_NORMALIZATION_MAP.items():
    if norm not in NORMALIZED_TO_ORIGINAL_MAP:
        NORMALIZED_TO_ORIGINAL_MAP[norm] = []
    NORMALIZED_TO_ORIGINAL_MAP[norm].append(orig)


def normalize_column_name(col_name: str) -> str:
    """å°†åˆ—åè§„èŒƒåŒ–ä¸ºç»Ÿä¸€çš„ç®€çŸ­åç§°ã€‚
    
    å¯¹äºé‡å¤çš„å±•å¼€åˆ—ï¼ˆå¦‚ kdigo_aki_aki, kdigo_creat_creaï¼‰ï¼Œè¿”å›è§„èŒƒåï¼ˆå¦‚ aki, creaï¼‰ã€‚
    å¯¹äºæ™®é€šåˆ—åï¼Œç›´æ¥è¿”å›åŸåã€‚
    
    Args:
        col_name: åŸå§‹åˆ—å
        
    Returns:
        è§„èŒƒåŒ–åçš„åˆ—å
    """
    return COLUMN_NORMALIZATION_MAP.get(col_name, col_name)


def count_unique_columns(column_names: list) -> int:
    """ç»Ÿè®¡å”¯ä¸€åˆ—æ•°é‡ï¼ˆè§„èŒƒåŒ–åå»é‡ï¼‰ã€‚
    
    æ¯ä¸ªå”¯ä¸€çš„æ•°æ®åˆ—ç®—ä½œä¸€ä¸ª conceptã€‚
    
    Args:
        column_names: åˆ—ååˆ—è¡¨
        
    Returns:
        å”¯ä¸€åˆ—æ•°é‡
    """
    normalized = set()
    for col in column_names:
        normalized.add(normalize_column_name(col))
    return len(normalized)


# ğŸ”§ ä¿æŒå‘åå…¼å®¹ï¼šæ—§å‡½æ•°åæŒ‡å‘æ–°å®ç°
def map_column_to_concept(col_name: str) -> str:
    """å°†åˆ—åæ˜ å°„åˆ°æ¦‚å¿µåï¼ˆå‘åå…¼å®¹ï¼Œç°åœ¨ä½¿ç”¨è§„èŒƒåŒ–ï¼‰ã€‚"""
    return normalize_column_name(col_name)


def count_unique_concepts(column_names: list) -> int:
    """ç»Ÿè®¡å”¯ä¸€æ¦‚å¿µæ•°é‡ï¼ˆå‘åå…¼å®¹ï¼Œç°åœ¨ä½¿ç”¨è§„èŒƒåŒ–ï¼‰ã€‚"""
    return count_unique_columns(column_names)


def get_unique_concepts(column_names: list) -> set:
    """è·å–å”¯ä¸€æ¦‚å¿µé›†åˆï¼ˆè§„èŒƒåŒ–åå»é‡ï¼‰ã€‚
    
    Args:
        column_names: åˆ—ååˆ—è¡¨
        
    Returns:
        å”¯ä¸€æ¦‚å¿µé›†åˆ
    """
    concepts = set()
    for col in column_names:
        concept = normalize_column_name(col)
        concepts.add(concept)
    return concepts

# ä¿æŒå‘åå…¼å®¹çš„CONCEPT_GROUPSï¼ˆé»˜è®¤ä¸­æ–‡ï¼‰
CONCEPT_GROUPS = {
    "â­ SOFA-2 è¯„åˆ† (2025æ–°æ ‡å‡†)": ['sofa2', 'sofa2_resp', 'sofa2_coag', 'sofa2_liver', 'sofa2_cardio', 'sofa2_cns', 'sofa2_renal'],
    "â­ Sepsis-3 è¯Šæ–­ (åŸºäºSOFA-2)": ['sep3_sofa2', 'susp_inf', 'infection_icd', 'samp'],
    "Sepsis-3 è¯Šæ–­ (åŸºäºSOFA-1)": ['sep3_sofa1', 'susp_inf', 'infection_icd', 'samp'],
    "ç”Ÿå‘½ä½“å¾ (vitals)": ['hr', 'map', 'sbp', 'dbp', 'temp', 'spo2', 'resp'],
    "å‘¼å¸æ”¯æŒ (respiratory)": ['pafi', 'safi', 'fio2', 'supp_o2', 'vent_ind', 'vent_start', 'vent_end', 'o2sat', 'sao2', 'mech_vent', 'ett_gcs', 'ecmo', 'ecmo_indication', 'adv_resp'],
    "å‘¼å¸æœºå‚æ•° (ventilator)": ['peep', 'tidal_vol', 'tidal_vol_set', 'pip', 'plateau_pres', 'mean_airway_pres', 'minute_vol', 'vent_rate', 'etco2', 'compliance', 'driving_pres', 'ps'],
    "è¡€æ°”åˆ†æ (blood gas)": ['be', 'cai', 'hbco', 'lact', 'methb', 'pco2', 'ph', 'po2', 'tco2'],
    "å®éªŒå®¤-ç”ŸåŒ– (chemistry)": ['alb', 'alp', 'alt', 'ast', 'bicar', 'bili', 'bili_dir', 'bun', 'ca', 'ck', 'ckmb', 'cl', 'crea', 'crp', 'glu', 'k', 'mg', 'na', 'phos', 'tnt', 'tri'],
    "å®éªŒå®¤-è¡€æ¶²å­¦ (hematology)": ['bnd', 'basos', 'eos', 'esr', 'fgn', 'hba1c', 'hct', 'hgb', 'inr_pt', 'lymph', 'mch', 'mchc', 'mcv', 'neut', 'plt', 'pt', 'ptt', 'rbc', 'rdw', 'wbc'],
    "è¡€ç®¡æ´»æ€§è¯ç‰© (vasopressors)": ['norepi_rate', 'norepi_dur', 'norepi_equiv', 'norepi60', 'epi_rate', 'epi_dur', 'epi60', 'dopa_rate', 'dopa_dur', 'dopa60', 'dobu_rate', 'dobu_dur', 'dobu60', 'adh_rate', 'phn_rate', 'vaso_ind', 'other_vaso'],
    "å…¶ä»–è¯ç‰© (medications)": ['abx', 'cort', 'dex', 'ins'],
    # ğŸ”§ 2026-02-04: ç§»é™¤é‡å¤çš„ kdigo_* æ¦‚å¿µ
    "è‚¾è„ä¸å°¿é‡ (renal)": ['urine', 'urine24', 'uo_6h', 'uo_12h', 'uo_24h', 'rrt', 'rrt_criteria', 'aki', 'aki_stage', 'aki_stage_creat', 'aki_stage_uo', 'aki_stage_rrt'],
    "ç¥ç»ç³»ç»Ÿ (neurological)": ['avpu', 'egcs', 'gcs', 'mgcs', 'rass', 'tgcs', 'vgcs', 'sedated_gcs', 'motor_response', 'delirium_positive', 'delirium_tx'],
    "å¾ªç¯æ”¯æŒ (circulatory)": ['mech_circ_support', 'circ_failure', 'circ_event'],
    "äººå£ç»Ÿè®¡ (demographics)": ['age', 'bmi', 'height', 'sex', 'weight', 'adm'],
    "SOFA-1 è¯„åˆ† (ä¼ ç»Ÿ)": ['sofa', 'sofa_resp', 'sofa_coag', 'sofa_liver', 'sofa_cardio', 'sofa_cns', 'sofa_renal'],
    "å…¶ä»–è¯„åˆ† (scores)": ['qsofa', 'sirs', 'mews', 'news'],
    "ç»“å±€ (outcome)": ['death', 'los_icu', 'los_hosp'],
}

# ğŸ†• ç‰¹æ®Šæ¦‚å¿µå®šä¹‰ï¼šè¿™äº›æ¦‚å¿µä¸åœ¨ concept-dict.json ä¸­ï¼Œéœ€è¦é€šè¿‡ä¸“ç”¨æ¨¡å—åŠ è½½
# æ ¼å¼: æ¦‚å¿µå -> (åŠ è½½å‡½æ•°æ¨¡å—, å‡½æ•°å, è¾“å‡ºåˆ—ååˆ—è¡¨)
SPECIAL_CONCEPTS = {
    # KDIGO AKI ç›¸å…³æ¦‚å¿µ - é€šè¿‡ kdigo_aki.py åŠ è½½
    'aki': ('pyricu.kdigo_aki', 'load_kdigo_aki', ['aki']),
    'aki_stage': ('pyricu.kdigo_aki', 'load_kdigo_aki', ['aki_stage']),
    'aki_stage_creat': ('pyricu.kdigo_aki', 'load_kdigo_aki', ['aki_stage_creat']),
    'aki_stage_uo': ('pyricu.kdigo_aki', 'load_kdigo_aki', ['aki_stage_uo']),
    'aki_stage_rrt': ('pyricu.kdigo_aki', 'load_kdigo_aki', ['aki_stage_rrt']),
    # å¾ªç¯è¡°ç«­ç›¸å…³æ¦‚å¿µ - é€šè¿‡ circ_failure.py åŠ è½½
    'circ_failure': ('pyricu.circ_failure', 'load_circ_failure', ['circ_failure']),
    'circ_event': ('pyricu.circ_failure', 'load_circ_failure', ['circ_event']),
}

# ç‰¹æ®Šæ¦‚å¿µçš„åˆ†ç»„ï¼ˆåŒä¸€æ¨¡å—çš„æ¦‚å¿µå¯ä»¥ä¸€èµ·åŠ è½½ï¼‰
SPECIAL_CONCEPT_GROUPS = {
    'kdigo_aki': ['aki', 'aki_stage', 'aki_stage_creat', 'aki_stage_uo', 'aki_stage_rrt'],
    'circ_failure': ['circ_failure', 'circ_event'],
}


def load_special_concepts(
    concepts: list,
    database: str,
    data_path: str,
    patient_ids: dict = None,
    max_patients: int = None,
    verbose: bool = False
) -> dict:
    """
    åŠ è½½ä¸åœ¨ concept-dict.json ä¸­çš„ç‰¹æ®Šæ¦‚å¿µã€‚
    
    è¿™äº›æ¦‚å¿µéœ€è¦é€šè¿‡ä¸“ç”¨æ¨¡å—ï¼ˆå¦‚ kdigo_aki.py, circ_failure.pyï¼‰åŠ è½½ã€‚
    
    Args:
        concepts: è¦åŠ è½½çš„æ¦‚å¿µåˆ—è¡¨
        database: æ•°æ®åº“åç§° ('miiv', 'eicu', 'aumc', 'hirid', 'mimic', 'sic')
        data_path: æ•°æ®è·¯å¾„
        patient_ids: æ‚£è€…IDè¿‡æ»¤å™¨ dict
        max_patients: æœ€å¤§æ‚£è€…æ•°
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
    Returns:
        dict: {concept_name: DataFrame} æ ¼å¼çš„ç»“æœ
    """
    results = {}
    
    # æŒ‰ç‰¹æ®Šæ¦‚å¿µåˆ†ç»„è¿›è¡ŒåŠ è½½ï¼Œé¿å…é‡å¤è°ƒç”¨
    loaded_groups = set()
    
    for concept in concepts:
        if concept not in SPECIAL_CONCEPTS:
            continue
            
        # æ£€æŸ¥è¿™ä¸ªæ¦‚å¿µå±äºå“ªä¸ªåˆ†ç»„
        for group_name, group_concepts in SPECIAL_CONCEPT_GROUPS.items():
            if concept in group_concepts and group_name not in loaded_groups:
                # åŠ è½½è¿™ä¸ªåˆ†ç»„çš„æ•°æ®
                try:
                    module_name, func_name, _ = SPECIAL_CONCEPTS[concept]
                    
                    # åŠ¨æ€å¯¼å…¥æ¨¡å—
                    import importlib
                    module = importlib.import_module(module_name)
                    load_func = getattr(module, func_name)
                    
                    # å‡†å¤‡åŠ è½½å‚æ•°
                    load_kwargs = {
                        'database': database,
                        'data_path': data_path,
                        'verbose': verbose,
                    }
                    if max_patients:
                        load_kwargs['max_patients'] = max_patients
                    if patient_ids:
                        # æå–æ‚£è€…IDåˆ—è¡¨
                        id_col = list(patient_ids.keys())[0] if patient_ids else None
                        if id_col:
                            load_kwargs['patient_ids'] = patient_ids[id_col]
                    
                    # è°ƒç”¨åŠ è½½å‡½æ•°
                    df = load_func(**load_kwargs)
                    
                    if isinstance(df, pd.DataFrame) and not df.empty:
                        # ä¸ºè¿™ä¸ªåˆ†ç»„ä¸­çš„æ¯ä¸ªæ¦‚å¿µåˆ›å»ºç»“æœ
                        for gc in group_concepts:
                            if gc in concepts:
                                _, _, output_cols = SPECIAL_CONCEPTS[gc]
                                # æ£€æŸ¥ DataFrame ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„åˆ—
                                available_cols = [c for c in output_cols if c in df.columns]
                                if available_cols:
                                    results[gc] = df
                    
                    loaded_groups.add(group_name)
                    
                except Exception as e:
                    if verbose:
                        print(f"Failed to load special concept {concept}: {e}")
                    continue
                break
    
    return results


def render_data_dictionary():
    """Render data dictionary (aligned with sidebar groups)."""
    lang = st.session_state.get('language', 'en')
    
    # åŒè¯­æ ‡é¢˜
    title = "### ğŸ“– Data Dictionary" if lang == 'en' else "### ğŸ“– æ•°æ®å­—å…¸"
    st.markdown(title)
    
    caption = "Feature abbreviations, English names, Chinese meanings, and units (aligned with module categories)" if lang == 'en' else "æ¯ä¸ªç‰¹å¾çš„ç¼©å†™ã€è‹±æ–‡åç§°ã€ä¸­æ–‡å«ä¹‰åŠå•ä½ï¼ˆä¸å·¦ä¾§æ¨¡å—åˆ†ç±»ä¸€è‡´ï¼‰"
    st.caption(caption)
    
    # è·å–åŒè¯­åˆ†ç»„
    concept_groups = get_concept_groups()
    
    # ä½¿ç”¨ tabs æˆ– expanders æ¥å±•ç¤º
    all_label = "All" if lang == 'en' else "å…¨éƒ¨"
    select_label = "Select Category" if lang == 'en' else "é€‰æ‹©ç±»åˆ«æŸ¥çœ‹"
    
    selected_category = st.selectbox(
        select_label,
        options=[all_label] + list(concept_groups.keys()),
        index=0,
        key="dict_category_select"
    )
    
    if selected_category == all_label:
        # æ˜¾ç¤ºæ‰€æœ‰ç±»åˆ«
        for cat_name, concepts in concept_groups.items():
            feat_label = "features" if lang == 'en' else "ä¸ªç‰¹å¾"
            with st.expander(f"ğŸ“ {cat_name} ({len(concepts)} {feat_label})", expanded=False):
                _render_category_table(concepts, lang)
    else:
        # åªæ˜¾ç¤ºé€‰ä¸­çš„ç±»åˆ«
        st.markdown(f"#### {selected_category}")
        _render_category_table(concept_groups[selected_category], lang)


def _render_category_table(concepts, lang='en'):
    """Render feature table for a single category with detailed descriptions."""
    rows = []
    for concept in concepts:
        if concept in CONCEPT_DICTIONARY:
            eng_name, chn_name, unit = CONCEPT_DICTIONARY[concept]
            # è·å–è¯¦ç»†æè¿°
            if concept in CONCEPT_DESCRIPTIONS:
                eng_desc, chn_desc = CONCEPT_DESCRIPTIONS[concept]
            else:
                eng_desc, chn_desc = '', ''
            
            if lang == 'en':
                rows.append({
                    'Abbr': concept,
                    'Full Name': eng_name,
                    'Description': eng_desc if eng_desc else chn_name,
                    'Unit': unit if unit else '-'
                })
            else:
                rows.append({
                    'ç¼©å†™': concept,
                    'å…¨å': eng_name,
                    'è¯¦ç»†è¯´æ˜': chn_desc if chn_desc else chn_name,
                    'å•ä½': unit if unit else '-'
                })
    
    if rows:
        df = pd.DataFrame(rows)
        if lang == 'en':
            st.dataframe(
                df,
                width="stretch",
                hide_index=True,
                column_config={
                    'Abbr': st.column_config.TextColumn('Abbr', width='small'),
                    'Full Name': st.column_config.TextColumn('Full Name', width='medium'),
                    'Description': st.column_config.TextColumn('Description', width='large'),
                    'Unit': st.column_config.TextColumn('Unit', width='small'),
                }
            )
        else:
            st.dataframe(
                df,
                width="stretch",
                hide_index=True,
                column_config={
                    'ç¼©å†™': st.column_config.TextColumn('ç¼©å†™', width='small'),
                    'å…¨å': st.column_config.TextColumn('å…¨å', width='medium'),
                    'è¯¦ç»†è¯´æ˜': st.column_config.TextColumn('è¯¦ç»†è¯´æ˜', width='large'),
                    'å•ä½': st.column_config.TextColumn('å•ä½', width='small'),
                }
            )


def check_data_status(data_path: str, database: str) -> dict:
    """æ£€æŸ¥æ•°æ®ç›®å½•çš„çŠ¶æ€ï¼Œè¿”å›æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯ã€‚"""
    from pathlib import Path
    
    path = Path(data_path)
    result = {
        'ready': False,
        'parquet_count': 0,
        'csv_count': 0,
        'csv_files': [],
        'parquet_files': [],
        'missing_tables': [],
    }
    
    # ç»Ÿè®¡ parquet æ–‡ä»¶ï¼ˆåŒ…æ‹¬åˆ†ç‰‡ç›®å½•ï¼‰
    parquet_files = list(path.glob('*.parquet'))
    # æ£€æŸ¥åˆ†ç‰‡ç›®å½•ï¼ˆå¦‚ chartevents/1.parquetï¼‰
    for subdir in path.iterdir():
        if subdir.is_dir():
            shard_files = list(subdir.glob('[0-9]*.parquet'))
            if shard_files:
                result['parquet_count'] += 1
                result['parquet_files'].append(subdir.name)
    
    result['parquet_count'] += len(parquet_files)
    result['parquet_files'].extend([f.stem for f in parquet_files])
    
    # ç»Ÿè®¡ CSV æ–‡ä»¶
    csv_files = list(path.glob('*.csv')) + list(path.glob('*.csv.gz'))
    result['csv_count'] = len(csv_files)
    result['csv_files'] = [f.name for f in csv_files]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ parquet æ–‡ä»¶ï¼ˆè‡³å°‘éœ€è¦ä¸€äº›æ ¸å¿ƒè¡¨ï¼‰
    core_tables = {
        'miiv': ['icustays', 'patients', 'admissions'],
        'eicu': ['patient', 'apachepatientresult'],
        'aumc': ['admissions', 'drugitems'],
        'hirid': ['general_table', 'observations'],
    }
    
    required = core_tables.get(database, [])
    found = set(f.lower() for f in result['parquet_files'])
    
    # å¦‚æœæœ‰ parquet æ–‡ä»¶ï¼Œæ£€æŸ¥æ ¸å¿ƒè¡¨æ˜¯å¦å­˜åœ¨
    if result['parquet_count'] > 0:
        missing = [t for t in required if t not in found]
        if len(missing) <= 1:  # å…è®¸ç¼ºå°‘1ä¸ªæ ¸å¿ƒè¡¨
            result['ready'] = True
        else:
            result['missing_tables'] = missing
    
    return result


def convert_data_with_progress(data_path: str, database: str):
    """å¸¦è¿›åº¦æ¡çš„æ•°æ®è½¬æ¢åŠŸèƒ½ã€‚"""
    import time
    
    lang = st.session_state.get('language', 'en')
    
    conv_title = "ğŸ”„ Data Conversion" if lang == 'en' else "ğŸ”„ æ•°æ®è½¬æ¢"
    st.markdown(f"### {conv_title}")
    
    warn_msg = "âš ï¸ **Note**: Converting large datasets may take a long time (30min~2hrs), please be patient." if lang == 'en' else "âš ï¸ **æ³¨æ„**ï¼šè½¬æ¢å¤§å‹æ•°æ®é›†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆ30åˆ†é’Ÿ~2å°æ—¶ï¼‰ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚"
    st.warning(warn_msg)
    
    info_msg = "ğŸ’¡ Using DuckDB for memory-efficient conversion. Large tables will be bucket-partitioned automatically." if lang == 'en' else "ğŸ’¡ ä½¿ç”¨ DuckDB è¿›è¡Œå†…å­˜å®‰å…¨è½¬æ¢ï¼Œå¤§è¡¨å°†è‡ªåŠ¨è¿›è¡Œåˆ†æ¡¶ä¼˜åŒ–ã€‚"
    st.info(info_msg)
    
    # å®šä¹‰éœ€è¦åˆ†æ¡¶è½¬æ¢çš„å¤§è¡¨
    BUCKET_TABLES = {
        'miiv': {
            'chartevents': ('itemid', 100),
            'labevents': ('itemid', 100),
            'inputevents': ('itemid', 50),
        },
        'eicu': {
            'nursecharting': ('nursingchartcelltypevalname', 30),  # æŒ‰å­—ç¬¦ä¸²hash
            'lab': ('labname', 50),
        },
        'aumc': {
            'numericitems': ('itemid', 100),
            'listitems': ('itemid', 50),
        },
        'hirid': {
            'observations': ('variableid', 100),
            'pharma': ('pharmaid', 50),
        },
        'mimic': {
            'chartevents': ('itemid', 100),
            'labevents': ('itemid', 100),
        },
        'sic': {
            'data_float_h': ('dataid', 50),
            'laboratory': ('laboratoryid', 50),
        },
    }
    
    try:
        from pyricu.duckdb_converter import DuckDBConverter
        from pyricu.bucket_converter import convert_to_buckets, BucketConfig
        import gc
        
        converter = DuckDBConverter(
            data_path=data_path, 
            memory_limit_gb=12.0,
            verbose=True
        )
        
        # è·å–éœ€è¦è½¬æ¢çš„æ–‡ä»¶åˆ—è¡¨
        csv_files = converter._find_csv_files()
        total_files = len(csv_files)
        
        if total_files == 0:
            err_msg = "No CSV files found to convert" if lang == 'en' else "æœªæ‰¾åˆ°éœ€è¦è½¬æ¢çš„ CSV æ–‡ä»¶"
            st.error(err_msg)
            return
        
        # åˆ†ç±»æ–‡ä»¶ï¼šå¤§è¡¨ç”¨åˆ†æ¡¶ï¼Œå°è¡¨ç”¨æ™®é€šè½¬æ¢
        bucket_tables_config = BUCKET_TABLES.get(database, {})
        bucket_files = []
        normal_files = []
        
        for csv_file in csv_files:
            stem = csv_file.stem.lower().replace('.csv', '')
            if stem in bucket_tables_config:
                bucket_files.append((csv_file, bucket_tables_config[stem]))
            else:
                normal_files.append(csv_file)
        
        detect_msg = f"ğŸ“Š Detected **{len(normal_files)}** normal + **{len(bucket_files)}** large tables" if lang == 'en' else f"ğŸ“Š å…±æ£€æµ‹åˆ° **{len(normal_files)}** ä¸ªæ™®é€šè¡¨ + **{len(bucket_files)}** ä¸ªå¤§è¡¨"
        st.markdown(detect_msg)
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        details_container = st.container()
        
        converted = 0
        skipped = 0
        failed = 0
        total = len(normal_files) + len(bucket_files)
        current = 0
        
        # 1. å…ˆè½¬æ¢æ™®é€šè¡¨
        for csv_file in normal_files:
            current += 1
            file_name = csv_file.name
            file_size_mb = csv_file.stat().st_size / (1024 * 1024)
            
            processing_msg = f"**Processing**: `{file_name}` ({file_size_mb:.1f} MB) [{current}/{total}]" if lang == 'en' else f"**æ­£åœ¨å¤„ç†**: `{file_name}` ({file_size_mb:.1f} MB) [{current}/{total}]"
            status_text.markdown(processing_msg)
            
            parquet_path = converter._get_parquet_path(csv_file)
            if parquet_path.exists():
                skipped += 1
                with details_container:
                    st.caption(f"â­ï¸ {file_name} (exists)")
            else:
                try:
                    result = converter.convert_file(csv_file)
                    if result['status'] == 'success':
                        converted += 1
                        with details_container:
                            st.caption(f"âœ… {file_name}: {result['row_count']:,} rows")
                    else:
                        failed += 1
                        with details_container:
                            st.caption(f"âŒ {file_name}: {result.get('error', 'unknown')[:40]}")
                except Exception as e:
                    failed += 1
                    with details_container:
                        st.caption(f"âŒ {file_name}: {str(e)[:40]}")
            
            progress_bar.progress(current / total)
            gc.collect()
        
        # 2. åˆ†æ¡¶è½¬æ¢å¤§è¡¨
        for csv_file, (partition_col, num_buckets) in bucket_files:
            current += 1
            file_name = csv_file.name
            file_size_mb = csv_file.stat().st_size / (1024 * 1024)
            stem = csv_file.stem.lower().replace('.csv', '')
            
            processing_msg = f"**Bucketing**: `{file_name}` ({file_size_mb:.1f} MB) â†’ {num_buckets} buckets [{current}/{total}]" if lang == 'en' else f"**åˆ†æ¡¶è½¬æ¢**: `{file_name}` ({file_size_mb:.1f} MB) â†’ {num_buckets} ä¸ªæ¡¶ [{current}/{total}]"
            status_text.markdown(processing_msg)
            
            # æ£€æŸ¥åˆ†æ¡¶ç›®å½•æ˜¯å¦å·²å­˜åœ¨
            bucket_dir = csv_file.parent / f"{stem}_bucket"
            if bucket_dir.exists() and list(bucket_dir.glob('*.parquet')):
                skipped += 1
                with details_container:
                    st.caption(f"â­ï¸ {file_name} (bucket exists)")
            else:
                try:
                    config = BucketConfig(
                        num_buckets=num_buckets,
                        partition_col=partition_col,
                        memory_limit='4GB'
                    )
                    result = convert_to_buckets(
                        source_path=csv_file,
                        output_dir=bucket_dir,
                        config=config,
                        overwrite=True
                    )
                    if result.success:
                        converted += 1
                        with details_container:
                            st.caption(f"âœ… {file_name} â†’ {result.num_buckets} buckets, {result.total_rows:,} rows")
                    else:
                        failed += 1
                        with details_container:
                            st.caption(f"âŒ {file_name}: {result.error[:40] if result.error else 'unknown'}")
                except Exception as e:
                    failed += 1
                    with details_container:
                        st.caption(f"âŒ {file_name}: {str(e)[:40]}")
            
            progress_bar.progress(current / total)
            gc.collect()
        
        # è½¬æ¢å®Œæˆ
        progress_bar.progress(1.0)
        status_text.empty()
        
        if lang == 'en':
            summary = f"""
            âœ… **Conversion Complete!**
            - Successfully converted: {converted} files
            - Already existed/skipped: {skipped} files
            - Failed: {failed} files
            """
        else:
            summary = f"""
            âœ… **è½¬æ¢å®Œæˆï¼**
            - æˆåŠŸè½¬æ¢: {converted} ä¸ªæ–‡ä»¶
            - å·²å­˜åœ¨è·³è¿‡: {skipped} ä¸ªæ–‡ä»¶
            - è½¬æ¢å¤±è´¥: {failed} ä¸ªæ–‡ä»¶
            """
        st.success(summary)
        
        if failed == 0:
            st.balloons()
            all_done_msg = "ğŸ‰ All data converted successfully, you can now load the data!" if lang == 'en' else "ğŸ‰ æ‰€æœ‰æ•°æ®å·²è½¬æ¢å®Œæˆï¼Œç°åœ¨å¯ä»¥åŠ è½½æ•°æ®äº†ï¼"
            st.info(all_done_msg)
        else:
            partial_msg = "Some files failed to convert, but you can still try loading the converted data." if lang == 'en' else "éƒ¨åˆ†æ–‡ä»¶è½¬æ¢å¤±è´¥ï¼Œä½†æ‚¨ä»å¯ä»¥å°è¯•åŠ è½½å·²è½¬æ¢çš„æ•°æ®ã€‚"
            st.warning(partial_msg)
            
    except ImportError as e:
        import_err = f"Data converter module not installed: {e}" if lang == 'en' else f"æ•°æ®è½¬æ¢æ¨¡å—æœªå®‰è£…: {e}"
        st.error(import_err)
    except Exception as e:
        conv_err = f"Conversion error: {str(e)}" if lang == 'en' else f"è½¬æ¢è¿‡ç¨‹å‡ºé”™: {str(e)}"
        st.error(conv_err)


# ============ ğŸš€ æ™ºèƒ½ç¡¬ä»¶æ£€æµ‹ä¸åŠ¨æ€å¹¶è¡Œé…ç½® ============

def get_system_resources():
    """æ£€æµ‹ç³»ç»Ÿç¡¬ä»¶èµ„æºã€‚
    
    ä½¿ç”¨ç»Ÿä¸€çš„ parallel_config æ¨¡å—ï¼Œç¡®ä¿ä»£ç ç«¯å’Œ Web ç«¯é…ç½®ä¸€è‡´ã€‚
    
    Returns:
        dict: åŒ…å« cpu_count, memory_gb, recommended_workers, recommended_backend
    """
    try:
        from ..parallel_config import get_global_config
        config = get_global_config()
        
        # æ ¹æ®é…ç½®é€‰æ‹©åç«¯
        if config.cpu_count >= 16 and config.total_memory_gb >= 32:
            recommended_backend = "loky"
        else:
            recommended_backend = "thread"
        
        return {
            'cpu_count': config.cpu_count,
            'total_memory_gb': round(config.total_memory_gb, 1),
            'available_memory_gb': round(config.available_memory_gb, 1),
            'recommended_workers': config.max_workers,
            'recommended_backend': recommended_backend,
            'performance_tier': config.performance_tier,
            'buckets_per_batch': config.buckets_per_batch,
        }
    except ImportError:
        # Fallback: ç›´æ¥æ£€æµ‹ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        import os
        try:
            import psutil
            mem_info = psutil.virtual_memory()
            total_memory_gb = mem_info.total / (1024 ** 3)
            available_memory_gb = mem_info.available / (1024 ** 3)
        except:
            total_memory_gb = 8
            available_memory_gb = 4
        
        cpu_count = os.cpu_count() or 4
        max_workers_by_memory = int(available_memory_gb / 2)
        max_workers_by_cpu = int(cpu_count * 0.75)
        recommended_workers = min(max_workers_by_memory, max_workers_by_cpu, 64)
        recommended_workers = max(recommended_workers, 1)
        
        if cpu_count >= 16 and total_memory_gb >= 32:
            recommended_backend = "loky"
        else:
            recommended_backend = "thread"
        
        return {
            'cpu_count': cpu_count,
            'total_memory_gb': round(total_memory_gb, 1),
            'available_memory_gb': round(available_memory_gb, 1),
            'recommended_workers': recommended_workers,
            'recommended_backend': recommended_backend,
        }


def get_optimal_parallel_config(num_patients: int = None, task_type: str = 'load'):
    """æ ¹æ®ç³»ç»Ÿèµ„æºå’Œä»»åŠ¡è§„æ¨¡è¿”å›æœ€ä¼˜çš„å¹¶è¡Œé…ç½®ã€‚
    
    Args:
        num_patients: è¦å¤„ç†çš„æ‚£è€…æ•°é‡ï¼ŒNone è¡¨ç¤ºæœªçŸ¥/å…¨é‡
        task_type: ä»»åŠ¡ç±»å‹ ('load', 'export', 'preview')
    
    Returns:
        tuple: (parallel_workers, parallel_backend)
    """
    resources = get_system_resources()
    base_workers = resources['recommended_workers']
    backend = resources['recommended_backend']
    
    # æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´
    if task_type == 'preview':
        # é¢„è§ˆåªéœ€å°‘é‡æ•°æ®ï¼Œä¸éœ€è¦å¤ªå¤šå¹¶è¡Œ
        workers = min(base_workers, 4)
        backend = "thread"  # é¢„è§ˆç”¨çº¿ç¨‹æ›´å¿«å¯åŠ¨
    elif task_type == 'load':
        # æ•°æ®åŠ è½½æ ¹æ®æ‚£è€…æ•°é‡è°ƒæ•´
        if num_patients is None or num_patients >= 50000:
            workers = base_workers  # å…¨é‡ä½¿ç”¨æ¨èé…ç½®
        elif num_patients >= 10000:
            workers = min(base_workers, max(8, base_workers // 2))
        elif num_patients >= 2000:
            workers = min(base_workers, 4)
        else:
            workers = 1  # å°‘é‡æ‚£è€…ä¸éœ€è¦å¹¶è¡Œ
    elif task_type == 'export':
        # å¯¼å‡ºä»»åŠ¡å¯ä»¥ä½¿ç”¨æ›´å¤šèµ„æº
        workers = base_workers
    else:
        workers = min(base_workers, 8)
    
    # Streamlit webapp ç¯å¢ƒä¸‹ï¼Œçº¿ç¨‹é€šå¸¸æ›´å®‰å…¨
    # åªæœ‰åœ¨æ˜ç¡®é«˜é…ç½®ç¯å¢ƒä¸‹æ‰ä½¿ç”¨è¿›ç¨‹æ± 
    if backend == "loky" and task_type != 'export':
        backend = "thread"  # webapp ä¸­ä¼˜å…ˆä½¿ç”¨çº¿ç¨‹
    
    return workers, backend


def init_session_state():
    """åˆå§‹åŒ– session stateã€‚"""
    # ğŸ†• å…¥å£æ¨¡å¼ï¼š'none' (å…¥å£é¡µ), 'demo' (æ¼”ç¤ºæ¨¡å¼), 'real' (çœŸå®æ•°æ®æ¨¡å¼)
    if 'entry_mode' not in st.session_state:
        st.session_state.entry_mode = 'none'
    if 'data_path' not in st.session_state:
        st.session_state.data_path = None
    if 'database' not in st.session_state:
        st.session_state.database = 'miiv'
    if 'loaded_concepts' not in st.session_state:
        st.session_state.loaded_concepts = {}
    if 'patient_ids' not in st.session_state:
        st.session_state.patient_ids = []
    if 'all_patient_count' not in st.session_state:
        st.session_state.all_patient_count = 0
    if 'selected_patient' not in st.session_state:
        st.session_state.selected_patient = None
    if 'use_mock_data' not in st.session_state:
        st.session_state.use_mock_data = False
    if 'id_col' not in st.session_state:
        st.session_state.id_col = 'stay_id'
    # æ–°å¢ï¼šç”¨äºç®€åŒ–æµç¨‹çš„çŠ¶æ€
    if 'selected_concepts' not in st.session_state:
        st.session_state.selected_concepts = []
    if 'export_completed' not in st.session_state:
        st.session_state.export_completed = False
    if 'mock_params' not in st.session_state:
        st.session_state.mock_params = {'n_patients': 100, 'hours': 72}
    if 'trigger_export' not in st.session_state:
        st.session_state.trigger_export = False
    if 'export_format' not in st.session_state:
        st.session_state.export_format = 'Parquet'  # é»˜è®¤Parquet
    if 'export_path' not in st.session_state:
        st.session_state.export_path = os.path.expanduser('~/easyicu_export')
    if 'path_validated' not in st.session_state:
        st.session_state.path_validated = False
    if 'language' not in st.session_state:
        st.session_state.language = 'en'  # é»˜è®¤è‹±æ–‡
    # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæ‚£è€…æ•°é‡é™åˆ¶
    # å…¨é‡ MIIV çº¦ 5ä¸‡æ‚£è€…/4000ä¸‡è¡Œï¼ŒåŠ è½½éœ€ ~50sï¼›100æ‚£è€…çº¦2s
    # ğŸ”§ FIX 2025-01-28: é»˜è®¤å…¨é‡åŠ è½½ï¼ˆ0=ä¸é™åˆ¶ï¼‰ï¼Œæ»¡è¶³å¤§å¤šæ•°ç”¨æˆ·éœ€æ±‚
    if 'patient_limit' not in st.session_state:
        st.session_state.patient_limit = 0  # é»˜è®¤å…¨é‡åŠ è½½
    if 'available_patient_ids' not in st.session_state:
        st.session_state.available_patient_ids = None
    # ğŸ†• æ­¥éª¤ç¡®è®¤çŠ¶æ€
    if 'step1_confirmed' not in st.session_state:
        st.session_state.step1_confirmed = False
    if 'step2_confirmed' not in st.session_state:
        st.session_state.step2_confirmed = False


# ============ è¾…åŠ©å‡½æ•°ï¼šè·å–å®Œæ•´çš„ mock_paramsï¼ˆåŒ…å«æœ€æ–°çš„ cohort_filterï¼‰ ============
def get_mock_params_with_cohort():
    """
    è·å–å®Œæ•´çš„ mock_paramsï¼ŒåŒ…å«æœ€æ–°çš„ cohort_filterã€‚
    
    ç”±äº Streamlit çš„æ¸²æŸ“é¡ºåºï¼ŒStep 1 (æ•°æ®æº) åœ¨ Step 2 (é˜Ÿåˆ—ç­›é€‰) ä¹‹å‰æ‰§è¡Œï¼Œ
    æ‰€ä»¥ mock_params ä¸­çš„ cohort_filter å¯èƒ½ä¸æ˜¯æœ€æ–°çš„ã€‚
    
    æ­¤å‡½æ•°ç¡®ä¿åœ¨è°ƒç”¨ generate_mock_data æ—¶ä½¿ç”¨æœ€æ–°çš„ cohort_filterã€‚
    """
    params = st.session_state.get('mock_params', {'n_patients': 100, 'hours': 72}).copy()
    
    # å¦‚æœå¯ç”¨äº†é˜Ÿåˆ—ç­›é€‰ï¼Œæ·»åŠ æœ€æ–°çš„ cohort_filter
    if st.session_state.get('cohort_enabled', False):
        cohort_filter = st.session_state.get('cohort_filter', None)
        if cohort_filter:
            params['cohort_filter'] = cohort_filter
    
    return params


# ============ å›½é™…åŒ–æ–‡æœ¬ ============
TEXTS = {
    'en': {
        'app_title': 'ğŸ¥ EasyICU Data Explorer',
        'app_subtitle': 'Local ICU Data Analytics Platform',
        'select_mode': 'ğŸ¯ Select Mode',
        'mode_extract': 'ğŸ’¾ Data Extraction (New Data)',
        'mode_viz': 'ğŸ“Š Quick Visualization (Existing Data)',
        'step1': 'Step 1: Data Source',
        'step2': 'Step 2: Cohort Selection',
        'step3': 'Step 3: Select Features',
        'step4': 'Step 4: Export Data',
        'demo_mode': 'ğŸ­ Demo Mode',
        'real_data': 'ğŸ“ Real Data',
        'demo_mode_desc': 'System generates simulated ICU data',
        'select_database': 'Select Database',
        'data_path': 'Data Path',
        'validate_path': 'âœ… Validate Path',
        'path_valid': 'âœ… Path Valid',
        'path_invalid': 'âŒ Path Invalid',
        'feature_groups': 'Feature Groups',
        'export_path': 'Export Path',
        'export_format': 'Export Format',
        'export_data': 'ğŸ’¾ Export Data',
        'quick_viz': 'ğŸ“ˆ Quick Visualization',
        'load_data': 'ğŸ” Load Data',
        'loading': 'Loading...',
        'data_loaded': 'âœ… Data Loaded',
        'features_loaded': 'features loaded',
        'patients_loaded': 'patients loaded',
        'select_tables': 'Select Tables to Load',
        'found_files': 'Found {n} data files',
        'no_files': 'No data files found in this directory',
        'dir_not_exist': 'Directory does not exist',
        'data_dir': 'ğŸ“ Data Directory',
        'file_list': 'ğŸ“‹ File List',
        'loaded_data': 'ğŸ“Š Loaded Data',
        'view_features': 'View Feature List',
        'load_hint': 'ğŸ’¡ Select a data directory and load data to start visualization',
        'home': 'ğŸ“š Tutorial',
        'quick_visualization': 'ğŸ“Š Quick Visualization',
        'cohort_compare': 'ğŸ“Š Cohort Analysis',
        'sub_data_table': 'ğŸ“‹ Data Tables',
        'sub_timeseries': 'ğŸ“ˆ Time Series',
        'sub_patient_view': 'ğŸ¥ Patient View',
        'sub_data_quality': 'ğŸ“Š Data Quality',
        'ready': 'ğŸ‰ Ready!',
        'ready_desc': 'Data loaded, you can start exploring.',
        'database': 'Database',
        'features': 'Features',
        'patients': 'Patients',
        'status': 'Status',
        'start_analysis': 'ğŸš€ Start Analysis',
        'select_tab': 'Select a tab above to explore data:',
        'data_summary': 'ğŸ“‹ Data Summary',
        'n_patients': 'Number of Patients',
        'n_hours': 'Data Duration (hours)',
        'current_task': 'ğŸ“ Current Task',
        'configure_source': 'Configure Data Source',
        'select_features': 'Select Features',
        'export_or_preview': 'Export Data or Load Preview',
        'data_dict': 'ğŸ“– Data Dictionary',
        'view_desc': 'View Feature Descriptions',
    },
    'zh': {
        'app_title': 'ğŸ¥ EasyICU æ•°æ®æ¢ç´¢å™¨',
        'app_subtitle': 'æœ¬åœ° ICU æ•°æ®åˆ†æä¸å¯è§†åŒ–å¹³å°',
        'select_mode': 'ğŸ¯ é€‰æ‹©æ“ä½œæ¨¡å¼',
        'mode_extract': 'ğŸ’¾ æ•°æ®æå–å¯¼å‡ºï¼ˆæ–°æ•°æ®ï¼‰',
        'mode_viz': 'ğŸ“Š å¿«é€Ÿå¯è§†åŒ–ï¼ˆå·²æœ‰æ•°æ®ï¼‰',
        'step1': 'æ­¥éª¤1: æ•°æ®æº',
        'step2': 'æ­¥éª¤2: é˜Ÿåˆ—ç­›é€‰',
        'step3': 'æ­¥éª¤3: é€‰æ‹©ç‰¹å¾',
        'step4': 'æ­¥éª¤4: å¯¼å‡ºæ•°æ®',
        'demo_mode': 'ğŸ­ æ¼”ç¤ºæ¨¡å¼',
        'real_data': 'ğŸ“ çœŸå®æ•°æ®',
        'demo_mode_desc': 'ç³»ç»Ÿç”Ÿæˆæ¨¡æ‹ŸICUæ•°æ®ä¾›ä½“éªŒ',
        'select_database': 'é€‰æ‹©æ•°æ®åº“',
        'data_path': 'æ•°æ®è·¯å¾„',
        'validate_path': 'âœ… éªŒè¯è·¯å¾„',
        'path_valid': 'âœ… è·¯å¾„æœ‰æ•ˆ',
        'path_invalid': 'âŒ è·¯å¾„æ— æ•ˆ',
        'feature_groups': 'ç‰¹å¾åˆ†ç»„',
        'export_path': 'å¯¼å‡ºè·¯å¾„',
        'export_format': 'å¯¼å‡ºæ ¼å¼',
        'export_data': 'ğŸ’¾ å¯¼å‡ºæ•°æ®',
        'quick_viz': 'ğŸ“ˆ å¿«é€Ÿå¯è§†åŒ–',
        'load_data': 'ğŸ” åŠ è½½æ•°æ®',
        'loading': 'åŠ è½½ä¸­...',
        'data_loaded': 'âœ… æ•°æ®å·²åŠ è½½',
        'features_loaded': 'ä¸ªç‰¹å¾å·²åŠ è½½',
        'patients_loaded': 'ä¸ªæ‚£è€…å·²åŠ è½½',
        'select_tables': 'é€‰æ‹©è¦åŠ è½½çš„è¡¨æ ¼',
        'found_files': 'å‘ç° {n} ä¸ªæ•°æ®æ–‡ä»¶',
        'no_files': 'è¯¥ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶',
        'dir_not_exist': 'ç›®å½•ä¸å­˜åœ¨',
        'data_dir': 'ğŸ“ æ•°æ®ç›®å½•',
        'file_list': 'ğŸ“‹ æ–‡ä»¶åˆ—è¡¨',
        'loaded_data': 'ğŸ“Š å·²åŠ è½½æ•°æ®',
        'view_features': 'æŸ¥çœ‹ç‰¹å¾åˆ—è¡¨',
        'load_hint': 'ğŸ’¡ é€‰æ‹©æ•°æ®ç›®å½•å¹¶åŠ è½½æ•°æ®åï¼Œå³å¯åœ¨å³ä¾§è¿›è¡Œå¯è§†åŒ–åˆ†æ',
        'home': 'ğŸ“š æ•™ç¨‹',
        'quick_visualization': 'ğŸ“Š å¿«é€Ÿå¯è§†åŒ–',
        'cohort_compare': 'ğŸ“Š é˜Ÿåˆ—åˆ†æ',
        'sub_data_table': 'ğŸ“‹ æ•°æ®å¤§è¡¨',
        'sub_timeseries': 'ğŸ“ˆ æ—¶åºåˆ†æ',
        'sub_patient_view': 'ğŸ¥ æ‚£è€…è§†å›¾',
        'sub_data_quality': 'ğŸ“Š æ•°æ®è´¨é‡',
        'ready': 'ğŸ‰ å‡†å¤‡å°±ç»ªï¼',
        'ready_desc': 'æ•°æ®å·²åŠ è½½ï¼Œæ‚¨å¯ä»¥å¼€å§‹æ¢ç´¢åˆ†æäº†ã€‚',
        'database': 'æ•°æ®åº“',
        'features': 'ç‰¹å¾',
        'patients': 'æ‚£è€…',
        'status': 'çŠ¶æ€',
        'start_analysis': 'ğŸš€ å¼€å§‹åˆ†æ',
        'select_tab': 'é€‰æ‹©ä¸Šæ–¹çš„æ ‡ç­¾é¡µå¼€å§‹æ¢ç´¢æ•°æ®ï¼š',
        'data_summary': 'ğŸ“‹ æ•°æ®æ‘˜è¦',
        'n_patients': 'æ‚£è€…æ•°é‡',
        'n_hours': 'æ•°æ®æ—¶é•¿(å°æ—¶)',
        'current_task': 'ğŸ“ å½“å‰ä»»åŠ¡',
        'configure_source': 'é…ç½®æ•°æ®æº',
        'select_features': 'é€‰æ‹©ç‰¹å¾',
        'export_or_preview': 'å¯¼å‡ºæ•°æ®æˆ–åŠ è½½é¢„è§ˆ',
        'data_dict': 'ğŸ“– æ•°æ®å­—å…¸',
        'view_desc': 'æŸ¥çœ‹ç‰¹å¾è¯´æ˜',
    }
}

def get_text(key: str) -> str:
    """æ ¹æ®å½“å‰è¯­è¨€è·å–æ–‡æœ¬ã€‚"""
    lang = st.session_state.get('language', 'en')
    return TEXTS.get(lang, TEXTS['en']).get(key, key)


def strip_emoji(text: str) -> str:
    """ç§»é™¤å­—ç¬¦ä¸²ä¸­çš„emojiå­—ç¬¦ï¼Œç”¨äºCSVå¯¼å‡ºç­‰åœºæ™¯é˜²æ­¢ä¹±ç ã€‚"""
    import re
    # åŒ¹é…æ›´å…¨é¢çš„emojièŒƒå›´
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags (iOS)
        "\U00002702-\U000027B0"  # dingbats
        "\U000024C2-\U0001F251"
        "\U0001F900-\U0001F9FF"  # Supplemental Symbols and Pictographs
        "\U0001FA00-\U0001FA6F"  # Chess Symbols
        "\U0001FA70-\U0001FAFF"  # Symbols and Pictographs Extended-A
        "\U00002600-\U000026FF"  # Misc symbols (includes ğŸ§ª etc)
        "\U00002B50-\U00002B55"  # stars
        "\U0001F004-\U0001F0CF"  # mahjong
        "\U0000203C-\U00003299"  # misc symbols
        "]+",
        flags=re.UNICODE
    )
    return emoji_pattern.sub('', text).strip()


def safe_format_number(val, decimals: int = 0) -> str:
    """å®‰å…¨åœ°æ ¼å¼åŒ–æ•°å€¼ï¼Œå¤„ç†éæ•°å€¼ç±»å‹ï¼ˆå¦‚å­—ç¬¦ä¸²ã€NaNç­‰ï¼‰ã€‚
    
    Args:
        val: è¦æ ¼å¼åŒ–çš„å€¼
        decimals: å°æ•°ä½æ•°
        
    Returns:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    import numpy as np
    
    # å¤„ç† None å’Œ NaN
    if val is None or (isinstance(val, float) and np.isnan(val)):
        return "N/A"
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œç›´æ¥è¿”å›
    if isinstance(val, (str, np.str_)):
        return str(val)
    
    # å°è¯•æ•°å€¼æ ¼å¼åŒ–
    try:
        return f"{float(val):.{decimals}f}"
    except (ValueError, TypeError):
        return str(val)


def validate_database_path(data_path: str, database: str) -> dict:
    """
    éªŒè¯æ•°æ®è·¯å¾„æ˜¯å¦åŒ…å«æŒ‡å®šæ•°æ®åº“æ‰€éœ€çš„æ–‡ä»¶ã€‚
    ä¸¥æ ¼æ£€æŸ¥æ¯ä¸ªæ¨¡å—æ‰€éœ€çš„æ‰€æœ‰è¡¨ã€‚
    
    è¿”å›:
        dict: {'valid': bool, 'message': str, 'suggestion': str (å¯é€‰)}
    """
    path = Path(data_path)
    lang = st.session_state.get('language', 'en')
    
    # å„æ•°æ®åº“éœ€è¦çš„æ ¸å¿ƒè¡¨ï¼ˆParquetæ ¼å¼ï¼‰- åŒ…æ‹¬åˆ†ç‰‡ç›®å½•
    # åˆ†ä¸ºå¿…éœ€è¡¨å’Œå¯é€‰è¡¨
    required_parquet_tables = {
        'miiv': {
            'core': ['icustays', 'patients', 'admissions'],  # æ ¸å¿ƒIDè¡¨
            'clinical': ['chartevents', 'labevents', 'inputevents', 'outputevents'],  # ä¸´åºŠæ•°æ®
            'medication': ['prescriptions', 'ingredientevents'],  # è¯ç‰©æ•°æ®
            'other': ['procedureevents', 'd_items', 'd_labitems'],  # å…¶ä»–
        },
        'eicu': {
            'core': ['patient'],
            'clinical': ['vitalperiodic', 'lab', 'nursecharting'],
            'medication': ['infusiondrug', 'medication'],
        },
        'aumc': {
            'core': ['admissions'],
            'clinical': ['numericitems', 'listitems'],
            'medication': ['drugitems'],
        },
        'hirid': {
            'core': ['general_table'],
            'clinical': ['observations'],
            'medication': ['pharma_records'],
        },
        'mimic': {  # MIMIC-III
            'core': ['icustays', 'patients', 'admissions'],
            'clinical': ['chartevents', 'labevents', 'outputevents'],
            'medication': ['prescriptions', 'inputevents_cv', 'inputevents_mv'],
        },
        'sic': {  # SICdb
            'core': ['cases'],
            'clinical': ['data_float_h', 'laboratory'],
            'medication': ['medication'],
        },
    }
    
    # å„æ•°æ®åº“éœ€è¦çš„æ ¸å¿ƒè¡¨ï¼ˆCSV/GZæ ¼å¼ - åŸå§‹æ–‡ä»¶ï¼‰
    required_csv_files = {
        'miiv': ['icustays.csv', 'chartevents.csv', 'labevents.csv', 'prescriptions.csv', 'inputevents.csv'],
        'eicu': ['patient.csv', 'vitalPeriodic.csv', 'lab.csv'],
        'aumc': ['admissions.csv', 'numericitems.csv', 'drugitems.csv'],
        'hirid': ['general_table.csv', 'pharma_records.csv'],
        'mimic': ['icustays.csv', 'chartevents.csv', 'labevents.csv', 'prescriptions.csv'],
        'sic': ['cases.csv', 'data_float_h.csv', 'laboratory.csv', 'medication.csv'],
    }
    
    db_name = {
        'miiv': 'MIMIC-IV', 'eicu': 'eICU-CRD',
        'aumc': 'AmsterdamUMCdb', 'hirid': 'HiRID',
        'mimic': 'MIMIC-III', 'sic': 'SICdb'
    }.get(database, database.upper())
    
    # æ£€æŸ¥Parquetæ–‡ä»¶å’Œåˆ†ç‰‡ç›®å½•
    parquet_files = list(path.rglob('*.parquet'))
    parquet_names = set(f.name.lower().replace('.parquet', '') for f in parquet_files)
    
    # å¯¹äºæŸäº›æ•°æ®åº“ï¼ˆå¦‚ HiRIDï¼‰ï¼ŒæŸäº›æ ¸å¿ƒè¡¨å¯èƒ½æ˜¯ CSV æ ¼å¼
    csv_files = list(path.glob('*.csv'))
    csv_names = set(f.name.lower().replace('.csv', '') for f in csv_files)
    
    # æ£€æŸ¥åˆ†ç‰‡ç›®å½•ï¼ˆå¦‚ chartevents/1.parquetï¼‰
    parquet_dirs = set()
    for pf in parquet_files:
        try:
            if pf.parent != path:
                rel = pf.parent.relative_to(path)
                # å¦‚æœæ˜¯ xxx/1.parquet æ ¼å¼ï¼Œè®°å½• xxx
                if pf.stem.isdigit():
                    parquet_dirs.add(pf.parent.name.lower())
        except ValueError:
            pass
    
    # æ£€æŸ¥åˆ†æ¡¶ç›®å½•ï¼ˆå¦‚ chartevents_bucket/bucket_id=*/data.parquetï¼‰
    bucket_dirs = set()
    for subdir in path.iterdir():
        if subdir.is_dir() and subdir.name.endswith('_bucket'):
            # æ£€æŸ¥æ˜¯å¦æœ‰ parquet æ–‡ä»¶
            bucket_parquets = list(subdir.rglob('*.parquet'))
            if bucket_parquets:
                # å»æ‰ _bucket åç¼€å¾—åˆ°è¡¨å
                table_name = subdir.name[:-7]  # remove '_bucket'
                bucket_dirs.add(table_name.lower())
    
    # åˆå¹¶æ‰€æœ‰æ‰¾åˆ°çš„è¡¨ï¼ˆå•æ–‡ä»¶ã€åˆ†ç‰‡ç›®å½•ã€åˆ†æ¡¶ç›®å½•ã€CSVæ–‡ä»¶ï¼‰
    all_found = parquet_names | parquet_dirs | bucket_dirs | csv_names
    
    # HiRID ç‰¹æ®Šå¤„ç†ï¼špharma_bucket â†’ pharma_records
    if database == 'hirid' and 'pharma' in all_found:
        all_found.add('pharma_records')
    
    # æ£€æŸ¥å„ç±»åˆ«çš„è¡¨
    db_tables = required_parquet_tables.get(database, {})
    found_tables = []
    missing_tables = []
    missing_by_category = {}
    
    for category, tables in db_tables.items():
        for table in tables:
            if table.lower() in all_found:
                found_tables.append(table)
            else:
                missing_tables.append(table)
                if category not in missing_by_category:
                    missing_by_category[category] = []
                missing_by_category[category].append(table)
    
    total_required = sum(len(tables) for tables in db_tables.values())
    
    # å¦‚æœå…¨éƒ¨æ‰¾åˆ°
    if len(missing_tables) == 0:
        bucket_info = f", {len(bucket_dirs)} bucketed" if bucket_dirs else ""
        msg = f'âœ… {db_name}: All {total_required} required tables found ({len(parquet_files)} Parquet files{bucket_info})' if lang == 'en' else f'âœ… {db_name}: æ‰€æœ‰ {total_required} ä¸ªå¿…éœ€è¡¨å·²æ‰¾åˆ° ({len(parquet_files)} ä¸ª Parquet æ–‡ä»¶{bucket_info})'
        return {
            'valid': True,
            'message': msg
        }
    
    # æ ¸å¿ƒè¡¨ç¼ºå¤±æ˜¯ä¸¥é‡é—®é¢˜
    core_missing = missing_by_category.get('core', [])
    if core_missing:
        missing_str = ', '.join(core_missing)
        if lang == 'en':
            msg = f'âŒ {db_name}: Missing core tables: {missing_str}'
            sug = f'ğŸ’¡ Core tables are required. Please ensure data is properly converted.'
        else:
            msg = f'âŒ {db_name}: ç¼ºå°‘æ ¸å¿ƒè¡¨: {missing_str}'
            sug = f'ğŸ’¡ æ ¸å¿ƒè¡¨æ˜¯å¿…éœ€çš„ï¼Œè¯·ç¡®ä¿æ•°æ®å·²æ­£ç¡®è½¬æ¢ã€‚'
        return {
            'valid': False,
            'message': msg,
            'suggestion': sug,
            'can_convert': True,
            'csv_path': str(path),
            'missing_tables': missing_tables,
        }
    
    # éƒ¨åˆ†è¡¨ç¼ºå¤±ï¼ˆéæ ¸å¿ƒï¼‰
    if len(found_tables) > 0:
        missing_str = ', '.join(missing_tables[:5])
        if len(missing_tables) > 5:
            missing_str += f' (+{len(missing_tables)-5} more)'
        if lang == 'en':
            msg = f'âš ï¸ {db_name}: Found {len(found_tables)}/{total_required} tables, missing: {missing_str}'
            sug = f'ğŸ’¡ Click "Convert to Parquet" to convert missing tables'
        else:
            msg = f'âš ï¸ {db_name}: æ‰¾åˆ° {len(found_tables)}/{total_required} ä¸ªè¡¨ï¼Œç¼ºå°‘: {missing_str}'
            sug = f'ğŸ’¡ ç‚¹å‡»ã€Œè½¬æ¢ä¸ºParquetã€è½¬æ¢ç¼ºå¤±çš„è¡¨'
        return {
            'valid': False,
            'message': msg,
            'suggestion': sug,
            'can_convert': True,
            'csv_path': str(path),
            'missing_tables': missing_tables,
        }
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ CSV æ–‡ä»¶ï¼ˆå¯èƒ½éœ€è¦è½¬æ¢ï¼‰
    csv_files = list(path.rglob('*.csv')) + list(path.rglob('*.csv.gz'))
    csv_names = [f.name.lower().replace('.gz', '') for f in csv_files]
    
    required_csvs = required_csv_files.get(database, [])
    found_csvs = []
    for req in required_csvs:
        if req.lower() in csv_names:
            found_csvs.append(req)
    
    if len(found_csvs) >= len(required_csvs) // 2:
        # æ‰¾åˆ° CSV æ–‡ä»¶ä½†æ²¡æœ‰ Parquet - éœ€è¦è½¬æ¢
        msg = f'âš ï¸ Found {db_name} raw CSV files ({len(csv_files)} files), need to convert to Parquet' if lang == 'en' else f'âš ï¸ æ‰¾åˆ° {db_name} åŸå§‹ CSV æ–‡ä»¶ ({len(csv_files)} ä¸ª)ï¼Œéœ€è¦è½¬æ¢ä¸º Parquet æ ¼å¼'
        sug = 'ğŸ’¡ Click "Convert to Parquet" button below to convert all files' if lang == 'en' else 'ğŸ’¡ ç‚¹å‡»ä¸‹æ–¹ã€Œè½¬æ¢ä¸ºParquetã€æŒ‰é’®è½¬æ¢æ‰€æœ‰æ–‡ä»¶'
        return {
            'valid': False,
            'message': msg,
            'suggestion': sug,
            'can_convert': True,
            'csv_path': str(path)
        }
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å­ç›®å½•ç»“æ„
    subdirs = [d for d in path.iterdir() if d.is_dir()]
    subdir_names = [d.name.lower() for d in subdirs]
    
    # æ£€æŸ¥å¸¸è§çš„å­ç›®å½•ç»“æ„
    expected_subdirs = {
        'miiv': ['hosp', 'icu', 'ed'],
        'eicu': ['eicu-crd'],
        'aumc': ['amsterdamumc'],
        'hirid': ['hirid'],
    }
    
    for expected in expected_subdirs.get(database, []):
        if expected.lower() in subdir_names:
            # æ‰¾åˆ°é¢„æœŸå­ç›®å½•
            lang = st.session_state.get('language', 'en')
            msg = f'âš ï¸ Detected {db_name} directory structure, but data may be in subdirectory' if lang == 'en' else f'âš ï¸ æ£€æµ‹åˆ° {db_name} ç›®å½•ç»“æ„ï¼Œä½†æ•°æ®å¯èƒ½åœ¨å­ç›®å½•ä¸­'
            sug = f'ğŸ’¡ Try path: {path / expected}' if lang == 'en' else f'ğŸ’¡ è¯·å°è¯•è·¯å¾„: {path / expected}'
            return {
                'valid': False,
                'message': msg,
                'suggestion': sug
            }
    
    # å®Œå…¨æ‰¾ä¸åˆ°ç›¸å…³æ–‡ä»¶
    lang = st.session_state.get('language', 'en')
    msg = f'âŒ Required data files for {db_name} not found in this path' if lang == 'en' else f'âŒ åœ¨æ­¤è·¯å¾„ä¸‹æœªæ‰¾åˆ° {db_name} æ‰€éœ€çš„æ•°æ®æ–‡ä»¶'
    sug = 'ğŸ’¡ Please verify: 1) Path is correct 2) Database type matches 3) Data is downloaded' if lang == 'en' else 'ğŸ’¡ è¯·ç¡®è®¤: 1) è·¯å¾„æ˜¯å¦æ­£ç¡® 2) æ•°æ®åº“ç±»å‹æ˜¯å¦åŒ¹é… 3) æ•°æ®æ˜¯å¦å·²ä¸‹è½½'
    return {
        'valid': False,
        'message': msg,
        'suggestion': sug
    }


def generate_mock_data(n_patients=10, hours=72, cohort_filter=None):
    """ç”Ÿæˆæ¨¡æ‹Ÿ ICU æ•°æ®ç”¨äºæ¼”ç¤ºã€‚
    
    Args:
        n_patients: è¦ç”Ÿæˆçš„æ‚£è€…æ•°é‡
        hours: æ•°æ®æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        cohort_filter: é˜Ÿåˆ—è¿‡æ»¤å™¨å­—å…¸ï¼Œæ”¯æŒä»¥ä¸‹å­—æ®µï¼š
            - age_min/age_max: å¹´é¾„èŒƒå›´
            - gender: 'M' æˆ– 'F'
            - survived: True/False
            - has_sepsis: True/False
            - los_min: æœ€çŸ­ä½é™¢æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
    """
    data = {}
    
    # ğŸ”§ å¦‚æœæœ‰è¿‡æ»¤å™¨ï¼Œæ ¹æ®è¿‡æ»¤æ¡ä»¶è®¡ç®—éœ€è¦çš„åˆå§‹æ‚£è€…æ•°
    # æ€§åˆ«è¿‡æ»¤çº¦50%é€šè¿‡ï¼Œå­˜æ´»è¿‡æ»¤çº¦85%é€šè¿‡ï¼Œsepsisè¿‡æ»¤çº¦30%/70%é€šè¿‡
    initial_multiplier = 1
    if cohort_filter:
        # ä¼°ç®—æ¯ä¸ªè¿‡æ»¤å™¨çš„é€šè¿‡ç‡
        if cohort_filter.get('gender') is not None:
            initial_multiplier *= 2.5  # æ€§åˆ«è¿‡æ»¤çº¦50%é€šè¿‡
        if cohort_filter.get('survived') is not None:
            if cohort_filter['survived']:
                initial_multiplier *= 1.3  # å­˜æ´»çº¦85%
            else:
                initial_multiplier *= 8  # æ­»äº¡çº¦15%
        if cohort_filter.get('has_sepsis') is not None:
            if cohort_filter['has_sepsis']:
                initial_multiplier *= 4  # sepsisçº¦30%
            else:
                initial_multiplier *= 1.5  # ésepsisçº¦70%
        if cohort_filter.get('age_min') is not None or cohort_filter.get('age_max') is not None:
            initial_multiplier *= 1.5  # å¹´é¾„èŒƒå›´è¿‡æ»¤
        initial_multiplier = max(3, int(initial_multiplier))  # æœ€å°‘3å€
    
    initial_n = n_patients * initial_multiplier
    all_patient_ids = list(range(10001, 10001 + initial_n))
    
    np.random.seed(42)
    time_points = np.arange(0, hours, 1)
    
    # ğŸ”§ FIX (2026-02-03): æ·»åŠ æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´ç”Ÿæˆå‡½æ•°
    def get_random_sample_times(pid, base_interval, jitter=0.3, min_samples=3):
        """ä¸ºæ¯ä¸ªæ‚£è€…ç”Ÿæˆéšæœºé‡‡æ ·æ—¶é—´ç‚¹
        
        Args:
            pid: æ‚£è€…IDï¼Œç”¨ä½œéšæœºç§å­çš„ä¸€éƒ¨åˆ†
            base_interval: åŸºç¡€é‡‡æ ·é—´éš”ï¼ˆå°æ—¶ï¼‰
            jitter: é—´éš”çš„éšæœºæŠ–åŠ¨æ¯”ä¾‹ (0-1)
            min_samples: æœ€å°‘é‡‡æ ·æ¬¡æ•°
        
        Returns:
            è¯¥æ‚£è€…çš„éšæœºé‡‡æ ·æ—¶é—´ç‚¹åˆ—è¡¨
        """
        rng = np.random.RandomState(pid * 17 + 31)  # æ¯ä¸ªæ‚£è€…æœ‰ç‹¬ç«‹çš„éšæœºçŠ¶æ€
        sample_times = [0]  # ä»0å¼€å§‹
        current_time = 0
        
        while current_time < hours - base_interval:
            # åœ¨åŸºç¡€é—´éš”ä¸Šæ·»åŠ éšæœºæŠ–åŠ¨
            interval = base_interval * (1 + rng.uniform(-jitter, jitter))
            interval = max(1, interval)  # è‡³å°‘1å°æ—¶é—´éš”
            current_time += interval
            if current_time < hours:
                sample_times.append(int(current_time))
        
        # ç¡®ä¿è‡³å°‘æœ‰æœ€å°‘é‡‡æ ·æ¬¡æ•°
        if len(sample_times) < min_samples:
            sample_times = list(np.linspace(0, hours-1, min_samples, dtype=int))
        
        return sample_times

    # 1. é¢„å…ˆç”Ÿæˆæ‚£è€…å…ƒæ•°æ®ï¼ˆç”¨äºåç»­è¿‡æ»¤ï¼‰
    patient_meta = {}
    for pid in all_patient_ids:
        # å¹´é¾„ (40-85å²)
        age = np.random.uniform(40, 85)
        # æ€§åˆ«
        sex = np.random.choice(['M', 'F'])
        # æ­»äº¡ç‡ 15%
        death = 1 if np.random.random() < 0.15 else 0
        # ICUä½é™¢æ—¶é•¿ (1-14å¤©è½¬æ¢ä¸ºå°æ—¶)
        los_icu = np.random.uniform(24, 14*24)  # æ”¹ä¸ºå°æ—¶
        # 30% æ¦‚ç‡æ‚£ sepsis
        is_septic = np.random.random() < 0.3
        # å‘ç—…æ—¶é—´éšæœºåˆ†å¸ƒåœ¨ 10h ~ hours-10h ä¹‹é—´
        onset = np.random.choice(range(10, max(11, hours-10))) if is_septic else -999
        
        # ç¡®å®šæ„ŸæŸ“çª—å£ (samp time)
        samp_time = -1
        if is_septic:
            # é‡‡æ ·æ—¶é—´é€šå¸¸åœ¨å‘ç—…å‰å
            samp_time = onset + np.random.randint(-4, 4)
            samp_time = max(0, min(hours-1, samp_time))
            
        patient_meta[pid] = {
            'age': age,
            'sex': sex,
            'death': death,
            'los_icu': los_icu,
            'is_septic': is_septic,
            'onset': onset,
            'samp_time': samp_time
        }
    
    # 2. åº”ç”¨é˜Ÿåˆ—è¿‡æ»¤å™¨
    filtered_patient_ids = all_patient_ids
    if cohort_filter:
        filtered_patient_ids = []
        for pid in all_patient_ids:
            meta = patient_meta[pid]
            include = True
            
            # å¹´é¾„è¿‡æ»¤
            if cohort_filter.get('age_min') is not None:
                if meta['age'] < cohort_filter['age_min']:
                    include = False
            if cohort_filter.get('age_max') is not None:
                if meta['age'] > cohort_filter['age_max']:
                    include = False
            
            # æ€§åˆ«è¿‡æ»¤
            if cohort_filter.get('gender') is not None:
                if meta['sex'] != cohort_filter['gender']:
                    include = False
            
            # å­˜æ´»çŠ¶æ€è¿‡æ»¤
            if cohort_filter.get('survived') is not None:
                if cohort_filter['survived'] and meta['death'] == 1:
                    include = False
                elif not cohort_filter['survived'] and meta['death'] == 0:
                    include = False
            
            # Sepsisè¿‡æ»¤
            if cohort_filter.get('has_sepsis') is not None:
                if cohort_filter['has_sepsis'] and not meta['is_septic']:
                    include = False
                elif not cohort_filter['has_sepsis'] and meta['is_septic']:
                    include = False
            
            # ä½é™¢æ—¶é•¿è¿‡æ»¤
            if cohort_filter.get('los_min') is not None:
                if meta['los_icu'] < cohort_filter['los_min']:
                    include = False
            
            if include:
                filtered_patient_ids.append(pid)
        
        # å¦‚æœè¿‡æ»¤åæ‚£è€…ä¸å¤Ÿï¼Œå‘å‡ºè­¦å‘Šä½†ä»ç»§ç»­
        if len(filtered_patient_ids) < n_patients:
            print(f"Warning: Only {len(filtered_patient_ids)} patients match cohort criteria (requested {n_patients})")
    
    # 3. é™åˆ¶åˆ°è¯·æ±‚çš„æ‚£è€…æ•°é‡
    patient_ids = filtered_patient_ids[:n_patients]
    
    # ä¸ºäº†å…¼å®¹åç»­ä»£ç ï¼Œåˆ›å»º patient_sepsis_meta
    patient_sepsis_meta = {pid: patient_meta[pid] for pid in patient_ids}
    
    # å¿ƒç‡ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œæ¨¡æ‹Ÿ10%ç¼ºå¤±ç‡ï¼‰
    hr_records = []
    for pid in patient_ids:
        base_hr = np.random.uniform(70, 90)
        # å¦‚æœ septic, å¿ƒç‡åœ¨å‘ç—…åå‡é«˜
        meta = patient_sepsis_meta[pid]
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´ï¼Œè€Œéå›ºå®šé—´éš”
        sample_times = get_random_sample_times(pid, base_interval=1, jitter=0.3)
        for t in sample_times:
            # 10%æ¦‚ç‡ç¼ºå¤±ï¼ˆåœ¨éšæœºé‡‡æ ·åŸºç¡€ä¸Šå†æ·»åŠ éšæœºç¼ºå¤±ï¼‰
            if np.random.random() < 0.9:
                hr = base_hr + np.sin(t / 6) * 10 + np.random.normal(0, 5)
                if meta['is_septic'] and t >= meta['onset']:
                    hr += 20 # å‘ç—…åå¿ƒç‡å¢åŠ 
                    
                hr_records.append({'stay_id': pid, 'time': t, 'hr': max(40, min(150, hr))})
    data['hr'] = pd.DataFrame(hr_records)
    
# MAPï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œæ¨¡æ‹Ÿ10%ç¼ºå¤±ç‡ï¼‰
    map_records = []
    for pid in patient_ids:
        base_map = np.random.uniform(65, 85)
        meta = patient_sepsis_meta[pid]
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=1, jitter=0.3)
        for t in sample_times:
            if np.random.random() < 0.9:
                map_val = base_map + np.cos(t / 8) * 8 + np.random.normal(0, 4)
                if meta['is_septic'] and t >= meta['onset']:
                    map_val -= 15 # å‘ç—…åè¡€å‹ä¸‹é™
                    
                map_records.append({'stay_id': pid, 'time': t, 'map': max(40, min(120, map_val))})
    data['map'] = pd.DataFrame(map_records)

    # SBPï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œæ¨¡æ‹Ÿ10%ç¼ºå¤±ç‡ï¼‰
    sbp_records = []
    for pid in patient_ids:
        base_sbp = np.random.uniform(110, 140)
        meta = patient_sepsis_meta[pid]
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=1, jitter=0.3)
        for t in sample_times:
            if np.random.random() < 0.9:
                sbp_val = base_sbp + np.sin(t / 5) * 15 + np.random.normal(0, 8)
                if meta['is_septic'] and t >= meta['onset']:
                    sbp_val -= 20
                    
                sbp_records.append({'stay_id': pid, 'time': t, 'sbp': max(70, min(200, sbp_val))})
    data['sbp'] = pd.DataFrame(sbp_records)
    
    # ä½“æ¸©ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯4å°æ—¶ï¼‰
    temp_records = []
    for pid in patient_ids:
        base_temp = np.random.uniform(36.5, 37.5)
        meta = patient_sepsis_meta[pid]
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=4, jitter=0.4)
        for t in sample_times:
            temp_val = base_temp + np.random.normal(0, 0.3)
            # éšæœºå‘çƒ­
            if np.random.random() < 0.1:
                temp_val += 1.5
            # Sepsis å‘çƒ­
            if meta['is_septic'] and t >= meta['onset']:
                 temp_val += 1.2
                 
            temp_records.append({'stay_id': pid, 'time': t, 'temp': max(35, min(41, temp_val))})
    data['temp'] = pd.DataFrame(temp_records)
    
    # å‘¼å¸ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œæ¨¡æ‹Ÿ15%ç¼ºå¤±ç‡ï¼‰
    resp_records = []
    for pid in patient_ids:
        base_resp = np.random.uniform(14, 18)
        meta = patient_sepsis_meta[pid]
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=1, jitter=0.3)
        for t in sample_times:
            # 15%æ¦‚ç‡ç¼ºå¤±
            if np.random.random() < 0.85:
                resp_val = base_resp + np.random.normal(0, 2)
                if meta['is_septic'] and t >= meta['onset']:
                    resp_val += 8
                    
                resp_records.append({'stay_id': pid, 'time': t, 'resp': max(8, min(40, resp_val))})
    data['resp'] = pd.DataFrame(resp_records)
    
    # SpO2ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œæ¨¡æ‹Ÿ10%ç¼ºå¤±ç‡ï¼‰
    spo2_records = []
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=1, jitter=0.3)
        for t in sample_times:
            if np.random.random() < 0.9:
                spo2_val = 97 + np.random.normal(0, 2)
                if np.random.random() < 0.05:
                    spo2_val -= 10
                spo2_records.append({'stay_id': pid, 'time': t, 'spo2': max(80, min(100, spo2_val))})
    data['spo2'] = pd.DataFrame(spo2_records)
    
    # EtCO2 (End-Tidal CO2ï¼Œæ¨¡æ‹Ÿ30%ç¼ºå¤±ç‡ - éœ€è¦ç‰¹æ®Šç›‘æµ‹ï¼‰
    etco2_records = []
    for pid in patient_ids:
        base_etco2 = np.random.uniform(35, 42)
        # ä»…40%æ‚£è€…æœ‰EtCO2ç›‘æµ‹
        if np.random.random() < 0.4:
            for t in time_points:
                if np.random.random() < 0.7:
                    etco2_val = base_etco2 + np.random.normal(0, 3)
                    etco2_records.append({'stay_id': pid, 'time': t, 'etco2': max(20, min(60, etco2_val))})
    data['etco2'] = pd.DataFrame(etco2_records) if etco2_records else pd.DataFrame(columns=['stay_id', 'time', 'etco2'])
    
    # O2Sat (Oxygen Saturation - alias for spo2)
    data['o2sat'] = data['spo2'].rename(columns={'spo2': 'o2sat'}).copy() if not data['spo2'].empty else pd.DataFrame(columns=['stay_id', 'time', 'o2sat'])
    data['sao2'] = data['spo2'].rename(columns={'spo2': 'sao2'}).copy() if not data['spo2'].empty else pd.DataFrame(columns=['stay_id', 'time', 'sao2'])
    
    # SOFAï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯6å°æ—¶ï¼‰
    sofa_records = []
    for pid in patient_ids:
        meta = patient_sepsis_meta[pid]
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=6, jitter=0.3)
        for t in sample_times:
            # åŸºç¡€åˆ†å¸ƒ
            probs = [0.6, 0.3, 0.1, 0.0, 0.0] 
            
            # å¦‚æœæ˜¯ sepsis æ‚£è€…ä¸”å¤„äºå‘ç—…æœŸï¼Œæ¦‚ç‡å‘é«˜åˆ†åç§»
            if meta['is_septic'] and t >= meta['onset']:
                probs = [0.1, 0.2, 0.3, 0.25, 0.15]
                
            sofa_resp = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa_coag = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa_liver = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa_cardio = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa_cns = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa_renal = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa_total = sofa_resp + sofa_coag + sofa_liver + sofa_cardio + sofa_cns + sofa_renal
            
            sofa_records.append({
                'stay_id': pid, 'time': t, 'sofa': sofa_total,
                'sofa_resp': sofa_resp, 'sofa_coag': sofa_coag, 'sofa_liver': sofa_liver,
                'sofa_cardio': sofa_cardio, 'sofa_cns': sofa_cns, 'sofa_renal': sofa_renal,
            })
    data['sofa'] = pd.DataFrame(sofa_records)
    
    # è‚Œé…ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯8å°æ—¶ï¼‰
    crea_records = []
    for pid in patient_ids:
        base_crea = np.random.uniform(0.8, 1.2)
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=8, jitter=0.3)
        for t in sample_times:
            crea_val = base_crea + np.random.normal(0, 0.2)
            crea_records.append({'stay_id': pid, 'time': t, 'crea': max(0.3, crea_val)})
    data['crea'] = pd.DataFrame(crea_records)
    
    # èƒ†çº¢ç´ ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯12å°æ—¶ï¼‰
    bili_records = []
    for pid in patient_ids:
        base_bili = np.random.uniform(0.5, 1.5)
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=12, jitter=0.3)
        for t in sample_times:
            bili_val = base_bili + np.random.normal(0, 0.3)
            bili_records.append({'stay_id': pid, 'time': t, 'bili': max(0.1, bili_val)})
    data['bili'] = pd.DataFrame(bili_records)
    
    # è¡€ç³– (Glucoseï¼Œä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯4å°æ—¶)
    glu_records = []
    for pid in patient_ids:
        base_glu = np.random.uniform(80, 120)
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=4, jitter=0.3)
        for t in sample_times:
            glu_val = base_glu + np.random.normal(0, 15)
            glu_records.append({'stay_id': pid, 'time': t, 'glu': max(40, min(400, glu_val))})
    data['glu'] = pd.DataFrame(glu_records)
    
    # ä¹³é…¸ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯6å°æ—¶ï¼‰
    lac_records = []
    for pid in patient_ids:
        base_lac = np.random.uniform(1.0, 2.0)
        meta = patient_sepsis_meta[pid]
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=6, jitter=0.3)
        for t in sample_times:
            lac_val = base_lac + np.random.normal(0, 0.5)
            if meta['is_septic'] and t >= meta['onset']:
                lac_val += 3.0 # ä¹³é…¸å‡é«˜
                
            lac_records.append({'stay_id': pid, 'time': t, 'lact': max(0.5, lac_val)})  # ğŸ”§ æ”¹ä¸º lactï¼ˆæ ‡å‡†åç§°ï¼‰
    data['lact'] = pd.DataFrame(lac_records)  # ğŸ”§ æ”¹ä¸º lactï¼ˆä¸ CONCEPT_GROUPS_INTERNAL ä¸€è‡´ï¼‰
    
    # è¡€å°æ¿ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯12å°æ—¶ï¼‰
    plt_records = []
    for pid in patient_ids:
        base_plt = np.random.uniform(150, 300)
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=12, jitter=0.3)
        for t in sample_times:
            plt_val = base_plt + np.random.normal(0, 30)
            plt_records.append({'stay_id': pid, 'time': t, 'plt': max(10, plt_val)})
    data['plt'] = pd.DataFrame(plt_records)
    
    # å»ç”²è‚¾ä¸Šè…ºç´ ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼‰
    norepi_records = []
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=1, jitter=0.3)
        for t in sample_times:
            if 12 <= t <= 48 and np.random.random() < 0.6:
                rate = np.random.uniform(0.05, 0.3)
                norepi_records.append({'stay_id': pid, 'time': t, 'norepi_rate': rate})
    data['norepi_rate'] = pd.DataFrame(norepi_records) if norepi_records else pd.DataFrame(
        columns=['stay_id', 'time', 'norepi_rate'])
    
    # SOFA-2 è¯„åˆ† (2025æ–°æ ‡å‡†ï¼Œä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯6å°æ—¶)
    sofa2_records = []
    for pid in patient_ids:
        meta = patient_sepsis_meta[pid]
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=6, jitter=0.3)
        for t in sample_times:
            # åŸºç¡€åˆ†å¸ƒ
            probs = [0.55, 0.3, 0.1, 0.05, 0.0]
            if meta['is_septic'] and t >= meta['onset']:
                probs = [0.1, 0.2, 0.3, 0.25, 0.15]
                
            sofa2_resp = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa2_coag = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa2_liver = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa2_cardio = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa2_cns = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa2_renal = np.random.choice([0, 1, 2, 3, 4], p=probs)
            sofa2_total = sofa2_resp + sofa2_coag + sofa2_liver + sofa2_cardio + sofa2_cns + sofa2_renal
            
            sofa2_records.append({
                'stay_id': pid, 'time': t, 'sofa2': sofa2_total,
                'sofa2_resp': sofa2_resp, 'sofa2_coag': sofa2_coag, 'sofa2_liver': sofa2_liver,
                'sofa2_cardio': sofa2_cardio, 'sofa2_cns': sofa2_cns, 'sofa2_renal': sofa2_renal,
            })
    data['sofa2'] = pd.DataFrame(sofa2_records)
    # æ·»åŠ å„ç»„ä»¶åˆ° data
    sofa2_df = data['sofa2']
    data['sofa2_resp'] = sofa2_df[['stay_id', 'time', 'sofa2_resp']].copy()
    data['sofa2_coag'] = sofa2_df[['stay_id', 'time', 'sofa2_coag']].copy()
    data['sofa2_liver'] = sofa2_df[['stay_id', 'time', 'sofa2_liver']].copy()
    data['sofa2_cardio'] = sofa2_df[['stay_id', 'time', 'sofa2_cardio']].copy()
    data['sofa2_cns'] = sofa2_df[['stay_id', 'time', 'sofa2_cns']].copy()
    data['sofa2_renal'] = sofa2_df[['stay_id', 'time', 'sofa2_renal']].copy()
    
    # Sepsis-3 è¯Šæ–­æ•°æ® (ä¸¥æ ¼åŸºäº SOFA å˜åŒ–)
    sep3_sofa2_records = []
    
    # å…ˆæŠŠ sofa2 è½¬æ¢ä¸º (stay_id, time) ç´¢å¼•ä»¥ä¾¿æŸ¥è¯¢
    sofa2_lookup = data['sofa2'].set_index(['stay_id', 'time'])['sofa2']
    
    for pid in patient_ids:
        meta = patient_sepsis_meta[pid]
        
        # 1. ç–‘ä¼¼æ„ŸæŸ“ susp_inf
        # å®šä¹‰: åœ¨å‘ç—…å‰24håˆ°å‘ç—…å72hä¸ºâ€œç–‘ä¼¼æ„ŸæŸ“çª—å£â€
        # è¿™é‡Œç®€åŒ–ï¼šåªè¦æ˜¯septicæ‚£è€…ï¼Œæˆ‘ä»¬åœ¨ onset ä¹‹åæ ‡è®°ç–‘ä¼¼
        # samp ä»…åœ¨å…·ä½“çš„é‡‡æ ·ç‚¹ä¸º 1
        
        for t in time_points:
            # é»˜è®¤å€¼
            susp_inf_val = 0
            samp_val = 0
            sep3_val = 0
            infection_icd_val = 0
            
            if meta['is_septic']:
                # infection_icd é€šå¸¸æ˜¯é™æ€è¯Šæ–­ï¼Œæ•´ç¨‹ä¸º1
                infection_icd_val = 1
                
                # samp: ä»…åœ¨é‡‡æ ·ç‚¹æœ‰å€¼ (ç¨€ç–)
                if t == meta['samp_time']:
                    samp_val = 1
                    
                # susp_inf: æ¨¡æ‹Ÿæœ‰ä¸€ä¸ª suspicions window
                # æ­¤å¤„è®¾ä¸ºï¼šsamp_time å‰24h åˆ° å72h
                samp_t = meta['samp_time']
                if samp_t >= 0 and (samp_t - 24 <= t <= samp_t + 72):
                    susp_inf_val = 1
                    
                # Sepsis-3: susp_inf=1 AND (current_sofa >= 2)
                # çœŸå®æ ‡å‡†æ˜¯ delta_sofa >= 2ï¼Œå‡è®¾ baseline=0ï¼Œåˆ™ absolute>=2
                try:
                    # æ³¨æ„ï¼šsofaæ•°æ®æ˜¯æ¯6å°æ—¶é‡‡æ ·çš„ï¼Œä¸­é—´æ—¶é—´ç‚¹å¯èƒ½åœ¨dataframeé‡Œæ²¡æœ‰
                    # è¿™é‡Œé€šè¿‡ lookup æŸ¥æ‰¾æœ€è¿‘çš„æœ‰æ•ˆå€¼ï¼Œæˆ–è€…å› ä¸ºæˆ‘ä»¬çš„ time_points åŒ…å«æ‰€æœ‰ç‚¹
                    # ä½† sofa2_df æ˜¯ dense çš„å—ï¼Ÿ generate logic æ˜¯ time_points[::6]
                    # æˆ‘ä»¬éœ€è¦æ’å€¼æˆ–å¯¹é½ã€‚ä¸ºç®€åŒ– mockï¼Œæˆ‘ä»¬åœ¨ç”Ÿæˆ sofa2 æ—¶åªç”Ÿæˆäº†éƒ¨åˆ†ç‚¹
                    # ä½† export è¦æ±‚å¯¹é½ã€‚è¿™é‡Œæˆ‘ä»¬ç®€å•å¤„ç†ï¼šè‹¥æ— æ³•æŸ¥åˆ°å‡†ç¡®sofaï¼Œåˆ™æ²¿ç”¨ä¸Šä¸€ä¸ª
                    pass 
                except:
                    pass
            
            sep3_sofa2_records.append({
                'stay_id': pid,
                'time': t,
                'sep3_sofa2': 0, # ç¨åè®¡ç®—
                'susp_inf': susp_inf_val,
                'infection_icd': infection_icd_val,
                'samp': samp_val,
            })
            
    # è®¡ç®— Sep3 ç»“æœ (éœ€è¦åˆå¹¶ sofa æ•°æ®)
    sep3_df = pd.DataFrame(sep3_sofa2_records)
    
    # å°† Sep3 è¡¨å’Œ SOFA2 è¡¨åˆå¹¶è®¡ç®—æœ€ç»ˆ Sep3 çŠ¶æ€
    # SOFA2 æ˜¯æ¯6å°æ—¶ä¸€ç‚¹ï¼Œæˆ‘ä»¬å…ˆ forward fill åˆ°æ¯å°æ—¶
    sofa2_full = pd.DataFrame({'stay_id': patient_ids, 'key': 1}).merge(pd.DataFrame({'time': time_points, 'key': 1}), on='key').drop(columns=['key'])
    sofa2_source = data['sofa2'][['stay_id', 'time', 'sofa2']]
    sofa2_interpolated = sofa2_full.merge(sofa2_source, on=['stay_id', 'time'], how='left')
    sofa2_interpolated['sofa2'] = sofa2_interpolated.groupby('stay_id')['sofa2'].ffill().fillna(0)
    
    # åˆå¹¶
    sep3_final = sep3_df.merge(sofa2_interpolated, on=['stay_id', 'time'], how='left')
    
    # åº”ç”¨ Sepsis3 è§„åˆ™: susp_inf == 1 AND sofa2 >= 2
    sep3_final['sep3_sofa2'] = ((sep3_final['susp_inf'] == 1) & (sep3_final['sofa2'] >= 2)).astype(int)
    
    # æ›´æ–°åˆ° data
    # ğŸ”§ ä¿ç•™æ‰€æœ‰æ—¶é—´ç‚¹ï¼ˆåŒ…æ‹¬0å’Œ1ï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®çš„ç¨€ç–æ€§å’Œç¼ºå¤±ç‡
    # sep3_sofa2: ä¿ç•™æ‰€æœ‰ç–‘ä¼¼æ„ŸæŸ“çª—å£å†…çš„æ—¶é—´ç‚¹ï¼ˆå«0å’Œ1ï¼‰
    sep3_with_context = sep3_final[
        (sep3_final['susp_inf'] == 1) |  # ç–‘ä¼¼æ„ŸæŸ“çª—å£
        (sep3_final['infection_icd'] == 1)  # æœ‰æ„ŸæŸ“è¯Šæ–­
    ].copy()
    
    # å¯¹äº sep3_sofa2ï¼Œä¿ç•™ç–‘ä¼¼æ„ŸæŸ“çª—å£å†…çš„æ‰€æœ‰è®°å½•ï¼ˆåŒ…å«0å€¼ï¼Œæ¨¡æ‹Ÿç¼ºå¤±ç‡ï¼‰
    data['sep3_sofa2'] = sep3_with_context[['stay_id', 'time', 'sep3_sofa2']] if len(sep3_with_context) > 0 else pd.DataFrame(columns=['stay_id', 'time', 'sep3_sofa2'])
    data['susp_inf'] = sep3_with_context[['stay_id', 'time', 'susp_inf']] if len(sep3_with_context) > 0 else pd.DataFrame(columns=['stay_id', 'time', 'susp_inf'])
    data['infection_icd'] = sep3_with_context[['stay_id', 'time', 'infection_icd']] if len(sep3_with_context) > 0 else pd.DataFrame(columns=['stay_id', 'time', 'infection_icd'])
    data['samp'] = sep3_final[sep3_final['samp'] == 1][['stay_id', 'time', 'samp']] if (sep3_final['samp'] == 1).any() else pd.DataFrame(columns=['stay_id', 'time', 'samp'])
    
    # ğŸ”§ åˆ é™¤ç»„åˆæ¦‚å¿µåˆ«åï¼ˆä¸ CONCEPT_GROUPS_INTERNAL ä¿æŒä¸€è‡´ï¼‰
    # åˆ é™¤: sep3_sofa2_susp_inf, sep3_sofa2_samp, sep3_sofa2_infection_icd
    
    # Sepsis-3 (SOFA-1) åŒç†
    sofa1_source = data['sofa'][['stay_id', 'time', 'sofa']]
    sofa1_interpolated = sofa2_full.merge(sofa1_source, on=['stay_id', 'time'], how='left')
    sofa1_interpolated['sofa'] = sofa1_interpolated.groupby('stay_id')['sofa'].ffill().fillna(0)
    
    sep3_sofa1_final = sep3_final[['stay_id', 'time', 'susp_inf', 'infection_icd']].merge(sofa1_interpolated, on=['stay_id', 'time'], how='left')
    sep3_sofa1_final['sep3_sofa1'] = ((sep3_sofa1_final['susp_inf'] == 1) & (sep3_sofa1_final['sofa'] >= 2)).astype(int)
    
    # sep3_sofa1: ä¿ç•™æ‰€æœ‰åœ¨æ„ŸæŸ“çª—å£å†…çš„è®°å½•ï¼ˆåŒ…æ‹¬ 0 å’Œ 1ï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®ç¼ºå¤±ç‡
    sep3_sofa1_in_window = sep3_sofa1_final[(sep3_sofa1_final['susp_inf'] == 1) | (sep3_sofa1_final['infection_icd'] == 1)]
    data['sep3_sofa1'] = sep3_sofa1_in_window[['stay_id', 'time', 'sep3_sofa1']] if len(sep3_sofa1_in_window) > 0 else pd.DataFrame(columns=['stay_id', 'time', 'sep3_sofa1'])
    
    # æ·»åŠ  SOFA-1 å„ç»„ä»¶åˆ° data
    sofa_df = data['sofa']
    data['sofa_resp'] = sofa_df[['stay_id', 'time', 'sofa_resp']].copy()
    data['sofa_coag'] = sofa_df[['stay_id', 'time', 'sofa_coag']].copy()
    data['sofa_liver'] = sofa_df[['stay_id', 'time', 'sofa_liver']].copy()
    data['sofa_cardio'] = sofa_df[['stay_id', 'time', 'sofa_cardio']].copy()
    data['sofa_cns'] = sofa_df[['stay_id', 'time', 'sofa_cns']].copy()
    data['sofa_renal'] = sofa_df[['stay_id', 'time', 'sofa_renal']].copy()
    
    # ============ è¡¥å……æ›´å¤šå¸¸ç”¨æ¦‚å¿µ ============
    
    # DBP (èˆ’å¼ å‹ï¼Œæ¨¡æ‹Ÿ10%ç¼ºå¤±ç‡ï¼‰
    dbp_records = []
    for pid in patient_ids:
        base_dbp = np.random.uniform(60, 80)
        for t in time_points:
            if np.random.random() < 0.9:
                dbp_val = base_dbp + np.sin(t / 5) * 8 + np.random.normal(0, 5)
                dbp_records.append({'stay_id': pid, 'time': t, 'dbp': max(40, min(110, dbp_val))})
    data['dbp'] = pd.DataFrame(dbp_records)
    
    # GCS (æ ¼æ‹‰æ–¯å“¥æ˜è¿·è¯„åˆ†ï¼Œä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯4å°æ—¶)
    gcs_records = []
    for pid in patient_ids:
        base_gcs = np.random.choice([15, 14, 13, 12, 10, 8], p=[0.5, 0.2, 0.1, 0.08, 0.07, 0.05])
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=4, jitter=0.4)
        for t in sample_times:
            gcs_val = base_gcs + np.random.choice([-1, 0, 0, 0, 1], p=[0.1, 0.3, 0.3, 0.2, 0.1])
            gcs_records.append({'stay_id': pid, 'time': t, 'gcs': max(3, min(15, gcs_val))})
    data['gcs'] = pd.DataFrame(gcs_records)
    
    # è¡€æ°”åˆ†æï¼špH, pco2, po2, lactï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯6å°æ—¶ï¼‰
    ph_records = []
    pco2_records = []
    po2_records = []
    for pid in patient_ids:
        base_ph = np.random.uniform(7.35, 7.45)
        base_pco2 = np.random.uniform(35, 45)
        base_po2 = np.random.uniform(80, 100)
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=6, jitter=0.4)
        for t in sample_times:
            ph_records.append({'stay_id': pid, 'time': t, 'ph': base_ph + np.random.normal(0, 0.03)})
            pco2_records.append({'stay_id': pid, 'time': t, 'pco2': base_pco2 + np.random.normal(0, 3)})
            po2_records.append({'stay_id': pid, 'time': t, 'po2': max(60, base_po2 + np.random.normal(0, 10))})
    data['ph'] = pd.DataFrame(ph_records)
    data['pco2'] = pd.DataFrame(pco2_records)
    data['po2'] = pd.DataFrame(po2_records)
    # ğŸ”§ lact å·²åœ¨ä¸Šæ–¹ç›´æ¥ç”Ÿæˆï¼ˆä¸å†éœ€è¦ä» lac åˆ›å»ºåˆ«åï¼‰
    
    # å‘¼å¸ç³»ç»Ÿï¼špafi, fio2, vent_indï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯4å°æ—¶ï¼‰
    pafi_records = []
    fio2_records = []
    vent_ind_records = []
    for pid in patient_ids:
        base_fio2 = np.random.choice([0.21, 0.3, 0.4, 0.5], p=[0.4, 0.3, 0.2, 0.1])
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=4, jitter=0.4)
        for t in sample_times:
            fio2_val = base_fio2 + np.random.uniform(-0.05, 0.05)
            fio2_val = max(0.21, min(1.0, fio2_val))
            po2_val = 80 + np.random.normal(0, 15)
            pafi_val = po2_val / fio2_val
            vent = 1 if fio2_val > 0.3 else 0
            pafi_records.append({'stay_id': pid, 'time': t, 'pafi': pafi_val})
            fio2_records.append({'stay_id': pid, 'time': t, 'fio2': fio2_val * 100})  # è½¬ä¸ºç™¾åˆ†æ¯”
            vent_ind_records.append({'stay_id': pid, 'time': t, 'vent_ind': vent})
    data['pafi'] = pd.DataFrame(pafi_records)
    data['fio2'] = pd.DataFrame(fio2_records)
    data['vent_ind'] = pd.DataFrame(vent_ind_records)
    
    # å°¿é‡ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œæ¨¡æ‹Ÿ30%ç¼ºå¤±ç‡ï¼‰
    urine_records = []
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=1, jitter=0.3)
        for t in sample_times:
            # 30%æ¦‚ç‡æ— è®°å½•ï¼ˆç¼ºå¤±ï¼‰
            if np.random.random() < 0.7:
                urine_val = np.random.uniform(30, 100)
                urine_records.append({'stay_id': pid, 'time': t, 'urine': urine_val})
    data['urine'] = pd.DataFrame(urine_records) if urine_records else pd.DataFrame(columns=['stay_id', 'time', 'urine'])
    
    # WBC (ç™½ç»†èƒï¼Œä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯12å°æ—¶)
    wbc_records = []
    for pid in patient_ids:
        base_wbc = np.random.uniform(6, 12)
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=12, jitter=0.4)
        for t in sample_times:
            wbc_val = base_wbc + np.random.normal(0, 2)
            wbc_records.append({'stay_id': pid, 'time': t, 'wbc': max(1, wbc_val)})
    data['wbc'] = pd.DataFrame(wbc_records)
    
    # ç»“å±€æ•°æ® (outcome) - ä½¿ç”¨é¢„å…ˆç”Ÿæˆçš„å…ƒæ•°æ®
    death_records = []
    los_icu_records = []
    los_hosp_records = []
    for pid in patient_ids:
        meta = patient_sepsis_meta[pid]
        death_records.append({'stay_id': pid, 'death': meta['death']})
        los_icu_records.append({'stay_id': pid, 'los_icu': meta['los_icu'] / 24})  # è½¬ä¸ºå¤©
        los_hosp = meta['los_icu'] / 24 + np.random.uniform(0, 10)  # ä½é™¢æ—¶é—´ >= ICUæ—¶é—´
        los_hosp_records.append({'stay_id': pid, 'los_hosp': los_hosp})
    data['death'] = pd.DataFrame(death_records)
    data['los_icu'] = pd.DataFrame(los_icu_records)
    data['los_hosp'] = pd.DataFrame(los_hosp_records)
    
    # äººå£ç»Ÿè®¡ (demographics) - ä½¿ç”¨é¢„å…ˆç”Ÿæˆçš„å…ƒæ•°æ®
    age_records = []
    weight_records = []
    height_records = []
    sex_records = []
    bmi_records = []
    adm_records = []
    for pid in patient_ids:
        meta = patient_sepsis_meta[pid]
        weight_val = np.random.uniform(50, 100)
        height_val = np.random.uniform(150, 190)
        bmi_val = weight_val / (height_val / 100) ** 2
        
        age_records.append({'stay_id': pid, 'age': meta['age']})
        weight_records.append({'stay_id': pid, 'weight': weight_val})
        height_records.append({'stay_id': pid, 'height': height_val})
        sex_records.append({'stay_id': pid, 'sex': meta['sex']})
        bmi_records.append({'stay_id': pid, 'bmi': bmi_val})
        adm_records.append({'stay_id': pid, 'adm': 1})  # æ‰€æœ‰æ‚£è€…å‡æœ‰å…¥é™¢è®°å½•
    
    data['age'] = pd.DataFrame(age_records)
    data['weight'] = pd.DataFrame(weight_records)
    data['height'] = pd.DataFrame(height_records)
    data['sex'] = pd.DataFrame(sex_records)
    data['bmi'] = pd.DataFrame(bmi_records)
    data['adm'] = pd.DataFrame(adm_records)
    
    # å…¶ä»–è¯„åˆ†ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯6å°æ—¶ï¼‰
    qsofa_records = []
    sirs_records = []
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=6, jitter=0.4)
        for t in sample_times:
            qsofa_records.append({'stay_id': pid, 'time': t, 'qsofa': np.random.choice([0, 1, 2, 3], p=[0.4, 0.3, 0.2, 0.1])})
            sirs_records.append({'stay_id': pid, 'time': t, 'sirs': np.random.choice([0, 1, 2, 3, 4], p=[0.2, 0.25, 0.25, 0.2, 0.1])})
    data['qsofa'] = pd.DataFrame(qsofa_records)
    data['sirs'] = pd.DataFrame(sirs_records)
    
    # è¯ç‰©ï¼šæŠ—ç”Ÿç´ ä½¿ç”¨
    abx_records = []
    for pid in patient_ids:
        abx_records.append({'stay_id': pid, 'abx': 1 if np.random.random() < 0.7 else 0})
    data['abx'] = pd.DataFrame(abx_records)
    
    # ğŸ”§ FIX (2026-02-03): è¯ç‰©ï¼šçš®è´¨ç±»å›ºé†‡ (corticosteroids) - åªè®°å½•å‘ç”Ÿçš„äº‹ä»¶ï¼ˆNaN/1æ ¼å¼ï¼‰
    # åªæœ‰å‘ç”Ÿæ—¶æ‰è®°å½•1ï¼Œæ²¡æœ‰å‘ç”Ÿæ—¶ä¸ç”Ÿæˆè®°å½•ï¼ˆè€Œä¸æ˜¯ç”Ÿæˆ0ï¼‰
    cort_records = []
    for pid in patient_ids:
        if np.random.random() < 0.25:  # 25%æ‚£è€…ä½¿ç”¨çš®è´¨ç±»å›ºé†‡
            start_time = np.random.uniform(0, 24)
            cort_records.append({'stay_id': pid, 'time': start_time, 'cort': 1})
    data['cort'] = pd.DataFrame(cort_records) if cort_records else pd.DataFrame(columns=['stay_id', 'time', 'cort'])
    
    # ============ KDIGO AKI æ€¥æ€§è‚¾æŸä¼¤æ•°æ®ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯4å°æ—¶ï¼‰ ============
    aki_records = []
    for pid in patient_ids:
        meta = patient_sepsis_meta[pid]
        baseline_crea = np.random.uniform(0.6, 1.2)
        
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=4, jitter=0.4)
        for t in sample_times:
            # åŸºçº¿è‚Œé…é™„è¿‘æ³¢åŠ¨
            crea = baseline_crea * (1 + np.random.normal(0, 0.1))
            
            # Sepsis æ‚£è€…åœ¨å‘ç—…åå¯èƒ½å‘ç”Ÿ AKI
            if meta['is_septic'] and t >= meta['onset']:
                # 30% æ¦‚ç‡å‘ç”Ÿ AKI
                if np.random.random() < 0.3:
                    crea = baseline_crea * np.random.uniform(1.5, 3.0)
            
            # è®¡ç®— AKI åˆ†æœŸ
            ratio = crea / baseline_crea
            if ratio >= 3.0 or crea >= 4.0:
                aki_stage = 3
            elif ratio >= 2.0:
                aki_stage = 2
            elif ratio >= 1.5 or crea >= baseline_crea + 0.3:
                aki_stage = 1
            else:
                aki_stage = 0
            
            aki_records.append({
                'stay_id': pid, 'time': t,
                'crea': round(crea, 2),
                'creat_low_past_7day': round(baseline_crea, 2),
                'aki_stage': aki_stage,
                'aki': 1 if aki_stage > 0 else 0
            })
    data['aki'] = pd.DataFrame(aki_records)
    data['aki_stage'] = data['aki'][['stay_id', 'time', 'aki_stage']].copy()
    # ğŸ”§ æ·»åŠ å®Œæ•´çš„AKIå­ç‰¹å¾ï¼ˆåŸºäºè‚Œé…ã€å°¿é‡ã€RRTå®šä¹‰çš„ï¼‰
    data['aki_stage_creat'] = data['aki'][['stay_id', 'time', 'aki_stage']].copy()
    data['aki_stage_creat'].columns = ['stay_id', 'time', 'aki_stage_creat']
    # å°¿é‡å®šä¹‰çš„AKIï¼ˆéšæœºç”Ÿæˆï¼Œå› ä¸ºdemoæ•°æ®ç®€åŒ–ï¼‰
    aki_uo_records = []
    for _, row in data['aki'].iterrows():
        # å°¿é‡AKIé€šå¸¸ä¸è‚Œé…AKIç›¸å…³ä½†ä¸å®Œå…¨ä¸€è‡´
        uo_stage = max(0, row['aki_stage'] - np.random.randint(0, 2)) if row['aki_stage'] > 0 else 0
        aki_uo_records.append({'stay_id': row['stay_id'], 'time': row['time'], 'aki_stage_uo': uo_stage})
    data['aki_stage_uo'] = pd.DataFrame(aki_uo_records)
    # RRTå®šä¹‰çš„AKIï¼ˆä»…æ¥å—RRTçš„æ‚£è€…ä¸ºStage 3ï¼‰
    aki_rrt_records = []
    for _, row in data['aki'].iterrows():
        rrt_stage = 3 if row['aki_stage'] == 3 and np.random.random() < 0.3 else 0
        aki_rrt_records.append({'stay_id': row['stay_id'], 'time': row['time'], 'aki_stage_rrt': rrt_stage})
    data['aki_stage_rrt'] = pd.DataFrame(aki_rrt_records)
    
    # ============ æ–°å¢ KDIGO ç›¸å…³ç‰¹å¾ (2026-02-04) ============
    # creat_low_past_48hr: è¿‡å»48å°æ—¶å†…æœ€ä½è‚Œé…ï¼ˆé€šå¸¸ä¸ creat_low_past_7day ç›¸ä¼¼æˆ–ç¨é«˜ï¼‰
    creat_48hr_records = []
    for _, row in data['aki'].iterrows():
        # 48hrå†…çš„æœ€ä½è‚Œé…é€šå¸¸ç•¥é«˜äº7å¤©å†…çš„æœ€ä½å€¼
        baseline = row['creat_low_past_7day']
        creat_48hr = round(baseline * np.random.uniform(1.0, 1.15), 2)
        creat_48hr_records.append({'stay_id': row['stay_id'], 'time': row['time'], 'creat_low_past_48hr': creat_48hr})
    data['creat_low_past_48hr'] = pd.DataFrame(creat_48hr_records)
    # æå– creat_low_past_7day ä½œä¸ºç‹¬ç«‹ç‰¹å¾
    data['creat_low_past_7day'] = data['aki'][['stay_id', 'time', 'creat_low_past_7day']].copy()
    
    # å°¿é‡ç‡ï¼ˆmL/kg/hï¼‰ï¼šåŸºäºæ‚£è€…ä½“é‡çš„å°¿é‡äº§å‡ºç‡
    # æ­£å¸¸å€¼: 0.5-1.5 mL/kg/hï¼ŒAKIæ—¶ <0.5 mL/kg/hï¼ˆStage 1ï¼‰, <0.3ï¼ˆStage 2/3ï¼‰
    uo_rate_records = []
    for pid in patient_ids:
        meta = patient_sepsis_meta[pid]
        patient_weight = data['weight'][data['weight']['stay_id'] == pid]['weight'].iloc[0] if len(data['weight'][data['weight']['stay_id'] == pid]) > 0 else 70
        
        # ä½¿ç”¨ä¸AKIç›¸åŒçš„æ—¶é—´ç‚¹
        patient_aki = data['aki'][data['aki']['stay_id'] == pid]
        for _, row in patient_aki.iterrows():
            t = row['time']
            aki_stage = row['aki_stage']
            
            # æ ¹æ®AKIåˆ†æœŸç”Ÿæˆå°¿é‡ç‡
            if aki_stage == 0:
                base_uo_rate = np.random.uniform(0.6, 1.5)  # æ­£å¸¸
            elif aki_stage == 1:
                base_uo_rate = np.random.uniform(0.3, 0.5)  # Stage 1: <0.5
            elif aki_stage == 2:
                base_uo_rate = np.random.uniform(0.15, 0.35)  # Stage 2: <0.3
            else:
                base_uo_rate = np.random.uniform(0.0, 0.2)  # Stage 3: <0.3æˆ–æ— å°¿
            
            # 6hr, 12hr, 24hr çª—å£çš„å°¿é‡ç‡ï¼ˆç•¥æœ‰å˜åŒ–ï¼‰
            uo_6hr = round(base_uo_rate * np.random.uniform(0.9, 1.1), 3)
            uo_12hr = round(base_uo_rate * np.random.uniform(0.85, 1.05), 3)
            uo_24hr = round(base_uo_rate * np.random.uniform(0.8, 1.0), 3)  # 24hrçª—å£é€šå¸¸æ›´å¹³æ»‘
            
            uo_rate_records.append({
                'stay_id': pid, 'time': t,
                'uo_rt_6hr': uo_6hr,
                'uo_rt_12hr': uo_12hr,
                'uo_rt_24hr': uo_24hr
            })
    uo_rate_df = pd.DataFrame(uo_rate_records)
    data['uo_rt_6hr'] = uo_rate_df[['stay_id', 'time', 'uo_rt_6hr']].copy()
    data['uo_rt_12hr'] = uo_rate_df[['stay_id', 'time', 'uo_rt_12hr']].copy()
    data['uo_rt_24hr'] = uo_rate_df[['stay_id', 'time', 'uo_rt_24hr']].copy()
    
    # ============ å¾ªç¯è¡°ç«­ (circEWS) æ•°æ® ============
    circ_failure_records = []
    for pid in patient_ids:
        meta = patient_sepsis_meta[pid]
        
        for t in time_points:
            # åŸºçº¿ä¹³é…¸å’ŒMAP
            base_lact = np.random.uniform(0.8, 1.5)
            base_map = np.random.uniform(75, 95)
            
            lact = base_lact + np.random.normal(0, 0.3)
            map_val = base_map + np.random.normal(0, 5)
            
            # Sepsis æ‚£è€…å‘ç—…åå¯èƒ½å‘ç”Ÿå¾ªç¯è¡°ç«­
            if meta['is_septic'] and t >= meta['onset']:
                if np.random.random() < 0.4:
                    lact = np.random.uniform(2.5, 8.0)
                    map_val = np.random.uniform(50, 70)
            
            # è®¡ç®—å¾ªç¯è¡°ç«­äº‹ä»¶ç­‰çº§
            lactate_elevated = lact >= 2.0
            map_low = map_val <= 65
            
            if lactate_elevated and map_low:
                circ_event = np.random.choice([1, 2, 3], p=[0.4, 0.35, 0.25])
            elif lactate_elevated:
                circ_event = 1 if np.random.random() < 0.3 else 0
            else:
                circ_event = 0
            
            circ_failure_records.append({
                'stay_id': pid, 'time': t,
                'lact': round(lact, 2),
                'map': round(map_val, 1),
                'circ_event': circ_event,
                'circ_failure': 1 if circ_event > 0 else 0
            })
    data['circ_failure'] = pd.DataFrame(circ_failure_records)
    # ğŸ”§ æ·»åŠ circ_eventä½œä¸ºç‹¬ç«‹ç‰¹å¾
    data['circ_event'] = data['circ_failure'][['stay_id', 'time', 'circ_event']].copy()
    
    # ============ å‘¼å¸æœºå‚æ•°ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼‰ ============
    peep_records = []
    tidal_vol_records = []
    tidal_vol_set_records = []
    pip_records = []
    plateau_pres_records = []
    mean_airway_pres_records = []
    minute_vol_records = []
    vent_rate_records = []
    compliance_records = []
    driving_pres_records = []
    ps_records = []
    
    for pid in patient_ids:
        # ä»…60%æ‚£è€…æœ‰å‘¼å¸æœºå‚æ•°ï¼ˆæ¨¡æ‹Ÿéæ‰€æœ‰æ‚£è€…éƒ½éœ€è¦æœºæ¢°é€šæ°”ï¼‰
        has_vent = np.random.random() < 0.6
        if has_vent:
            # å‘¼å¸æœºå¼€å§‹æ—¶é—´éšæœºåœ¨6-24å°æ—¶ä¹‹é—´
            vent_start = np.random.choice(range(6, min(24, hours)))
            # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
            sample_times = get_random_sample_times(pid, base_interval=2, jitter=0.4)
            for t in sample_times:
                if t >= vent_start:
                    # å†æœ‰20%æ¦‚ç‡è¯¥æ—¶é—´ç‚¹ç¼ºå¤±è®°å½•ï¼ˆè®¾å¤‡æ•…éšœ/è®°å½•ç¼ºå¤±ï¼‰
                    if np.random.random() < 0.8:
                        peep = np.random.uniform(5, 15)
                        tidal_vol = np.random.uniform(350, 550)
                        tidal_vol_set = np.random.uniform(400, 600)
                        pip = np.random.uniform(15, 35)
                        plateau = np.random.uniform(18, 30)
                        mean_airway = np.random.uniform(10, 20)
                        minute_vol = np.random.uniform(6, 12)
                        rate = np.random.uniform(12, 20)
                        compliance = tidal_vol / max(1, plateau - peep)
                        driving = plateau - peep
                        ps = np.random.uniform(5, 15)
                        
                        peep_records.append({'stay_id': pid, 'time': t, 'peep': peep})
                        tidal_vol_records.append({'stay_id': pid, 'time': t, 'tidal_vol': tidal_vol})
                        # tidal_vol_setè¾ƒå°‘è®°å½•ï¼ˆ50%æ¦‚ç‡ï¼‰
                        if np.random.random() < 0.5:
                            tidal_vol_set_records.append({'stay_id': pid, 'time': t, 'tidal_vol_set': tidal_vol_set})
                        pip_records.append({'stay_id': pid, 'time': t, 'pip': pip})
                        # plateau_preså’Œcomplianceè¾ƒå°‘è®°å½•ï¼ˆ40%æ¦‚ç‡ï¼‰
                        if np.random.random() < 0.4:
                            plateau_pres_records.append({'stay_id': pid, 'time': t, 'plateau_pres': plateau})
                            compliance_records.append({'stay_id': pid, 'time': t, 'compliance': compliance})
                            driving_pres_records.append({'stay_id': pid, 'time': t, 'driving_pres': driving})
                        # mean_airwayå’Œminute_volä¸­ç­‰è®°å½•ç‡ï¼ˆ60%æ¦‚ç‡ï¼‰
                        if np.random.random() < 0.6:
                            mean_airway_pres_records.append({'stay_id': pid, 'time': t, 'mean_airway_pres': mean_airway})
                            minute_vol_records.append({'stay_id': pid, 'time': t, 'minute_vol': minute_vol})
                        vent_rate_records.append({'stay_id': pid, 'time': t, 'vent_rate': rate})
                        ps_records.append({'stay_id': pid, 'time': t, 'ps': ps})
    
    data['peep'] = pd.DataFrame(peep_records) if peep_records else pd.DataFrame(columns=['stay_id', 'time', 'peep'])
    data['tidal_vol'] = pd.DataFrame(tidal_vol_records) if tidal_vol_records else pd.DataFrame(columns=['stay_id', 'time', 'tidal_vol'])
    data['tidal_vol_set'] = pd.DataFrame(tidal_vol_set_records) if tidal_vol_set_records else pd.DataFrame(columns=['stay_id', 'time', 'tidal_vol_set'])
    data['pip'] = pd.DataFrame(pip_records) if pip_records else pd.DataFrame(columns=['stay_id', 'time', 'pip'])
    data['plateau_pres'] = pd.DataFrame(plateau_pres_records) if plateau_pres_records else pd.DataFrame(columns=['stay_id', 'time', 'plateau_pres'])
    data['mean_airway_pres'] = pd.DataFrame(mean_airway_pres_records) if mean_airway_pres_records else pd.DataFrame(columns=['stay_id', 'time', 'mean_airway_pres'])
    data['minute_vol'] = pd.DataFrame(minute_vol_records) if minute_vol_records else pd.DataFrame(columns=['stay_id', 'time', 'minute_vol'])
    data['vent_rate'] = pd.DataFrame(vent_rate_records) if vent_rate_records else pd.DataFrame(columns=['stay_id', 'time', 'vent_rate'])
    data['compliance'] = pd.DataFrame(compliance_records) if compliance_records else pd.DataFrame(columns=['stay_id', 'time', 'compliance'])
    data['driving_pres'] = pd.DataFrame(driving_pres_records) if driving_pres_records else pd.DataFrame(columns=['stay_id', 'time', 'driving_pres'])
    data['ps'] = pd.DataFrame(ps_records) if ps_records else pd.DataFrame(columns=['stay_id', 'time', 'ps'])
    
    # ============ è¡¥å……æ›´å¤šå®éªŒå®¤æ£€æŸ¥ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯12å°æ—¶ï¼‰ ============
    alp_records = []
    bun_records = []
    alt_records = []
    ast_records = []
    ca_records = []
    mg_records = []
    cl_records = []
    ck_records = []
    ckmb_records = []
    tri_records = []
    tnt_records = []
    crp_records = []
    bicar_records = []
    bili_dir_records = []
    alb_records = []
    be_records = []
    cai_records = []
    tco2_records = []
    
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=12, jitter=0.4)
        for t in sample_times:
            alp_records.append({'stay_id': pid, 'time': t, 'alp': np.random.uniform(40, 120)})
            bun_records.append({'stay_id': pid, 'time': t, 'bun': np.random.uniform(10, 40)})
            alt_records.append({'stay_id': pid, 'time': t, 'alt': np.random.uniform(10, 60)})
            ast_records.append({'stay_id': pid, 'time': t, 'ast': np.random.uniform(10, 60)})
            ca_records.append({'stay_id': pid, 'time': t, 'ca': np.random.uniform(8.5, 10.5)})
            mg_records.append({'stay_id': pid, 'time': t, 'mg': np.random.uniform(1.5, 2.5)})
            cl_records.append({'stay_id': pid, 'time': t, 'cl': np.random.uniform(95, 110)})
            ck_records.append({'stay_id': pid, 'time': t, 'ck': np.random.uniform(50, 300)})
            ckmb_records.append({'stay_id': pid, 'time': t, 'ckmb': np.random.uniform(0, 10)})
            tri_records.append({'stay_id': pid, 'time': t, 'tri': np.random.uniform(0, 0.5)})
            tnt_records.append({'stay_id': pid, 'time': t, 'tnt': np.random.uniform(0, 0.5)})
            crp_records.append({'stay_id': pid, 'time': t, 'crp': np.random.uniform(5, 100)})
            bicar_records.append({'stay_id': pid, 'time': t, 'bicar': np.random.uniform(22, 28)})
            bili_dir_records.append({'stay_id': pid, 'time': t, 'bili_dir': np.random.uniform(0.1, 0.5)})
            alb_records.append({'stay_id': pid, 'time': t, 'alb': np.random.uniform(3.0, 4.5)})
            be_records.append({'stay_id': pid, 'time': t, 'be': np.random.uniform(-3, 3)})
            cai_records.append({'stay_id': pid, 'time': t, 'cai': np.random.uniform(1.1, 1.3)})
            tco2_records.append({'stay_id': pid, 'time': t, 'tco2': np.random.uniform(23, 29)})
    
    data['alp'] = pd.DataFrame(alp_records)
    data['bun'] = pd.DataFrame(bun_records)
    data['alt'] = pd.DataFrame(alt_records)
    data['ast'] = pd.DataFrame(ast_records)
    data['ca'] = pd.DataFrame(ca_records)
    data['mg'] = pd.DataFrame(mg_records)
    data['cl'] = pd.DataFrame(cl_records)
    data['ck'] = pd.DataFrame(ck_records)
    data['ckmb'] = pd.DataFrame(ckmb_records)
    data['tri'] = pd.DataFrame(tri_records)
    data['tnt'] = pd.DataFrame(tnt_records)
    data['crp'] = pd.DataFrame(crp_records)
    data['bicar'] = pd.DataFrame(bicar_records)
    data['bili_dir'] = pd.DataFrame(bili_dir_records)
    data['alb'] = pd.DataFrame(alb_records)
    data['be'] = pd.DataFrame(be_records)
    data['cai'] = pd.DataFrame(cai_records)
    data['tco2'] = pd.DataFrame(tco2_records)
    # ğŸ”§ åˆ é™¤åˆ«åæ¦‚å¿µï¼ˆä¸ CONCEPT_GROUPS_INTERNAL ä¿æŒä¸€è‡´ï¼‰
    # åˆ é™¤: bicarb (bicarçš„åˆ«å), potassium (kçš„åˆ«å)
    
    # ============ è¡€æ¶²å­¦æ‰©å±•ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼Œçº¦æ¯12å°æ—¶ï¼‰ ============
    hct_records = []
    rbc_records = []
    rdw_records = []
    mcv_records = []
    mch_records = []
    mchc_records = []
    neut_records = []
    lymph_records = []
    eos_records = []
    basos_records = []
    bnd_records = []
    inr_pt_records = []
    ptt_records = []
    pt_records = []
    fgn_records = []
    esr_records = []
    hba1c_records = []
    
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=12, jitter=0.4)
        for t in sample_times:
            hct_records.append({'stay_id': pid, 'time': t, 'hct': np.random.uniform(30, 45)})
            rbc_records.append({'stay_id': pid, 'time': t, 'rbc': np.random.uniform(3.5, 5.5)})
            rdw_records.append({'stay_id': pid, 'time': t, 'rdw': np.random.uniform(11, 15)})
            mcv_records.append({'stay_id': pid, 'time': t, 'mcv': np.random.uniform(80, 100)})
            mch_records.append({'stay_id': pid, 'time': t, 'mch': np.random.uniform(27, 32)})
            mchc_records.append({'stay_id': pid, 'time': t, 'mchc': np.random.uniform(32, 36)})
            neut_records.append({'stay_id': pid, 'time': t, 'neut': np.random.uniform(40, 75)})
            lymph_records.append({'stay_id': pid, 'time': t, 'lymph': np.random.uniform(20, 40)})
            eos_records.append({'stay_id': pid, 'time': t, 'eos': np.random.uniform(1, 5)})
            basos_records.append({'stay_id': pid, 'time': t, 'basos': np.random.uniform(0, 2)})
            bnd_records.append({'stay_id': pid, 'time': t, 'bnd': np.random.uniform(0, 10)})
            inr_pt_records.append({'stay_id': pid, 'time': t, 'inr_pt': np.random.uniform(0.9, 1.3)})
            ptt_records.append({'stay_id': pid, 'time': t, 'ptt': np.random.uniform(25, 35)})
            pt_records.append({'stay_id': pid, 'time': t, 'pt': np.random.uniform(11, 14)})
            fgn_records.append({'stay_id': pid, 'time': t, 'fgn': np.random.uniform(200, 400)})
            esr_records.append({'stay_id': pid, 'time': t, 'esr': np.random.uniform(5, 25)})
            hba1c_records.append({'stay_id': pid, 'time': t, 'hba1c': np.random.uniform(5.0, 7.0)})
    
    data['hct'] = pd.DataFrame(hct_records)
    data['rbc'] = pd.DataFrame(rbc_records)
    data['rdw'] = pd.DataFrame(rdw_records)
    data['mcv'] = pd.DataFrame(mcv_records)
    data['mch'] = pd.DataFrame(mch_records)
    data['mchc'] = pd.DataFrame(mchc_records)
    data['neut'] = pd.DataFrame(neut_records)
    data['lymph'] = pd.DataFrame(lymph_records)
    data['eos'] = pd.DataFrame(eos_records)
    data['basos'] = pd.DataFrame(basos_records)
    data['bnd'] = pd.DataFrame(bnd_records)
    data['inr_pt'] = pd.DataFrame(inr_pt_records)
    data['ptt'] = pd.DataFrame(ptt_records)
    data['pt'] = pd.DataFrame(pt_records)
    data['fgn'] = pd.DataFrame(fgn_records)
    data['esr'] = pd.DataFrame(esr_records)
    data['hba1c'] = pd.DataFrame(hba1c_records)
    
    # ============ æ›´å¤šè¯ç‰© ============
    dopa_rate_records = []
    dopa_dur_records = []
    dopa60_records = []
    epi_dur_records = []
    epi_rate_records = []
    epi60_records = []
    norepi_rate_records = []
    norepi_dur_records = []
    norepi60_records = []
    adh_rate_records = []
    phn_rate_records = []
    dobu_rate_records = []
    dobu_dur_records = []
    dobu60_records = []
    ins_records = []
    dex_records = []
    
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=3, jitter=0.4)
        for t in sample_times:
            if np.random.random() < 0.3:
                dopa_rate_records.append({'stay_id': pid, 'time': t, 'dopa_rate': np.random.uniform(2, 10)})
                epi_rate_records.append({'stay_id': pid, 'time': t, 'epi_rate': np.random.uniform(0.01, 0.1)})
                norepi_rate_records.append({'stay_id': pid, 'time': t, 'norepi_rate': np.random.uniform(0.01, 1.0)})
                dobu_rate_records.append({'stay_id': pid, 'time': t, 'dobu_rate': np.random.uniform(2, 10)})
                adh_rate_records.append({'stay_id': pid, 'time': t, 'adh_rate': np.random.uniform(0.01, 0.04)})
                phn_rate_records.append({'stay_id': pid, 'time': t, 'phn_rate': np.random.uniform(0.1, 0.5)})
        
        dopa_dur_records.append({'stay_id': pid, 'dopa_dur': np.random.uniform(0, 48)})
        epi_dur_records.append({'stay_id': pid, 'epi_dur': np.random.uniform(0, 24)})
        norepi_dur_records.append({'stay_id': pid, 'norepi_dur': np.random.uniform(0, 72)})
        dobu_dur_records.append({'stay_id': pid, 'dobu_dur': np.random.uniform(0, 36)})
        dopa60_records.append({'stay_id': pid, 'dopa60': 1 if np.random.random() < 0.4 else 0})
        epi60_records.append({'stay_id': pid, 'epi60': 1 if np.random.random() < 0.3 else 0})
        norepi60_records.append({'stay_id': pid, 'norepi60': 1 if np.random.random() < 0.5 else 0})
        dobu60_records.append({'stay_id': pid, 'dobu60': 1 if np.random.random() < 0.3 else 0})
        ins_records.append({'stay_id': pid, 'ins': np.random.uniform(0, 10)})
        dex_records.append({'stay_id': pid, 'dex': np.random.uniform(0, 1.5)})
    
    data['dopa_rate'] = pd.DataFrame(dopa_rate_records) if dopa_rate_records else pd.DataFrame(columns=['stay_id', 'time', 'dopa_rate'])
    data['dopa_dur'] = pd.DataFrame(dopa_dur_records)
    data['dopa60'] = pd.DataFrame(dopa60_records)
    data['epi_rate'] = pd.DataFrame(epi_rate_records) if epi_rate_records else pd.DataFrame(columns=['stay_id', 'time', 'epi_rate'])
    data['epi_dur'] = pd.DataFrame(epi_dur_records)
    data['epi60'] = pd.DataFrame(epi60_records)
    data['norepi_rate'] = pd.DataFrame(norepi_rate_records) if norepi_rate_records else pd.DataFrame(columns=['stay_id', 'time', 'norepi_rate'])
    data['norepi_dur'] = pd.DataFrame(norepi_dur_records)
    data['norepi60'] = pd.DataFrame(norepi60_records)
    data['adh_rate'] = pd.DataFrame(adh_rate_records) if adh_rate_records else pd.DataFrame(columns=['stay_id', 'time', 'adh_rate'])
    data['phn_rate'] = pd.DataFrame(phn_rate_records) if phn_rate_records else pd.DataFrame(columns=['stay_id', 'time', 'phn_rate'])
    data['dobu_rate'] = pd.DataFrame(dobu_rate_records) if dobu_rate_records else pd.DataFrame(columns=['stay_id', 'time', 'dobu_rate'])
    data['dobu_dur'] = pd.DataFrame(dobu_dur_records)
    data['dobu60'] = pd.DataFrame(dobu60_records)
    data['ins'] = pd.DataFrame(ins_records)
    data['dex'] = pd.DataFrame(dex_records)
    data['norepi_equiv'] = data['norepi_rate'].copy() if 'norepi_rate' in data else pd.DataFrame()
    
    # vaso_ind (è¡€ç®¡æ´»æ€§è¯ç‰©æŒ‡ç¤º)
    vaso_ind_records = []
    for pid in patient_ids:
        vaso_ind_records.append({'stay_id': pid, 'vaso_ind': 1 if np.random.random() < 0.6 else 0})
    data['vaso_ind'] = pd.DataFrame(vaso_ind_records)
    
    # ============ ç¥ç»å’Œå…¶ä»–æ”¯æŒï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼‰ ============
    rass_records = []
    avpu_records = []
    egcs_records = []
    mgcs_records = []
    vgcs_records = []
    tgcs_records = []
    sedated_gcs_records = []
    
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times = get_random_sample_times(pid, base_interval=6, jitter=0.4)
        for t in sample_times:
            rass_records.append({'stay_id': pid, 'time': t, 'rass': np.random.choice([-5, -4, -3, -2, -1, 0, 1, 2, 3, 4], p=[0.05, 0.1, 0.15, 0.2, 0.15, 0.2, 0.05, 0.05, 0.03, 0.02])})
            egcs_records.append({'stay_id': pid, 'time': t, 'egcs': np.random.choice([1, 2, 3, 4], p=[0.1, 0.2, 0.3, 0.4])})
            mgcs_records.append({'stay_id': pid, 'time': t, 'mgcs': np.random.choice([1, 2, 3, 4, 5, 6], p=[0.05, 0.1, 0.15, 0.2, 0.25, 0.25])})
            vgcs_records.append({'stay_id': pid, 'time': t, 'vgcs': np.random.choice([1, 2, 3, 4, 5], p=[0.1, 0.15, 0.2, 0.25, 0.3])})
            avpu_records.append({'stay_id': pid, 'time': t, 'avpu': np.random.choice(['A', 'V', 'P', 'U'], p=[0.6, 0.2, 0.1, 0.1])})
        tgcs_records.append({'stay_id': pid, 'tgcs': np.random.choice([15, 14, 13, 12, 10, 8, 6], p=[0.5, 0.2, 0.1, 0.08, 0.07, 0.03, 0.02])})
        sedated_gcs_records.append({'stay_id': pid, 'sedated_gcs': np.random.choice([15, 14, 13], p=[0.7, 0.2, 0.1])})
    
    data['rass'] = pd.DataFrame(rass_records)
    data['avpu'] = pd.DataFrame(avpu_records)
    data['egcs'] = pd.DataFrame(egcs_records)
    data['mgcs'] = pd.DataFrame(mgcs_records)
    data['vgcs'] = pd.DataFrame(vgcs_records)
    data['tgcs'] = pd.DataFrame(tgcs_records)
    data['sedated_gcs'] = pd.DataFrame(sedated_gcs_records)
    
    # ============ å…¶ä»–æŒ‡æ ‡ï¼ˆä½¿ç”¨é«˜æ•ˆå¾ªç¯è€Œéåˆ—è¡¨æ¨å¯¼å¼ï¼‰============
    # é™æ€æŒ‡æ ‡ï¼ˆæ¯æ‚£è€…ä¸€ä¸ªå€¼ï¼‰
    static_records = {
        'rrt': [], 'ecmo': [], 'height': [], 'bmi': [], 'sex': [], 'adm': [], 
        'los_hosp': [], 'vent_start': [], 'vent_end': [], 'cort': []
    }
    
    # RRTæ”¹ä¸ºæ—¶é—´åºåˆ—æ•°æ®ï¼ˆä»…10%æ‚£è€…ä½¿ç”¨ï¼‰
    rrt_records = []
    rrt_patient_ids = set()  # è®°å½•æœ‰RRTçš„æ‚£è€…ID
    for pid in patient_ids:
        # 10%æ‚£è€…æ¥å—RRT
        if np.random.random() < 0.1:
            rrt_patient_ids.add(pid)
            # RRTå¼€å§‹æ—¶é—´éšæœºåœ¨12-48å°æ—¶ä¹‹é—´
            rrt_start = np.random.choice(range(12, min(48, hours)))
            for t in time_points:
                if t >= rrt_start:
                    rrt_records.append({'stay_id': pid, 'time': t, 'rrt': 1})
    data['rrt'] = pd.DataFrame(rrt_records) if rrt_records else pd.DataFrame(columns=['stay_id', 'time', 'rrt'])
    
    # rrt_criteria ä¹Ÿæ”¹ä¸ºæ—¶é—´åºåˆ—ï¼ˆä¸rrtç›¸åŒï¼Œä½†åˆ—åä¸åŒï¼‰
    if rrt_records:
        data['rrt_criteria'] = data['rrt'].rename(columns={'rrt': 'rrt_criteria'}).copy()
    else:
        data['rrt_criteria'] = pd.DataFrame(columns=['stay_id', 'time', 'rrt_criteria'])
    
    for pid in patient_ids:
        # ä¿ç•™é™æ€ç‰ˆæœ¬ç”¨äºå…¶ä»–ç”¨é€”ï¼ˆä½†ä¸è¦†ç›–æ—¶é—´åºåˆ—ç‰ˆæœ¬ï¼‰
        static_records['rrt'].append({'stay_id': pid, 'rrt_static': 1 if pid in rrt_patient_ids else 0})
        # ğŸ”§ FIX (2026-02-03): ecmoåªè®°å½•å‘ç”Ÿçš„äº‹ä»¶ï¼ˆNaN/1æ ¼å¼ï¼‰
        # åªæœ‰5%æ‚£è€…ä½¿ç”¨ECMOï¼Œåªåœ¨å‘ç”Ÿæ—¶è®°å½•1
        if np.random.random() < 0.05:
            static_records['ecmo'].append({'stay_id': pid, 'ecmo': 1})
        # ğŸ”§ æ³¨æ„ï¼šheight, bmi, sex, adm, los_hosp å·²åœ¨å‰é¢ä½¿ç”¨ patient_sepsis_meta æ­£ç¡®ç”Ÿæˆ
        # è¿™é‡Œåªç”Ÿæˆé‚£äº›å‰é¢æ²¡æœ‰ç”Ÿæˆçš„é™æ€å­—æ®µ
        static_records['vent_start'].append({'stay_id': pid, 'vent_start': np.random.choice(time_points[:min(24, len(time_points))])})
        static_records['vent_end'].append({'stay_id': pid, 'vent_end': np.random.choice(time_points[-min(24, len(time_points)):])})
        # ğŸ”§ FIX (2026-02-03): cortåªè®°å½•å‘ç”Ÿçš„äº‹ä»¶ï¼ˆNaN/1æ ¼å¼ï¼‰
        if np.random.random() < 0.3:
            static_records['cort'].append({'stay_id': pid, 'cort': 1})
    
    # åªä¸ºéRRTä¸”æœªåœ¨å‰é¢ç”Ÿæˆçš„é™æ€æŒ‡æ ‡åˆ›å»ºDataFrame
    # ğŸ”§ è·³è¿‡å·²æ­£ç¡®ç”Ÿæˆçš„: rrt(æ—¶é—´åºåˆ—), sex, age, death, los_icu, los_hosp, weight, height, bmi, adm
    already_generated = {'rrt', 'sex', 'age', 'death', 'los_icu', 'los_hosp', 'weight', 'height', 'bmi', 'adm'}
    for key, records in static_records.items():
        if key not in already_generated:
            # ğŸ”§ FIX: å¦‚æœè®°å½•ä¸ºç©ºï¼Œåˆ›å»ºå¸¦æ­£ç¡®åˆ—åçš„ç©ºDataFrame
            if records:
                data[key] = pd.DataFrame(records)
            else:
                # æ ¹æ®keyç¡®å®šåˆ—å
                if key == 'ecmo':
                    data[key] = pd.DataFrame(columns=['stay_id', 'ecmo'])
                elif key == 'cort':
                    data[key] = pd.DataFrame(columns=['stay_id', 'cort'])
                else:
                    data[key] = pd.DataFrame(records)
    
    # ğŸ”§ æ³¨æ„: ecmo, ecmo_indication, mech_circ_support åœ¨åé¢çš„ä»£ç ä¸­å•ç‹¬ç”Ÿæˆ
    # ï¼ˆçº¦ç¬¬3298-3320è¡Œï¼‰ï¼Œæ­¤å¤„ä¸å†å¤åˆ¶ï¼Œé¿å…ç”Ÿæˆé¡ºåºé—®é¢˜
    
    # æ—¶é—´åºåˆ—æŒ‡æ ‡ï¼ˆä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·ï¼‰
    mews_records = []
    news_records = []
    hbco_records = []
    methb_records = []
    k_records = []
    na_records = []
    phos_records = []
    hgb_records = []
    safi_records = []
    
    for pid in patient_ids:
        # ğŸ”§ FIX (2026-02-03): ä½¿ç”¨æ‚£è€…çº§éšæœºé‡‡æ ·æ—¶é—´
        sample_times_6h = get_random_sample_times(pid, base_interval=6, jitter=0.4)
        sample_times_12h = get_random_sample_times(pid, base_interval=12, jitter=0.4)
        sample_times_4h = get_random_sample_times(pid, base_interval=4, jitter=0.4)
        
        for t in sample_times_6h:
            mews_records.append({'stay_id': pid, 'time': t, 'mews': np.random.choice([0, 1, 2, 3, 4, 5], p=[0.3, 0.25, 0.2, 0.15, 0.07, 0.03])})
            news_records.append({'stay_id': pid, 'time': t, 'news': np.random.choice([0, 1, 2, 3, 4, 5, 6, 7], p=[0.25, 0.2, 0.18, 0.15, 0.1, 0.07, 0.03, 0.02])})
        
        for t in sample_times_12h:
            if 'k' not in data:
                k_records.append({'stay_id': pid, 'time': t, 'k': np.random.uniform(3.5, 5.0)})
            if 'na' not in data:
                na_records.append({'stay_id': pid, 'time': t, 'na': np.random.uniform(135, 145)})
            if 'phos' not in data:
                phos_records.append({'stay_id': pid, 'time': t, 'phos': np.random.uniform(2.5, 4.5)})
            if 'hgb' not in data:
                hgb_records.append({'stay_id': pid, 'time': t, 'hgb': np.random.uniform(10, 15)})
            hbco_records.append({'stay_id': pid, 'time': t, 'hbco': np.random.uniform(0, 5)})
            methb_records.append({'stay_id': pid, 'time': t, 'methb': np.random.uniform(0, 2)})
        
        for t in sample_times_4h:
            safi_records.append({'stay_id': pid, 'time': t, 'safi': np.random.uniform(200, 450)})
    
    data['mews'] = pd.DataFrame(mews_records)
    data['news'] = pd.DataFrame(news_records)
    data['hbco'] = pd.DataFrame(hbco_records)
    data['methb'] = pd.DataFrame(methb_records)
    data['safi'] = pd.DataFrame(safi_records)
    
    if k_records:
        data['k'] = pd.DataFrame(k_records)
    if na_records:
        data['na'] = pd.DataFrame(na_records)
    if phos_records:
        data['phos'] = pd.DataFrame(phos_records)
    if hgb_records:
        data['hgb'] = pd.DataFrame(hgb_records)
    
    # æ•°æ®å¤åˆ¶å’Œåˆ«å
    data['mech_vent'] = data['vent_ind'].copy() if 'vent_ind' in data and not data['vent_ind'].empty else pd.DataFrame(columns=['stay_id', 'time', 'mech_vent'])
    
    # vent_start å’Œ vent_end (æœºæ¢°é€šæ°”èµ·æ­¢æ—¶é—´)
    vent_start_records = []
    vent_end_records = []
    if 'vent_ind' in data and not data['vent_ind'].empty:
        for pid in patient_ids:
            pid_vent = data['vent_ind'][data['vent_ind']['stay_id'] == pid].copy()
            if len(pid_vent) > 0 and (pid_vent['vent_ind'] == 1).any():
                vent_times = pid_vent[pid_vent['vent_ind'] == 1]['time']
                if len(vent_times) > 0:
                    start_t = vent_times.min()
                    end_t = vent_times.max() + 4  # å‡è®¾æ¯æ¬¡æµ‹é‡æŒç»­4å°æ—¶
                    vent_start_records.append({'stay_id': pid, 'time': start_t, 'vent_start': 1})
                    vent_end_records.append({'stay_id': pid, 'time': end_t, 'vent_end': 1})
    data['vent_start'] = pd.DataFrame(vent_start_records) if vent_start_records else pd.DataFrame(columns=['stay_id', 'time', 'vent_start'])
    data['vent_end'] = pd.DataFrame(vent_end_records) if vent_end_records else pd.DataFrame(columns=['stay_id', 'time', 'vent_end'])
    
    # ECMO (ä½“å¤–è†œè‚ºæ°§åˆ) - ç½•è§äº‹ä»¶ï¼Œçº¦3%æ‚£è€…
    ecmo_records = []
    ecmo_indication_records = []
    for pid in patient_ids:
        if np.random.random() < 0.03:  # 3%æ¦‚ç‡ä½¿ç”¨ECMO
            ecmo_start = np.random.uniform(12, 48)
            ecmo_indication = np.random.choice(['ARDS', 'Cardiogenic_shock', 'Bridge_to_transplant'])
            ecmo_records.append({'stay_id': pid, 'time': ecmo_start, 'ecmo': 1})
            ecmo_indication_records.append({'stay_id': pid, 'time': ecmo_start, 'ecmo_indication': ecmo_indication})
    data['ecmo'] = pd.DataFrame(ecmo_records) if ecmo_records else pd.DataFrame(columns=['stay_id', 'time', 'ecmo'])
    data['ecmo_indication'] = pd.DataFrame(ecmo_indication_records) if ecmo_indication_records else pd.DataFrame(columns=['stay_id', 'time', 'ecmo_indication'])
    
    # ğŸ”§ FIX (2026-02-04): mech_circ_support - æœºæ¢°å¾ªç¯æ”¯æŒï¼ˆIABP/LVAD/Impella/VA-ECMOï¼‰
    # çœŸå®æ•°æ®ä¸­éå¸¸ç½•è§ï¼Œçº¦2-3%çš„ICUæ‚£è€…ä½¿ç”¨ï¼ˆæ¯”ECMOç¨å¤šï¼Œå› ä¸ºåŒ…æ‹¬IABPç­‰ï¼‰
    # è¿™é‡Œåœ¨ecmoç”Ÿæˆä¹‹åæ›´æ–°mech_circ_supportï¼Œç¡®ä¿åæ˜ æ­£ç¡®çš„ç¼ºå¤±ç‡
    mech_circ_records = []
    for pid in patient_ids:
        # 2.5%æ¦‚ç‡ä½¿ç”¨æœºæ¢°å¾ªç¯æ”¯æŒï¼ˆåŒ…æ‹¬ECMO + IABP + LVADç­‰ï¼‰
        if np.random.random() < 0.025:
            mcs_start = np.random.uniform(12, 48)
            mech_circ_records.append({'stay_id': pid, 'time': mcs_start, 'mech_circ_support': 1})
    data['mech_circ_support'] = pd.DataFrame(mech_circ_records) if mech_circ_records else pd.DataFrame(columns=['stay_id', 'time', 'mech_circ_support'])
    
    if 'fio2' in data and not data['fio2'].empty:
        data['supp_o2'] = data['fio2'].copy()
        data['supp_o2']['supp_o2'] = (data['supp_o2']['fio2'] > 21).astype(int)
        data['supp_o2'] = data['supp_o2'][['stay_id', 'time', 'supp_o2']]
    else:
        data['supp_o2'] = pd.DataFrame(columns=['stay_id', 'time', 'supp_o2'])
    
    # spo2/sao2 åˆ«åå¤„ç†ï¼ˆé¿å…å¾ªç¯å¼•ç”¨ï¼‰
    if 'spo2' in data and not data['spo2'].empty:
        # spo2å·²ç»å­˜åœ¨ï¼Œåˆ›å»ºo2satå’Œsao2åˆ«å
        if 'o2sat' not in data or data['o2sat'].empty:
            data['o2sat'] = data['spo2'].rename(columns={'spo2': 'o2sat'}).copy()
        if 'sao2' not in data or data['sao2'].empty:
            data['sao2'] = data['spo2'].rename(columns={'spo2': 'sao2'}).copy()
    
    data['ett_gcs'] = data['gcs'].copy() if 'gcs' in data and not data['gcs'].empty else pd.DataFrame(columns=['stay_id', 'time', 'ett_gcs'])
    # urine24: 24å°æ—¶ç´¯è®¡å°¿é‡ï¼Œæ¯6å°æ—¶ä¸€ä¸ªè®°å½•ç‚¹ï¼ˆæ¨¡æ‹ŸçœŸå®é‡‡æ ·é¢‘ç‡ï¼‰
    urine24_records = []
    if 'urine' in data and not data['urine'].empty:
        for pid in patient_ids:
            pid_urine = data['urine'][data['urine']['stay_id'] == pid]
            for t in time_points[::6]:  # æ¯6å°æ—¶è®°å½•ä¸€æ¬¡
                # è®¡ç®—è¿‡å»24å°æ—¶çš„å°¿é‡
                recent_urine = pid_urine[(pid_urine['time'] >= max(0, t-24)) & (pid_urine['time'] <= t)]
                if len(recent_urine) > 0:  # åªæœ‰å½“æœ‰æ•°æ®æ—¶æ‰è®°å½•
                    urine24_records.append({
                        'stay_id': pid,
                        'time': t,
                        'urine24': recent_urine['urine'].sum()
                    })
    data['urine24'] = pd.DataFrame(urine24_records) if urine24_records else pd.DataFrame(columns=['stay_id', 'time', 'urine24'])
    
    # === ğŸ†• æ–°å¢ 12 ä¸ªç¼ºå¤±çš„æ¦‚å¿µï¼ˆ2026-02-03ï¼‰===
    
    # 1. uo_6h, uo_12h, uo_24h: 6/12/24å°æ—¶å°¿é‡ç‡ (mL/kg/h)
    uo_6h_records = []
    uo_12h_records = []
    uo_24h_records = []
    if 'urine' in data and not data['urine'].empty and 'weight' in data and not data['weight'].empty:
        weight_dict = data['weight'].set_index('stay_id')['weight'].to_dict()
        for pid in patient_ids:
            if pid not in weight_dict:
                continue
            weight = weight_dict[pid]
            pid_urine = data['urine'][data['urine']['stay_id'] == pid]
            
            for t in time_points[::3]:  # æ¯3å°æ—¶é‡‡æ ·ä¸€æ¬¡
                # 6å°æ—¶å°¿é‡ç‡
                recent_6h = pid_urine[(pid_urine['time'] >= max(0, t-6)) & (pid_urine['time'] <= t)]
                if len(recent_6h) > 0:
                    uo_6h = recent_6h['urine'].sum() / weight / 6.0
                    uo_6h_records.append({'stay_id': pid, 'time': t, 'uo_6h': uo_6h})
                
                # 12å°æ—¶å°¿é‡ç‡
                recent_12h = pid_urine[(pid_urine['time'] >= max(0, t-12)) & (pid_urine['time'] <= t)]
                if len(recent_12h) > 0:
                    uo_12h = recent_12h['urine'].sum() / weight / 12.0
                    uo_12h_records.append({'stay_id': pid, 'time': t, 'uo_12h': uo_12h})
                
                # 24å°æ—¶å°¿é‡ç‡
                recent_24h = pid_urine[(pid_urine['time'] >= max(0, t-24)) & (pid_urine['time'] <= t)]
                if len(recent_24h) > 0:
                    uo_24h = recent_24h['urine'].sum() / weight / 24.0
                    uo_24h_records.append({'stay_id': pid, 'time': t, 'uo_24h': uo_24h})
    
    data['uo_6h'] = pd.DataFrame(uo_6h_records) if uo_6h_records else pd.DataFrame(columns=['stay_id', 'time', 'uo_6h'])
    data['uo_12h'] = pd.DataFrame(uo_12h_records) if uo_12h_records else pd.DataFrame(columns=['stay_id', 'time', 'uo_12h'])
    data['uo_24h'] = pd.DataFrame(uo_24h_records) if uo_24h_records else pd.DataFrame(columns=['stay_id', 'time', 'uo_24h'])
    
    # ğŸ”§ 2026-02-04: ç§»é™¤äº†é‡å¤çš„ kdigo_creat/kdigo_uo/kdigo_aki åˆ›å»ºä»£ç 
    # è¿™äº›æ¦‚å¿µä¸ aki_stage_creat/aki_stage_uo/aki_stage å®Œå…¨é‡å¤ï¼Œåªä¿ç•™åè€…
    
    # 3. motor_response: GCSè¿åŠ¨ååº”åˆ†é¡¹ï¼ˆä»gcsä¸­æå–ï¼‰
    motor_response_records = []
    if 'gcs' in data and not data['gcs'].empty:
        for pid in patient_ids:
            pid_gcs = data['gcs'][data['gcs']['stay_id'] == pid]
            for _, row in pid_gcs.iterrows():
                # motor response é€šå¸¸æ˜¯ GCS ä¸­çš„ä¸€éƒ¨åˆ† (1-6åˆ†)
                # è¿™é‡Œç®€åŒ–ä¸º GCS/3 å–æ•´ï¼ˆæ¨¡æ‹Ÿï¼‰
                motor_score = max(1, min(6, int(row['gcs'] / 3)))
                motor_response_records.append({
                    'stay_id': pid,
                    'time': row['time'],
                    'motor_response': motor_score
                })
    data['motor_response'] = pd.DataFrame(motor_response_records) if motor_response_records else pd.DataFrame(columns=['stay_id', 'time', 'motor_response'])
    
    # 4. delirium_positive: è°µå¦„é˜³æ€§ï¼ˆåŸºäºRASSå’ŒGCSè¯„ä¼°ï¼‰
    delirium_positive_records = []
    if 'rass' in data and not data['rass'].empty:
        for pid in patient_ids:
            pid_rass = data['rass'][data['rass']['stay_id'] == pid]
            for _, row in pid_rass.iterrows():
                # è°µå¦„é€šå¸¸å‡ºç°åœ¨ RASS > 0 ä¸” < 4ï¼Œæˆ–æ³¢åŠ¨æ€§æ„è¯†çŠ¶æ€
                # è¿™é‡Œç®€åŒ–ä¸º RASS åœ¨ 1-3 æ—¶çº¦30%å‡ ç‡é˜³æ€§
                is_delirium = 1 if (1 <= row['rass'] <= 3 and np.random.random() < 0.3) else 0
                delirium_positive_records.append({
                    'stay_id': pid,
                    'time': row['time'],
                    'delirium_positive': is_delirium
                })
    data['delirium_positive'] = pd.DataFrame(delirium_positive_records) if delirium_positive_records else pd.DataFrame(columns=['stay_id', 'time', 'delirium_positive'])
    
    # 5. delirium_tx: è°µå¦„æ²»ç–—ï¼ˆé€šå¸¸ä½¿ç”¨æŠ—ç²¾ç¥ç—…è¯ç‰©ï¼‰
    delirium_tx_records = []
    if 'delirium_positive' in data and not data['delirium_positive'].empty:
        # å‡è®¾çº¦50%çš„è°µå¦„é˜³æ€§æ‚£è€…ä¼šæ¥å—æ²»ç–—
        delirium_pts = data['delirium_positive'][data['delirium_positive']['delirium_positive'] == 1]['stay_id'].unique()
        for pid in delirium_pts:
            if np.random.random() < 0.5:  # 50%æ¥å—æ²»ç–—
                treatment_start = np.random.uniform(12, 60)
                delirium_tx_records.append({
                    'stay_id': pid,
                    'time': treatment_start,
                    'delirium_tx': 1
                })
    data['delirium_tx'] = pd.DataFrame(delirium_tx_records) if delirium_tx_records else pd.DataFrame(columns=['stay_id', 'time', 'delirium_tx'])
    
    # 6. adv_resp: é«˜çº§å‘¼å¸æ”¯æŒï¼ˆæœºæ¢°é€šæ°” + PEEP > 5ï¼‰
    adv_resp_records = []
    if 'vent_ind' in data and not data['vent_ind'].empty and 'peep' in data and not data['peep'].empty:
        # åˆå¹¶ vent_ind å’Œ peep
        vent_peep = pd.merge(
            data['vent_ind'],
            data['peep'],
            on=['stay_id', 'time'],
            how='inner'
        )
        for _, row in vent_peep.iterrows():
            # é«˜çº§å‘¼å¸æ”¯æŒ = æœºæ¢°é€šæ°” + PEEP > 5
            is_adv = 1 if (row['vent_ind'] == 1 and row['peep'] > 5) else 0
            adv_resp_records.append({
                'stay_id': row['stay_id'],
                'time': row['time'],
                'adv_resp': is_adv
            })
    data['adv_resp'] = pd.DataFrame(adv_resp_records) if adv_resp_records else pd.DataFrame(columns=['stay_id', 'time', 'adv_resp'])
    
    # 7. other_vaso: å…¶ä»–è¡€ç®¡æ´»æ€§è¯ç‰©ï¼ˆä¸åŒ…æ‹¬å¸¸è§çš„norepi/epi/dopa/dobuï¼‰
    # ç¤ºä¾‹ï¼šè¡€ç®¡åŠ å‹ç´ (vasopressin)ã€å»ç”²è‚¾ä¸Šè…ºç´ (phenylephrine)ç­‰
    other_vaso_records = []
    if 'phn_rate' in data and not data['phn_rate'].empty:
        data['other_vaso'] = data['phn_rate'].copy()
        data['other_vaso'] = data['other_vaso'].rename(columns={'phn_rate': 'other_vaso'})
        data['other_vaso']['other_vaso'] = (data['other_vaso']['other_vaso'] > 0).astype(int)
    else:
        # ç”Ÿæˆå°‘é‡è®°å½•ï¼ˆçº¦10%æ‚£è€…ï¼‰
        for pid in patient_ids:
            if np.random.random() < 0.1:
                start_time = np.random.uniform(6, 48)
                for t in range(int(start_time), min(72, int(start_time + 24)), 4):
                    other_vaso_records.append({
                        'stay_id': pid,
                        'time': float(t),
                        'other_vaso': 1
                    })
        data['other_vaso'] = pd.DataFrame(other_vaso_records) if other_vaso_records else pd.DataFrame(columns=['stay_id', 'time', 'other_vaso'])
    
    # 8. sep3: Sepsis-3 è¯Šæ–­ï¼ˆsep3_sofa1 çš„åˆ«åï¼‰
    if 'sep3_sofa1' in data and not data['sep3_sofa1'].empty:
        data['sep3'] = data['sep3_sofa1'].copy()
        data['sep3'] = data['sep3'].rename(columns={'sep3_sofa1': 'sep3'})
    else:
        data['sep3'] = pd.DataFrame(columns=['stay_id', 'time', 'sep3'])
    
    # ğŸ”§ å·²åˆ é™¤å†—ä½™åˆ«åæ¦‚å¿µï¼ˆ2025-02-06ï¼‰ï¼šä¸ CONCEPT_GROUPS_INTERNAL ä¿æŒä¸€è‡´
    # åˆ é™¤: sepsis_sofa2 (sep3_sofa2çš„åˆ«å), sep3 (sep3_sofa1çš„åˆ«å)
    
    return data, patient_ids


def render_visualization_mode():
    """æ¸²æŸ“å¿«é€Ÿå¯è§†åŒ–æ¨¡å¼çš„ä¾§è¾¹æ å†…å®¹ - å·²åºŸå¼ƒï¼ŒåŠŸèƒ½ç§»è‡³ render_quick_visualization_pageã€‚"""
    # è¯¥å‡½æ•°å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç 
    pass


def render_quick_visualization_page():
    """æ¸²æŸ“å¿«é€Ÿå¯è§†åŒ–ä¸»é¡µé¢ - åŒ…å«æ•°æ®åŠ è½½åŒºåŸŸå’Œå››ä¸ªå­æ¨¡å—ã€‚"""
    lang = st.session_state.get('language', 'en')
    entry_mode = st.session_state.get('entry_mode', 'none')
    
    # ============ é¡¶éƒ¨ï¼šæ•°æ®åŠ è½½åŒºåŸŸ ============
    st.markdown(f"### {get_text('quick_viz')}")
    
    # æ ¹æ® entry_mode æ˜¾ç¤ºä¸åŒæç¤º
    if entry_mode == 'demo':
        hint_text = "Generate demo data or load from exported files for interactive analysis" if lang == 'en' else "ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®æˆ–ä»å·²å¯¼å‡ºæ–‡ä»¶åŠ è½½ï¼Œè¿›è¡Œäº¤äº’å¼åˆ†æ"
    else:
        hint_text = "Load data from exported files for interactive analysis" if lang == 'en' else "ä»å·²å¯¼å‡ºçš„æ•°æ®æ–‡ä»¶åŠ è½½ï¼Œè¿›è¡Œäº¤äº’å¼åˆ†æ"
    st.caption(hint_text)
    
    # æ£€æŸ¥æ˜¯å¦å·²åŠ è½½æ•°æ®
    data_loaded = len(st.session_state.loaded_concepts) > 0
    
    # æ•°æ®åŠ è½½é…ç½®åŒºåŸŸï¼ˆæŠ˜å å¼ï¼ŒåŠ è½½åé»˜è®¤æ”¶èµ·ï¼‰
    expander_label = "âš™ï¸ Data Loading Settings" if lang == 'en' else "âš™ï¸ æ•°æ®åŠ è½½è®¾ç½®"
    with st.expander(expander_label, expanded=not data_loaded):
        
        # çœŸå®æ•°æ®æ¨¡å¼ï¼šåªèƒ½å¯¼å…¥æ–‡ä»¶ï¼Œä¸èƒ½ä½¿ç”¨ Demo
        if entry_mode == 'real':
            # ç›´æ¥è¿›å…¥å¯¼å‡ºæ–‡ä»¶æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºæ•°æ®æºé€‰æ‹©
            st.session_state.viz_data_source = 1  # å¼ºåˆ¶è®¾ä¸ºæ–‡ä»¶æ¨¡å¼
            
            info_msg = "ğŸ“ Load data from exported CSV/Parquet files" if lang == 'en' else "ğŸ“ ä»å·²å¯¼å‡ºçš„ CSV/Parquet æ–‡ä»¶åŠ è½½æ•°æ®"
            st.info(info_msg)
        else:
            # æ¼”ç¤ºæ¨¡å¼ï¼šå¯ä»¥é€‰æ‹© Demo æˆ– å¯¼å‡ºæ–‡ä»¶
            source_label = "Data Source" if lang == 'en' else "æ•°æ®æ¥æº"
            st.markdown(f"**{source_label}**")
            
            # åˆå§‹åŒ–æ•°æ®æºé€‰æ‹© - é»˜è®¤ä¸ºå¯¼å‡ºæ–‡ä»¶æ¨¡å¼ï¼ˆå› ä¸ºç”¨æˆ·å¯èƒ½å…ˆç”¨æå–å™¨å¯¼å‡ºè¿‡ï¼‰
            if 'viz_data_source' not in st.session_state:
                st.session_state.viz_data_source = 1  # é»˜è®¤å¯¼å‡ºæ–‡ä»¶
            
            # ä½¿ç”¨ä¸¤ä¸ªæŒ‰é’®æ›¿ä»£ radioï¼Œé¿å…åŒå‡»é—®é¢˜ï¼ˆå¯¼å‡ºæ–‡ä»¶ä¼˜å…ˆæ˜¾ç¤ºï¼‰
            src_col1, src_col2 = st.columns(2)
            with src_col1:
                file_label = "ğŸ“ Exported Files" if lang == 'en' else "ğŸ“ å·²å¯¼å‡ºæ–‡ä»¶"
                file_type = "primary" if st.session_state.viz_data_source == 1 else "secondary"
                if st.button(file_label, key="viz_src_file", type=file_type, use_container_width=True):
                    st.session_state.viz_data_source = 1
                    st.rerun()
            with src_col2:
                demo_label = "ğŸ­ Demo Data" if lang == 'en' else "ğŸ­ æ¨¡æ‹Ÿæ•°æ®"
                demo_type = "primary" if st.session_state.viz_data_source == 0 else "secondary"
                if st.button(demo_label, key="viz_src_demo", type=demo_type, use_container_width=True):
                    st.session_state.viz_data_source = 0
                    st.rerun()
        
        # ğŸ”§ æ ¹æ®æ•°æ®æºé€‰æ‹©æ˜¾ç¤ºä¸åŒUI (å¯¼å‡ºæ–‡ä»¶æ¨¡å¼ä¼˜å…ˆæ£€æŸ¥)
        if st.session_state.viz_data_source == 1 or entry_mode == 'real':
            # ===== å¯¼å‡ºæ–‡ä»¶æ¨¡å¼ =====
            st.markdown("---")
            import platform
            
            # ğŸ”§ é»˜è®¤è·¯å¾„ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·åœ¨æ•°æ®æå–å™¨ä¸­ä¿å­˜çš„è·¯å¾„
            # ğŸ”§ FIX: ä½¿ç”¨ last_export_full_dirï¼ˆåŒ…å«cohortå­ç›®å½•ï¼‰è€Œé last_export_dir
            if st.session_state.get('last_export_full_dir'):
                # ä¼˜å…ˆä½¿ç”¨æœ€åä¸€æ¬¡å¯¼å‡ºçš„å®Œæ•´ç›®å½•ï¼ˆå«cohortå­ç›®å½•ï¼‰
                default_base_path = st.session_state['last_export_full_dir']
            elif st.session_state.get('last_export_dir'):
                # å…¶æ¬¡ä½¿ç”¨å¯¼å‡ºæ ¹ç›®å½•
                default_base_path = st.session_state['last_export_dir']
            elif st.session_state.get('export_path'):
                # å…¶æ¬¡ä½¿ç”¨æ•°æ®æå–å™¨ä¸­è®¾ç½®çš„å¯¼å‡ºè·¯å¾„
                default_base_path = st.session_state['export_path']
            elif platform.system() == 'Windows':
                default_base_path = r'D:\easyicu_export'
            else:
                default_base_path = os.path.expanduser('~/easyicu_export')
            
            # ğŸ”§ æ•°æ®åº“é€‰æ‹© - æ ¹æ®å…¥å£æ¨¡å¼æä¾›ä¸åŒé€‰é¡¹
            db_select_label = "ğŸ“Š Database" if lang == 'en' else "ğŸ“Š æ•°æ®åº“"
            
            # Real Dataæ¨¡å¼ï¼šåªæœ‰6ä¸ªçœŸå®æ•°æ®åº“ï¼Œæ— mock
            if entry_mode == 'real':
                db_options = ['(Auto Detect)', 'miiv', 'eicu', 'aumc', 'hirid', 'mimic', 'sic']
                db_labels = {
                    '(Auto Detect)': '(Auto Detect)' if lang == 'en' else '(è‡ªåŠ¨æ£€æµ‹)',
                    'miiv': 'MIMIC-IV ğŸŸ¢',
                    'eicu': 'eICU ğŸŸ ',
                    'aumc': 'Amsterdam ğŸ”µ',
                    'hirid': 'HiRID ğŸ”´',
                    'mimic': 'MIMIC-III ğŸŸ£',
                    'sic': 'SICdb âš«',
                }
            else:
                # Demoæ¨¡å¼ï¼šåŒ…å«mocké€‰é¡¹
                db_options = ['(Auto Detect)', 'miiv', 'eicu', 'aumc', 'hirid', 'mimic', 'sic', 'mock']
                db_labels = {
                    '(Auto Detect)': '(Auto Detect)' if lang == 'en' else '(è‡ªåŠ¨æ£€æµ‹)',
                    'miiv': 'MIMIC-IV ğŸŸ¢',
                    'eicu': 'eICU ğŸŸ ',
                    'aumc': 'Amsterdam ğŸ”µ',
                    'hirid': 'HiRID ğŸ”´',
                    'mimic': 'MIMIC-III ğŸŸ£',
                    'sic': 'SICdb âš«',
                    'mock': 'ğŸ­ Mock/Demo',
                }
            
            # è·¯å¾„è¾“å…¥è¡Œï¼šè·¯å¾„è¾“å…¥ + æ•°æ®åº“é€‰æ‹©
            path_col1, path_col2 = st.columns([3, 1])
            
            with path_col1:
                path_label = "Export Directory Path" if lang == 'en' else "å¯¼å‡ºæ•°æ®ç›®å½•è·¯å¾„"
                path_help = "Enter root export folder or specific database folder" if lang == 'en' else "è¾“å…¥å¯¼å‡ºæ ¹ç›®å½•æˆ–å…·ä½“æ•°æ®åº“æ–‡ä»¶å¤¹"
                
                # ğŸ”§ FIX: ä¼˜å…ˆä½¿ç”¨åˆšå¯¼å‡ºçš„è·¯å¾„ï¼Œé¿å…widget keyå†²çª
                default_export_path = st.session_state.get('last_export_dir') or st.session_state.get('viz_export_path') or default_base_path
                
                # ğŸ”§ FIX: ä½¿ç”¨åŠ¨æ€ç‰ˆæœ¬å·keyï¼Œç¡®ä¿å¯¼å‡ºååˆ·æ–°æ˜¾ç¤º
                path_version = st.session_state.get('_viz_export_path_version', 0)
                export_path = st.text_input(
                    path_label,
                    value=default_export_path,
                    help=path_help,
                    key=f"viz_export_path_input_v{path_version}"
                )
            st.session_state.viz_export_path = export_path
            
            with path_col2:
                selected_db = st.selectbox(
                    db_select_label,
                    options=db_options,
                    format_func=lambda x: db_labels.get(x, x),
                    key="viz_export_db_select",
                    help="Filter by database or auto-detect" if lang == 'en' else "æŒ‰æ•°æ®åº“ç­›é€‰æˆ–è‡ªåŠ¨æ£€æµ‹"
                )
            
            # ğŸ”§ FIX (2026-02-04): å…ˆæ£€æµ‹è¾“å…¥ç›®å½•ä¸‹æ˜¯å¦æœ‰å­æ–‡ä»¶å¤¹æ¥å†³å®šæ¨¡å¼
            def has_subdirectories(base_path: str) -> bool:
                """æ£€æµ‹ç›®å½•ä¸‹æ˜¯å¦æœ‰å­æ–‡ä»¶å¤¹"""
                base = Path(base_path)
                if not base.exists():
                    return False
                for item in base.iterdir():
                    if item.is_dir():
                        return True
                return False
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºç²¾ç¡®æŸ¥æ‰¾æ¨¡å¼ï¼ˆç›®å½•ä¸‹æ²¡æœ‰å­æ–‡ä»¶å¤¹ï¼‰
            is_exact_match_mode = Path(export_path).exists() and not has_subdirectories(export_path)
            
            # ğŸ”§ FIX (2026-02-04): åªæœ‰åœ¨éç²¾ç¡®æŸ¥æ‰¾æ¨¡å¼ä¸‹ï¼ŒAuto Detect æ‰å›é€€åˆ°çˆ¶ç›®å½•
            if not is_exact_match_mode and selected_db == '(Auto Detect)':
                # æ£€æµ‹å½“å‰è·¯å¾„æ˜¯å¦æ˜¯å­ç›®å½•ï¼ˆåŒ…å«æ•°æ®åº“åç§°å‰ç¼€ï¼‰
                export_path_obj = Path(export_path)
                db_prefixes = ['miiv', 'eicu', 'aumc', 'hirid', 'mimic', 'sic', 'mock']
                current_dir_name = export_path_obj.name.lower()
                
                # å¦‚æœå½“å‰ç›®å½•åä»¥æ•°æ®åº“å‰ç¼€å¼€å¤´ï¼Œè¯´æ˜ç”¨æˆ·åœ¨å­ç›®å½•ä¸­ï¼Œåº”å›é€€åˆ°çˆ¶ç›®å½•
                for prefix in db_prefixes:
                    if current_dir_name.startswith(prefix):
                        parent_dir = str(export_path_obj.parent)
                        if Path(parent_dir).exists():
                            export_path = parent_dir
                            st.info(f"ğŸ” Auto Detect: searching in `{parent_dir}`" if lang == 'en' else f"ğŸ” è‡ªåŠ¨æ£€æµ‹ï¼šåœ¨ `{parent_dir}` ä¸­æœç´¢æ‰€æœ‰æ•°æ®åº“")
                        break
            
            # ğŸ”§ æ™ºèƒ½ç›®å½•æœç´¢ï¼šæ ¹æ®è·¯å¾„å’Œæ•°æ®åº“é€‰æ‹©ï¼ŒåŠ¨æ€æŸ¥æ‰¾å¯ç”¨ç›®å½•
            def find_export_directories(base_path: str, db_filter: str) -> list:
                """æ™ºèƒ½æœç´¢å¯¼å‡ºæ•°æ®ç›®å½•"""
                result = []
                base = Path(base_path)
                
                
                if not base.exists():
                    return result
                
                # å¦‚æœæŒ‡å®šäº†æ•°æ®åº“ï¼Œåªæœç´¢åŒ¹é…çš„å­ç›®å½•
                if db_filter and db_filter != '(Auto Detect)':
                    # ç›´æ¥æ£€æŸ¥ base_path æ˜¯å¦å°±æ˜¯ç›®æ ‡ç›®å½•
                    if base.name == db_filter:
                        files = list(base.glob('*.csv')) + list(base.glob('*.parquet'))
                        if files:
                            result.append(('', len(files)))  # å½“å‰ç›®å½•
                    # æ£€æŸ¥å­ç›®å½•
                    for subdir in base.iterdir():
                        if subdir.is_dir() and (subdir.name == db_filter or subdir.name.startswith(f'{db_filter}_')):
                            files = list(subdir.glob('*.csv')) + list(subdir.glob('*.parquet'))
                            if files:
                                result.append((subdir.name, len(files)))
                else:
                    # è‡ªåŠ¨æ£€æµ‹ï¼šæ‰«ææ‰€æœ‰å­ç›®å½•
                    # å…ˆæ£€æŸ¥å½“å‰ç›®å½•
                    files = list(base.glob('*.csv')) + list(base.glob('*.parquet'))
                    if files:
                        result.append(('(Current Dir)' if lang == 'en' else '(å½“å‰ç›®å½•)', len(files)))
                    
                    # æ£€æŸ¥å­ç›®å½•
                    for subdir in sorted(base.iterdir()):
                        if subdir.is_dir():
                            files = list(subdir.glob('*.csv')) + list(subdir.glob('*.parquet'))
                            if files:
                                result.append((subdir.name, len(files)))
                
                return result
            
            # æŸ¥æ‰¾å¯ç”¨ç›®å½•
            available_dirs = find_export_directories(export_path, selected_db)
            
            # ğŸ”§ æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦æ˜¾ç¤ºé€‰æ‹©æ¡†
            if is_exact_match_mode:
                # ç²¾ç¡®æŸ¥æ‰¾æ¨¡å¼ï¼šç›®å½•ä¸‹æ²¡æœ‰å­æ–‡ä»¶å¤¹ï¼Œç›´æ¥ä½¿ç”¨å½“å‰ç›®å½•
                actual_path = export_path
                # ä¸æ˜¾ç¤º Select Export Folder é€‰æ‹©æ¡†
            elif len(available_dirs) > 1:
                dir_options = [d[0] for d in available_dirs]
                dir_labels = {d[0]: f"{d[0]} ({d[1]} files)" for d in available_dirs}
                
                selected_subdir = st.selectbox(
                    "ğŸ“‚ " + ("Select Export Folder" if lang == 'en' else "é€‰æ‹©å¯¼å‡ºæ–‡ä»¶å¤¹"),
                    options=dir_options,
                    format_func=lambda x: dir_labels.get(x, x),
                    key="viz_export_subdir"
                )
                
                # æ›´æ–°å®é™…è·¯å¾„
                if selected_subdir and selected_subdir not in ['(Current Dir)', '(å½“å‰ç›®å½•)']:
                    actual_path = os.path.join(export_path, selected_subdir)
                else:
                    actual_path = export_path
            elif len(available_dirs) == 1:
                # åªæœ‰ä¸€ä¸ªç›®å½•ï¼Œç›´æ¥ä½¿ç”¨
                if available_dirs[0][0] not in ['(Current Dir)', '(å½“å‰ç›®å½•)']:
                    actual_path = os.path.join(export_path, available_dirs[0][0])
                else:
                    actual_path = export_path
                st.success(f"âœ… " + (f"Found export folder: {available_dirs[0][0]} ({available_dirs[0][1]} files)" if lang == 'en' else f"æ‰¾åˆ°å¯¼å‡ºæ–‡ä»¶å¤¹ï¼š{available_dirs[0][0]}ï¼ˆ{available_dirs[0][1]}ä¸ªæ–‡ä»¶ï¼‰"))
            else:
                actual_path = export_path
            
            # æ£€æŸ¥è·¯å¾„å¹¶æ˜¾ç¤ºå¯ç”¨æ–‡ä»¶
            if actual_path and Path(actual_path).exists():
                available_files = list(Path(actual_path).glob('*.csv')) + \
                                  list(Path(actual_path).glob('*.parquet')) + \
                                  list(Path(actual_path).glob('*.xlsx'))
                
                if available_files:
                    file_names = [f.stem for f in available_files]
                    found_msg = f"âœ… Found {len(available_files)} data files" if lang == 'en' else f"âœ… å‘ç° {len(available_files)} ä¸ªæ•°æ®æ–‡ä»¶"
                    st.success(found_msg)
                    
                    # æ–‡ä»¶é€‰æ‹©
                    select_label = "Select Tables to Load" if lang == 'en' else "é€‰æ‹©è¦åŠ è½½çš„è¡¨æ ¼"
                    
                    # ğŸ”§ FIX: ä½¿ç”¨å¸¦ç‰ˆæœ¬å·çš„ key æ¥å¼ºåˆ¶åˆ·æ–° multiselect
                    # æ¯æ¬¡ç‚¹å‡» All/Clear æŒ‰é’®ï¼Œç‰ˆæœ¬å·é€’å¢ï¼Œmultiselect ä¼šé‡æ–°åˆ›å»º
                    if '_viz_select_version_v2' not in st.session_state:
                        st.session_state._viz_select_version_v2 = 0
                    
                    # ğŸ”§ ä¿å­˜å½“å‰æ–‡ä»¶åˆ—è¡¨åˆ° session_stateï¼Œè®©å›è°ƒèƒ½è®¿é—®
                    st.session_state._current_filenames_v2 = file_names.copy()
                    
                    # åˆå§‹åŒ–é»˜è®¤é€‰ä¸­ - é»˜è®¤å…¨é€‰
                    ms_key = f"viz_file_multiselect_v{st.session_state._viz_select_version_v2}"
                    if ms_key not in st.session_state:
                        # æ–°ç‰ˆæœ¬çš„ keyï¼Œéœ€è¦åˆå§‹åŒ–é»˜è®¤å€¼
                        default_selection = file_names.copy()  # é»˜è®¤å…¨é€‰
                    else:
                        # å·²å­˜åœ¨çš„ keyï¼Œè¿‡æ»¤æ‰æ— æ•ˆæ–‡ä»¶
                        existing = st.session_state.get(ms_key, [])
                        default_selection = [f for f in existing if f in file_names] or file_names.copy()
                    
                    # ğŸ”§ FIX: å›è°ƒå‡½æ•° - å…¨é€‰
                    def select_all_v2():
                        version = st.session_state._viz_select_version_v2 + 1
                        st.session_state._viz_select_version_v2 = version
                        # è®¾ç½®ä¸‹ä¸€ä¸ªç‰ˆæœ¬çš„ multiselect key çš„é»˜è®¤å€¼
                        new_key = f"viz_file_multiselect_v{version}"
                        st.session_state[new_key] = st.session_state._current_filenames_v2.copy()
                    
                    # ğŸ”§ FIX: å›è°ƒå‡½æ•° - æ¸…ç©º
                    def clear_all_v2():
                        version = st.session_state._viz_select_version_v2 + 1
                        st.session_state._viz_select_version_v2 = version
                        new_key = f"viz_file_multiselect_v{version}"
                        st.session_state[new_key] = []
                    
                    col_all, col_clear = st.columns(2)
                    with col_all:
                        all_label = "âœ… ALL" if lang == 'en' else "âœ… å…¨é€‰"
                        st.button(all_label, key="viz_select_all_v2", use_container_width=True, 
                                 on_click=select_all_v2, type="primary")
                    with col_clear:
                        clear_label = "âŒ Clear" if lang == 'en' else "âŒ æ¸…ç©º"
                        st.button(clear_label, key="viz_clear_all_v2", use_container_width=True,
                                 on_click=clear_all_v2)
                    
                    # ğŸ”§ FIX (2026-02-04): é¿å… default å’Œ session_state å†²çª
                    # å¦‚æœ key å·²ç»åœ¨ session_state ä¸­ï¼Œä¸ä¼  default å‚æ•°
                    if ms_key in st.session_state:
                        selected_files = st.multiselect(
                            select_label,
                            options=file_names,
                            key=ms_key
                        )
                    else:
                        selected_files = st.multiselect(
                            select_label,
                            options=file_names,
                            default=default_selection,
                            key=ms_key
                        )
                    
                    # æ‚£è€…æ•°é‡é™åˆ¶
                    patient_limit_label = "Max Patients to Load" if lang == 'en' else "æœ€å¤§åŠ è½½æ‚£è€…æ•°"
                    patient_options = [50, 100, 200, 500, -1]
                    option_labels = {
                        50: "50 (Fast)" if lang == 'en' else "50 (å¿«é€Ÿ)",
                        100: "100 (Recommended)" if lang == 'en' else "100 (æ¨è)",
                        200: "200" if lang == 'en' else "200",
                        500: "500 (Slow)" if lang == 'en' else "500 (è¾ƒæ…¢)",
                        -1: "All (May Lag)" if lang == 'en' else "å…¨éƒ¨ (å¯èƒ½å¡é¡¿)"
                    }
                    max_patients_opt = st.selectbox(
                        patient_limit_label,
                        options=patient_options,
                        index=1,
                        format_func=lambda x: option_labels[x],
                        key="viz_max_patients"
                    )
                    max_patients = None if max_patients_opt == -1 else max_patients_opt
                    
                    # åŠ è½½æŒ‰é’®
                    load_btn_label = "ğŸ” Load Data" if lang == 'en' else "ğŸ” åŠ è½½æ•°æ®"
                    if selected_files:
                        if st.button(load_btn_label, type="primary", use_container_width=True, key="viz_load_files"):
                            loading_msg = "Loading data..." if lang == 'en' else "æ­£åœ¨åŠ è½½æ•°æ®..."
                            with st.spinner(loading_msg):
                                load_from_exported(actual_path, selected_files=selected_files, max_patients=max_patients)
                            st.rerun()
                    else:
                        st.button(load_btn_label, type="primary", use_container_width=True, disabled=True, key="viz_load_disabled")
                        warn_msg = "âš ï¸ Please select at least one file" if lang == 'en' else "âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶"
                        st.warning(warn_msg)
                else:
                    warn_msg = "âš ï¸ No data files found in this directory (CSV/Parquet/Excel)" if lang == 'en' else "âš ï¸ è¯¥ç›®å½•ä¸‹æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ (CSV/Parquet/Excel)"
                    st.warning(warn_msg)
            elif export_path:
                err_msg = "âŒ Directory does not exist" if lang == 'en' else "âŒ ç›®å½•ä¸å­˜åœ¨"
                st.error(err_msg)
        
        # ===== Demo æ¨¡å¼ (å½“é€‰æ‹©æ¨¡æ‹Ÿæ•°æ®ä¸”érealæ¨¡å¼) =====
        elif st.session_state.viz_data_source == 0 and entry_mode != 'real':
            st.markdown("---")
            demo_info = "Generate ALL simulated ICU features for full exploration" if lang == 'en' else "ç”Ÿæˆå…¨éƒ¨æ¨¡æ‹ŸICUç‰¹å¾ä¾›å®Œæ•´ä½“éªŒ"
            st.info(f"âœ¨ {demo_info}")
            
            col1, col2 = st.columns(2)
            with col1:
                n_patients_label = "Number of Patients" if lang == 'en' else "æ‚£è€…æ•°é‡"
                n_patients = st.slider(n_patients_label, 10, 200, 50, key="viz_demo_patients")
            with col2:
                hours_label = "Data Duration (hours)" if lang == 'en' else "æ•°æ®æ—¶é•¿(å°æ—¶)"
                hours = st.slider(hours_label, 24, 168, 72, key="viz_demo_hours")
            
            # æ˜¾ç¤ºå°†ç”Ÿæˆçš„ç‰¹å¾æ•°é‡æç¤º
            feature_hint = "Will generate ~160+ features across all modules (Vitals, Labs, SOFA, Sepsis, AKI, etc.)" if lang == 'en' else "å°†ç”Ÿæˆçº¦160+ä¸ªç‰¹å¾ï¼Œè¦†ç›–æ‰€æœ‰æ¨¡å—ï¼ˆç”Ÿå‘½ä½“å¾ã€å®éªŒå®¤ã€SOFAã€è„“æ¯’ç—‡ã€AKIç­‰ï¼‰"
            st.caption(f"ğŸ’¡ {feature_hint}")
            
            load_btn_label = "ğŸš€ Generate & Load All Demo Data" if lang == 'en' else "ğŸš€ ç”Ÿæˆå¹¶åŠ è½½å…¨éƒ¨æ¨¡æ‹Ÿæ•°æ®"
            if st.button(load_btn_label, type="primary", use_container_width=True, key="viz_load_demo"):
                loading_msg = "Generating all mock data (~160+ features)..." if lang == 'en' else "æ­£åœ¨ç”Ÿæˆå…¨éƒ¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆçº¦160+ç‰¹å¾ï¼‰..."
                with st.spinner(loading_msg):
                    # ğŸ”§ ä½¿ç”¨ get_mock_params_with_cohort è·å–å®Œæ•´å‚æ•°ï¼ˆåŒ…å« cohort_filterï¼‰
                    params = get_mock_params_with_cohort()
                    params['n_patients'] = n_patients  # ä½¿ç”¨å½“å‰ slider çš„å€¼
                    params['hours'] = hours
                    mock_data, patient_ids = generate_mock_data(**params)
                    st.session_state.loaded_concepts = mock_data
                    st.session_state.patient_ids = patient_ids
                    st.session_state.id_col = 'stay_id'
                    st.session_state.time_col = 'time'
                st.rerun()
    
    # æ˜¾ç¤ºå·²åŠ è½½æ•°æ®çŠ¶æ€
    if data_loaded:
        st.markdown("---")
        
        # ============ ä¸‹æ–¹ï¼šå››ä¸ªå­æ¨¡å— Tabs ============
        sub_tab1, sub_tab2, sub_tab3, sub_tab4 = st.tabs([
            get_text('sub_data_table'),
            get_text('sub_timeseries'),
            get_text('sub_patient_view'),
            get_text('sub_data_quality'),
        ])
        
        with sub_tab1:
            render_data_table_subtab()
        
        with sub_tab2:
            render_timeseries_page()
        
        with sub_tab3:
            render_patient_page()
        
        with sub_tab4:
            render_quality_page()
    
    else:
        # æœªåŠ è½½æ•°æ®æ—¶æ˜¾ç¤ºæç¤º
        st.markdown("---")
        no_data_msg = """
        <div style="text-align: center; padding: 60px 20px; background: linear-gradient(135deg, #f8f9fa, #e9ecef); border-radius: 16px; margin: 20px 0;">
            <div style="font-size: 4rem; margin-bottom: 20px;">ğŸ“Š</div>
            <h3 style="color: #495057; margin-bottom: 10px;">""" + ("No Data Loaded" if lang == 'en' else "å°šæœªåŠ è½½æ•°æ®") + """</h3>
            <p style="color: #6c757d;">""" + ("Please configure data source above and click Load button" if lang == 'en' else "è¯·åœ¨ä¸Šæ–¹é…ç½®æ•°æ®æ¥æºï¼Œç„¶åç‚¹å‡»åŠ è½½æŒ‰é’®") + """</p>
        </div>
        """
        st.markdown(no_data_msg, unsafe_allow_html=True)


def render_visualization_mode_legacy():
    
    # æ•°æ®ç›®å½•é€‰æ‹© - æ”¯æŒé€‰æ‹©å·²å¯¼å‡ºçš„æ–‡ä»¶å¤¹
    import platform
    
    # å…è®¸ç”¨æˆ·è‡ªå®šä¹‰åŸºç¡€æœç´¢è·¯å¾„
    if 'viz_base_path' not in st.session_state:
        if platform.system() == 'Windows':
            st.session_state.viz_base_path = r'D:\easyicu_export'
        else:
            st.session_state.viz_base_path = os.path.expanduser('~/easyicu_export')
    
    # åŸºç¡€è·¯å¾„é…ç½®
    base_path_label = "Base search directory" if st.session_state.language == 'en' else "åŸºç¡€æœç´¢ç›®å½•"
    base_path_help = "Directory containing exported data folders" if st.session_state.language == 'en' else "åŒ…å«å·²å¯¼å‡ºæ•°æ®æ–‡ä»¶å¤¹çš„ç›®å½•"
    
    with st.expander("âš™ï¸ " + ("Path Settings" if st.session_state.language == 'en' else "è·¯å¾„è®¾ç½®"), expanded=True):
        new_base_path = st.text_input(
            base_path_label,
            value=st.session_state.viz_base_path,
            key="viz_base_path_input",
            help=base_path_help
        )
        
        col_update, col_reset = st.columns(2)
        with col_update:
            update_btn = "ğŸ”„ Update & Scan" if st.session_state.language == 'en' else "ğŸ”„ æ›´æ–°å¹¶æ‰«æ"
            if st.button(update_btn, width='stretch'):
                st.session_state.viz_base_path = new_base_path
                st.rerun()
        
        with col_reset:
            reset_btn = "â†©ï¸ Reset Default" if st.session_state.language == 'en' else "â†©ï¸ é‡ç½®é»˜è®¤"
            if st.button(reset_btn, width='stretch'):
                if platform.system() == 'Windows':
                    st.session_state.viz_base_path = r'D:\easyicu_export'
                else:
                    st.session_state.viz_base_path = os.path.expanduser('~/easyicu_export')
                st.rerun()
    
    base_export_path = st.session_state.viz_base_path
    
    # æ‰«æå·²æœ‰çš„å¯¼å‡ºæ–‡ä»¶å¤¹
    available_folders = []
    if Path(base_export_path).exists():
        available_folders = sorted(
            [d.name for d in Path(base_export_path).iterdir() if d.is_dir()],
            reverse=True  # æœ€æ–°çš„åœ¨å‰
        )
    else:
        path_not_exist_msg = f"âš ï¸ Base path does not exist: {base_export_path}" if st.session_state.language == 'en' else f"âš ï¸ åŸºç¡€è·¯å¾„ä¸å­˜åœ¨: {base_export_path}"
        st.warning(path_not_exist_msg)
    
    # æ–‡ä»¶å¤¹ç­›é€‰å™¨
    selected_folder_path = None  # ğŸ”§ åœ¨å¤–éƒ¨åˆå§‹åŒ–ï¼Œç¡®ä¿ä½œç”¨åŸŸæ­£ç¡®
    
    # åˆå§‹åŒ–å·²ç¡®è®¤çš„è·¯å¾„ï¼ˆå­˜å‚¨åœ¨session_stateä¸­ï¼‰
    if 'viz_confirmed_path' not in st.session_state:
        st.session_state.viz_confirmed_path = None
    
    if available_folders:
        filter_label = "Filter by database" if st.session_state.language == 'en' else "æŒ‰æ•°æ®åº“ç­›é€‰"
        db_prefixes = ['miiv', 'eicu', 'aumc', 'hirid', 'mimic', 'sic', 'mock', 'all']
        db_options = ['All'] + [p for p in db_prefixes if any(f.startswith(p) for f in available_folders)]
        db_filter = st.selectbox(
            filter_label,
            options=db_options,
            index=0,
            key="viz_db_filter"
        )
        
        # è¿‡æ»¤æ–‡ä»¶å¤¹åˆ—è¡¨
        if db_filter != 'All':
            filtered_folders = [f for f in available_folders if f.startswith(db_filter)]
        else:
            filtered_folders = available_folders
        
        # æ–‡ä»¶å¤¹é€‰æ‹©å™¨
        if filtered_folders:
            folder_label = "Select exported folder" if st.session_state.language == 'en' else "é€‰æ‹©å¯¼å‡ºæ–‡ä»¶å¤¹"
            selected_folder = st.selectbox(
                folder_label,
                options=filtered_folders,
                index=0,
                key="viz_folder_select",
                help="Folders are sorted by timestamp (newest first)" if st.session_state.language == 'en' else "æ–‡ä»¶å¤¹æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰"
            )
            
            # ğŸ”§ æ„å»ºå®Œæ•´è·¯å¾„
            if selected_folder:
                selected_folder_path = str(Path(base_export_path) / selected_folder)
                # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„è·¯å¾„
                current_path_msg = f"ğŸ“‚ Selected: `{selected_folder_path}`" if st.session_state.language == 'en' else f"ğŸ“‚ å·²é€‰æ‹©: `{selected_folder_path}`"
                st.info(current_path_msg)
                
                # ğŸ”§ æ·»åŠ ç¡®è®¤æŒ‰é’®
                confirm_label = "âœ… Confirm and Use This Folder" if st.session_state.language == 'en' else "âœ… ç¡®è®¤ä½¿ç”¨æ­¤æ–‡ä»¶å¤¹"
                if st.button(confirm_label, key="confirm_filter_path", type="primary", width='stretch'):
                    st.session_state.viz_confirmed_path = selected_folder_path
                    st.rerun()
        else:
            no_folder_msg = "No folders match the filter" if st.session_state.language == 'en' else "æ²¡æœ‰ç¬¦åˆç­›é€‰æ¡ä»¶çš„æ–‡ä»¶å¤¹"
            st.info(no_folder_msg)
    
    # ğŸ”§ ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„ data_dir
    if st.session_state.viz_confirmed_path:
        # ä½¿ç”¨å·²ç¡®è®¤çš„è·¯å¾„
        data_dir = st.session_state.viz_confirmed_path
        manual_expanded = False
    elif st.session_state.get('last_export_dir'):
        data_dir = st.session_state.get('last_export_dir')
        manual_expanded = True
    else:
        data_dir = st.session_state.get('export_path', str(Path(base_export_path) / 'miiv'))
        manual_expanded = True
    
    # ä»ç„¶æä¾›æ‰‹åŠ¨è¾“å…¥é€‰é¡¹
    manual_label = "Or enter path manually" if st.session_state.language == 'en' else "æˆ–æ‰‹åŠ¨è¾“å…¥è·¯å¾„"
    with st.expander(manual_label, expanded=False):
        manual_note = "ğŸ’¡ Use this to specify a custom path" if st.session_state.language == 'en' else "ğŸ’¡ ä½¿ç”¨æ­¤é€‰é¡¹æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„"
        st.caption(manual_note)
        
        manual_data_dir = st.text_input(
            get_text('data_dir'),
            value="" if not manual_expanded else data_dir,  # ğŸ”§ Filteræ¨¡å¼æ—¶æ¸…ç©ºï¼Œé¿å…æ··æ·†
            placeholder="Enter full path to exported data directory" if st.session_state.language == 'en' else "è¾“å…¥å¯¼å‡ºæ•°æ®ç›®å½•çš„å®Œæ•´è·¯å¾„",
            key="viz_data_dir_manual",
            help="Directory containing exported CSV/Parquet/Excel files" if st.session_state.language == 'en' else "åŒ…å«å·²å¯¼å‡ºçš„ CSV/Parquet/Excel æ–‡ä»¶çš„ç›®å½•"
        )
        
        # ğŸ”§ æ·»åŠ æ‰‹åŠ¨è·¯å¾„ç¡®è®¤æŒ‰é’®
        if manual_data_dir and manual_data_dir.strip():
            manual_confirm_label = "âœ… Confirm and Use Manual Path" if st.session_state.language == 'en' else "âœ… ç¡®è®¤ä½¿ç”¨æ‰‹åŠ¨è·¯å¾„"
            if st.button(manual_confirm_label, key="confirm_manual_path", type="primary", width='stretch'):
                st.session_state.viz_confirmed_path = manual_data_dir.strip()
                st.rerun()
    
    # ğŸ”§ æ˜¾ç¤ºæœ€ç»ˆç¡®è®¤çš„è·¯å¾„
    if st.session_state.viz_confirmed_path:
        final_path_msg = f"ğŸ¯ Active path: `{st.session_state.viz_confirmed_path}`" if st.session_state.language == 'en' else f"ğŸ¯ å½“å‰æ¿€æ´»è·¯å¾„: `{st.session_state.viz_confirmed_path}`"
        st.success(final_path_msg)
        data_dir = st.session_state.viz_confirmed_path
    else:
        hint_msg = "âš ï¸ Please select a folder and click Confirm button" if st.session_state.language == 'en' else "âš ï¸ è¯·é€‰æ‹©æ–‡ä»¶å¤¹å¹¶ç‚¹å‡»ç¡®è®¤æŒ‰é’®"
        st.warning(hint_msg)
        data_dir = None  # æœªç¡®è®¤æ—¶ä¸è®¾ç½®è·¯å¾„
    
    # æ·»åŠ è·¯å¾„æ£€æŸ¥æŒ‰é’®
    check_btn = "ğŸ” Check Path" if st.session_state.language == 'en' else "ğŸ” æ£€æŸ¥è·¯å¾„"
    if st.button(check_btn, key="check_viz_path", width="stretch"):
        if data_dir:
            if Path(data_dir).exists():
                files = list(Path(data_dir).glob('*.csv')) + list(Path(data_dir).glob('*.parquet')) + list(Path(data_dir).glob('*.xlsx'))
                if files:
                    ok_msg = f"âœ… Path valid! Found {len(files)} data files" if st.session_state.language == 'en' else f"âœ… è·¯å¾„æœ‰æ•ˆï¼å‘ç° {len(files)} ä¸ªæ•°æ®æ–‡ä»¶"
                    st.success(ok_msg)
                else:
                    warn_msg = "âš ï¸ Directory exists but no data files found" if st.session_state.language == 'en' else "âš ï¸ ç›®å½•å­˜åœ¨ä½†æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶"
                    st.warning(warn_msg)
            else:
                err_msg = "âŒ Path does not exist" if st.session_state.language == 'en' else "âŒ è·¯å¾„ä¸å­˜åœ¨"
                st.error(err_msg)
        else:
            warn_msg = "âš ï¸ Please enter a path first" if st.session_state.language == 'en' else "âš ï¸ è¯·å…ˆè¾“å…¥è·¯å¾„"
            st.warning(warn_msg)
    
    if data_dir and Path(data_dir).exists():
        # æ‰«æå¯ç”¨æ–‡ä»¶
        available_files = list(Path(data_dir).glob('*.csv')) + \
                          list(Path(data_dir).glob('*.parquet')) + \
                          list(Path(data_dir).glob('*.xlsx'))
        
        if available_files:
            file_names = [f.stem for f in available_files]
            found_msg = f"âœ… Found {len(available_files)} data files" if st.session_state.language == 'en' else f"âœ… å‘ç° {len(available_files)} ä¸ªæ•°æ®æ–‡ä»¶"
            st.success(found_msg)
            
            # è®©ç”¨æˆ·é€‰æ‹©è¦åŠ è½½çš„è¡¨æ ¼
            select_label = "Select Tables to Load" if st.session_state.language == 'en' else "é€‰æ‹©è¦åŠ è½½çš„è¡¨æ ¼"
            select_help = "Select tables to load for visualization (max 3 recommended)" if st.session_state.language == 'en' else "é€‰æ‹©è¦åŠ è½½åˆ°å¯è§†åŒ–çš„è¡¨æ ¼ï¼ˆå»ºè®®ä¸è¶…è¿‡3ä¸ªä»¥ä¿è¯æµç•…æ€§ï¼‰"
            
            # ğŸ”§ FIX: ä½¿ç”¨å¸¦ç‰ˆæœ¬å·çš„ key æ¥å¼ºåˆ¶åˆ·æ–° multiselectï¼ˆä¸ Export Directory æ¨¡å¼ç»Ÿä¸€ï¼‰
            if '_viz_select_version_filter' not in st.session_state:
                st.session_state._viz_select_version_filter = 0
            
            # ä¿å­˜å½“å‰æ–‡ä»¶åˆ—è¡¨åˆ° session_state
            st.session_state._current_filenames_filter = file_names.copy()
            
            # ç¡®å®š multiselect çš„ key å’Œé»˜è®¤å€¼
            ms_key_filter = f"viz_files_select_filter_v{st.session_state._viz_select_version_filter}"
            if ms_key_filter not in st.session_state:
                default_selection_filter = file_names.copy()  # é»˜è®¤å…¨é€‰
            else:
                existing = st.session_state.get(ms_key_filter, [])
                default_selection_filter = [f for f in existing if f in file_names] or file_names.copy()
            
            # ğŸ”§ FIX: å›è°ƒå‡½æ•° - å…¨é€‰
            def select_all_filter():
                version = st.session_state._viz_select_version_filter + 1
                st.session_state._viz_select_version_filter = version
                new_key = f"viz_files_select_filter_v{version}"
                st.session_state[new_key] = st.session_state._current_filenames_filter.copy()
            
            # ğŸ”§ FIX: å›è°ƒå‡½æ•° - æ¸…ç©º
            def clear_all_filter():
                version = st.session_state._viz_select_version_filter + 1
                st.session_state._viz_select_version_filter = version
                new_key = f"viz_files_select_filter_v{version}"
                st.session_state[new_key] = []
            
            # æ·»åŠ  ALL / Clear æŒ‰é’®
            col_all, col_clear = st.columns(2)
            with col_all:
                all_label = "âœ… ALL" if st.session_state.language == 'en' else "âœ… å…¨é€‰"
                st.button(all_label, key="select_all_tables_filter", use_container_width=True, 
                         on_click=select_all_filter, type="primary")
            with col_clear:
                clear_label = "âŒ Clear" if st.session_state.language == 'en' else "âŒ æ¸…ç©º"
                st.button(clear_label, key="clear_all_tables_filter", use_container_width=True,
                         on_click=clear_all_filter)
            
            # ğŸ”§ FIX (2026-02-04): é¿å… default å’Œ session_state å†²çª
            if ms_key_filter in st.session_state:
                selected_files = st.multiselect(
                    select_label,
                    options=file_names,
                    help=select_help,
                    key=ms_key_filter,
                )
            else:
                selected_files = st.multiselect(
                    select_label,
                    options=file_names,
                    default=default_selection_filter,
                    help=select_help,
                    key=ms_key_filter,
                )
            
            if selected_files:
                selected_msg = f"{len(selected_files)} tables selected" if st.session_state.language == 'en' else f"å·²é€‰ {len(selected_files)} ä¸ªè¡¨æ ¼"
                st.caption(selected_msg)
                
                # æ‚£è€…æ•°é‡é€‰æ‹©å™¨
                st.markdown("---")
                patient_limit_label = "Patients to Load" if st.session_state.language == 'en' else "åŠ è½½æ‚£è€…æ•°é‡"
                
                # ä½¿ç”¨ selectbox ä»£æ›¿ sliderï¼Œæä¾›é¢„è®¾é€‰é¡¹å’Œ"å…¨éƒ¨"é€‰é¡¹
                patient_options = [50, 100, 200, 500, -1]  # -1 è¡¨ç¤ºå…¨éƒ¨
                option_labels = {
                    50: "50 (Fast)" if st.session_state.language == 'en' else "50 (å¿«é€Ÿ)",
                    100: "100 (Recommended)" if st.session_state.language == 'en' else "100 (æ¨è)",
                    200: "200 (Slow)" if st.session_state.language == 'en' else "200 (è¾ƒæ…¢)",
                    500: "500 (Very Slow)" if st.session_state.language == 'en' else "500 (å¾ˆæ…¢)",
                    -1: "ğŸ”“ All (May Lag!)" if st.session_state.language == 'en' else "ğŸ”“ å…¨éƒ¨ (å¯èƒ½å¡é¡¿ï¼)"
                }
                
                selected_option = st.selectbox(
                    patient_limit_label,
                    options=patient_options,
                    index=1,  # é»˜è®¤é€‰æ‹©100
                    format_func=lambda x: option_labels[x],
                    key="viz_max_patients"
                )
                
                # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºè­¦å‘Š
                if selected_option == -1:
                    all_warn = "âš ï¸ Loading ALL patients may cause UI lag or crash for large datasets!" if st.session_state.language == 'en' else "âš ï¸ åŠ è½½å…¨éƒ¨æ‚£è€…å¯èƒ½å¯¼è‡´ç•Œé¢å¡é¡¿ç”šè‡³å´©æºƒï¼å¤§æ•°æ®é›†è¯·è°¨æ…ä½¿ç”¨"
                    st.warning(all_warn)
                    max_patients = None  # None è¡¨ç¤ºä¸é™åˆ¶
                elif selected_option >= 200:
                    perf_warn = "âš ï¸ High patient count may cause slow performance" if st.session_state.language == 'en' else "âš ï¸ æ‚£è€…æ•°è¾ƒå¤šï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™"
                    st.warning(perf_warn)
                    max_patients = selected_option
                else:
                    max_patients = selected_option
                
                st.markdown("---")
                
                # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
                is_loaded = len(st.session_state.loaded_concepts) > 0
                if is_loaded:
                    # ğŸ”§ FIX (2026-02-04): ç»Ÿè®¡å”¯ä¸€æ¦‚å¿µæ•°
                    concept_count = count_unique_concepts(list(st.session_state.loaded_concepts.keys()))
                    loaded_msg = f"ğŸ“Š {concept_count} concepts, {len(st.session_state.patient_ids)} patients loaded" if st.session_state.language == 'en' else f"ğŸ“Š å·²åŠ è½½ {concept_count} ä¸ªæ¦‚å¿µï¼Œ{len(st.session_state.patient_ids)} ä¸ªæ‚£è€…"
                    st.info(loaded_msg)
                
                if st.button(get_text('load_data'), type="primary", width="stretch"):
                    loading_msg = "Loading data..." if st.session_state.language == 'en' else "æ­£åœ¨åŠ è½½æ•°æ®..."
                    with st.spinner(loading_msg):
                        load_from_exported(data_dir, selected_files=selected_files, max_patients=max_patients)
                    st.rerun()
            else:
                st.button(get_text('load_data'), type="primary", width="stretch", disabled=True)
                warn_msg = "âš ï¸ Please select at least one table" if st.session_state.language == 'en' else "âš ï¸ è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªè¡¨æ ¼"
                st.caption(warn_msg)
            
            # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
            with st.expander(get_text('file_list'), expanded=False):
                for f in available_files[:10]:
                    st.caption(f"â€¢ {f.name}")
                if len(available_files) > 10:
                    more_msg = f"... {len(available_files)} files total" if st.session_state.language == 'en' else f"... å…± {len(available_files)} ä¸ªæ–‡ä»¶"
                    st.caption(more_msg)
        else:
            st.warning(get_text('no_files'))
            format_msg = "Supported formats: CSV, Parquet, Excel" if st.session_state.language == 'en' else "æ”¯æŒæ ¼å¼ï¼šCSVã€Parquetã€Excel"
            st.caption(format_msg)
    elif data_dir:
        st.error(get_text('dir_not_exist'))
        check_msg = "Please check if the path is correct" if st.session_state.language == 'en' else "è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®"
        st.caption(check_msg)
    
    st.markdown("---")
    
    # æ˜¾ç¤ºå·²åŠ è½½æ•°æ®çš„çŠ¶æ€
    if len(st.session_state.loaded_concepts) > 0:
        st.markdown(f"### {get_text('loaded_data')}")
        # ğŸ”§ FIX (2026-02-04): ç»Ÿè®¡å”¯ä¸€æ¦‚å¿µæ•°
        concept_count = count_unique_concepts(list(st.session_state.loaded_concepts.keys()))
        feat_msg = f"âœ… {concept_count} concepts" if st.session_state.language == 'en' else f"âœ… {concept_count} ä¸ªæ¦‚å¿µ"
        pat_msg = f"âœ… {len(st.session_state.patient_ids)} patients" if st.session_state.language == 'en' else f"âœ… {len(st.session_state.patient_ids)} ä¸ªæ‚£è€…"
        st.success(feat_msg)
        st.success(pat_msg)
        
        with st.expander(get_text('view_features'), expanded=False):
            for concept in sorted(st.session_state.loaded_concepts.keys()):
                st.caption(f"â€¢ {concept}")
    else:
        st.info(get_text('load_hint'))


def render_entry_page():
    """æ¸²æŸ“å…¥å£é€‰æ‹©é¡µé¢ - Demoæ¨¡å¼æˆ–çœŸå®æ•°æ®æ¨¡å¼"""
    lang = st.session_state.get('language', 'en')
    
    # è¯­è¨€åˆ‡æ¢ï¼ˆå³ä¸Šè§’ï¼‰
    col_lang = st.columns([6, 1])[1]
    with col_lang:
        lang_select = st.selectbox(
            "ğŸŒ",
            options=['EN', 'ZH'],
            index=0 if lang == 'en' else 1,
            key="entry_lang_select",
            label_visibility="collapsed"
        )
        if (lang_select == 'EN' and lang != 'en') or (lang_select == 'ZH' and lang != 'zh'):
            st.session_state.language = 'en' if lang_select == 'EN' else 'zh'
            st.rerun()
    
    # ä¸»æ ‡é¢˜
    if lang == 'en':
        st.markdown('<div class="main-header">ğŸ¥ EasyICU Data Explorer</div>', unsafe_allow_html=True)
        st.markdown('<div class="sub-header">Local ICU Data Analytics Platform</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="main-header">ğŸ¥ EasyICU æ•°æ®æ¢ç´¢å™¨</div>', unsafe_allow_html=True)
        st.markdown('<div class="sub-header">æœ¬åœ° ICU æ•°æ®åˆ†æä¸å¯è§†åŒ–å¹³å°</div>', unsafe_allow_html=True)
    
    st.markdown("<br><br>", unsafe_allow_html=True)
    
    # å…¥å£é€‰æ‹©å¡ç‰‡æ ·å¼ï¼ˆä½¿ç”¨çº¯æ–‡æœ¬æŒ‰é’® + CSSç¾åŒ–ï¼‰
    st.markdown("""
    <style>
    /* å…¥å£é¡µé¢çš„é€‰æ‹©æŒ‰é’® - å¡ç‰‡å¼è®¾è®¡ */
    div[data-testid="column"] > div[data-testid="stVerticalBlock"] > div[data-testid="stButton"] {
        height: 100%;
    }
    
    div[data-testid="column"] > div[data-testid="stVerticalBlock"] > div[data-testid="stButton"] > button {
        min-height: 280px !important;
        height: 100% !important;
        padding: 40px 30px !important;
        font-size: 1.3rem !important;
        white-space: pre-line !important;
        line-height: 1.8 !important;
        border-radius: 24px !important;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1) !important;
        border: none !important;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08) !important;
        position: relative !important;
        text-align: center !important;
        font-weight: 500 !important;
    }
    
    div[data-testid="column"] > div[data-testid="stVerticalBlock"] > div[data-testid="stButton"] > button:hover {
        transform: translateY(-8px) scale(1.02) !important;
        box-shadow: 0 12px 35px rgba(0, 0, 0, 0.15) !important;
    }
    
    /* DemoæŒ‰é’®æ ·å¼ï¼ˆç»¿è‰²æ¸å˜ï¼‰ */
    div[data-testid="column"] > div[data-testid="stVerticalBlock"] > div[data-testid="stButton"] > button[kind="primary"] {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%) !important;
        border: 3px solid rgba(5, 150, 105, 0.3) !important;
        color: white !important;
    }
    
    div[data-testid="column"] > div[data-testid="stVerticalBlock"] > div[data-testid="stButton"] > button[kind="primary"]:hover {
        border-color: rgba(5, 150, 105, 0.6) !important;
    }
    
    /* Real DataæŒ‰é’®æ ·å¼ï¼ˆè“è‰²æ¸å˜ï¼‰ */
    div[data-testid="column"] > div[data-testid="stVerticalBlock"] > div[data-testid="stButton"] > button[kind="secondary"] {
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%) !important;
        border: 3px solid rgba(37, 99, 235, 0.3) !important;
        color: white !important;
    }
    
    div[data-testid="column"] > div[data-testid="stVerticalBlock"] > div[data-testid="stButton"] > button[kind="secondary"]:hover {
        border-color: rgba(37, 99, 235, 0.6) !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # é€‰æ‹©æ¨¡å¼æç¤º
    if lang == 'en':
        st.markdown("<h2 style='text-align: center; color: #475569; margin-bottom: 40px; font-size: 2rem;'>ğŸ¯ Choose Your Mode</h2>", unsafe_allow_html=True)
    else:
        st.markdown("<h2 style='text-align: center; color: #475569; margin-bottom: 40px; font-size: 2rem;'>ğŸ¯ é€‰æ‹©ä½¿ç”¨æ¨¡å¼</h2>", unsafe_allow_html=True)
    
    # ä¸¤åˆ—å¸ƒå±€æ˜¾ç¤ºä¸¤ä¸ªé€‰æ‹©å¡ç‰‡
    col1, col2 = st.columns(2, gap="large")
    
    with col1:
        # Demoæ¨¡å¼å¡ç‰‡ - ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼ŒåŠ å¤§å­—ä½“
        if lang == 'en':
            demo_label = "ğŸ­\n\nDemo Mode\n\nExplore EasyICU with simulated ICU data.\nNo real data required.\n\nâœ¨ Quick Start"
        else:
            demo_label = "ğŸ­\n\næ¼”ç¤ºæ¨¡å¼\n\nä½¿ç”¨æ¨¡æ‹ŸICUæ•°æ®ä½“éªŒEasyICUåŠŸèƒ½ã€‚\næ— éœ€çœŸå®æ•°æ®ã€‚\n\nâœ¨ å¿«é€Ÿå¼€å§‹"
        
        demo_clicked = st.button(
            demo_label,
            key="entry_demo_btn",
            use_container_width=True,
            type="primary"
        )
        
        if demo_clicked:
            st.session_state.entry_mode = 'demo'
            st.session_state.use_mock_data = True
            st.session_state.database = 'mock'
            # æ¸…ç©ºæ—§æ•°æ®ï¼ˆåŒ…æ‹¬Cohort Comparisonç›¸å…³ï¼‰
            st.session_state.loaded_concepts = {}
            st.session_state.patient_ids = []
            # æ¸…ç†Cohortç›¸å…³ç¼“å­˜
            for key in ['group_a_data', 'group_b_data', 'multidb_data', 'dash_demographics',
                        'multidb_is_demo', 'dash_is_demo', 'cohort_is_demo']:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()
    
    with col2:
        # Real Dataæ¨¡å¼å¡ç‰‡ - ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼ŒåŠ å¤§å­—ä½“
        if lang == 'en':
            real_label = "ğŸ“Š\n\nReal Data Mode\n\nConnect to local ICU databases\n(MIMIC-IV, eICU, AUMC, HiRID, etc.)\n\nğŸ”¬ Research Ready"
        else:
            real_label = "ğŸ“Š\n\nçœŸå®æ•°æ®æ¨¡å¼\n\nè¿æ¥æœ¬åœ°ICUæ•°æ®åº“\n(MIMIC-IVã€eICUã€AUMCã€HiRIDç­‰)\n\nğŸ”¬ ç§‘ç ”å°±ç»ª"
        
        real_clicked = st.button(
            real_label,
            key="entry_real_btn",
            use_container_width=True,
            type="secondary"
        )
        
        if real_clicked:
            st.session_state.entry_mode = 'real'
            st.session_state.use_mock_data = False
            # æ¸…ç©ºæ—§æ•°æ®ï¼ˆåŒ…æ‹¬Cohort Comparisonç›¸å…³ï¼‰
            st.session_state.loaded_concepts = {}
            st.session_state.patient_ids = []
            # æ¸…ç†Cohortç›¸å…³ç¼“å­˜
            for key in ['group_a_data', 'group_b_data', 'multidb_data', 'dash_demographics',
                        'multidb_is_demo', 'dash_is_demo', 'cohort_is_demo']:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()
    
    st.markdown("<br><br>", unsafe_allow_html=True)
    
    # åŠŸèƒ½ç‰¹æ€§ä»‹ç»
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    if lang == 'en':
        st.markdown("### âœ¨ Key Features")
        feature_cols = st.columns(4)
        features = [
            ("ğŸ“ˆ", "Time Series Analysis", "Visualize patient metrics over time"),
            ("ğŸ¥", "Patient View", "Comprehensive single patient data"),
            ("ğŸ“Š", "Cohort Comparison", "Compare patient groups"),
            ("ğŸ’¾", "Data Export", "Export to CSV/Parquet/Excel"),
        ]
    else:
        st.markdown("### âœ¨ æ ¸å¿ƒåŠŸèƒ½")
        feature_cols = st.columns(4)
        features = [
            ("ğŸ“ˆ", "æ—¶åºåˆ†æ", "å¯è§†åŒ–æ‚£è€…æŒ‡æ ‡æ—¶é—´è¶‹åŠ¿"),
            ("ğŸ¥", "æ‚£è€…è§†å›¾", "ç»¼åˆæŸ¥çœ‹å•ä¸ªæ‚£è€…æ•°æ®"),
            ("ğŸ“Š", "é˜Ÿåˆ—å¯¹æ¯”", "å¯¹æ¯”ä¸åŒæ‚£è€…ç»„"),
            ("ğŸ’¾", "æ•°æ®å¯¼å‡º", "å¯¼å‡ºä¸ºCSV/Parquet/Excel"),
        ]
    
    for col, (icon, title, desc) in zip(feature_cols, features):
        with col:
            st.markdown(f"""
            <div class="feature-card" style="text-align: center; padding: 24px;">
                <div style="font-size: 2.5rem;">{icon}</div>
                <h4 style="margin: 12px 0 8px 0; font-size: 1.15rem; font-weight: 600;">{title}</h4>
                <p style="font-size: 0.95rem; color: #64748b; line-height: 1.5;">{desc}</p>
            </div>
            """, unsafe_allow_html=True)


def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ  - æ ¹æ®entry_modeæ˜¾ç¤ºä¸åŒå†…å®¹ã€‚"""
    # ä½¿ç”¨åŒè¯­ç‰¹å¾åˆ†ç»„
    concept_groups = get_concept_groups()
    
    # æ‰€æœ‰å¯ç”¨çš„ concepts åˆ—è¡¨ï¼ˆç”¨äºè‡ªå®šä¹‰é€‰æ‹©ï¼‰
    all_available_concepts = sorted(set(c for group_concepts in concept_groups.values() for c in group_concepts))
    
    # è·å–å½“å‰æ¨¡å¼
    entry_mode = st.session_state.get('entry_mode', 'none')
    
    with st.sidebar:
        # ï¿½ å±•å¼€/æ”¶èµ·æŒ‰é’®
        expand_col1, expand_col2 = st.columns([3, 1])
        with expand_col2:
            if st.session_state.sidebar_expanded:
                expand_label = "â¬…ï¸" if st.session_state.language == 'en' else "â¬…ï¸"
                expand_help = "Collapse sidebar" if st.session_state.language == 'en' else "æ”¶èµ·ä¾§è¾¹æ "
            else:
                expand_label = "â¤¢" if st.session_state.language == 'en' else "â¤¢"
                expand_help = "Expand to full width" if st.session_state.language == 'en' else "å±•å¼€åˆ°å…¨å±"
            
            if st.button(expand_label, key="toggle_sidebar_expand", help=expand_help):
                st.session_state.sidebar_expanded = not st.session_state.sidebar_expanded
                st.rerun()
        
        # ï¿½ğŸ”™ è¿”å›å…¥å£é¡µé¢æŒ‰é’®ï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼Œé™¤éåœ¨å…¥å£é¡µï¼‰
        if entry_mode != 'none':
            back_label = "ğŸ”™ Back to Mode Selection" if st.session_state.language == 'en' else "ğŸ”™ è¿”å›æ¨¡å¼é€‰æ‹©"
            if st.button(back_label, key="back_to_entry", use_container_width=True):
                st.session_state.entry_mode = 'none'
                # æ¸…ç©ºæ‰€æœ‰æ•°æ®
                st.session_state.loaded_concepts = {}
                st.session_state.patient_ids = []
                st.session_state.use_mock_data = False
                # æ¸…ç†Cohortç›¸å…³ç¼“å­˜
                for key in ['group_a_data', 'group_b_data', 'multidb_data', 'dash_demographics',
                            'multidb_is_demo', 'dash_is_demo', 'cohort_is_demo']:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()
            st.markdown("---")
        
        # æ˜¾ç¤ºå½“å‰æ¨¡å¼æ ‡è¯†
        if entry_mode == 'demo':
            mode_badge = "ğŸ­ Demo Mode" if st.session_state.language == 'en' else "ğŸ­ æ¼”ç¤ºæ¨¡å¼"
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, #10b981, #059669); 
                        padding: 12px 16px; border-radius: 10px; color: white; margin-bottom: 15px; text-align: center;">
                <b style="font-size: 1.1rem;">{mode_badge}</b>
            </div>
            """, unsafe_allow_html=True)
        elif entry_mode == 'real':
            mode_badge = "ğŸ“Š Real Data Mode" if st.session_state.language == 'en' else "ğŸ“Š çœŸå®æ•°æ®æ¨¡å¼"
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, #3b82f6, #2563eb); 
                        padding: 12px 16px; border-radius: 10px; color: white; margin-bottom: 15px; text-align: center;">
                <b style="font-size: 1.1rem;">{mode_badge}</b>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown(f"## {get_text('app_title')}")
        
        # è¯­è¨€åˆ‡æ¢ - æ›´ç´§å‡‘çš„å¸ƒå±€
        lang = st.selectbox(
            "ğŸŒ Language",
            options=['EN', 'ZH'],
            index=0 if st.session_state.language == 'en' else 1,
            key="lang_select",
        )
        if (lang == 'EN' and st.session_state.language != 'en') or \
           (lang == 'ZH' and st.session_state.language != 'zh'):
            st.session_state.language = 'en' if lang == 'EN' else 'zh'
            st.rerun()
        
        st.markdown("---")
        
        # ============ ä¾§è¾¹æ ä»…ç”¨äºæ•°æ®æå–å¯¼å‡ºæ¨¡å¼ ============
        # å¿«é€Ÿå¯è§†åŒ–åŠŸèƒ½å·²ç§»è‡³ä¸»é¡µé¢çš„ "Quick Visualization" æ ‡ç­¾é¡µ
        
        sidebar_title = "ğŸ“¤ Data Extraction" if st.session_state.language == 'en' else "ğŸ“¤ æ•°æ®æå–å¯¼å‡º"
        st.markdown(f"### {sidebar_title}")
        
        # ğŸ”§ FIX (2026-02-03): å¯¼å‡ºå®Œæˆåæ˜¾ç¤º"é‡æ–°æå–"æŒ‰é’®ï¼Œè€ŒéStep 1-4
        if st.session_state.get('export_completed', False):
            # æ˜¾ç¤ºå¯¼å‡ºæˆåŠŸä¿¡æ¯
            success_msg = "âœ… Export Completed!" if st.session_state.language == 'en' else "âœ… å¯¼å‡ºå®Œæˆï¼"
            export_dir = st.session_state.get('last_export_dir', '')
            st.success(success_msg)
            if export_dir:
                path_msg = f"ğŸ“‚ {export_dir}"
                st.info(path_msg)
            
            # æ˜¾ç¤ºå¯¼å‡ºç»Ÿè®¡
            result = st.session_state.get('_export_success_result', {})
            if result:
                n_files = len(result.get('files', []))
                n_patients = result.get('patient_count', 0)
                stats_label = f"ğŸ“Š {n_files} files, {n_patients} patients" if st.session_state.language == 'en' else f"ğŸ“Š {n_files} ä¸ªæ–‡ä»¶, {n_patients} ä¸ªæ‚£è€…"
                st.caption(stats_label)
            
            st.markdown("---")
            
            # é‡æ–°æå–æŒ‰é’®
            restart_label = "ğŸ”„ Start New Extraction" if st.session_state.language == 'en' else "ğŸ”„ é‡æ–°æå–"
            restart_help = "Reset all settings and start a new extraction" if st.session_state.language == 'en' else "é‡ç½®æ‰€æœ‰è®¾ç½®å¹¶å¼€å§‹æ–°çš„æ•°æ®æå–"
            if st.button(restart_label, type="primary", use_container_width=True, key="restart_extraction", help=restart_help):
                # é‡ç½®æ‰€æœ‰å¯¼å‡ºç›¸å…³çŠ¶æ€
                st.session_state.export_completed = False
                st.session_state.trigger_export = False
                st.session_state.step1_confirmed = False
                st.session_state.step2_confirmed = False
                st.session_state.selected_concepts = []
                st.session_state.concept_checkboxes = {}
                st.session_state.selected_groups = []
                st.session_state.loaded_concepts = {}
                # æ¸…ç†å¯¼å‡ºç»“æœ
                if '_export_success_result' in st.session_state:
                    del st.session_state['_export_success_result']
                if '_skipped_modules' in st.session_state:
                    del st.session_state['_skipped_modules']
                if '_overwrite_modules' in st.session_state:
                    del st.session_state['_overwrite_modules']
                st.rerun()
            
            # è¿”å›é¦–é¡µæŒ‰é’®
            home_label = "ğŸ  Back to Home" if st.session_state.language == 'en' else "ğŸ  è¿”å›é¦–é¡µ"
            if st.button(home_label, use_container_width=True, key="back_to_home_after_export"):
                st.session_state.active_page = 'home_extract'
                st.rerun()
            
            return  # ä¸æ˜¾ç¤ºåç»­Stepå†…å®¹
        
        # ============ æ­¥éª¤1: æ•°æ®æºé€‰æ‹© ============
        # ğŸ†• æ ¹æ®entry_modeå†³å®šæ˜¾ç¤ºå†…å®¹ï¼Œä¸å†å…è®¸åˆ‡æ¢
        
        if entry_mode == 'demo':
            # ===== DEMO æ¨¡å¼ï¼šåªæ˜¾ç¤ºæ¨¡æ‹Ÿæ•°æ®å‚æ•°ï¼Œä¸æ˜¾ç¤ºæ•°æ®åº“é€‰æ‹© =====
            st.markdown(f"### ğŸ“Š {get_text('step1')}")
            demo_title = "âœ¨ Demo Mode" if st.session_state.language == 'en' else "âœ¨ æ¼”ç¤ºæ¨¡å¼"
            demo_desc = "System generates simulated ICU data for exploration" if st.session_state.language == 'en' else "ç³»ç»Ÿç”Ÿæˆæ¨¡æ‹ŸICUæ•°æ®ä¾›ä½“éªŒ"
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, #10b981, #059669); 
                        padding: 12px 16px; border-radius: 10px; color: white; margin: 8px 0;">
                <b>{demo_title}</b><br>
                <small>{demo_desc}</small>
            </div>
            """, unsafe_allow_html=True)
            st.session_state.database = 'mock'
            st.session_state.use_mock_data = True
            
            # æ¨¡æ‹Ÿæ•°æ®å‚æ•°
            n_patients_label = "Number of Patients" if st.session_state.language == 'en' else "æ‚£è€…æ•°é‡"
            hours_label = "Data Duration (hours)" if st.session_state.language == 'en' else "æ•°æ®æ—¶é•¿(å°æ—¶)"
            n_patients = st.slider(n_patients_label, 50, 500, st.session_state.mock_params.get('n_patients', 100))
            hours = st.slider(hours_label, 24, 168, st.session_state.mock_params.get('hours', 72))
            # ğŸ”§ æ³¨æ„: mock_params éœ€è¦åœ¨ Step 2 (Cohort Selection) ä¹‹åæ›´æ–°
            # è¿™é‡Œåªä¿å­˜åŸºæœ¬å‚æ•°ï¼Œcohort_filter åœ¨ Step 2 ä¹‹åçš„å‡½æ•°ä¸­åŠ¨æ€è·å–
            st.session_state.mock_params = {'n_patients': n_patients, 'hours': hours}
            
            # âœ… Step 1 ç¡®è®¤æŒ‰é’®
            step1_confirm_label = "âœ… Confirm Data Source" if st.session_state.language == 'en' else "âœ… ç¡®è®¤æ•°æ®æºé…ç½®"
            if st.button(step1_confirm_label, type="primary", use_container_width=True, key="step1_confirm_demo"):
                st.session_state.step1_confirmed = True
                step1_done_msg = "âœ… Step 1 completed! Proceed to Step 2: Cohort Selection" if st.session_state.language == 'en' else "âœ… æ­¥éª¤1å·²å®Œæˆï¼è¯·ç»§ç»­æ­¥éª¤2: é˜Ÿåˆ—ç­›é€‰"
                st.success(step1_done_msg)
            
        elif entry_mode == 'real':
            # ===== REAL DATA æ¨¡å¼ï¼šåªæ˜¾ç¤ºæ•°æ®åº“é€‰æ‹©ï¼Œä¸æ˜¾ç¤ºDemoé€‰é¡¹ =====
            st.markdown(f"### ğŸ“Š {get_text('step1')}")
            
            # ğŸ”§ è‡ªåŠ¨æ£€æµ‹æ•°æ®åº“ï¼šæ ¹æ®è·¯å¾„ä¸­çš„å…³é”®è¯è‡ªåŠ¨é€‰æ‹©
            def detect_database_from_path(path: str) -> str:
                """æ ¹æ®è·¯å¾„è‡ªåŠ¨æ£€æµ‹æ•°æ®åº“ç±»å‹"""
                if not path:
                    return st.session_state.get('database', 'miiv')
                path_lower = path.lower()
                if 'hirid' in path_lower:
                    return 'hirid'
                elif 'eicu' in path_lower:
                    return 'eicu'
                elif 'aumc' in path_lower or 'amsterdam' in path_lower:
                    return 'aumc'
                elif 'mimiciii' in path_lower or 'mimic-iii' in path_lower or 'mimic_iii' in path_lower or 'mimic3' in path_lower:
                    return 'mimic'
                elif 'mimiciv' in path_lower or 'mimic-iv' in path_lower or 'mimic_iv' in path_lower or 'mimic4' in path_lower:
                    return 'miiv'
                elif 'sic' in path_lower:
                    return 'sic'
                return st.session_state.get('database', 'miiv')
            
            db_options = ['miiv', 'eicu', 'aumc', 'hirid', 'mimic', 'sic']
            detected_db = detect_database_from_path(st.session_state.get('data_path', ''))
            default_idx = db_options.index(detected_db) if detected_db in db_options else 0
            
            db_label = "Select Database" if st.session_state.language == 'en' else "é€‰æ‹©æ•°æ®åº“"
            database = st.selectbox(
                db_label,
                options=db_options,
                index=default_idx,
                format_func=lambda x: {
                    'miiv': 'MIMIC-IV', 'eicu': 'eICU-CRD', 
                    'aumc': 'AmsterdamUMCdb', 'hirid': 'HiRID',
                    'mimic': 'MIMIC-III', 'sic': 'SICdb'
                }.get(x, x)
            )
            st.session_state.database = database
            st.session_state.use_mock_data = False
            
            # æ ¹æ®æ“ä½œç³»ç»Ÿå’Œæ•°æ®åº“è®¾ç½®é»˜è®¤è·¯å¾„
            import platform
            if platform.system() == 'Windows':
                default_paths = {
                    'miiv': r'D:\mimic-iv-3.1',
                    'eicu': r'D:\eicu-crd-2.0',
                    'aumc': r'D:\amsterdamumcdb-1.0.2',
                    'hirid': r'D:\hirid-1.1.1',
                    'mimic': r'D:\mimic-iii-1.4',
                    'sic': r'D:\sicdb-1.0.6',
                }
            else:
                default_paths = {
                    'miiv': '/home/zhuhb/icudb/mimiciv/3.1',
                    'eicu': '/home/zhuhb/icudb/eicu/2.0.1',
                    'aumc': '/home/zhuhb/icudb/aumc/1.0.2',
                    'hirid': '/home/zhuhb/icudb/hirid/1.1.1',
                    'mimic': '/home/zhuhb/icudb/mimiciii/1.4',
                    'sic': '/home/zhuhb/icudb/sicdb/1.0.6',
                }
            default_path = default_paths.get(database, '')
            path_label = "Data Path" if st.session_state.language == 'en' else "æ•°æ®è·¯å¾„"
            data_path = st.text_input(
                path_label,
                value=st.session_state.data_path or default_path,
                placeholder=f"/path/to/{database}",
                on_change=lambda: None  # è§¦å‘ rerun ä»¥æ£€æµ‹æ–°æ•°æ®åº“
            )
            
            # ğŸ”§ å½“è·¯å¾„å˜åŒ–æ—¶è‡ªåŠ¨æ£€æµ‹å¹¶æ›´æ–°æ•°æ®åº“
            if data_path and data_path != st.session_state.get('_last_data_path', ''):
                detected_db = detect_database_from_path(data_path)
                if detected_db != database:
                    st.session_state.database = detected_db
                    st.session_state._last_data_path = data_path
                    st.rerun()
                st.session_state._last_data_path = data_path
            
            # éªŒè¯æŒ‰é’®
            validate_btn = "ğŸ” Validate Data Path" if st.session_state.language == 'en' else "ğŸ” éªŒè¯æ•°æ®è·¯å¾„"
            if st.button(validate_btn, width="stretch", key="validate_path"):
                if not data_path:
                    err_msg = "âŒ Please enter data path" if st.session_state.language == 'en' else "âŒ è¯·è¾“å…¥æ•°æ®è·¯å¾„"
                    st.error(err_msg)
                elif not Path(data_path).exists():
                    err_msg = "âŒ Path does not exist" if st.session_state.language == 'en' else "âŒ è·¯å¾„ä¸å­˜åœ¨"
                    st.error(err_msg)
                else:
                    # æ£€æŸ¥æ•°æ®åº“æ‰€éœ€æ–‡ä»¶
                    validation_result = validate_database_path(data_path, database)
                    st.session_state.last_validation = validation_result
                    st.session_state.last_validated_path = data_path
                    
                    if validation_result['valid']:
                        st.session_state.data_path = data_path
                        st.session_state.path_validated = True
                        st.success(f"âœ… {validation_result['message']}")
                    else:
                        st.session_state.path_validated = False
                        st.error(validation_result['message'])
                        if validation_result.get('suggestion'):
                            st.info(validation_result['suggestion'])
            
            # æ˜¾ç¤ºå½“å‰éªŒè¯çŠ¶æ€å’Œè½¬æ¢æŒ‰é’®
            last_validation = st.session_state.get('last_validation', {})
            last_path = st.session_state.get('last_validated_path', '')
            
            if st.session_state.get('path_validated') and st.session_state.data_path == data_path:
                validated_msg = "âœ… Path validated" if st.session_state.language == 'en' else "âœ… è·¯å¾„å·²éªŒè¯"
                st.success(validated_msg)
            elif last_validation.get('can_convert') and last_path == data_path:
                # æ˜¾ç¤ºè½¬æ¢æŒ‰é’®
                convert_btn = "ğŸ”„ Convert to Parquet" if st.session_state.language == 'en' else "ğŸ”„ è½¬æ¢ä¸ºParquet"
                if st.button(convert_btn, width="stretch", type="primary", key="convert_csv"):
                    st.session_state.show_convert_dialog = True
                    st.session_state.convert_source_path = data_path
                    st.rerun()
                convert_hint = "ğŸ’¡ Converting to Parquet enables faster data loading" if st.session_state.language == 'en' else "ğŸ’¡ è½¬æ¢ä¸ºParquetæ ¼å¼å¯å¤§å¹…åŠ é€Ÿæ•°æ®åŠ è½½"
                st.caption(convert_hint)
            elif data_path and Path(data_path).exists():
                validate_hint = "ğŸ’¡ Click the button above to validate data format" if st.session_state.language == 'en' else "ğŸ’¡ ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®éªŒè¯æ•°æ®æ ¼å¼"
                st.caption(validate_hint)
        
        st.markdown("---")
        
        # ============ æ­¥éª¤2: é˜Ÿåˆ—ç­›é€‰ï¼ˆæ–°å¢ï¼‰ ============
        step2_cohort_title = "Step 2: Cohort Selection" if st.session_state.language == 'en' else "æ­¥éª¤2: é˜Ÿåˆ—ç­›é€‰"
        st.markdown(f"### ğŸ‘¥ {step2_cohort_title}")
        
        # ğŸ”§ FIX (2026-02-03): æ£€æŸ¥æ­¥éª¤ä¾èµ– - Step1å¿…é¡»å…ˆå®Œæˆ
        use_mock = st.session_state.get('use_mock_data', False)
        if use_mock:
            step1_complete = st.session_state.get('step1_confirmed', False)
        else:
            step1_complete = st.session_state.data_path and Path(st.session_state.data_path).exists()
        
        if not step1_complete:
            # æç¤ºç”¨æˆ·å…ˆå®ŒæˆStep1
            step_dep_msg = "âš ï¸ Please complete Step 1 first" if st.session_state.language == 'en' else "âš ï¸ è¯·å…ˆå®Œæˆæ­¥éª¤1"
            st.warning(step_dep_msg)
            return  # ä¸æ¸²æŸ“åç»­å†…å®¹
        
        # åˆå§‹åŒ–é˜Ÿåˆ—ç­›é€‰çš„ session state
        if 'cohort_filter' not in st.session_state:
            st.session_state.cohort_filter = {
                'age_min': None,
                'age_max': None,
                'first_icu_stay': None,
                'los_min': None,
                'los_max': None,
                'gender': None,
                'survived': None,
                'has_sepsis': None,
            }
        if 'cohort_enabled' not in st.session_state:
            st.session_state.cohort_enabled = False
        if 'filtered_patient_count' not in st.session_state:
            st.session_state.filtered_patient_count = None
        
        # å¯ç”¨é˜Ÿåˆ—ç­›é€‰å¼€å…³ - ä½¿ç”¨ key å‚æ•°è®© Streamlit è‡ªåŠ¨ç®¡ç†çŠ¶æ€
        cohort_toggle_label = "Enable Cohort Filtering" if st.session_state.language == 'en' else "å¯ç”¨é˜Ÿåˆ—ç­›é€‰"
        cohort_help = "Filter patients by demographics and clinical criteria" if st.session_state.language == 'en' else "æ ¹æ®äººå£ç»Ÿè®¡å­¦å’Œä¸´åºŠæ ‡å‡†ç­›é€‰æ‚£è€…"
        st.toggle(cohort_toggle_label, key="cohort_enabled", help=cohort_help)
        
        # ä» session_state è·å–å½“å‰å€¼ï¼ˆç”± toggle çš„ key è‡ªåŠ¨æ›´æ–°ï¼‰
        cohort_enabled = st.session_state.cohort_enabled
        
        if cohort_enabled:
            # å¹´é¾„ç­›é€‰
            age_label = "ğŸ‚ Age Range" if st.session_state.language == 'en' else "ğŸ‚ å¹´é¾„èŒƒå›´"
            with st.expander(age_label, expanded=True):
                age_col1, age_col2 = st.columns(2)
                with age_col1:
                    age_min_label = "Min Age" if st.session_state.language == 'en' else "æœ€å°å¹´é¾„"
                    # ğŸ”§ ADD (2026-02-05): æ·»åŠ "ä¸é™åˆ¶"é€‰é¡¹
                    no_limit_min_label = "No Limit" if st.session_state.language == 'en' else "ä¸é™åˆ¶"
                    age_min_no_limit = st.checkbox(no_limit_min_label, value=st.session_state.cohort_filter['age_min'] is None, key="cohort_age_min_no_limit")
                    if age_min_no_limit:
                        st.session_state.cohort_filter['age_min'] = None
                        st.caption("âœ“ " + ("No minimum age limit" if st.session_state.language == 'en' else "æ— æœ€å°å¹´é¾„é™åˆ¶"))
                    else:
                        age_min = st.number_input(
                            age_min_label, min_value=0, max_value=120, 
                            value=18 if st.session_state.cohort_filter['age_min'] is None else int(st.session_state.cohort_filter['age_min']),
                            key="cohort_age_min"
                        )
                        st.session_state.cohort_filter['age_min'] = age_min if age_min > 0 else None
                with age_col2:
                    age_max_label = "Max Age" if st.session_state.language == 'en' else "æœ€å¤§å¹´é¾„"
                    # ğŸ”§ ADD (2026-02-05): æ·»åŠ "ä¸é™åˆ¶"é€‰é¡¹
                    no_limit_max_label = "No Limit" if st.session_state.language == 'en' else "ä¸é™åˆ¶"
                    age_max_no_limit = st.checkbox(no_limit_max_label, value=st.session_state.cohort_filter['age_max'] is None, key="cohort_age_max_no_limit")
                    if age_max_no_limit:
                        st.session_state.cohort_filter['age_max'] = None
                        st.caption("âœ“ " + ("No maximum age limit" if st.session_state.language == 'en' else "æ— æœ€å¤§å¹´é¾„é™åˆ¶"))
                    else:
                        age_max = st.number_input(
                            age_max_label, min_value=0, max_value=120, 
                            value=100 if st.session_state.cohort_filter['age_max'] is None else int(st.session_state.cohort_filter['age_max']),
                            key="cohort_age_max"
                        )
                        st.session_state.cohort_filter['age_max'] = age_max if age_max < 120 else None
            
            # é¦–æ¬¡å…¥ICUç­›é€‰
            first_icu_label = "ğŸ¥ First ICU Stay Only" if st.session_state.language == 'en' else "ğŸ¥ ä»…é¦–æ¬¡å…¥ICU"
            first_icu_options = {
                'any': 'Any' if st.session_state.language == 'en' else 'ä¸é™',
                'yes': 'Yes (First ICU only)' if st.session_state.language == 'en' else 'æ˜¯ï¼ˆä»…é¦–æ¬¡ï¼‰',
                'no': 'No (Readmissions only)' if st.session_state.language == 'en' else 'å¦ï¼ˆä»…å†å…¥é™¢ï¼‰',
            }
            first_icu_val = st.radio(
                first_icu_label,
                options=list(first_icu_options.keys()),
                format_func=lambda x: first_icu_options[x],
                index=0,
                horizontal=True,
                key="cohort_first_icu"
            )
            if first_icu_val == 'yes':
                st.session_state.cohort_filter['first_icu_stay'] = True
            elif first_icu_val == 'no':
                st.session_state.cohort_filter['first_icu_stay'] = False
            else:
                st.session_state.cohort_filter['first_icu_stay'] = None
            
            # ä½é™¢æ—¶é•¿ç­›é€‰ï¼ˆåªéœ€è¦æœ€çŸ­æ—¶é•¿ï¼Œé»˜è®¤24å°æ—¶ï¼‰
            los_label = "â±ï¸ Min ICU Stay (hours)" if st.session_state.language == 'en' else "â±ï¸ æœ€çŸ­ä½é™¢æ—¶é•¿ï¼ˆå°æ—¶ï¼‰"
            los_help = "Minimum ICU stay duration to include patients (default 24h)" if st.session_state.language == 'en' else "çº³å…¥æ‚£è€…çš„æœ€çŸ­ICUä½é™¢æ—¶é•¿ï¼ˆé»˜è®¤24å°æ—¶ï¼‰"
            los_min = st.number_input(
                los_label, min_value=0, max_value=10000, value=24,
                help=los_help,
                key="cohort_los_min"
            )
            st.session_state.cohort_filter['los_min'] = los_min if los_min > 0 else None
            st.session_state.cohort_filter['los_max'] = None  # ä¸å†ä½¿ç”¨max
            
            # æ€§åˆ«ç­›é€‰
            gender_label = "ğŸ‘¤ Gender" if st.session_state.language == 'en' else "ğŸ‘¤ æ€§åˆ«"
            gender_options = {
                'any': 'Any' if st.session_state.language == 'en' else 'ä¸é™',
                'M': 'Male' if st.session_state.language == 'en' else 'ç”·æ€§',
                'F': 'Female' if st.session_state.language == 'en' else 'å¥³æ€§',
            }
            gender_val = st.radio(
                gender_label,
                options=list(gender_options.keys()),
                format_func=lambda x: gender_options[x],
                index=0,
                horizontal=True,
                key="cohort_gender"
            )
            st.session_state.cohort_filter['gender'] = gender_val if gender_val != 'any' else None
            
            # å­˜æ´»çŠ¶æ€ç­›é€‰
            survival_label = "ğŸ’š Survival Status" if st.session_state.language == 'en' else "ğŸ’š å­˜æ´»çŠ¶æ€"
            survival_options = {
                'any': 'Any' if st.session_state.language == 'en' else 'ä¸é™',
                'survived': 'Survived' if st.session_state.language == 'en' else 'å­˜æ´»',
                'deceased': 'Deceased' if st.session_state.language == 'en' else 'æ­»äº¡',
            }
            survival_val = st.radio(
                survival_label,
                options=list(survival_options.keys()),
                format_func=lambda x: survival_options[x],
                index=0,
                horizontal=True,
                key="cohort_survival"
            )
            if survival_val == 'survived':
                st.session_state.cohort_filter['survived'] = True
            elif survival_val == 'deceased':
                st.session_state.cohort_filter['survived'] = False
            else:
                st.session_state.cohort_filter['survived'] = None
            
            # ğŸ”§ ç§»é™¤ Sepsis ç­›é€‰å™¨ï¼ˆå¤ªå¤æ‚ï¼Œç”¨æˆ·å¯èƒ½ä¸ç†è§£ï¼‰
            # ç›´æ¥è®¾ç½®ä¸º Noneï¼ˆä¸ç­›é€‰ï¼‰
            st.session_state.cohort_filter['has_sepsis'] = None
            
            # æ˜¾ç¤ºå½“å‰ç­›é€‰æ¡ä»¶æ‘˜è¦
            filter_summary = []
            cf = st.session_state.cohort_filter
            if cf['age_min'] is not None or cf['age_max'] is not None:
                age_range = f"{cf['age_min'] or 0}-{cf['age_max'] or 'âˆ'}"
                filter_summary.append(f"Age: {age_range}" if st.session_state.language == 'en' else f"å¹´é¾„: {age_range}")
            if cf['first_icu_stay'] is not None:
                filter_summary.append(f"First ICU: {'Yes' if cf['first_icu_stay'] else 'No'}" if st.session_state.language == 'en' else f"é¦–æ¬¡å…¥ICU: {'æ˜¯' if cf['first_icu_stay'] else 'å¦'}")
            # ğŸ”§ ADD (2026-02-05): æ˜¾ç¤º Min ICU Stay ç­›é€‰æ¡ä»¶
            if cf.get('los_min') is not None:
                filter_summary.append(f"Min ICU Stay: {cf['los_min']}h" if st.session_state.language == 'en' else f"æœ€çŸ­ä½é™¢: {cf['los_min']}å°æ—¶")
            if cf['gender'] is not None:
                filter_summary.append(f"Gender: {cf['gender']}" if st.session_state.language == 'en' else f"æ€§åˆ«: {'ç”·' if cf['gender']=='M' else 'å¥³'}")
            if cf['survived'] is not None:
                filter_summary.append(f"Survived: {'Yes' if cf['survived'] else 'No'}" if st.session_state.language == 'en' else f"å­˜æ´»: {'æ˜¯' if cf['survived'] else 'å¦'}")
            if cf['has_sepsis'] is not None:
                filter_summary.append(f"Sepsis: {'Yes' if cf['has_sepsis'] else 'No'}" if st.session_state.language == 'en' else f"è„“æ¯’ç—‡: {'æ˜¯' if cf['has_sepsis'] else 'å¦'}")
            
            if filter_summary:
                summary_text = " | ".join(filter_summary)
                st.info(f"ğŸ“‹ {summary_text}")
                # ğŸ”§ åœ¨æ¼”ç¤ºæ¨¡å¼ä¸‹æç¤ºç”¨æˆ·è¿‡æ»¤å™¨å°†åº”ç”¨äºæ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ
                if st.session_state.get('use_mock_data', False):
                    demo_filter_hint = "âœ¨ These filters will be applied when generating mock data" if st.session_state.language == 'en' else "âœ¨ è¿™äº›ç­›é€‰æ¡ä»¶å°†åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®æ—¶åº”ç”¨"
                    st.caption(demo_filter_hint)
            else:
                no_filter_msg = "No filters applied (will load all patients)" if st.session_state.language == 'en' else "æœªè®¾ç½®ç­›é€‰æ¡ä»¶ï¼ˆå°†åŠ è½½æ‰€æœ‰æ‚£è€…ï¼‰"
                st.caption(no_filter_msg)
            
            # âœ… Step 2 ç¡®è®¤æŒ‰é’®
            step2_confirm_label = "âœ… Confirm Cohort Selection" if st.session_state.language == 'en' else "âœ… ç¡®è®¤é˜Ÿåˆ—ç­›é€‰"
            if st.button(step2_confirm_label, type="primary", use_container_width=True, key="step2_confirm"):
                st.session_state.step2_confirmed = True
                step2_done_msg = "âœ… Step 2 completed! Proceed to Step 3: Select Features" if st.session_state.language == 'en' else "âœ… æ­¥éª¤2å·²å®Œæˆï¼è¯·ç»§ç»­æ­¥éª¤3: é€‰æ‹©ç‰¹å¾"
                st.success(step2_done_msg)
        else:
            # é˜Ÿåˆ—ç­›é€‰ç¦ç”¨æ—¶çš„æç¤º
            disabled_msg = "ğŸ’¡ Enable cohort filtering to select specific patient populations" if st.session_state.language == 'en' else "ğŸ’¡ å¯ç”¨é˜Ÿåˆ—ç­›é€‰å¯é€‰æ‹©ç‰¹å®šæ‚£è€…äººç¾¤"
            st.caption(disabled_msg)
            
            # âœ… Step 2 ç¡®è®¤æŒ‰é’®ï¼ˆå³ä½¿ç¦ç”¨ç­›é€‰ä¹Ÿéœ€è¦ç¡®è®¤ï¼‰
            step2_confirm_label = "âœ… Confirm (No Filtering)" if st.session_state.language == 'en' else "âœ… ç¡®è®¤ï¼ˆä¸ç­›é€‰ï¼‰"
            if st.button(step2_confirm_label, type="primary", use_container_width=True, key="step2_confirm_no_filter"):
                st.session_state.step2_confirmed = True
                step2_done_msg = "âœ… Step 2 completed! Proceed to Step 3: Select Features" if st.session_state.language == 'en' else "âœ… æ­¥éª¤2å·²å®Œæˆï¼è¯·ç»§ç»­æ­¥éª¤3: é€‰æ‹©ç‰¹å¾"
                st.success(step2_done_msg)
        
        st.markdown("---")
        
        # ============ æ­¥éª¤3: Concept é€‰æ‹© ============
        step3_title = "Step 3: Select Features" if st.session_state.language == 'en' else "æ­¥éª¤3: é€‰æ‹©ç‰¹å¾"
        st.markdown(f"### ğŸ”§ {step3_title}")
        
        # ğŸ”§ FIX (2026-02-05): æ£€æŸ¥æ­¥éª¤ä¾èµ– - Step2å¿…é¡»å…ˆç¡®è®¤ï¼Œå¦åˆ™ä¸æ˜¾ç¤ºç‰¹å¾é€‰æ‹©
        step2_complete = st.session_state.get('step2_confirmed', False)
        if not step2_complete:
            # æç¤ºç”¨æˆ·å…ˆå®ŒæˆStep2ï¼Œä¸æ˜¾ç¤ºåç»­å†…å®¹
            step_dep_msg = "âš ï¸ Please complete Step 2 first (click Confirm Cohort Selection button)" if st.session_state.language == 'en' else "âš ï¸ è¯·å…ˆå®Œæˆæ­¥éª¤2ï¼ˆç‚¹å‡»ç¡®è®¤é˜Ÿåˆ—ç­›é€‰æŒ‰é’®ï¼‰"
            st.warning(step_dep_msg)
            return  # ä¸å†æ˜¾ç¤ºStep 3çš„å†…å®¹
        
        # åˆå§‹åŒ– session state
        if 'concept_checkboxes' not in st.session_state:
            st.session_state.concept_checkboxes = {}
        if 'selected_groups' not in st.session_state:
            st.session_state.selected_groups = []
        
        selected_concepts = []
        
        # ä½¿ç”¨ multiselect ç®¡ç†ç±»åˆ«é€‰æ‹©
        valid_defaults = [g for g in st.session_state.selected_groups if g in concept_groups]
        
        cat_label = "Select Feature Categories" if st.session_state.language == 'en' else "é€‰æ‹©ç‰¹å¾ç±»åˆ«"
        cat_help = "Multi-select, click Ã— to remove" if st.session_state.language == 'en' else "å¯å¤šé€‰ï¼Œç‚¹å‡» Ã— åˆ é™¤"
        cat_placeholder = "Click to select..." if st.session_state.language == 'en' else "ç‚¹å‡»é€‰æ‹©..."
        
        # æ·»åŠ  ALL æŒ‰é’®
        col_select, col_all = st.columns([4, 1])
        with col_all:
            all_label = "ALL" if st.session_state.language == 'en' else "å…¨é€‰"
            if st.button(all_label, key="select_all_groups", width='stretch'):
                st.session_state.selected_groups = list(concept_groups.keys())
                # è‡ªåŠ¨é€‰ä¸­æ‰€æœ‰æ¦‚å¿µ
                for grp in concept_groups.keys():
                    for concept in concept_groups.get(grp, []):
                        st.session_state.concept_checkboxes[concept] = True
                st.rerun()
        
        with col_select:
            current_selection = st.multiselect(
                cat_label,
                options=list(concept_groups.keys()),
                default=valid_defaults,
                help=cat_help,
                placeholder=cat_placeholder
            )
        
        # æ£€æµ‹å˜åŒ–å¹¶æ›´æ–°
        if current_selection != st.session_state.selected_groups:
            added_groups = set(current_selection) - set(st.session_state.selected_groups)
            for grp in added_groups:
                for concept in concept_groups.get(grp, []):
                    st.session_state.concept_checkboxes[concept] = True
            
            removed_groups = set(st.session_state.selected_groups) - set(current_selection)
            for grp in removed_groups:
                for concept in concept_groups.get(grp, []):
                    if concept in st.session_state.concept_checkboxes:
                        del st.session_state.concept_checkboxes[concept]
            
            st.session_state.selected_groups = current_selection
            st.rerun()
        
        # æ˜¾ç¤ºå·²é€‰ç±»åˆ«çš„è¯¦ç»†ç‰¹å¾é…ç½®
        if st.session_state.selected_groups:
            import hashlib
            
            detail_label = "ğŸ¯ Feature Detail Configuration" if st.session_state.language == 'en' else "ğŸ¯ ç‰¹å¾è¯¦ç»†é…ç½®"
            with st.expander(detail_label, expanded=True):
                for group_name in st.session_state.selected_groups:
                    if group_name not in concept_groups:
                        continue
                    key_hash = hashlib.md5(group_name.encode()).hexdigest()[:8]
                    
                    st.markdown(f"**{group_name}**")
                    group_concepts = concept_groups.get(group_name, [])
                    cols = st.columns(3)
                    for cidx, concept in enumerate(group_concepts):
                        with cols[cidx % 3]:
                            default_val = st.session_state.concept_checkboxes.get(concept, True)
                            checked = st.checkbox(concept, value=default_val, key=f"cb_{key_hash}_{concept}")
                            st.session_state.concept_checkboxes[concept] = checked
                    st.markdown("---")
            
            # æ”¶é›†æ‰€æœ‰é€‰ä¸­çš„ concepts
            for group_name in st.session_state.selected_groups:
                for concept in concept_groups.get(group_name, []):
                    if st.session_state.concept_checkboxes.get(concept, True):
                        selected_concepts.append(concept)
            
            selected_concepts = list(set(selected_concepts))
            selected_msg = f"âœ… {len(selected_concepts)} features selected" if st.session_state.language == 'en' else f"âœ… å·²é€‰ {len(selected_concepts)} ä¸ªç‰¹å¾"
            st.success(selected_msg)
        
        st.session_state.selected_concepts = selected_concepts
        
        # ğŸ”§ ADD (2026-02-05): ç¡®è®¤é€‰æ‹©æŒ‰é’® - åªæœ‰ç‚¹å‡»åæ‰èƒ½è¿›å…¥Step 4
        if len(selected_concepts) > 0:
            step3_confirm_label = "âœ… Confirm Selection" if st.session_state.language == 'en' else "âœ… ç¡®è®¤é€‰æ‹©"
            if st.button(step3_confirm_label, type="primary", use_container_width=True, key="step3_confirm_selection"):
                st.session_state.step3_confirmed = True
                step3_done_msg = "âœ… Step 3 completed! Proceed to Step 4: Export Data" if st.session_state.language == 'en' else "âœ… æ­¥éª¤3å·²å®Œæˆï¼è¯·ç»§ç»­æ­¥éª¤4: å¯¼å‡ºæ•°æ®"
                st.success(step3_done_msg)
                st.rerun()
            
            # æ˜¾ç¤ºå·²ç¡®è®¤çŠ¶æ€
            if st.session_state.get('step3_confirmed', False):
                step3_confirmed_msg = "âœ… Selection confirmed" if st.session_state.language == 'en' else "âœ… å·²ç¡®è®¤é€‰æ‹©"
                st.info(step3_confirmed_msg)
        else:
            # å¦‚æœæ²¡æœ‰é€‰ä¸­ä»»ä½•æ¦‚å¿µï¼Œé‡ç½®ç¡®è®¤çŠ¶æ€
            st.session_state.step3_confirmed = False
        
        st.markdown("---")
        
        # ============ æ­¥éª¤4: ç›´æ¥å¯¼å‡º ============
        step4_title = "Step 4: Export Data" if st.session_state.language == 'en' else "æ­¥éª¤4: å¯¼å‡ºæ•°æ®"
        st.markdown(f"### ğŸ’¾ {step4_title}")
        
        # ğŸ”§ FIX (2026-02-05): æ£€æŸ¥æ­¥éª¤ä¾èµ– - Step3å¿…é¡»å…ˆç¡®è®¤ï¼ˆç‚¹å‡»ç¡®è®¤é€‰æ‹©æŒ‰é’®ï¼‰
        step3_complete = st.session_state.get('step3_confirmed', False) and len(st.session_state.get('selected_concepts', [])) > 0
        if not step3_complete:
            # æç¤ºç”¨æˆ·å…ˆå®ŒæˆStep3å¹¶ç‚¹å‡»ç¡®è®¤æŒ‰é’®
            step_dep_msg = "âš ï¸ Please complete Step 3 first (select features and click Confirm Selection)" if st.session_state.language == 'en' else "âš ï¸ è¯·å…ˆå®Œæˆæ­¥éª¤3ï¼ˆé€‰æ‹©ç‰¹å¾å¹¶ç‚¹å‡»ç¡®è®¤é€‰æ‹©ï¼‰"
            st.warning(step_dep_msg)
            # ä¸å†ç»§ç»­æ˜¾ç¤ºStep4çš„å†…å®¹
            return
        
        # å¯¼å‡ºè·¯å¾„é…ç½® - å®æ—¶æ ¹æ®æ•°æ®åº“æ˜¾ç¤ºå­ç›®å½•ï¼Œæ·»åŠ æ—¶é—´æˆ³åç¼€
        import platform
        from datetime import datetime
        if platform.system() == 'Windows':
            base_export_path = r'D:\easyicu_export'
        else:
            base_export_path = os.path.expanduser('~/easyicu_export')
        db_name = st.session_state.get('database', 'mock')
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„é»˜è®¤ç›®å½•åï¼ˆåªä¿ç•™å¹´æœˆæ—¥ï¼‰
        timestamp_suffix = datetime.now().strftime('%Y%m%d')
        default_export_path = str(Path(base_export_path) / f"{db_name}_{timestamp_suffix}")
        
        export_path = st.text_input(
            "Export Path" if st.session_state.language == 'en' else "å¯¼å‡ºè·¯å¾„",
            value=default_export_path,
            placeholder="Select export directory" if st.session_state.language == 'en' else "é€‰æ‹©å¯¼å‡ºç›®å½•",
            help=(f"Data will be exported to this directory (Current database: {db_name.upper()})" if st.session_state.language == 'en' else f"æ•°æ®å°†å¯¼å‡ºåˆ°æ­¤ç›®å½•ï¼ˆå½“å‰æ•°æ®åº“: {db_name.upper()}ï¼‰")
        )
        st.session_state.export_path = export_path
        
        # æ£€æŸ¥è·¯å¾„å¹¶æä¾›åˆ›å»ºé€‰é¡¹
        if export_path:
            if Path(export_path).exists():
                path_ok_msg = "âœ… Path valid" if st.session_state.language == 'en' else "âœ… è·¯å¾„æœ‰æ•ˆ"
                st.success(path_ok_msg)
            else:
                col_create, col_info = st.columns([1, 2])
                with col_create:
                    create_btn = "ğŸ“ Create Directory" if st.session_state.language == 'en' else "ğŸ“ åˆ›å»ºç›®å½•"
                    if st.button(create_btn, key="create_export_dir"):
                        try:
                            Path(export_path).mkdir(parents=True, exist_ok=True)
                            ok_msg = "âœ… Directory created" if st.session_state.language == 'en' else "âœ… ç›®å½•å·²åˆ›å»º"
                            st.success(ok_msg)
                            st.rerun()
                        except Exception as e:
                            err_msg = f"Creation failed: {e}" if st.session_state.language == 'en' else f"åˆ›å»ºå¤±è´¥: {e}"
                            st.error(err_msg)
                with col_info:
                    not_exist_msg = "Path does not exist" if st.session_state.language == 'en' else "è·¯å¾„ä¸å­˜åœ¨"
                    st.caption(not_exist_msg)
        
        # å¯¼å‡ºæ ¼å¼é€‰æ‹©ï¼ˆä¼˜å…ˆParquetï¼‰
        format_label = "Export Format" if st.session_state.language == 'en' else "å¯¼å‡ºæ ¼å¼"
        format_help = "Parquet format is smaller and faster to load, recommended" if st.session_state.language == 'en' else "Parquetæ ¼å¼ä½“ç§¯å°ã€åŠ è½½å¿«ï¼Œæ¨èä½¿ç”¨"
        export_format = st.selectbox(
            format_label,
            options=['Parquet', 'CSV', 'Excel'],
            index=0,
            help=format_help
        )
        st.session_state.export_format = export_format
        
        # ğŸš€ æ‚£è€…æ•°é‡é™åˆ¶ï¼ˆæ€§èƒ½ä¼˜åŒ–é€‰é¡¹ï¼‰
        limit_label = "Patient Limit" if st.session_state.language == 'en' else "æ‚£è€…æ•°é‡é™åˆ¶"
        limit_help = "Limit number of patients to speed up loading. 0 = no limit (full data, may be slow)" if st.session_state.language == 'en' else "é™åˆ¶åŠ è½½çš„æ‚£è€…æ•°é‡ä»¥åŠ é€Ÿã€‚0 = ä¸é™åˆ¶ï¼ˆå…¨é‡æ•°æ®ï¼Œå¯èƒ½è¾ƒæ…¢ï¼‰"
        patient_limit_options = [100, 1000, 5000, 10000, 20000, 50000, 0]
        patient_limit_labels = {
            100: "100 (quick test)" if st.session_state.language == 'en' else "100ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰",
            1000: "1,000",
            5000: "5,000", 
            10000: "10,000",
            20000: "20,000",
            0: "All patients" if st.session_state.language == 'en' else "å…¨éƒ¨æ‚£è€…"
        }
        current_limit = st.session_state.get('patient_limit', 0)  # é»˜è®¤å…¨é‡
        if current_limit not in patient_limit_options:
            current_limit = 0  # ğŸ”§ FIX: é»˜è®¤å…¨é‡åŠ è½½
        patient_limit = st.selectbox(
            limit_label,
            options=patient_limit_options,
            index=patient_limit_options.index(current_limit),
            format_func=lambda x: patient_limit_labels.get(x, str(x)),
            help=limit_help
        )
        st.session_state.patient_limit = patient_limit
        
        # å¯¼å‡ºæŒ‰é’®
        use_mock = st.session_state.get('use_mock_data', False)
        has_loaded_data = len(st.session_state.get('loaded_concepts', {})) > 0  # ğŸ”§ FIX: æ£€æŸ¥æ˜¯å¦æœ‰å·²åŠ è½½çš„æ•°æ®
        can_export = (use_mock or has_loaded_data or (st.session_state.data_path and Path(st.session_state.data_path).exists())) and selected_concepts and export_path and Path(export_path).exists()
        
        # ğŸ”§ FIX (2026-02-03): å¦‚æœæœ‰å·²åŠ è½½æ•°æ®ä½†æ²¡æœ‰é€‰æ‹©ç‰¹å¾ï¼Œè‡ªåŠ¨ä½¿ç”¨å·²åŠ è½½æ•°æ®çš„keys
        if has_loaded_data and not selected_concepts:
            selected_concepts = list(st.session_state.loaded_concepts.keys())
            st.session_state.selected_concepts = selected_concepts
            can_export = export_path and Path(export_path).exists()
        
        export_btn = "ğŸ“¥ Export Data" if st.session_state.language == 'en' else "ğŸ“¥ å¯¼å‡ºæ•°æ®"
        if can_export:
            if st.button(export_btn, type="primary", width="stretch"):
                st.session_state.trigger_export = True
                st.session_state.export_completed = False
                st.session_state['_exporting_in_progress'] = True  # ğŸ†• æ ‡è®°å¯¼å‡ºæ­£åœ¨è¿›è¡Œ
                st.rerun()
        else:
            st.button(export_btn, type="primary", width="stretch", disabled=True)
            if not selected_concepts:
                feat_warn = "âš ï¸ Please select features first" if st.session_state.language == 'en' else "âš ï¸ è¯·å…ˆé€‰æ‹©ç‰¹å¾"
                st.caption(feat_warn)
            elif not use_mock and not st.session_state.data_path:
                path_warn = "âš ï¸ Please set data path first" if st.session_state.language == 'en' else "âš ï¸ è¯·å…ˆè®¾ç½®æ•°æ®è·¯å¾„"
                st.caption(path_warn)
        
        # ============ ç³»ç»Ÿèµ„æºä¿¡æ¯ ============
        st.markdown("---")
        resources = get_system_resources()
        perf_title = "âš¡ Performance" if st.session_state.language == 'en' else "âš¡ æ€§èƒ½é…ç½®"
        with st.expander(perf_title, expanded=False):
            if st.session_state.language == 'en':
                st.markdown(f"""
                **System Resources:**
                - ğŸ–¥ï¸ CPU: {resources['cpu_count']} cores
                - ğŸ’¾ RAM: {resources['total_memory_gb']} GB total
                - ğŸ“Š Available: {resources['available_memory_gb']} GB
                
                **Auto-optimized:**
                - Workers: {resources['recommended_workers']}
                - Backend: {resources['recommended_backend']}
                """)
            else:
                st.markdown(f"""
                **ç³»ç»Ÿèµ„æº:**
                - ğŸ–¥ï¸ CPU: {resources['cpu_count']} æ ¸å¿ƒ
                - ğŸ’¾ å†…å­˜: {resources['total_memory_gb']} GB æ€»è®¡
                - ğŸ“Š å¯ç”¨: {resources['available_memory_gb']} GB
                
                **è‡ªåŠ¨ä¼˜åŒ–é…ç½®:**
                - å¹¶è¡Œæ•°: {resources['recommended_workers']}
                - åç«¯: {resources['recommended_backend']}
                """)


def load_from_exported(export_dir: str, max_patients: int = 100, selected_files: list = None):
    """ä»å·²å¯¼å‡ºçš„æ•°æ®æ–‡ä»¶åŠ è½½æ•°æ®ï¼ˆé™åˆ¶æ‚£è€…æ•°ç”¨äºå¿«é€Ÿé¢„è§ˆï¼‰ã€‚
    
    ä»å®½è¡¨ä¸­æå–æ¯ä¸ªç‰¹å¾åˆ—ï¼Œä½¿å…¶å¯ä»¥å•ç‹¬é€‰æ‹©å’Œå¯è§†åŒ–ã€‚
    
    Args:
        export_dir: å¯¼å‡ºç›®å½•è·¯å¾„
        max_patients: æœ€å¤§æ‚£è€…æ•°é™åˆ¶ï¼ˆé»˜è®¤100ï¼‰
        selected_files: è¦åŠ è½½çš„æ–‡ä»¶ååˆ—è¡¨ï¼ˆä¸å«æ‰©å±•åï¼‰ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨åŠ è½½
    """
    try:
        import time
        load_start = time.time()
        
        export_path = Path(export_dir)
        raw_data = {}  # åŸå§‹æ–‡ä»¶æ•°æ®
        
        # IDåˆ—å’Œæ—¶é—´åˆ—ï¼Œä¸ä½œä¸ºç‰¹å¾
        id_candidates = ['stay_id', 'hadm_id', 'icustay_id', 
                        'patientunitstayid', 'admissionid', 'patientid']
        time_candidates = ['time', 'charttime', 'starttime', 'endtime', 
                          'datetime', 'timestamp', 'index']
        exclude_cols = set(id_candidates + time_candidates)
        
        # æ‰«æå¹¶åŠ è½½é€‰ä¸­çš„æ•°æ®æ–‡ä»¶
        for file in export_path.iterdir():
            file_stem = file.stem
            
            # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶åˆ—è¡¨ï¼ŒåªåŠ è½½é€‰ä¸­çš„
            if selected_files is not None and file_stem not in selected_files:
                continue
            
            if file.suffix == '.csv':
                df = pd.read_csv(file)
                raw_data[file_stem] = df
            elif file.suffix == '.parquet':
                df = pd.read_parquet(file)
                raw_data[file_stem] = df
            elif file.suffix == '.xlsx':
                df = pd.read_excel(file)
                raw_data[file_stem] = df
        
        if not raw_data:
            lang = st.session_state.get('language', 'en')
            warn_msg = "âš ï¸ No valid data files found" if lang == 'en' else "âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®æ–‡ä»¶"
            st.warning(warn_msg)
            return
        
        # ä»å®½è¡¨ä¸­æå–æ¯ä¸ªç‰¹å¾åˆ—ä½œä¸ºå•ç‹¬çš„concept
        data = {}
        
        # é¦–å…ˆç¡®å®šå…¨å±€IDåˆ—ï¼ˆç”¨äºæ‚£è€…ç­›é€‰ï¼‰
        id_col_found = 'stay_id'
        for file_name, df in raw_data.items():
            if isinstance(df, pd.DataFrame):
                for col in id_candidates:
                    if col in df.columns:
                        id_col_found = col
                        break
                break
        
        # ä»æ¯ä¸ªå®½è¡¨ä¸­æå–ç‰¹å¾åˆ—
        # æ³¨æ„ï¼šæ¯ä¸ªæ–‡ä»¶å¯èƒ½æœ‰ä¸åŒçš„æ—¶é—´åˆ—ï¼Œéœ€è¦å•ç‹¬æ£€æµ‹
        # ğŸ”§ 2026-02-12: æ·»åŠ åˆ—åè§„èŒƒåŒ–å’Œå»é‡é€»è¾‘
        for file_name, df in raw_data.items():
            if isinstance(df, pd.DataFrame):
                # ä¸ºå½“å‰æ–‡ä»¶æ‰¾æ—¶é—´åˆ—ï¼ˆæ¯ä¸ªæ–‡ä»¶å•ç‹¬æ£€æµ‹ï¼‰
                file_time_col = None
                for col in time_candidates:
                    if col in df.columns:
                        file_time_col = col
                        break
                
                # è·å–ç‰¹å¾åˆ—ï¼ˆæ’é™¤IDåˆ—ã€æ—¶é—´åˆ—å’Œå…ƒæ•°æ®åˆ—å¦‚_conceptï¼‰
                meta_cols = {'_concept'}
                feature_cols = [c for c in df.columns if c not in exclude_cols and c not in meta_cols]
                
                # ä¸ºæ¯ä¸ªç‰¹å¾åˆ›å»ºå•ç‹¬çš„DataFrame
                for feat_col in feature_cols:
                    # ğŸ”§ è§„èŒƒåŒ–åˆ—åï¼ˆå»é‡ï¼‰
                    normalized_col = normalize_column_name(feat_col)
                    
                    # å¦‚æœè§„èŒƒåŒ–åçš„åˆ—åå·²å­˜åœ¨ï¼Œè·³è¿‡ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªé‡åˆ°çš„ï¼‰
                    if normalized_col in data:
                        continue
                    
                    # ä¿ç•™IDåˆ—ã€è¯¥æ–‡ä»¶çš„æ—¶é—´åˆ—å’Œè¯¥ç‰¹å¾åˆ—
                    keep_cols = []
                    if id_col_found in df.columns:
                        keep_cols.append(id_col_found)
                    if file_time_col and file_time_col in df.columns:
                        keep_cols.append(file_time_col)
                    keep_cols.append(feat_col)
                    
                    feat_df = df[keep_cols].copy()
                    # ğŸ”§ é‡å‘½åç‰¹å¾åˆ—ä¸ºè§„èŒƒåŒ–åçš„åç§°
                    if feat_col != normalized_col:
                        feat_df = feat_df.rename(columns={feat_col: normalized_col})
                    data[normalized_col] = feat_df
        
        # è·å–æ‚£è€…åˆ—è¡¨
        patient_ids = set()
        
        for concept_df in data.values():
            if isinstance(concept_df, pd.DataFrame):
                if id_col_found in concept_df.columns:
                    patient_ids.update(concept_df[id_col_found].unique())
        
        all_patient_count = len(patient_ids)
        
        # é™åˆ¶æ‚£è€…æ•°ç”¨äºå¯è§†åŒ–é¢„è§ˆï¼ˆmax_patients=None è¡¨ç¤ºåŠ è½½å…¨éƒ¨ï¼‰
        if max_patients is None or max_patients <= 0:
            preview_patient_ids = sorted(list(patient_ids))
            is_limited = False
        else:
            preview_patient_ids = sorted(list(patient_ids))[:max_patients]
            is_limited = all_patient_count > max_patients
        
        # ç­›é€‰æ•°æ®åªä¿ç•™é™åˆ¶çš„æ‚£è€…
        filtered_data = {}
        for concept_name, df in data.items():
            if isinstance(df, pd.DataFrame) and id_col_found in df.columns:
                filtered_df = df[df[id_col_found].isin(preview_patient_ids)]
                # å³ä½¿DataFrameä¸ºç©ºä¹Ÿä¿ç•™ï¼Œç¡®ä¿ç‰¹å¾æ•°é‡ä¸€è‡´
                filtered_data[concept_name] = filtered_df
            else:
                # å¯¹äºæ²¡æœ‰IDåˆ—çš„DataFrameï¼ˆå¦‚é™æ€æŒ‡æ ‡ï¼‰ï¼Œç›´æ¥ä¿ç•™
                filtered_data[concept_name] = df
        
        st.session_state.loaded_concepts = filtered_data
        st.session_state.patient_ids = preview_patient_ids
        st.session_state.all_patient_count = all_patient_count
        st.session_state.id_col = id_col_found
        
        # ğŸ”§ FIX (2026-02-03): è®¾ç½® selected_concepts ä»¥ä¾¿ä¾§è¾¹æ çš„å¯¼å‡ºæŒ‰é’®å¯ç”¨
        st.session_state.selected_concepts = list(filtered_data.keys())
        
        # ğŸ”§ FIX (2026-02-12): è§„èŒƒåŒ–åæ¯åˆ—å°±æ˜¯ä¸€ä¸ªæ¦‚å¿µï¼Œç›´æ¥ç»Ÿè®¡åˆ—æ•°
        # ç”±äºåœ¨åŠ è½½æ—¶å·²ç»å»é‡ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨ len(filtered_data)
        unique_concept_count = len(filtered_data)
        
        # ğŸ”§ FIX (2026-02-03): Load Dataåé‡ç½®å¯¼å‡ºè§¦å‘çŠ¶æ€ï¼Œé¿å…ç™½å±
        # æ³¨æ„ï¼šä¸åº”è¯¥é‡ç½® export_completedï¼Œå› ä¸º Quick Visualization çš„ Load Data
        # æ˜¯ç‹¬ç«‹äºä¾§è¾¹æ æ•°æ®æå–å™¨çš„åŠŸèƒ½ï¼Œä¸åº”è¯¥å½±å“å¯¼å‡ºå®ŒæˆçŠ¶æ€
        st.session_state.trigger_export = False
        st.session_state['_exporting_in_progress'] = False
        # æ¸…ç†è·³è¿‡/è¦†ç›–æ¨¡å—çŠ¶æ€ï¼ˆè¿™äº›æ˜¯å¯¼å‡ºè¿‡ç¨‹ä¸­çš„ä¸´æ—¶çŠ¶æ€ï¼Œå¯ä»¥å®‰å…¨æ¸…ç†ï¼‰
        if '_skipped_modules' in st.session_state:
            del st.session_state['_skipped_modules']
        if '_overwrite_modules' in st.session_state:
            del st.session_state['_overwrite_modules']
        
        load_elapsed = time.time() - load_start
        
        # æ˜¾ç¤ºæç¤ºä¿¡æ¯
        # ğŸ”§ FIX (2026-02-12): è§„èŒƒåŒ–å concepts = columns (å·²å»é‡)
        lang = st.session_state.get('language', 'en')
        if lang == 'en':
            st.success(f"âœ… Loaded {unique_concept_count} concepts, {len(preview_patient_ids)}/{all_patient_count} patients ({load_elapsed:.1f}s)")
            if is_limited:
                st.info(f"ğŸ’¡ For better performance, preview is limited to {max_patients} patients. Full data has been exported to disk.")
        else:
            st.success(f"âœ… å·²åŠ è½½ {unique_concept_count} ä¸ªæ¦‚å¿µï¼Œ{len(preview_patient_ids)}/{all_patient_count} ä¸ªæ‚£è€… ({load_elapsed:.1f}ç§’)")
            if is_limited:
                st.info(f"ğŸ’¡ ä¸ºä¿è¯æµç•…æ€§ï¼Œå¯è§†åŒ–é¢„è§ˆä»…åŠ è½½å‰ {max_patients} ä¸ªæ‚£è€…ã€‚å®Œæ•´æ•°æ®å·²å¯¼å‡ºåˆ°ç£ç›˜ï¼Œå¯ä½¿ç”¨Python/Rè¿›è¡Œå®Œæ•´åˆ†æã€‚")
        
    except Exception as e:
        lang = st.session_state.get('language', 'en')
        err_msg = f"Loading failed: {e}" if lang == 'en' else f"åŠ è½½å¤±è´¥: {e}"
        st.error(err_msg)


def load_data():
    """Load data with parallel acceleration support - optimized batch loading."""
    lang = st.session_state.get('language', 'en')
    
    if not st.session_state.data_path:
        err_msg = "Please set data path first" if lang == 'en' else "è¯·å…ˆè®¾ç½®æ•°æ®è·¯å¾„"
        st.error(err_msg)
        return
    
    if not st.session_state.selected_concepts:
        err_msg = "Please select at least one concept" if lang == 'en' else "è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ª Concept"
        st.error(err_msg)
        return
    
    # æ˜¾ç¤ºåŠ è½½æç¤º
    n_selected = len(st.session_state.selected_concepts)
    if lang == 'en':
        st.info(f"â³ Loading {n_selected} features in batch mode, please wait...")
        spinner_msg = "Batch loading data, please wait..."
    else:
        st.info(f"â³ æ‰¹é‡åŠ è½½ {n_selected} ä¸ªç‰¹å¾æ•°æ®ï¼Œè¯·ç¨å€™...")
        spinner_msg = "æ­£åœ¨æ‰¹é‡åŠ è½½æ•°æ®ï¼Œè¯·ç¨å€™..."
    
    with st.spinner(spinner_msg):
        try:
            # åŠ¨æ€å¯¼å…¥ä»¥é¿å…å¾ªç¯å¯¼å…¥
            from pyricu import load_concepts
            import time
            import os
            
            concepts_list = st.session_state.selected_concepts
            n_concepts = len(concepts_list)
            
            load_start = time.time()
            
            # ğŸš€ ä¼˜åŒ–ï¼šçœŸæ­£çš„æ‰¹é‡åŠ è½½ - ä¸€æ¬¡è°ƒç”¨åŠ è½½æ‰€æœ‰concepts
            # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šå‚ç…§ extract_baseline_features.py çš„é…ç½®
            # å…³é”®ï¼šä½¿ç”¨ patient_ids é™åˆ¶åŠ è½½çš„æ‚£è€…èŒƒå›´ï¼ˆé»˜è®¤0è¡¨ç¤ºå…¨é‡ï¼‰
            patient_limit = st.session_state.get('patient_limit', 0)
            
            # è·å–å¯ç”¨çš„æ‚£è€…IDåˆ—è¡¨ï¼ˆå¦‚æœæœ‰ç¼“å­˜å°±ä½¿ç”¨ç¼“å­˜ï¼‰
            patient_ids_filter = None
            if patient_limit and patient_limit > 0:
                # å°è¯•ä» icustays è·å–æ‚£è€…ID
                try:
                    data_path = Path(st.session_state.data_path)
                    database = st.session_state.get('database', 'miiv')
                    
                    # æ ¹æ®æ•°æ®åº“ç±»å‹ç¡®å®š ID åˆ—å
                    id_col_map = {
                        'miiv': 'stay_id',
                        'eicu': 'patientunitstayid', 
                        'aumc': 'admissionid',
                        'hirid': 'patientid'
                    }
                    id_col = id_col_map.get(database, 'stay_id')
                    
                    # è¯»å– icustays è·å–æ‚£è€…ID
                    icustays_files = ['icustays.parquet', 'patient.parquet', 'admissions.parquet']
                    for f in icustays_files:
                        fp = data_path / f
                        if fp.exists():
                            icustays_df = pd.read_parquet(fp, columns=[id_col] if id_col else None)
                            if id_col in icustays_df.columns:
                                all_patient_ids = icustays_df[id_col].unique().tolist()
                                # é™åˆ¶æ‚£è€…æ•°é‡
                                if len(all_patient_ids) > patient_limit:
                                    sample_ids = all_patient_ids[:patient_limit]
                                else:
                                    sample_ids = all_patient_ids
                                patient_ids_filter = {id_col: sample_ids}
                                break
                except Exception:
                    pass  # æ— æ³•è·å–æ‚£è€…IDï¼Œä¸ä½¿ç”¨è¿‡æ»¤
            
            # ğŸš€ æ™ºèƒ½å¹¶è¡Œé…ç½®ï¼šæ ¹æ®ç³»ç»Ÿèµ„æºå’Œæ‚£è€…æ•°é‡åŠ¨æ€è°ƒæ•´
            num_patients = len(patient_ids_filter.get(id_col, [])) if patient_ids_filter else None
            parallel_workers, parallel_backend = get_optimal_parallel_config(num_patients, task_type='load')
            
            try:
                # ğŸ”§ é€ä¸ªåŠ è½½æ¦‚å¿µï¼Œè·³è¿‡ä¸å¯ç”¨çš„ï¼ˆæŸäº›æ¦‚å¿µåœ¨ç‰¹å®šæ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®æºé…ç½®ï¼‰
                data = {}
                failed_concepts = []
                empty_concepts = []  # ğŸ†• è·Ÿè¸ªè¿”å›ç©ºç»“æœçš„æ¦‚å¿µ
                
                for i, concept in enumerate(concepts_list):
                    try:
                        load_kwargs = {
                            'data_path': st.session_state.data_path,
                            'database': st.session_state.get('database'),
                            'concepts': [concept],
                            'verbose': False,
                            'merge': False,
                            'concept_workers': 1,
                            'parallel_workers': parallel_workers,
                            'parallel_backend': parallel_backend,
                        }
                        if patient_ids_filter:
                            load_kwargs['patient_ids'] = patient_ids_filter
                        
                        result = load_concepts(**load_kwargs)
                        
                        # å¤„ç†è¿”å›ç»“æœï¼ˆå¯èƒ½æ˜¯ dict æˆ– DataFrameï¼‰
                        if isinstance(result, dict):
                            for cname, df in result.items():
                                # ğŸ”§ å¤„ç†å„ç§è¿”å›ç±»å‹ï¼ˆICUTable, ConceptFrameç­‰ï¼‰
                                if hasattr(df, 'to_pandas'):
                                    df = df.to_pandas()
                                elif hasattr(df, 'dataframe'):
                                    df = df.dataframe()
                                elif hasattr(df, 'data') and isinstance(df.data, pd.DataFrame):
                                    df = df.data
                                
                                if isinstance(df, pd.DataFrame) and len(df) > 0:
                                    data[cname] = df
                                elif isinstance(df, pd.Series):
                                    data[cname] = df.to_frame().reset_index()
                                else:
                                    # ç©ºç»“æœï¼ˆå¯èƒ½æ˜¯æ•°æ®æºæœªé…ç½®æˆ–æµ‹è¯•æ‚£è€…æ²¡æœ‰è¯¥æ•°æ®ï¼‰
                                    empty_concepts.append(cname)
                        elif isinstance(result, pd.DataFrame):
                            # å•æ¦‚å¿µåŠ è½½è¿”å› DataFrame
                            if len(result) > 0:
                                data[concept] = result
                            else:
                                empty_concepts.append(concept)
                    except Exception:
                        failed_concepts.append(concept)
                        continue  # è·³è¿‡å¤±è´¥çš„æ¦‚å¿µï¼Œç»§ç»­åŠ è½½å…¶ä»–çš„
                
                if failed_concepts:
                    skip_msg = f"âš ï¸ Skipped {len(failed_concepts)} unavailable: {', '.join(failed_concepts[:5])}" if lang == 'en' else f"âš ï¸ è·³è¿‡ {len(failed_concepts)} ä¸ªä¸å¯ç”¨: {', '.join(failed_concepts[:5])}"
                    st.warning(skip_msg)
                
                # ğŸ†• æ˜¾ç¤ºç©ºç»“æœæ¦‚å¿µæç¤º
                if empty_concepts:
                    empty_msg = f"â„¹ï¸ {len(empty_concepts)} concepts returned empty (not configured or no data): {', '.join(empty_concepts[:8])}" if lang == 'en' else f"â„¹ï¸ {len(empty_concepts)} ä¸ªæ¦‚å¿µè¿”å›ç©ºç»“æœï¼ˆæœªé…ç½®æˆ–æ— æ•°æ®ï¼‰: {', '.join(empty_concepts[:8])}"
                    st.info(empty_msg)
                    
            except Exception as batch_err:
                # åŠ è½½å®Œå…¨å¤±è´¥
                batch_err_msg = f"âš ï¸ Loading failed: {batch_err}" if lang == 'en' else f"âš ï¸ åŠ è½½å¤±è´¥: {batch_err}"
                st.warning(batch_err_msg)
                data = {}
            
            load_elapsed = time.time() - load_start
            
            if not data:
                warn_msg = "âš ï¸ Failed to load any data, please check data path and concept selection" if lang == 'en' else "âš ï¸ æœªèƒ½åŠ è½½ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œ Concept é€‰æ‹©"
                st.warning(warn_msg)
                return
            
            st.session_state.loaded_concepts = data
            
            # è·å–æ‚£è€…åˆ—è¡¨ - ç»Ÿè®¡æ‰€æœ‰æ‚£è€…æ•°ï¼Œä½†UIé€‰æ‹©å™¨é™åˆ¶æ˜¾ç¤ºæ•°é‡
            patient_ids = set()
            id_candidates = ['stay_id', 'hadm_id', 'icustay_id', 
                           'patientunitstayid', 'admissionid', 'patientid']
            
            for concept_df in data.values():
                if isinstance(concept_df, pd.DataFrame):
                    for col in id_candidates:
                        if col in concept_df.columns:
                            patient_ids.update(concept_df[col].unique())
                            break
            
            # ä¿å­˜å®Œæ•´æ‚£è€…åˆ—è¡¨ç”¨äºç»Ÿè®¡ï¼ŒUIé€‰æ‹©å™¨ç”¨æˆªæ–­åˆ—è¡¨
            all_patient_ids = sorted(list(patient_ids))
            st.session_state.all_patient_count = len(all_patient_ids)  # ä¿å­˜çœŸå®æ‚£è€…æ•°
            st.session_state.patient_ids = all_patient_ids[:5000]  # UIé€‰æ‹©å™¨é™åˆ¶5000ä¸ª
            
            if lang == 'en':
                st.success(f"âœ… Loaded {len(data)} concepts, {len(all_patient_ids)} patients ({load_elapsed:.1f}s)")
            else:
                st.success(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ä¸ª Conceptsï¼Œ{len(all_patient_ids)} ä¸ªæ‚£è€… ({load_elapsed:.1f}ç§’)")
            
        except Exception as e:
            err_msg = f"Loading failed: {e}" if lang == 'en' else f"åŠ è½½å¤±è´¥: {e}"
            st.error(err_msg)


def load_data_for_preview(max_patients: int = 50):
    """Load limited data for preview visualization (memory-friendly version)."""
    lang = st.session_state.get('language', 'en')
    
    if not st.session_state.data_path:
        err_msg = "Please set data path first" if lang == 'en' else "è¯·å…ˆè®¾ç½®æ•°æ®è·¯å¾„"
        st.error(err_msg)
        return
    
    selected = st.session_state.get('selected_concepts', [])
    if not selected:
        err_msg = "Please select at least one feature" if lang == 'en' else "è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªç‰¹å¾"
        st.error(err_msg)
        return
    
    try:
        from pyricu import load_concepts
        import time
        
        load_start = time.time()
        data = {}
        
        # åªåŠ è½½å‰5ä¸ªconceptä½œä¸ºé¢„è§ˆ
        preview_concepts = selected[:5]
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šå‚ç…§ extract_baseline_features.py
        # é¢„è§ˆåªåŠ è½½å°‘é‡æ‚£è€…ï¼ˆmax_patients ä¸ªï¼‰
        patient_ids_filter = None
        id_col = 'stay_id'
        try:
            data_path = Path(st.session_state.data_path)
            database = st.session_state.get('database', 'miiv')
            id_col_map = {'miiv': 'stay_id', 'eicu': 'patientunitstayid', 'aumc': 'admissionid', 'hirid': 'patientid', 'mimic': 'icustay_id', 'sic': 'CaseID'}
            id_col = id_col_map.get(database, 'stay_id')
            
            for f in ['icustays.parquet', 'patient.parquet', 'admissions.parquet']:
                fp = data_path / f
                if fp.exists():
                    icustays_df = pd.read_parquet(fp, columns=[id_col] if id_col else None)
                    if id_col in icustays_df.columns:
                        # é¢„è§ˆåªéœ€è¦ max_patients ä¸ªæ‚£è€…
                        sample_ids = icustays_df[id_col].unique().tolist()[:max_patients]
                        patient_ids_filter = {id_col: sample_ids}
                        break
        except Exception:
            pass
        
        try:
            load_kwargs = {
                'data_path': st.session_state.data_path,
                'database': st.session_state.get('database'),
                'concepts': preview_concepts,
                'verbose': False,
                'merge': False,
                'concept_workers': 1,
                'parallel_workers': 1,  # é¢„è§ˆæ•°æ®å°‘ï¼Œä¸éœ€è¦å¹¶è¡Œ
                'parallel_backend': "thread",
            }
            if patient_ids_filter:
                load_kwargs['patient_ids'] = patient_ids_filter
            
            result = load_concepts(**load_kwargs)
            
            if isinstance(result, dict):
                for concept, df in result.items():
                    # ğŸ”§ å¤„ç†å„ç§è¿”å›ç±»å‹
                    if hasattr(df, 'to_pandas'):
                        df = df.to_pandas()
                    elif hasattr(df, 'dataframe'):
                        df = df.dataframe()
                    elif hasattr(df, 'data') and isinstance(df.data, pd.DataFrame):
                        df = df.data
                    
                    # ä¿ç•™æ‰€æœ‰ç‰¹å¾ï¼ŒåŒ…æ‹¬ç©ºDataFrameï¼ˆç¡®ä¿ç‰¹å¾æ•°é‡ä¸€è‡´ï¼‰
                    if isinstance(df, pd.DataFrame):
                        data[concept] = df
                    elif isinstance(df, pd.Series):
                        data[concept] = df.to_frame().reset_index()
            elif isinstance(result, pd.DataFrame):
                # å•æ¦‚å¿µåŠ è½½è¿”å› DataFrameï¼ˆå³ä½¿ä¸ºç©ºä¹Ÿä¿ç•™ï¼‰
                data[preview_concepts[0]] = result
        except Exception:
            # æ‰¹é‡å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªåŠ è½½
            for concept in preview_concepts:
                try:
                    df = load_concepts(
                        data_path=st.session_state.data_path,
                        database=st.session_state.get('database'),
                        concepts=[concept],
                        verbose=False,
                        merge=True,
                    )
                    if hasattr(df, 'to_pandas'):
                        df = df.to_pandas()
                    elif hasattr(df, 'dataframe'):
                        df = df.dataframe()
                    if isinstance(df, pd.DataFrame) and len(df) > 0:
                        data[concept] = df
                except Exception:
                    pass
        
        if not data:
            lang = st.session_state.get('language', 'en')
            warn_msg = "âš ï¸ Failed to load any data" if lang == 'en' else "âš ï¸ æœªèƒ½åŠ è½½ä»»ä½•æ•°æ®"
            st.warning(warn_msg)
            return
        
        # è·å–æ‚£è€…åˆ—è¡¨å¹¶é™åˆ¶æ•°é‡
        patient_ids = set()
        id_col_found = 'stay_id'
        id_candidates = ['stay_id', 'hadm_id', 'icustay_id', 
                       'patientunitstayid', 'admissionid', 'patientid']
        
        for concept_df in data.values():
            if isinstance(concept_df, pd.DataFrame):
                for col in id_candidates:
                    if col in concept_df.columns:
                        patient_ids.update(concept_df[col].unique())
                        id_col_found = col
                        break
        
        all_patient_count = len(patient_ids)
        preview_patient_ids = sorted(list(patient_ids))[:max_patients]
        
        # ç­›é€‰æ•°æ®åªä¿ç•™é™åˆ¶çš„æ‚£è€…
        filtered_data = {}
        for concept_name, df in data.items():
            if isinstance(df, pd.DataFrame) and id_col_found in df.columns:
                filtered_df = df[df[id_col_found].isin(preview_patient_ids)]
                # ä¿ç•™æ‰€æœ‰ç‰¹å¾ï¼ŒåŒ…æ‹¬ç©ºDataFrameï¼ˆç¡®ä¿ç‰¹å¾æ•°é‡ä¸€è‡´ï¼‰
                filtered_data[concept_name] = filtered_df
            else:
                # å¯¹äºæ²¡æœ‰IDåˆ—çš„DataFrameï¼ˆå¦‚é™æ€æŒ‡æ ‡ï¼‰ï¼Œç›´æ¥ä¿ç•™
                filtered_data[concept_name] = df
        
        st.session_state.loaded_concepts = filtered_data
        st.session_state.patient_ids = preview_patient_ids
        st.session_state.all_patient_count = all_patient_count
        st.session_state.id_col = id_col_found
        
        load_elapsed = time.time() - load_start
        
        # ğŸ”§ FIX (2026-02-04): ç»Ÿè®¡å”¯ä¸€æ¦‚å¿µæ•°
        unique_concept_count = count_unique_concepts(list(filtered_data.keys()))
        
        lang = st.session_state.get('language', 'en')
        if lang == 'en':
            st.success(f"âœ… Preview data loaded: {unique_concept_count} concepts ({len(filtered_data)} columns), {len(preview_patient_ids)}/{all_patient_count} patients ({load_elapsed:.1f}s)")
            if all_patient_count > max_patients:
                st.info(f"ğŸ’¡ For better performance, visualization is limited to {max_patients} patients. Export data first for full analysis with Python/R.")
        else:
            st.success(f"âœ… é¢„è§ˆæ•°æ®å·²åŠ è½½ï¼š{unique_concept_count} ä¸ªæ¦‚å¿µï¼ˆ{len(filtered_data)} åˆ—ï¼‰ï¼Œ{len(preview_patient_ids)}/{all_patient_count} ä¸ªæ‚£è€… ({load_elapsed:.1f}ç§’)")
            if all_patient_count > max_patients:
                st.info(f"ğŸ’¡ ä¸ºä¿è¯æµç•…æ€§ï¼Œå¯è§†åŒ–ä»…åŠ è½½å‰ {max_patients} ä¸ªæ‚£è€…ã€‚å»ºè®®å…ˆå¯¼å‡ºæ•°æ®ï¼Œå†ç”¨Python/Rå·¥å…·è¿›è¡Œå®Œæ•´åˆ†æã€‚")
        
    except Exception as e:
        lang = st.session_state.get('language', 'en')
        err_msg = f"Loading failed: {e}" if lang == 'en' else f"åŠ è½½å¤±è´¥: {e}"
        st.error(err_msg)


def render_data_overview():
    """æ¸²æŸ“å·²åŠ è½½æ•°æ®çš„æ¦‚è§ˆé¡µé¢ã€‚"""
    lang = st.session_state.language
    
    # æ ‡é¢˜å·²ç»åœ¨main()ä¸­æ¸²æŸ“ï¼Œè¿™é‡Œä¸å†é‡å¤
    
    # å‡†å¤‡å°±ç»ªæç¤º
    ready_title = "ğŸ‰ Ready!" if lang == 'en' else "ğŸ‰ å‡†å¤‡å°±ç»ªï¼"
    ready_desc = "Data loaded, you can start exploring." if lang == 'en' else "æ•°æ®å·²åŠ è½½ï¼Œæ‚¨å¯ä»¥å¼€å§‹æ¢ç´¢åˆ†æäº†ã€‚"
    st.markdown(f"## {ready_title}")
    st.markdown(ready_desc)
    
    # çŠ¶æ€æ¦‚è§ˆ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        db_display = "ğŸ­ DEMO" if st.session_state.get('use_mock_data', False) else st.session_state.get('database', 'N/A').upper()
        db_label = "Database" if lang == 'en' else "æ•°æ®åº“"
        st.markdown(f'''
        <div class="metric-card">
            <div class="stat-label">{db_label}</div>
            <div class="stat-number" style="font-size:1.8rem">{db_display}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col2:
        # ğŸ”§ FIX (2026-02-04): ç»Ÿè®¡å”¯ä¸€æ¦‚å¿µæ•°
        n_concepts = count_unique_concepts(list(st.session_state.loaded_concepts.keys()))
        feat_label = "Concepts" if lang == 'en' else "å·²åŠ è½½æ¦‚å¿µ"
        st.markdown(f'''
        <div class="metric-card">
            <div class="stat-label">{feat_label}</div>
            <div class="stat-number">{n_concepts}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col3:
        # ä¼˜å…ˆä»å·²åŠ è½½æ•°æ®ä¸­è®¡ç®—å®é™…æ‚£è€…æ•°
        n_patients = 0
        if st.session_state.loaded_concepts:
            # ä»åŠ è½½çš„æ•°æ®ä¸­æå–å®é™…æ‚£è€…æ•°
            all_ids = set()
            id_col = st.session_state.get('id_col', 'stay_id')
            for df in st.session_state.loaded_concepts.values():
                if isinstance(df, pd.DataFrame) and id_col in df.columns:
                    all_ids.update(df[id_col].unique())
            n_patients = len(all_ids) if all_ids else len(st.session_state.patient_ids)
        else:
            n_patients = len(st.session_state.patient_ids)
        
        pat_label = "Patients" if lang == 'en' else "æ‚£è€…æ•°é‡"
        st.markdown(f'''
        <div class="metric-card">
            <div class="stat-label">{pat_label}</div>
            <div class="stat-number">{n_patients:,}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col4:
        status_label = "Status" if lang == 'en' else "æ•°æ®çŠ¶æ€"
        st.markdown(f'''
        <div class="metric-card">
            <div class="stat-label">{status_label}</div>
            <div class="stat-number" style="color:#28a745">âœ… {"Ready" if lang == 'en' else "å°±ç»ª"}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    # å¿«æ·å¯¼èˆª
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    start_label = "ğŸš€ Start Analysis" if lang == 'en' else "ğŸš€ å¼€å§‹åˆ†æ"
    tab_hint = "Select a tab above to explore data:" if lang == 'en' else "é€‰æ‹©ä¸Šæ–¹çš„æ ‡ç­¾é¡µå¼€å§‹æ¢ç´¢æ•°æ®ï¼š"
    st.markdown(f"### {start_label}")
    st.markdown(tab_hint)
    
    if lang == 'en':
        features = [
            ("ğŸ“ˆ", "Time Series", "Interactive time series visualization, single/multi-patient comparison"),
            ("ğŸ¥", "Patient View", "Single patient multi-dimensional dashboard"),
            ("ğŸ“Š", "Data Quality", "Missing rate analysis and data distribution statistics"),
        ]
    else:
        features = [
            ("ğŸ“ˆ", "æ—¶åºåˆ†æ", "äº¤äº’å¼æ—¶é—´åºåˆ—å¯è§†åŒ–ï¼Œæ”¯æŒå•æ‚£è€…/å¤šæ‚£è€…æ¯”è¾ƒ"),
            ("ğŸ¥", "æ‚£è€…è§†å›¾", "å•æ‚£è€…å¤šç»´åº¦ä»ªè¡¨ç›˜ï¼Œå…¨æ™¯äº†è§£æ‚£è€…çŠ¶æ€"),
            ("ğŸ“Š", "æ•°æ®è´¨é‡", "ç¼ºå¤±ç‡åˆ†æä¸æ•°æ®åˆ†å¸ƒç»Ÿè®¡"),
        ]
    
    cols = st.columns(3)
    for i, (icon, title, desc) in enumerate(features):
        with cols[i]:
            st.markdown(f'''
            <div class="feature-card" style="text-align:center;min-height:160px;display:flex;flex-direction:column;justify-content:center;padding:20px">
                <div style="font-size:2.5rem">{icon}</div>
                <div style="font-weight:600;color:#4fc3f7;margin:10px 0 6px 0;font-size:1.1rem">{title}</div>
                <div style="font-size:0.95rem;color:#333;line-height:1.5">{desc}</div>
            </div>
            ''', unsafe_allow_html=True)
    
    # æ•°æ®æ‘˜è¦
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    summary_label = "ğŸ“‹ Data Summary" if lang == 'en' else "ğŸ“‹ æ•°æ®æ‘˜è¦"
    st.markdown(f"### {summary_label}")
    
    concept_stats = []
    for name, df in st.session_state.loaded_concepts.items():
        if isinstance(df, pd.DataFrame):
            n_records = len(df)
            n_pts = df[st.session_state.id_col].nunique() if st.session_state.id_col in df.columns else 0
            concept_stats.append({
                'Feature' if lang == 'en' else 'Concept': name,
                'Records' if lang == 'en' else 'è®°å½•æ•°': f"{n_records:,}",
                'Patients' if lang == 'en' else 'æ‚£è€…æ•°': n_pts,
            })
    
    if concept_stats:
        st.dataframe(pd.DataFrame(concept_stats), width="stretch", hide_index=True)


def render_home():
    """æ¸²æŸ“é¦–é¡µ - å¼•å¯¼å¼æ•™ç¨‹ï¼Œæ ¹æ®ç”¨æˆ·è¿›åº¦åŠ¨æ€æ˜¾ç¤ºã€‚"""
    lang = st.session_state.language
    
    # å¦‚æœå·²åŠ è½½æ•°æ®ï¼Œç›´æ¥æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
    if len(st.session_state.loaded_concepts) > 0:
        render_data_overview()
        return
    
    # æ ‡é¢˜å·²ç»åœ¨main()ä¸­æ¸²æŸ“ï¼Œè¿™é‡Œä¸å†é‡å¤
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # è·å–å½“å‰æ¨¡å¼ - ä½¿ç”¨app_modeï¼ˆ'extract'æˆ–'viz'ï¼‰
    current_mode = st.session_state.get('app_mode', 'extract')
    is_viz_mode = current_mode == 'viz'
    
    if is_viz_mode:
        # ============ å¿«é€Ÿå¯è§†åŒ–æ¨¡å¼æ•™ç¨‹ ============
        render_home_viz_mode(lang)
    else:
        # ============ æ•°æ®æå–å¯¼å‡ºæ¨¡å¼æ•™ç¨‹ ============
        render_home_extract_mode(lang)


def render_home_viz_mode(lang):
    """æ¸²æŸ“å¿«é€Ÿå¯è§†åŒ–æ¨¡å¼çš„é¦–é¡µæ•™ç¨‹ã€‚"""
    # è¿›åº¦æŒ‡ç¤ºå™¨
    col1, col2 = st.columns(2)
    
    # æ£€æŸ¥çŠ¶æ€
    viz_dir = st.session_state.get('viz_data_dir', '')
    has_files = False
    if viz_dir and Path(viz_dir).exists():
        files = list(Path(viz_dir).glob('*.csv')) + list(Path(viz_dir).glob('*.parquet')) + list(Path(viz_dir).glob('*.xlsx'))
        has_files = len(files) > 0
    
    step1_done = has_files
    step2_done = len(st.session_state.loaded_concepts) > 0
    
    done_text = "âœ… Done" if lang == 'en' else "âœ… å®Œæˆ"
    in_progress_text = "ğŸ”µ In Progress" if lang == 'en' else "ğŸ”µ è¿›è¡Œä¸­"
    waiting_text = "â³ Waiting" if lang == 'en' else "â³ ç­‰å¾…"
    
    with col1:
        status = done_text if step1_done else in_progress_text
        color = "#28a745" if step1_done else "#ffc107"
        step_label = "Step 1" if lang == 'en' else "æ­¥éª¤ 1"
        step_desc = "Select Data Directory" if lang == 'en' else "é€‰æ‹©æ•°æ®ç›®å½•"
        st.markdown(f'''
        <div class="metric-card" style="border-left: 4px solid {color}">
            <div class="stat-label">{step_label}</div>
            <div style="font-weight:600">{step_desc}</div>
            <div style="color:{color};font-size:0.9rem">{status}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col2:
        if step1_done:
            status = done_text if step2_done else in_progress_text
            color = "#28a745" if step2_done else "#ffc107"
        else:
            status = waiting_text
            color = "#6c757d"
        step_label = "Step 2" if lang == 'en' else "æ­¥éª¤ 2"
        step_desc = "Load & Visualize" if lang == 'en' else "åŠ è½½å¹¶å¯è§†åŒ–"
        st.markdown(f'''
        <div class="metric-card" style="border-left: 4px solid {color}">
            <div class="stat-label">{step_label}</div>
            <div style="font-weight:600">{step_desc}</div>
            <div style="color:{color};font-size:0.9rem">{status}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # æ•™ç¨‹å†…å®¹
    if not step1_done:
        task_header = "ğŸ“ Current Task: Select Data Directory" if lang == 'en' else "ğŸ“ å½“å‰ä»»åŠ¡ï¼šé€‰æ‹©æ•°æ®ç›®å½•"
        st.markdown(f"## {task_header}")
        
        if lang == 'en':
            st.markdown('''
            <div class="highlight-card">
                <h4>ğŸ‘ˆ Please specify the data directory in the left sidebar</h4>
                <p style="color:#333; margin-bottom:12px">
                    Quick Visualization mode loads data from previously exported files:
                </p>
                <ul style="color:#444; font-size:0.9rem;">
                    <li>Enter the path to the directory containing exported data files</li>
                    <li>Supported formats: <b>CSV, Parquet, Excel</b></li>
                    <li>If you haven't exported data yet, switch to "Data Extraction" mode first</li>
                </ul>
                <p style="color:#b45309; margin-top:12px;">
                    <b>ğŸ’¡ Tip:</b> Default path is <code>~/easyicu_export/miiv</code>
                </p>
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="highlight-card">
                <h4>ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ æŒ‡å®šæ•°æ®ç›®å½•</h4>
                <p style="color:#333; margin-bottom:12px">
                    å¿«é€Ÿå¯è§†åŒ–æ¨¡å¼ä»å·²å¯¼å‡ºçš„æ–‡ä»¶åŠ è½½æ•°æ®ï¼š
                </p>
                <ul style="color:#444; font-size:0.9rem;">
                    <li>è¾“å…¥åŒ…å«å·²å¯¼å‡ºæ•°æ®æ–‡ä»¶çš„ç›®å½•è·¯å¾„</li>
                    <li>æ”¯æŒçš„æ ¼å¼ï¼š<b>CSVã€Parquetã€Excel</b></li>
                    <li>å¦‚æœæ‚¨è¿˜æ²¡æœ‰å¯¼å‡ºè¿‡æ•°æ®ï¼Œè¯·å…ˆåˆ‡æ¢åˆ°ã€Œæ•°æ®æå–å¯¼å‡ºã€æ¨¡å¼</li>
                </ul>
                <p style="color:#b45309; margin-top:12px;">
                    <b>ğŸ’¡ æç¤ºï¼š</b> é»˜è®¤è·¯å¾„æ˜¯ <code>~/easyicu_export/miiv</code>
                </p>
            </div>
            ''', unsafe_allow_html=True)
    else:
        task_header = "ğŸ“ Current Task: Load Data" if lang == 'en' else "ğŸ“ å½“å‰ä»»åŠ¡ï¼šåŠ è½½æ•°æ®"
        st.markdown(f"## {task_header}")
        
        if lang == 'en':
            st.markdown('''
            <div class="highlight-card">
                <h4>ğŸ‘ˆ Click "Load Data" in the left sidebar</h4>
                <p style="color:#333; margin-bottom:12px">
                    Data files found! You can now:
                </p>
                <ul style="color:#444; font-size:0.9rem;">
                    <li>Select specific tables to load (recommended â‰¤ 3 for best performance)</li>
                    <li>Click <b>"Load Data"</b> button to load into memory</li>
                    <li>After loading, use the tabs above to explore and visualize</li>
                </ul>
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="highlight-card">
                <h4>ğŸ‘ˆ åœ¨å·¦ä¾§è¾¹æ ç‚¹å‡»ã€ŒåŠ è½½æ•°æ®ã€</h4>
                <p style="color:#333; margin-bottom:12px">
                    å·²å‘ç°æ•°æ®æ–‡ä»¶ï¼æ‚¨ç°åœ¨å¯ä»¥ï¼š
                </p>
                <ul style="color:#444; font-size:0.9rem;">
                    <li>é€‰æ‹©è¦åŠ è½½çš„è¡¨æ ¼ï¼ˆå»ºè®®ä¸è¶…è¿‡3ä¸ªä»¥ä¿è¯æµç•…æ€§ï¼‰</li>
                    <li>ç‚¹å‡» <b>ã€ŒåŠ è½½æ•°æ®ã€</b> æŒ‰é’®å°†æ•°æ®åŠ è½½åˆ°å†…å­˜</li>
                    <li>åŠ è½½å®Œæˆåï¼Œä½¿ç”¨ä¸Šæ–¹çš„æ ‡ç­¾é¡µè¿›è¡Œæ¢ç´¢å’Œå¯è§†åŒ–</li>
                </ul>
            </div>
            ''', unsafe_allow_html=True)
    
    # åŠŸèƒ½é¢„è§ˆ
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    preview_title = "ğŸ¯ What You Can Do After Loading" if lang == 'en' else "ğŸ¯ åŠ è½½åå¯ç”¨åŠŸèƒ½"
    st.markdown(f"### {preview_title}")
    
    if lang == 'en':
        features = [
            ("ï¿½", "Data Tables", "Browse and merge features"),
            ("ğŸ“ˆ", "Time Series", "Interactive visualization"),
            ("ğŸ¥", "Patient View", "Patient dashboard"),
            ("ğŸ“Š", "Data Quality", "Missing rate analysis"),
        ]
    else:
        features = [
            ("ğŸ“‹", "æ•°æ®å¤§è¡¨", "æµè§ˆä¸åˆå¹¶ç‰¹å¾"),
            ("ğŸ“ˆ", "æ—¶åºåˆ†æ", "äº¤äº’å¼å¯è§†åŒ–"),
            ("ğŸ¥", "æ‚£è€…è§†å›¾", "æ‚£è€…ä»ªè¡¨ç›˜"),
            ("ğŸ“Š", "æ•°æ®è´¨é‡", "ç¼ºå¤±ç‡åˆ†æ"),
        ]
    
    cols = st.columns(4)
    for i, (icon, title, desc) in enumerate(features):
        with cols[i]:
            st.markdown(f'''
            <div class="feature-card" style="text-align:center;min-height:160px;display:flex;flex-direction:column;justify-content:center;padding:20px">
                <div style="font-size:2.5rem">{icon}</div>
                <div style="font-weight:600;color:#4fc3f7;margin:10px 0 6px 0;font-size:1.1rem">{title}</div>
                <div style="font-size:0.95rem;color:#333;line-height:1.5">{desc}</div>
            </div>
            ''', unsafe_allow_html=True)


def render_home_extract_mode(lang):
    """æ¸²æŸ“æ•°æ®æå–å¯¼å‡ºæ¨¡å¼çš„é¦–é¡µæ•™ç¨‹ã€‚"""
    
    # è®¡ç®—å½“å‰æ­¥éª¤å®ŒæˆçŠ¶æ€ï¼ˆ4ä¸ªæ­¥éª¤ï¼‰
    # Step 1: Demoæ¨¡å¼éœ€è¦ç‚¹å‡»ConfirmæŒ‰é’®ï¼ŒReal Dataæ¨¡å¼éœ€è¦æœ‰æ•ˆè·¯å¾„
    if st.session_state.get('use_mock_data', False):
        step1_done = st.session_state.get('step1_confirmed', False)
    else:
        step1_done = st.session_state.data_path and Path(st.session_state.data_path).exists()
    step2_done = st.session_state.get('step2_confirmed', False)
    # ğŸ”§ FIX (2026-02-05): Step 3 å¿…é¡»ç‚¹å‡»ç¡®è®¤æŒ‰é’®åæ‰ç®—å®Œæˆ
    step3_done = st.session_state.get('step3_confirmed', False) and len(st.session_state.get('selected_concepts', [])) > 0
    # Step 4 åªåœ¨çœŸæ­£å¯¼å‡ºå®Œæˆåæ‰ç®—å®Œæˆ
    step4_done = st.session_state.get('export_completed', False)
    
    # ============ è¿›åº¦æŒ‡ç¤ºå™¨ ============
    # æ·»åŠ é”šç‚¹å’Œå¤§æ ‡é¢˜
    st.markdown('<div id="progress"></div>', unsafe_allow_html=True)
    progress_title = "ğŸ“‹ Progress" if lang == 'en' else "ğŸ“‹ è¿›åº¦"
    st.markdown(f'<h2 style="background:linear-gradient(135deg,#667eea,#764ba2);-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text;border-bottom:3px solid #667eea;padding-bottom:10px;margin-top:10px;font-size:1.8rem;">{progress_title}</h2>', unsafe_allow_html=True)
    
    # ğŸ†• æ·»åŠ è¯´æ˜æ–‡å­—
    if lang == 'en':
        progress_desc = """
        <div style="font-size: 1.15rem; color: #333; margin-bottom: 20px; line-height: 1.6;">
            ğŸ‘ˆ <b>Simply click through the left sidebar</b> to complete the 4 steps below. 
            You'll easily define your ICU cohort, select features, and extract data!
        </div>
        """
    else:
        progress_desc = """
        <div style="font-size: 1.15rem; color: #333; margin-bottom: 20px; line-height: 1.6;">
            ğŸ‘ˆ <b>åªéœ€é€šè¿‡å·¦ä¾§è¾¹æ ç‚¹å‡»</b>ï¼Œå®Œæˆä¸‹é¢çš„4ä¸ªæ­¥éª¤ï¼Œ
            å³å¯è½»æ¾å®ŒæˆICUæ•°æ®çš„é˜Ÿåˆ—å®šä¹‰ã€ç‰¹å¾é€‰æ‹©å’Œæ•°æ®æå–ï¼
        </div>
        """
    st.markdown(progress_desc, unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    # çŠ¶æ€æ–‡æœ¬
    done_text = "âœ… Done" if lang == 'en' else "âœ… å®Œæˆ"
    in_progress_text = "ğŸ”µ In Progress" if lang == 'en' else "ğŸ”µ è¿›è¡Œä¸­"
    waiting_text = "â³ Waiting" if lang == 'en' else "â³ ç­‰å¾…"
    
    with col1:
        status = done_text if step1_done else in_progress_text
        color = "#28a745" if step1_done else "#ffc107"
        step_label = "Step 1" if lang == 'en' else "æ­¥éª¤ 1"
        step_desc = "Data Source" if lang == 'en' else "é…ç½®æ•°æ®æº"
        st.markdown(f'''
        <div class="metric-card" style="border-left: 4px solid {color}">
            <div class="stat-label">{step_label}</div>
            <div style="font-weight:600">{step_desc}</div>
            <div style="color:{color};font-size:0.9rem">{status}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col2:
        if step1_done:
            status = done_text if step2_done else in_progress_text
            color = "#28a745" if step2_done else "#ffc107"
        else:
            status = waiting_text
            color = "#6c757d"
        step_label = "Step 2" if lang == 'en' else "æ­¥éª¤ 2"
        step_desc = "Cohort Selection" if lang == 'en' else "é˜Ÿåˆ—ç­›é€‰"
        st.markdown(f'''
        <div class="metric-card" style="border-left: 4px solid {color}">
            <div class="stat-label">{step_label}</div>
            <div style="font-weight:600">{step_desc}</div>
            <div style="color:{color};font-size:0.9rem">{status}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col3:
        if step1_done and step2_done:
            status = done_text if step3_done else in_progress_text
            color = "#28a745" if step3_done else "#ffc107"
        else:
            status = waiting_text
            color = "#6c757d"
        step_label = "Step 3" if lang == 'en' else "æ­¥éª¤ 3"
        step_desc = "Select Features" if lang == 'en' else "é€‰æ‹©ç‰¹å¾"
        st.markdown(f'''
        <div class="metric-card" style="border-left: 4px solid {color}">
            <div class="stat-label">{step_label}</div>
            <div style="font-weight:600">{step_desc}</div>
            <div style="color:{color};font-size:0.9rem">{status}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col4:
        if step1_done and step2_done and step3_done:
            status = done_text if step4_done else in_progress_text
            color = "#28a745" if step4_done else "#ffc107"
        else:
            status = waiting_text
            color = "#6c757d"
        step_label = "Step 4" if lang == 'en' else "æ­¥éª¤ 4"
        step_desc = "Export Data" if lang == 'en' else "å¯¼å‡ºæ•°æ®"
        st.markdown(f'''
        <div class="metric-card" style="border-left: 4px solid {color}">
            <div class="stat-label">{step_label}</div>
            <div style="font-weight:600">{step_desc}</div>
            <div style="color:{color};font-size:0.9rem">{status}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # ============ åŠ¨æ€å¼•å¯¼å†…å®¹ ============
    # æ·»åŠ å¼•å¯¼é”šç‚¹å’ŒåŠ¨æ€æ ‡é¢˜ï¼ˆæ ¹æ®å½“å‰æ­¥éª¤å˜åŒ–ï¼‰
    st.markdown('<div id="guide"></div>', unsafe_allow_html=True)
    
    # ğŸ†• åŠ¨æ€Guideæ ‡é¢˜ï¼Œæ ¹æ®Progressè‡ªåŠ¨è½¬æ¢
    if not step1_done:
        guide_step = "Data Source" if lang == 'en' else "æ•°æ®æºé…ç½®"
    elif not step2_done:
        guide_step = "Cohort Selection" if lang == 'en' else "é˜Ÿåˆ—ç­›é€‰"
    elif not step3_done:
        guide_step = "Select Features" if lang == 'en' else "ç‰¹å¾é€‰æ‹©"
    elif not step4_done:
        guide_step = "Export Data" if lang == 'en' else "æ•°æ®å¯¼å‡º"
    else:
        guide_step = "Complete" if lang == 'en' else "å®Œæˆ"
    
    guide_title = f"ğŸ“ Guide: {guide_step}" if lang == 'en' else f"ğŸ“ å¼•å¯¼: {guide_step}"
    st.markdown(f'<h2 style="background:linear-gradient(135deg,#667eea,#764ba2);-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text;border-bottom:3px solid #667eea;padding-bottom:10px;margin-top:10px;font-size:1.8rem;">{guide_title}</h2>', unsafe_allow_html=True)
    
    if not step1_done:
        # æ­¥éª¤1å¼•å¯¼ï¼šé…ç½®æ•°æ®æº
        if lang == 'en':
            st.markdown('''
            <div class="highlight-card" style="font-size: 1.1rem; line-height: 1.8;">
                <h3 style="color: #667eea; margin-bottom: 15px;">ğŸ‘ˆ Configure Data Source in the Left Sidebar</h3>
                <p style="margin-bottom: 15px;">Choose one of the following modes to get started:</p>
                <div style="background: rgba(16, 185, 129, 0.1); padding: 15px; border-radius: 10px; margin-bottom: 15px;">
                    <h4 style="color: #10b981;">ğŸ­ Demo Mode (Recommended for First-time Users)</h4>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>No real data required - system generates realistic simulated ICU data</li>
                        <li>Perfect for learning how EasyICU works</li>
                        <li>Adjust patient count (50-500) and data duration (24-168 hours)</li>
                        <li>Click <b>"âœ… Confirm Data Source"</b> when ready</li>
                    </ul>
                </div>
                <div style="background: rgba(59, 130, 246, 0.1); padding: 15px; border-radius: 10px;">
                    <h4 style="color: #3b82f6;">ğŸ“Š Real Data Mode (For Research)</h4>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>Supports MIMIC-IV, eICU, AUMC, HiRID, MIMIC-III, SICdb</li>
                        <li>Enter your local database path</li>
                        <li>Click "Validate Path" to verify data format</li>
                        <li>All processing is done locally - your data stays secure ğŸ”’</li>
                    </ul>
                </div>
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="highlight-card" style="font-size: 1.1rem; line-height: 1.8;">
                <h3 style="color: #667eea; margin-bottom: 15px;">ğŸ‘ˆ åœ¨å·¦ä¾§è¾¹æ é…ç½®æ•°æ®æº</h3>
                <p style="margin-bottom: 15px;">é€‰æ‹©ä»¥ä¸‹ä»»ä¸€æ¨¡å¼å¼€å§‹ä½¿ç”¨ï¼š</p>
                <div style="background: rgba(16, 185, 129, 0.1); padding: 15px; border-radius: 10px; margin-bottom: 15px;">
                    <h4 style="color: #10b981;">ğŸ­ æ¼”ç¤ºæ¨¡å¼ï¼ˆæ¨èæ–°ç”¨æˆ·ä½¿ç”¨ï¼‰</h4>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>æ— éœ€çœŸå®æ•°æ® - ç³»ç»Ÿä¼šç”Ÿæˆé€¼çœŸçš„æ¨¡æ‹ŸICUæ•°æ®</li>
                        <li>éå¸¸é€‚åˆå­¦ä¹ EasyICUçš„å·¥ä½œæ–¹å¼</li>
                        <li>å¯è°ƒæ•´æ‚£è€…æ•°é‡ï¼ˆ50-500ï¼‰å’Œæ•°æ®æ—¶é•¿ï¼ˆ24-168å°æ—¶ï¼‰</li>
                        <li>è®¾ç½®å®Œæˆåç‚¹å‡» <b>"âœ… ç¡®è®¤æ•°æ®æºé…ç½®"</b></li>
                    </ul>
                </div>
                <div style="background: rgba(59, 130, 246, 0.1); padding: 15px; border-radius: 10px;">
                    <h4 style="color: #3b82f6;">ğŸ“Š çœŸå®æ•°æ®æ¨¡å¼ï¼ˆç”¨äºç§‘ç ”ï¼‰</h4>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>æ”¯æŒ MIMIC-IVã€eICUã€AUMCã€HiRIDã€MIMIC-IIIã€SICdb</li>
                        <li>è¾“å…¥æ‚¨æœ¬åœ°çš„æ•°æ®åº“è·¯å¾„</li>
                        <li>ç‚¹å‡»"éªŒè¯è·¯å¾„"ç¡®è®¤æ•°æ®æ ¼å¼</li>
                        <li>æ‰€æœ‰å¤„ç†éƒ½åœ¨æœ¬åœ°å®Œæˆ - æ‚¨çš„æ•°æ®å®‰å…¨æ— å¿§ ğŸ”’</li>
                    </ul>
                </div>
            </div>
            ''', unsafe_allow_html=True)
        
    elif not step2_done:
        # æ­¥éª¤2å¼•å¯¼ï¼šé˜Ÿåˆ—ç­›é€‰
        if lang == 'en':
            st.markdown('''
            <div class="highlight-card" style="font-size: 1.1rem; line-height: 1.8;">
                <h3 style="color: #667eea; margin-bottom: 15px;">ğŸ‘ˆ Configure Cohort Selection in the Left Sidebar</h3>
                <p style="margin-bottom: 15px;">Define your study cohort by filtering patients:</p>
                <div style="background: rgba(99, 102, 241, 0.1); padding: 15px; border-radius: 10px; margin-bottom: 15px;">
                    <h4 style="color: #6366f1;">ğŸ”§ Available Filters</h4>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li><b>Age Range</b> - Filter patients by age (e.g., 18-65 years)</li>
                        <li><b>Gender</b> - Select Male, Female, or Any</li>
                        <li><b>Survival Status</b> - Include survivors, non-survivors, or all</li>
                        <li><b>ICU Stay Duration</b> - Minimum length of stay in hours</li>
                    </ul>
                </div>
                <div style="background: rgba(16, 185, 129, 0.1); padding: 15px; border-radius: 10px;">
                    <h4 style="color: #10b981;">ğŸ’¡ Tips</h4>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>Enable "Cohort Filtering" toggle to activate filters</li>
                        <li>You can skip this step by clicking <b>"âœ… Confirm (No Filtering)"</b></li>
                        <li>Filters will be applied when generating/loading data</li>
                    </ul>
                </div>
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="highlight-card" style="font-size: 1.1rem; line-height: 1.8;">
                <h3 style="color: #667eea; margin-bottom: 15px;">ğŸ‘ˆ åœ¨å·¦ä¾§è¾¹æ é…ç½®é˜Ÿåˆ—ç­›é€‰</h3>
                <p style="margin-bottom: 15px;">é€šè¿‡ç­›é€‰æ‚£è€…æ¥å®šä¹‰æ‚¨çš„ç ”ç©¶é˜Ÿåˆ—ï¼š</p>
                <div style="background: rgba(99, 102, 241, 0.1); padding: 15px; border-radius: 10px; margin-bottom: 15px;">
                    <h4 style="color: #6366f1;">ğŸ”§ å¯ç”¨çš„ç­›é€‰æ¡ä»¶</h4>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li><b>å¹´é¾„èŒƒå›´</b> - æŒ‰å¹´é¾„ç­›é€‰æ‚£è€…ï¼ˆå¦‚ 18-65 å²ï¼‰</li>
                        <li><b>æ€§åˆ«</b> - é€‰æ‹©ç”·æ€§ã€å¥³æ€§æˆ–ä¸é™</li>
                        <li><b>å­˜æ´»çŠ¶æ€</b> - åŒ…å«å­˜æ´»è€…ã€æ­»äº¡è€…æˆ–å…¨éƒ¨</li>
                        <li><b>ICUä½é™¢æ—¶é•¿</b> - æœ€çŸ­ä½é™¢æ—¶é•¿ï¼ˆå°æ—¶ï¼‰</li>
                    </ul>
                </div>
                <div style="background: rgba(16, 185, 129, 0.1); padding: 15px; border-radius: 10px;">
                    <h4 style="color: #10b981;">ğŸ’¡ æç¤º</h4>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>å¯ç”¨"é˜Ÿåˆ—ç­›é€‰"å¼€å…³æ¥æ¿€æ´»ç­›é€‰åŠŸèƒ½</li>
                        <li>å¯ä»¥ç‚¹å‡» <b>"âœ… ç¡®è®¤ï¼ˆä¸ç­›é€‰ï¼‰"</b> è·³è¿‡æ­¤æ­¥éª¤</li>
                        <li>ç­›é€‰æ¡ä»¶å°†åœ¨ç”Ÿæˆ/åŠ è½½æ•°æ®æ—¶åº”ç”¨</li>
                    </ul>
                </div>
            </div>
            ''', unsafe_allow_html=True)
        
    elif not step3_done:
        # æ­¥éª¤3å¼•å¯¼ï¼šé€‰æ‹©ç‰¹å¾
        if lang == 'en':
            st.markdown('''
            <div class="highlight-card" style="font-size: 1.1rem; line-height: 1.8;">
                <h3 style="color: #0369a1; margin-bottom: 15px;">ğŸ‘ˆ Select Features in the Left Sidebar</h3>
                <p style="margin-bottom: 15px;">EasyICU provides <b>168 comprehensive ICU clinical features</b> across 19 categories, covering:</p>
                <div style="display: flex; gap: 20px; flex-wrap: wrap; margin-bottom: 15px;">
                    <div style="flex: 1; min-width: 200px; background: rgba(59, 130, 246, 0.15); padding: 12px; border-radius: 8px;">
                        <b style="color: #1d4ed8;">ğŸ“Š Vital Signs</b>
                        <p style="color: #1e40af; margin-top: 5px; font-size: 0.95rem;">Heart rate, blood pressure, temperature, SpO2, respiratory rate</p>
                    </div>
                    <div style="flex: 1; min-width: 200px; background: rgba(16, 185, 129, 0.15); padding: 12px; border-radius: 8px;">
                        <b style="color: #047857;">ğŸ§ª Laboratory Tests</b>
                        <p style="color: #065f46; margin-top: 5px; font-size: 0.95rem;">Blood chemistry, hematology, coagulation, blood gas analysis</p>
                    </div>
                    <div style="flex: 1; min-width: 200px; background: rgba(251, 191, 36, 0.15); padding: 12px; border-radius: 8px;">
                        <b style="color: #b45309;">ğŸ’Š Medications</b>
                        <p style="color: #92400e; margin-top: 5px; font-size: 0.95rem;">Vasopressors, sedatives, antibiotics, fluid therapy</p>
                    </div>
                    <div style="flex: 1; min-width: 200px; background: rgba(139, 92, 246, 0.15); padding: 12px; border-radius: 8px;">
                        <b style="color: #6d28d9;">ğŸ¥ Clinical Scores</b>
                        <p style="color: #5b21b6; margin-top: 5px; font-size: 0.95rem;">SOFA, GCS, urine output, organ failure indicators</p>
                    </div>
                </div>
                <div style="background: rgba(251, 191, 36, 0.2); padding: 15px; border-radius: 10px; margin-bottom: 15px;">
                    <h4 style="color: #b45309;">ğŸ”¥ Quick Selection Methods</h4>
                    <ul style="margin-left: 20px; margin-top: 10px; color: #78350f;">
                        <li><b>By Category</b> - Expand a group and select entire group or individual features</li>
                        <li><b>Custom</b> - Mix and match based on your research needs</li>
                    </ul>
                </div>
                <div style="background: rgba(139, 92, 246, 0.2); padding: 15px; border-radius: 10px;">
                    <h4 style="color: #6d28d9;">ğŸ“– Need Help Choosing?</h4>
                    <p style="margin-top: 10px; color: #5b21b6;">
                        ğŸ‘‡ Check the <b>Data Dictionary</b> below for detailed descriptions of each feature!
                    </p>
                </div>
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="highlight-card" style="font-size: 1.1rem; line-height: 1.8;">
                <h3 style="color: #0369a1; margin-bottom: 15px;">ğŸ‘ˆ åœ¨å·¦ä¾§è¾¹æ é€‰æ‹©ç‰¹å¾</h3>
                <p style="margin-bottom: 15px;">EasyICU æä¾› <b>168 ä¸ª ICU ä¸´åºŠç‰¹å¾</b>ï¼ˆ19 ä¸ªç±»åˆ«ï¼‰ï¼Œæ¶µç›–ï¼š</p>
                <div style="display: flex; gap: 20px; flex-wrap: wrap; margin-bottom: 15px;">
                    <div style="flex: 1; min-width: 200px; background: rgba(59, 130, 246, 0.15); padding: 12px; border-radius: 8px;">
                        <b style="color: #1d4ed8;">ğŸ“Š ç”Ÿå‘½ä½“å¾</b>
                        <p style="color: #1e40af; margin-top: 5px; font-size: 0.95rem;">å¿ƒç‡ã€è¡€å‹ã€ä½“æ¸©ã€è¡€æ°§é¥±å’Œåº¦ã€å‘¼å¸é¢‘ç‡</p>
                    </div>
                    <div style="flex: 1; min-width: 200px; background: rgba(16, 185, 129, 0.15); padding: 12px; border-radius: 8px;">
                        <b style="color: #047857;">ğŸ§ª å®éªŒå®¤æ£€éªŒ</b>
                        <p style="color: #065f46; margin-top: 5px; font-size: 0.95rem;">è¡€ç”ŸåŒ–ã€è¡€å¸¸è§„ã€å‡è¡€åŠŸèƒ½ã€è¡€æ°”åˆ†æ</p>
                    </div>
                    <div style="flex: 1; min-width: 200px; background: rgba(251, 191, 36, 0.15); padding: 12px; border-radius: 8px;">
                        <b style="color: #b45309;">ğŸ’Š è¯ç‰©æ²»ç–—</b>
                        <p style="color: #92400e; margin-top: 5px; font-size: 0.95rem;">è¡€ç®¡æ´»æ€§è¯ã€é•‡é™è¯ã€æŠ—ç”Ÿç´ ã€æ¶²ä½“æ²»ç–—</p>
                    </div>
                    <div style="flex: 1; min-width: 200px; background: rgba(139, 92, 246, 0.15); padding: 12px; border-radius: 8px;">
                        <b style="color: #6d28d9;">ğŸ¥ ä¸´åºŠè¯„åˆ†</b>
                        <p style="color: #5b21b6; margin-top: 5px; font-size: 0.95rem;">SOFA è¯„åˆ†ã€GCS è¯„åˆ†ã€å°¿é‡ã€å™¨å®˜è¡°ç«­æŒ‡æ ‡</p>
                    </div>
                </div>
                <div style="background: rgba(251, 191, 36, 0.2); padding: 15px; border-radius: 10px; margin-bottom: 15px;">
                    <h4 style="color: #b45309;">ğŸ”¥ å¿«é€Ÿé€‰æ‹©æ–¹æ³•</h4>
                    <ul style="margin-left: 20px; margin-top: 10px; color: #78350f;">
                        <li><b>æŒ‰ç±»åˆ«</b> - å±•å¼€æŸä¸ªåˆ†ç»„ï¼Œé€‰æ‹©æ•´ç»„æˆ–å•ä¸ªç‰¹å¾</li>
                        <li><b>è‡ªå®šä¹‰</b> - æ ¹æ®ç ”ç©¶éœ€æ±‚è‡ªç”±ç»„åˆ</li>
                    </ul>
                </div>
                <div style="background: rgba(139, 92, 246, 0.2); padding: 15px; border-radius: 10px;">
                    <h4 style="color: #6d28d9;">ğŸ“– ä¸çŸ¥é“è¯¥é€‰ä»€ä¹ˆï¼Ÿ</h4>
                    <p style="margin-top: 10px; color: #5b21b6;">
                        ğŸ‘‡ æŸ¥çœ‹ä¸‹æ–¹çš„ <b>æ•°æ®å­—å…¸</b>ï¼Œäº†è§£æ¯ä¸ªç‰¹å¾çš„è¯¦ç»†æè¿°ï¼
                    </p>
                </div>
            </div>
            ''', unsafe_allow_html=True)
        
    elif not step4_done:
        # Step 4 Guide: Export Data
        # ğŸ†• æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¯¼å‡ºæˆ–åˆšå®Œæˆå¯¼å‡º
        exporting_in_progress = st.session_state.get('_exporting_in_progress', False)
        
        if exporting_in_progress:
            # ğŸ†• å¯¼å‡ºæ­£åœ¨è¿›è¡Œä¸­ï¼Œæ˜¾ç¤ºè¿›åº¦æ ‡é¢˜
            if lang == 'en':
                st.markdown('''<div class="highlight-card" style="border-left: 4px solid #ff9800; background: linear-gradient(135deg, #fff8e1 0%, #ffffff 100%);">
<h3 style="color: #ff9800; margin-bottom: 10px;">â³ Export in Progress...</h3>
<p style="color: #555; margin: 0; font-size: 1.1rem;">Please wait while your data is being exported. Progress details will appear below.</p>
</div>''', unsafe_allow_html=True)
            else:
                st.markdown('''<div class="highlight-card" style="border-left: 4px solid #ff9800; background: linear-gradient(135deg, #fff8e1 0%, #ffffff 100%);">
<h3 style="color: #ff9800; margin-bottom: 10px;">â³ å¯¼å‡ºè¿›è¡Œä¸­...</h3>
<p style="color: #555; margin: 0; font-size: 1.1rem;">è¯·ç¨å€™ï¼Œæ•°æ®æ­£åœ¨å¯¼å‡ºä¸­ã€‚è¿›åº¦è¯¦æƒ…å°†æ˜¾ç¤ºåœ¨ä¸‹æ–¹ã€‚</p>
</div>''', unsafe_allow_html=True)
        else:
            # æ˜¾ç¤ºå¯¼å‡ºæ•™ç¨‹
            if lang == 'en':
                export_guide_html = '''<div class="highlight-card" style="border-left: 4px solid #28a745;">
<h3 style="color: #28a745; margin-bottom: 15px;">ğŸ“¥ How to Export Data</h3>
<div style="display: flex; gap: 25px; flex-wrap: wrap;">
<div style="flex: 1; min-width: 280px;">
<ol style="color: #1a1a1a; font-size: 1.1rem; line-height: 1.8;">
<li>Go to <b>"Data Export"</b> tab above</li>
<li>Select export format (CSV/Parquet/Excel)</li>
<li>Choose save location</li>
<li>Click <b>"Export Data"</b> button</li>
</ol>
<p style="color: #28a745; margin-top: 10px; font-size: 1rem;">âœ… Best for large datasets - saves directly to disk without loading to memory</p>
</div>
</div>
</div>'''
                st.markdown(export_guide_html, unsafe_allow_html=True)
            else:
                export_guide_html = '''<div class="highlight-card" style="border-left: 4px solid #28a745;">
<h3 style="color: #28a745; margin-bottom: 15px;">ğŸ“¥ å¦‚ä½•å¯¼å‡ºæ•°æ®</h3>
<div style="display: flex; gap: 25px; flex-wrap: wrap;">
<div style="flex: 1; min-width: 280px;">
<ol style="color: #1a1a1a; font-size: 1.1rem; line-height: 1.8;">
<li>ç‚¹å‡»ä¸Šæ–¹ <b>"æ•°æ®å¯¼å‡º"</b> æ ‡ç­¾é¡µ</li>
<li>é€‰æ‹©å¯¼å‡ºæ ¼å¼ï¼ˆCSV/Parquet/Excelï¼‰</li>
<li>é€‰æ‹©ä¿å­˜ä½ç½®</li>
<li>ç‚¹å‡» <b>"å¯¼å‡ºæ•°æ®"</b> æŒ‰é’®</li>
</ol>
<p style="color: #28a745; margin-top: 10px; font-size: 1rem;">âœ… é€‚åˆå¤§æ•°æ®é›† - ç›´æ¥ä¿å­˜åˆ°ç£ç›˜ï¼Œä¸å ç”¨å†…å­˜</p>
</div>
<div style="flex: 1; min-width: 280px;">
<ol style="color: #1a1a1a; font-size: 1.1rem; line-height: 1.8;">
<li>ç‚¹å‡»ä¸Šæ–¹ <b>"æ•°æ®å¯¼å‡º"</b> æ ‡ç­¾é¡µ</li>
<li>é€‰æ‹©å¯¼å‡ºæ ¼å¼ï¼ˆCSV/Parquet/Excelï¼‰</li>
<li>é€‰æ‹©ä¿å­˜ä½ç½®</li>
<li>ç‚¹å‡» <b>"å¯¼å‡ºæ•°æ®"</b> æŒ‰é’®</li>
</ol>
<p style="color: #28a745; margin-top: 10px; font-size: 1rem;">âœ… é€‚åˆå¤§æ•°æ®é›† - ç›´æ¥ä¿å­˜åˆ°ç£ç›˜ï¼Œä¸å ç”¨å†…å­˜</p>
</div>
</div>
</div>'''
                st.markdown(export_guide_html, unsafe_allow_html=True)
            
            # æ˜¾ç¤ºå½“å‰é€‰æ‹©æ‘˜è¦
            selected = st.session_state.get('selected_concepts', [])
            if st.session_state.get('use_mock_data', False):
                source_info = "ğŸ­ Demo Mode" if lang == 'en' else "ğŸ­ æ¼”ç¤ºæ¨¡å¼"
            else:
                source_info = f"ğŸ“Š {st.session_state.get('data_path', '')}"
            
            source_label = "Data Source" if lang == 'en' else "æ•°æ®æº"
            feat_label = "Selected Features" if lang == 'en' else "å·²é€‰ç‰¹å¾"
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f'''
                <div class="metric-card">
                    <div class="stat-label">{source_label}</div>
                    <div style="font-weight:600">{source_info}</div>
                </div>
                ''', unsafe_allow_html=True)
            with col2:
                st.markdown(f'''
                <div class="metric-card">
                    <div class="stat-label">{feat_label}</div>
                    <div class="stat-number">{len(selected)}</div>
                </div>
                ''', unsafe_allow_html=True)
        
        # ğŸ†• å¯¼å‡ºè¿›åº¦åŒºåŸŸï¼ˆæ— è®ºæ˜¯å¦æ­£åœ¨å¯¼å‡ºéƒ½åˆ›å»ºï¼Œå¯¼å‡ºæ—¶å†…å®¹ä¼šå¡«å……è¿›æ¥ï¼‰
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        export_section = st.container()
        st.session_state['_export_progress_container'] = export_section
    
    else:
        # æ‰€æœ‰æ­¥éª¤å®Œæˆ - Guide: Complete
        
        # ğŸ†• é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰åˆšå®Œæˆçš„å¯¼å‡ºç»“æœè¦æ˜¾ç¤º
        export_result = st.session_state.get('_export_success_result')
        if export_result:
            # æ˜¾ç¤ºå¯¼å‡ºæˆåŠŸæ¶ˆæ¯
            exported_files = export_result['files']
            export_dir = export_result['export_dir']
            total_elapsed = export_result['total_time']
            module_times = export_result.get('module_times', {})
            # ğŸ”§ FIX (2026-02-04): ä½¿ç”¨ä¿å­˜çš„æ¦‚å¿µæ•°
            concept_count = export_result.get('concept_count', len(exported_files))
            
            success_msg = f"âœ… Successfully exported {len(exported_files)} files to `{export_dir}`" if lang == 'en' else f"âœ… æˆåŠŸå¯¼å‡º {concept_count} ä¸ªæ¦‚å¿µï¼ˆ{len(exported_files)} ä¸ªæ–‡ä»¶ï¼‰åˆ° `{export_dir}`"
            st.success(success_msg)
            
            # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
            time_stats_title = "â±ï¸ Export Time Statistics" if lang == 'en' else "â±ï¸ å¯¼å‡ºè€—æ—¶ç»Ÿè®¡"
            with st.expander(time_stats_title, expanded=False):
                for mod_name, mod_time in module_times.items():
                    if mod_time >= 60:
                        time_str = f"{mod_time/60:.1f} min"
                    else:
                        time_str = f"{mod_time:.1f} s"
                    st.text(f"  â€¢ {mod_name}: {time_str}")
                
                if total_elapsed >= 60:
                    total_str = f"{total_elapsed/60:.1f} min"
                else:
                    total_str = f"{total_elapsed:.1f} s"
                total_msg = f"**Total: {total_str}**" if lang == 'en' else f"**æ€»è®¡: {total_str}**"
                st.markdown(total_msg)
            
            # æ˜¾ç¤ºå¯¼å‡ºçš„æ–‡ä»¶åˆ—è¡¨
            view_files_label = "ğŸ“ View Exported Files" if lang == 'en' else "ğŸ“ æŸ¥çœ‹å¯¼å‡ºæ–‡ä»¶"
            with st.expander(view_files_label, expanded=True):
                # ä½¿ç”¨å¤šåˆ—å¸ƒå±€æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                files_to_show = exported_files[:12]  # æœ€å¤šæ˜¾ç¤º12ä¸ª
                num_cols = 3  # æ¯è¡Œ3ä¸ªæ–‡ä»¶
                for i in range(0, len(files_to_show), num_cols):
                    cols = st.columns(num_cols)
                    for j, col in enumerate(cols):
                        idx = i + j
                        if idx < len(files_to_show):
                            with col:
                                st.markdown(f"<p style='color: #1e1e1e; font-size: 0.9rem; margin: 2px 0;'>â€¢ {Path(files_to_show[idx]).name}</p>", unsafe_allow_html=True)
                if len(exported_files) > 12:
                    more_msg = f"... and {len(exported_files) - 12} more files" if lang == 'en' else f"... åŠå…¶ä»– {len(exported_files) - 12} ä¸ªæ–‡ä»¶"
                    st.markdown(f"<p style='color: #1e1e1e; font-size: 0.9rem; margin: 2px 0;'>{more_msg}</p>", unsafe_allow_html=True)
            
            # ğŸ†• æ˜¾ç¤ºè¢«é€‰æ‹©ä½†æœªèƒ½æå–çš„ç‰¹å¾ï¼ˆè¿™æ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸æ˜¯é”™è¯¯ï¼‰
            unavailable_concepts = export_result.get('unavailable_concepts', [])
            if unavailable_concepts:
                # ğŸ”§ æ˜¾ç¤ºæ‰€æœ‰ä¸å¯ç”¨çš„ç‰¹å¾ï¼Œä½¿ç”¨æ¢è¡Œåˆ†éš”
                concepts_formatted = '<br>'.join([', '.join(unavailable_concepts[i:i+8]) for i in range(0, len(unavailable_concepts), 8)])
                if lang == 'en':
                    unavailable_msg = f"""<div class="info-box" style="margin-top: 15px;">
<p style="margin-bottom: 10px;"><b>{len(unavailable_concepts)} selected features</b> were not extracted because they are not available in this database:</p>
<p style="color: #64748b; font-size: 0.95rem; line-height: 1.8;">{concepts_formatted}</p>
<p style="margin-top: 10px; font-size: 0.9rem; color: #6b7280;">ğŸ’¡ <i>This is normal â€” not all features are available across all ICU databases.</i></p>
</div>"""
                else:
                    unavailable_msg = f"""<div class="info-box" style="margin-top: 15px;">
<p style="margin-bottom: 10px;"><b>{len(unavailable_concepts)} ä¸ªå·²é€‰ç‰¹å¾</b>æœªèƒ½æå–ï¼Œå› ä¸ºå®ƒä»¬åœ¨å½“å‰æ•°æ®åº“ä¸­ä¸å¯ç”¨ï¼š</p>
<p style="color: #64748b; font-size: 0.95rem; line-height: 1.8;">{concepts_formatted}</p>
<p style="margin-top: 10px; font-size: 0.9rem; color: #6b7280;">ğŸ’¡ <i>è¿™æ˜¯æ­£å¸¸ç°è±¡â€”â€”å¹¶éæ‰€æœ‰ç‰¹å¾éƒ½åœ¨æ‰€æœ‰ICUæ•°æ®åº“ä¸­å¯ç”¨ã€‚</i></p>
</div>"""
                st.markdown(unavailable_msg, unsafe_allow_html=True)
            
            st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
            # ğŸ”§ FIX (2026-02-04): åœ¨åˆ é™¤å‰ä¿å­˜æ¦‚å¿µæ•°å’Œæ‚£è€…æ•°ï¼Œä¾›åé¢çš„å¡ç‰‡ä½¿ç”¨
            st.session_state['_last_export_concept_count'] = export_result.get('concept_count', len(exported_files))
            st.session_state['_last_export_patient_count'] = export_result.get('patient_count', 0)
            # æ¸…é™¤å¯¼å‡ºç»“æœï¼Œé¿å…é‡å¤æ˜¾ç¤º
            del st.session_state['_export_success_result']
        
        # æ˜¾ç¤ºçŠ¶æ€æ¦‚è§ˆå¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)
        
        db_label = "Database" if lang == 'en' else "æ•°æ®åº“"
        feat_label = "Loaded Concepts" if lang == 'en' else "å·²åŠ è½½æ¦‚å¿µ"
        patient_label = "Patients" if lang == 'en' else "æ‚£è€…æ•°é‡"
        status_label = "Status" if lang == 'en' else "æ•°æ®çŠ¶æ€"
        ready_status = "âœ… Ready" if lang == 'en' else "âœ… å°±ç»ª"
        
        with col1:
            db_display = "ğŸ­ DEMO" if st.session_state.get('use_mock_data', False) else st.session_state.get('database', 'N/A').upper()
            st.markdown(f'''
            <div class="metric-card">
                <div class="stat-label">{db_label}</div>
                <div class="stat-number" style="font-size:1.8rem">{db_display}</div>
            </div>
            ''', unsafe_allow_html=True)
        
        with col2:
            # ğŸ”§ FIX (2026-02-12): ç”±äºåˆ—åå·²åœ¨ load_from_exported() ä¸­è§„èŒƒåŒ–å¹¶å»é‡ï¼Œ
            # ç›´æ¥ä½¿ç”¨ len() ç»Ÿè®¡ï¼Œæ¯åˆ—å°±æ˜¯ä¸€ä¸ª concept
            export_result = st.session_state.get('_export_success_result')
            if export_result and 'concept_count' in export_result:
                # ä½¿ç”¨å¯¼å‡ºæ—¶ç»Ÿè®¡çš„å®é™…æ¦‚å¿µæ•°
                n_concepts = export_result['concept_count']
            elif '_last_export_concept_count' in st.session_state:
                # ä½¿ç”¨ä¸Šæ¬¡å¯¼å‡ºä¿å­˜çš„æ¦‚å¿µæ•°
                n_concepts = st.session_state['_last_export_concept_count']
            elif st.session_state.loaded_concepts:
                # ğŸ”§ ä½¿ç”¨å·²åŠ è½½çš„æ¦‚å¿µæ•°ï¼ˆå·²è§„èŒƒåŒ–å»é‡ï¼‰
                n_concepts = len(st.session_state.loaded_concepts)
            elif st.session_state.get('selected_concepts'):
                # DEMOæ¨¡å¼ï¼šä½¿ç”¨é€‰ä¸­çš„æ¦‚å¿µæ•°
                n_concepts = len(st.session_state.selected_concepts)
            else:
                # æ²¡æœ‰æ•°æ®æ—¶æ˜¾ç¤º 0
                n_concepts = 0
            st.markdown(f'''
            <div class="metric-card">
                <div class="stat-label">{feat_label}</div>
                <div class="stat-number">{n_concepts}</div>
            </div>
            ''', unsafe_allow_html=True)
        
        with col3:
            # æ˜¾ç¤ºæ‚£è€…æ•°ï¼šä¼˜å…ˆä½¿ç”¨å¯¼å‡ºæ—¶è®°å½•çš„å®é™…æ•°é‡ï¼ˆcohort filter åçš„çœŸå®æ•°é‡ï¼‰
            n_patients = 0
            id_col = st.session_state.get('id_col', 'stay_id')
            
            # ğŸ”§ DEBUG: æ‰“å°å„ä¸ªæ¥æºçš„å€¼
            print(f"[DEBUG Guide] _exported_patient_count: {st.session_state.get('_exported_patient_count')}")
            print(f"[DEBUG Guide] patient_ids len: {len(st.session_state.patient_ids) if st.session_state.patient_ids else 0}")
            print(f"[DEBUG Guide] mock_params: {st.session_state.get('mock_params')}")
            
            # æœ€é«˜ä¼˜å…ˆçº§ï¼šå¯¼å‡ºæ—¶è®°å½•çš„å®é™…æ‚£è€…æ•°ï¼ˆfilter åçš„çœŸå®æ•°é‡ï¼‰
            if st.session_state.get('_exported_patient_count'):
                n_patients = st.session_state['_exported_patient_count']
            
            # å…¶æ¬¡ï¼šä»å·²åŠ è½½æ•°æ®ä¸­è®¡ç®—å”¯ä¸€æ‚£è€…æ•°
            if n_patients == 0 and st.session_state.loaded_concepts:
                all_ids = set()
                for df in st.session_state.loaded_concepts.values():
                    if isinstance(df, pd.DataFrame) and id_col in df.columns:
                        all_ids.update(df[id_col].unique())
                if all_ids:
                    n_patients = len(all_ids)
            
            # ç„¶åï¼šä½¿ç”¨ patient_ids åˆ—è¡¨
            if n_patients == 0 and st.session_state.patient_ids:
                n_patients = len(st.session_state.patient_ids)
            
            # æœ€åï¼šç”¨ mock_paramsï¼ˆä»…ç”¨äºæ˜¾ç¤ºé¢„æœŸå€¼ï¼‰
            if n_patients == 0:
                mock_params = st.session_state.get('mock_params', {})
                if mock_params.get('n_patients'):
                    n_patients = mock_params['n_patients']
            
            st.markdown(f'''
            <div class="metric-card">
                <div class="stat-label">{patient_label}</div>
                <div class="stat-number">{n_patients:,}</div>
            </div>
            ''', unsafe_allow_html=True)
        
        with col4:
            st.markdown(f'''
            <div class="metric-card">
                <div class="stat-label">{status_label}</div>
                <div class="stat-number" style="color:#28a745">{ready_status}</div>
            </div>
            ''', unsafe_allow_html=True)
        
        # ğŸ†• What's Next? ä¸¤ä¸ªé€‰é¡¹
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        next_step_title = "ğŸ”„ What's Next?" if lang == 'en' else "ğŸ”„ ä¸‹ä¸€æ­¥ï¼Ÿ"
        st.markdown(f"### {next_step_title}")
        
        col_opt1, col_opt2 = st.columns(2)
        
        with col_opt1:
            # Option A: Quick Visualization
            if lang == 'en':
                st.markdown('''<div class="highlight-card" style="border-left: 4px solid #0277bd;">
<h4 style="color: #0277bd; margin-bottom: 12px;">ğŸ“ˆ Option A: Quick Visualization</h4>
<p style="color: #1a1a1a; margin-bottom: 15px;">Explore your data with interactive visualizations:</p>
<ul style="color: #2a2a2a; margin: 10px 0 0 15px; font-size: 0.95rem; line-height: 1.8;">
<li><b>Data Tables Explorer</b> â€” Browse and explore loaded data by module, view complete data tables with sorting and filtering</li>
<li><b>Time Series Analysis</b> â€” Visualize clinical trends over time with multi-feature overlay, interactive zoom, and customizable aggregation</li>
<li><b>Patient Overview</b> â€” Comprehensive single-patient dashboard showing all clinical trajectories and key events</li>
<li><b>Data Quality Assessment</b> â€” Analyze missing rates, temporal coverage, and data completeness across all features</li>
</ul>
</div>''', unsafe_allow_html=True)
            else:
                st.markdown('''<div class="highlight-card" style="border-left: 4px solid #0277bd;">
<h4 style="color: #0277bd; margin-bottom: 12px;">ğŸ“ˆ é€‰é¡¹ Aï¼šå¿«é€Ÿå¯è§†åŒ–</h4>
<p style="color: #1a1a1a; margin-bottom: 15px;">é€šè¿‡äº¤äº’å¼å¯è§†åŒ–æ¢ç´¢æ•°æ®ï¼š</p>
<ul style="color: #2a2a2a; margin: 10px 0 0 15px; font-size: 0.95rem; line-height: 1.8;">
<li><b>æ•°æ®è¡¨æµè§ˆå™¨</b> â€” æŒ‰æ¨¡å—æµè§ˆå’Œæ¢ç´¢å·²åŠ è½½æ•°æ®ï¼ŒæŸ¥çœ‹å®Œæ•´æ•°æ®è¡¨å¹¶æ”¯æŒæ’åºç­›é€‰</li>
<li><b>æ—¶åºåˆ†æ</b> â€” å¯è§†åŒ–ä¸´åºŠæŒ‡æ ‡éšæ—¶é—´çš„å˜åŒ–è¶‹åŠ¿ï¼Œæ”¯æŒå¤šç‰¹å¾å åŠ ã€äº¤äº’ç¼©æ”¾å’Œè‡ªå®šä¹‰èšåˆ</li>
<li><b>æ‚£è€…æ¦‚è§ˆ</b> â€” ç»¼åˆå•æ‚£è€…ä»ªè¡¨ç›˜ï¼Œå±•ç¤ºæ‰€æœ‰ä¸´åºŠè½¨è¿¹å’Œå…³é”®äº‹ä»¶</li>
<li><b>æ•°æ®è´¨é‡è¯„ä¼°</b> â€” åˆ†ææ‰€æœ‰ç‰¹å¾çš„ç¼ºå¤±ç‡ã€æ—¶é—´è¦†ç›–åº¦å’Œæ•°æ®å®Œæ•´æ€§</li>
</ul>
</div>''', unsafe_allow_html=True)
            
            # Option A æŒ‰é’®
            viz_label = "ğŸ“ˆ Go to Visualization" if lang == 'en' else "ğŸ“ˆ å‰å¾€å¯è§†åŒ–"
            if st.button(viz_label, use_container_width=True, key="goto_viz_home", type="primary"):
                st.session_state['_scroll_to_tab'] = 'viz'
                st.rerun()
        
        with col_opt2:
            # Option B: Cohort Analysis
            if lang == 'en':
                st.markdown('''<div class="highlight-card" style="border-left: 4px solid #6d28d9;">
<h4 style="color: #6d28d9; margin-bottom: 12px;">ğŸ”¬ Option B: Cohort Analysis</h4>
<p style="color: #1a1a1a; margin-bottom: 15px;">Perform statistical analysis on your cohort:</p>
<ul style="color: #2a2a2a; margin: 10px 0 0 15px; font-size: 0.95rem; line-height: 1.8;">
<li><b>Group Comparison Analysis</b> â€” Compare subgroups with statistical tests</li>
<li><b>Multi-Database Feature Distribution</b> â€” Compare feature distributions across different ICU databases</li>
<li><b>Cohort Dashboard</b> â€” Interactive overview of cohort demographics, outcomes, and key clinical characteristics</li>
</ul>
</div>''', unsafe_allow_html=True)
            else:
                st.markdown('''<div class="highlight-card" style="border-left: 4px solid #6d28d9;">
<h4 style="color: #6d28d9; margin-bottom: 12px;">ğŸ”¬ é€‰é¡¹ Bï¼šé˜Ÿåˆ—åˆ†æ</h4>
<p style="color: #1a1a1a; margin-bottom: 15px;">å¯¹é˜Ÿåˆ—è¿›è¡Œç»Ÿè®¡åˆ†æï¼š</p>
<ul style="color: #2a2a2a; margin: 10px 0 0 15px; font-size: 0.95rem; line-height: 1.8;">
<li><b>ç»„é—´æ¯”è¾ƒåˆ†æ</b> â€” ä½¿ç”¨ç»Ÿè®¡æ£€éªŒï¼ˆtæ£€éªŒã€å¡æ–¹æ£€éªŒã€Mann-Whitney Uï¼‰æ¯”è¾ƒäºšç»„å¹¶ç”Ÿæˆ Table 1</li>
<li><b>å¤šæ•°æ®åº“ç‰¹å¾åˆ†å¸ƒ</b> â€” æ¯”è¾ƒä¸åŒICUæ•°æ®åº“ï¼ˆMIMICã€eICUç­‰ï¼‰é—´çš„ç‰¹å¾åˆ†å¸ƒå·®å¼‚</li>
<li><b>é˜Ÿåˆ—ä»ªè¡¨ç›˜</b> â€” é˜Ÿåˆ—äººå£ç»Ÿè®¡å­¦ã€ç»“å±€å’Œå…³é”®ä¸´åºŠç‰¹å¾çš„äº¤äº’å¼æ¦‚è§ˆ</li>
</ul>
</div>''', unsafe_allow_html=True)
            
            # Option B æŒ‰é’®
            cohort_label = "ğŸ”¬ Go to Cohort Analysis" if lang == 'en' else "ğŸ”¬ å‰å¾€é˜Ÿåˆ—åˆ†æ"
            if st.button(cohort_label, use_container_width=True, key="goto_cohort_home", type="primary"):
                st.session_state['_scroll_to_tab'] = 'cohort'
                st.rerun()
        
        # ğŸ†• åœ¨ Guide: Complete ä¸‹æ–¹åˆ›å»ºå¯¼å‡ºè¿›åº¦åŒºåŸŸ
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        export_section = st.container()
        st.session_state['_export_progress_container'] = export_section
    
    # ============ æ•°æ®å­—å…¸å±•ç¤º ============
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    # æ·»åŠ å­—å…¸é”šç‚¹å’Œå¤§æ ‡é¢˜
    st.markdown('<div id="dictionary"></div>', unsafe_allow_html=True)
    dict_header = "ğŸ“– Data Dictionary" if lang == 'en' else "ğŸ“– æ•°æ®å­—å…¸"
    st.markdown(f'<h2 style="background:linear-gradient(135deg,#667eea,#764ba2);-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text;border-bottom:3px solid #667eea;padding-bottom:10px;margin-top:10px;font-size:1.6rem;">{dict_header}</h2>', unsafe_allow_html=True)
    
    # æ·»åŠ æ•°æ®å­—å…¸è¯´æ˜
    if lang == 'en':
        st.markdown('''
        <div style="background: rgba(102, 126, 234, 0.15); padding: 18px; border-radius: 12px; margin-bottom: 20px; border-left: 4px solid #667eea;">
            <p style="color: #333; font-size: 1.15rem; margin: 0; line-height: 1.7;">
                ğŸ“š <b>Reference Guide</b>: This dictionary contains all 168 ICU clinical features available in EasyICU, organized into 19 categories. 
                Each feature includes its code name, full description, and measurement unit. 
                Use this to understand what data you're extracting and make informed selections.
                Note that some features may not be available in all ICU databases.
            </p>
        </div>
        ''', unsafe_allow_html=True)
    else:
        st.markdown('''
        <div style="background: rgba(102, 126, 234, 0.15); padding: 18px; border-radius: 12px; margin-bottom: 20px; border-left: 4px solid #667eea;">
            <p style="color: #333; font-size: 1.15rem; margin: 0; line-height: 1.7;">
                ğŸ“š <b>å‚è€ƒæŒ‡å—</b>ï¼šæœ¬å­—å…¸åŒ…å« EasyICU æä¾›çš„å…¨éƒ¨ 168 ä¸ª ICU ä¸´åºŠç‰¹å¾ï¼Œåˆ†ä¸º 19 ä¸ªç±»åˆ«ã€‚
                æ¯ä¸ªç‰¹å¾åŒ…æ‹¬ä»£ç åç§°ã€å®Œæ•´æè¿°å’Œæµ‹é‡å•ä½ã€‚
                ä½¿ç”¨æ­¤å­—å…¸äº†è§£æ‚¨æ­£åœ¨æå–çš„æ•°æ®ï¼Œåšå‡ºæ˜æ™ºçš„é€‰æ‹©ã€‚
            </p>
        </div>
        ''', unsafe_allow_html=True)
    
    render_home_data_dictionary(lang)
    
    # é¡µè„šä¿¡æ¯
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    if lang == 'en':
        st.markdown('''
        <div style="text-align:center;color:#aaa;font-size:0.85rem">
            <p>ğŸ¥ EasyICU - ICU Data Analysis Toolkit | 
            ğŸ“¦ <a href="https://github.com/your-repo/pyricu" style="color:#4fc3f7">GitHub</a> | 
            ğŸ“– <a href="#" style="color:#4fc3f7">Docs</a></p>
            <p>All data processing is done locally, no data is uploaded to any server ğŸ”’</p>
        </div>
        ''', unsafe_allow_html=True)
    else:
        st.markdown('''
        <div style="text-align:center;color:#aaa;font-size:0.85rem">
            <p>ğŸ¥ EasyICU - ICU æ•°æ®åˆ†æå·¥å…·åŒ… | 
            ğŸ“¦ <a href="https://github.com/your-repo/pyricu" style="color:#4fc3f7">GitHub</a> | 
            ğŸ“– <a href="#" style="color:#4fc3f7">æ–‡æ¡£</a></p>
            <p>æ‰€æœ‰æ•°æ®å¤„ç†å‡åœ¨æœ¬åœ°å®Œæˆï¼Œä¸ä¼šä¸Šä¼ åˆ°ä»»ä½•æœåŠ¡å™¨ ğŸ”’</p>
        </div>
        ''', unsafe_allow_html=True)


def render_home_data_dictionary(lang):
    """åœ¨é¦–é¡µæ¸²æŸ“å®Œæ•´çš„æ•°æ®å­—å…¸ã€‚"""
    dict_title = "ğŸ“– Complete Data Dictionary" if lang == 'en' else "ğŸ“– å®Œæ•´æ•°æ®å­—å…¸"
    
    with st.expander(dict_title, expanded=True):

        
        # è·å–åˆ†ç»„
        concept_groups = get_concept_groups()
        
        # æ‰€æœ‰åˆ†ç±»ç»Ÿä¸€ç”¨ expander å±•ç¤ºï¼ˆä¸å†åˆ†å¼€å‰8ä¸ªå’Œæ›´å¤šç±»åˆ«ï¼‰
        categories_title = "ğŸ“‚ Categories" if lang == 'en' else "ğŸ“‚ ç±»åˆ«"
        st.markdown(f"#### {categories_title}")
        
        for group_name in concept_groups.keys():
            feat_text = "features" if lang == 'en' else "ä¸ªç‰¹å¾"
            with st.expander(f"{group_name} ({len(concept_groups[group_name])} {feat_text})"):
                _render_home_dict_table(concept_groups[group_name], lang)


def _render_home_dict_table(concepts, lang):
    """ä¸ºé¦–é¡µæ•°æ®å­—å…¸æ¸²æŸ“è¡¨æ ¼ã€‚"""
    rows = []
    for concept in concepts:
        if concept in CONCEPT_DICTIONARY:
            eng_name, chn_name, unit = CONCEPT_DICTIONARY[concept]
            # è·å–è¯¦ç»†æè¿°
            if concept in CONCEPT_DESCRIPTIONS:
                eng_desc, chn_desc = CONCEPT_DESCRIPTIONS[concept]
            else:
                eng_desc, chn_desc = eng_name, chn_name  # ç”¨åç§°ä½œä¸ºé»˜è®¤æè¿°
            
            if lang == 'en':
                rows.append({
                    'Code': concept,
                    'Full Name': eng_name,
                    'Description': eng_desc,
                    'Unit': unit if unit else '-'
                })
            else:
                rows.append({
                    'ä»£ç ': concept,
                    'å…¨ç§°': eng_name,
                    'è¯´æ˜': chn_desc,
                    'å•ä½': unit if unit else '-'
                })
    
    if rows:
        df = pd.DataFrame(rows)
        st.dataframe(df, width="stretch", hide_index=True, height=300)


def render_timeseries_page():
    """æ¸²æŸ“æ—¶åºåˆ†æé¡µé¢ã€‚"""
    lang = st.session_state.get('language', 'en')
    
    page_title = "ğŸ“ˆ Time Series Analysis" if lang == 'en' else "ğŸ“ˆ æ—¶åºæ•°æ®åˆ†æ"
    st.markdown(f"## {page_title}")
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    if len(st.session_state.loaded_concepts) == 0:
        if lang == 'en':
            st.markdown('''
            <div class="info-box">
                <strong>ğŸ‘ˆ Please load data from the sidebar first</strong><br>
                ğŸ’¡ Tip: Click "Enable Demo Mode" on homepage for quick start
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="info-box">
                <strong>ğŸ‘ˆ è¯·å…ˆåœ¨ä¾§è¾¹æ åŠ è½½æ•°æ®</strong><br>
                ğŸ’¡ æç¤ºï¼šç‚¹å‡»é¦–é¡µã€Œä¸€é”®ä½“éªŒæ¼”ç¤ºæ¨¡å¼ã€å¿«é€Ÿå¼€å§‹
            </div>
            ''', unsafe_allow_html=True)
        return
    
    # Concept é€‰æ‹©åŒºåŸŸ
    available_concepts = list(st.session_state.loaded_concepts.keys())
    
    # åˆ†ææ¨¡å¼é€‰æ‹©
    mode_label = "Analysis Mode" if lang == 'en' else "åˆ†ææ¨¡å¼"
    mode_single = "Single Patient" if lang == 'en' else "å•æ‚£è€…åˆ†æ"
    mode_multi = "Multi-Patient Comparison" if lang == 'en' else "å¤šæ‚£è€…æ¯”è¾ƒ"
    analysis_mode = st.radio(
        mode_label,
        options=[mode_single, mode_multi],
        horizontal=True,
        key="ts_mode"
    )
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    if analysis_mode == mode_single:
        # é¡¶éƒ¨æ§åˆ¶é¢æ¿ - ğŸ”§ FIX: æ·»åŠ æ¨¡å—ç­›é€‰ï¼Œæ–¹ä¾¿ç”¨æˆ·åœ¨100+ç‰¹å¾ä¸­æ‰¾åˆ°æƒ³è¦çš„
        col1, col2, col3, col4, col5 = st.columns([1, 1, 1, 1, 1])
        
        with col1:
            # ğŸ”§ FIX: å…ˆé€‰æ‹©æ¨¡å—ï¼Œå†é€‰æ‹©ç‰¹å¾
            module_label = "ğŸ“‚ Select Module" if lang == 'en' else "ğŸ“‚ é€‰æ‹©æ¨¡å—"
            all_modules_opt = "All Modules" if lang == 'en' else "å…¨éƒ¨æ¨¡å—"
            
            # è·å–æ¨¡å—åˆ—è¡¨ - ğŸ”§ FIX (2026-02-05): åªæ˜¾ç¤ºæ”¯æŒæ—¶åºåˆ†æçš„æ¨¡å—
            module_options = [all_modules_opt]
            for grp_key in CONCEPT_GROUPS_INTERNAL:
                # è·³è¿‡ä¸æ”¯æŒæ—¶åºåˆ†æçš„æ¨¡å—ï¼ˆdemographics, outcomeï¼‰
                if grp_key not in TIME_SERIES_COMPATIBLE_MODULES:
                    continue
                grp_concepts = CONCEPT_GROUPS_INTERNAL[grp_key]
                # æ£€æŸ¥è¯¥æ¨¡å—æ˜¯å¦æœ‰å·²åŠ è½½çš„æ¦‚å¿µ
                if any(c in available_concepts for c in grp_concepts):
                    display_name = CONCEPT_GROUPS_DISPLAY.get(grp_key, grp_key)
                    module_options.append(display_name)
            
            selected_module = st.selectbox(
                module_label,
                options=module_options,
                key="ts_module"
            )
        
        with col2:
            # æ ¹æ®é€‰æ‹©çš„æ¨¡å—è¿‡æ»¤æ¦‚å¿µ
            if selected_module == all_modules_opt:
                filtered_concepts = available_concepts
            else:
                # æ‰¾åˆ°å¯¹åº”çš„ group_key
                selected_grp_key = None
                for grp_key, display in CONCEPT_GROUPS_DISPLAY.items():
                    if display == selected_module:
                        selected_grp_key = grp_key
                        break
                if selected_grp_key:
                    grp_concepts = CONCEPT_GROUPS_INTERNAL.get(selected_grp_key, [])
                    filtered_concepts = [c for c in available_concepts if c in grp_concepts]
                else:
                    filtered_concepts = available_concepts
            
            concept_label = "ğŸ“‹ Select Concept" if lang == 'en' else "ğŸ“‹ é€‰æ‹© Concept"
            concept_help = "Select data type to visualize" if lang == 'en' else "é€‰æ‹©è¦å¯è§†åŒ–çš„æ•°æ®ç±»å‹"
            selected_concept = st.selectbox(
                concept_label,
                options=filtered_concepts if filtered_concepts else available_concepts,
                key="ts_concept",
                help=concept_help
            )
        
        with col3:
            if st.session_state.patient_ids:
                patient_label = "ğŸ‘¤ Select Patient" if lang == 'en' else "ğŸ‘¤ é€‰æ‹©æ‚£è€…"
                # ğŸ”§ FIX: æ”¯æŒç”¨æˆ·è¾“å…¥æœç´¢æ‚£è€…ID
                patient_search = st.text_input(
                    "ğŸ” Search Patient ID" if lang == 'en' else "ğŸ” æœç´¢æ‚£è€…ID",
                    key="ts_patient_search",
                    placeholder="Type to filter..." if lang == 'en' else "è¾“å…¥IDè¿‡æ»¤..."
                )
                
                # è¿‡æ»¤æ‚£è€…åˆ—è¡¨
                all_patients = st.session_state.patient_ids[:500]  # é™åˆ¶å‰500ä¸ª
                if patient_search:
                    filtered_patients = [p for p in all_patients if str(patient_search) in str(p)]
                else:
                    filtered_patients = all_patients[:100]
                
                patient_id = st.selectbox(
                    patient_label,
                    options=filtered_patients if filtered_patients else all_patients[:100],
                    key="ts_patient"
                )
            else:
                patient_id = None
                no_patient_msg = "No patients found" if lang == 'en' else "æœªæ‰¾åˆ°æ‚£è€…"
                st.warning(no_patient_msg)
        
        with col4:
            chart_label = "ğŸ“Š Chart Type" if lang == 'en' else "ğŸ“Š å›¾è¡¨ç±»å‹"
            line_opt = "Line Chart" if lang == 'en' else "æŠ˜çº¿å›¾"
            scatter_opt = "Scatter Plot" if lang == 'en' else "æ•£ç‚¹å›¾"
            area_opt = "Area Chart" if lang == 'en' else "é¢ç§¯å›¾"
            chart_type = st.selectbox(
                chart_label,
                options=[line_opt, scatter_opt, area_opt],
                key="ts_chart_type"
            )
        
        with col5:
            show_stats_label = "Show Statistics" if lang == 'en' else "æ˜¾ç¤ºç»Ÿè®¡"
            show_stats = st.checkbox(show_stats_label, value=True, key="ts_show_stats")
        
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        
        # ä¸»å›¾è¡¨åŒºåŸŸ
        if selected_concept and patient_id:
            df = st.session_state.loaded_concepts[selected_concept]
            
            # ç¡®ä¿æ˜¯ DataFrame
            if not isinstance(df, pd.DataFrame):
                format_warn = f"Data format not supported: {type(df).__name__}" if lang == 'en' else f"æ•°æ®æ ¼å¼ä¸æ”¯æŒ: {type(df).__name__}"
                st.warning(format_warn)
                return
            
            # è¿‡æ»¤æ•°æ®
            id_col = st.session_state.id_col
            if id_col and id_col in df.columns:
                patient_df = df[df[id_col] == patient_id].copy()
            else:
                patient_df = df.copy()
            
            # æ˜¾ç¤ºå›¾è¡¨
            if len(patient_df) > 0:
                try:
                    import plotly.express as px
                    import plotly.graph_objects as go
                    
                    # ç¡®å®šæ•°å€¼åˆ—
                    numeric_cols = patient_df.select_dtypes(include=['number']).columns
                    # æ’é™¤IDåˆ—å’Œæ‰€æœ‰å¯èƒ½çš„æ—¶é—´åˆ—
                    exclude_cols = ['stay_id', 'hadm_id', 'icustay_id', 'index', 'time', 
                                   'charttime', 'starttime', 'endtime', 'datetime', 'timestamp',
                                   'patientunitstayid', 'admissionid', 'patientid']
                    value_cols = [c for c in numeric_cols if c not in exclude_cols]
                    
                    # æ£€æµ‹æ—¶é—´åˆ— - æ”¯æŒå¤šç§å‘½å
                    time_candidates = ['time', 'charttime', 'starttime', 'endtime', 'datetime', 'timestamp']
                    time_col = None
                    for tc in time_candidates:
                        if tc in patient_df.columns:
                            time_col = tc
                            break
                    
                    if value_cols:
                        value_col = value_cols[0]
                        
                        if time_col:
                            # æ ¹æ®å›¾è¡¨ç±»å‹åˆ›å»ºå›¾è¡¨
                            line_type = "Line Chart" if lang == 'en' else "æŠ˜çº¿å›¾"
                            scatter_type = "Scatter Plot" if lang == 'en' else "æ•£ç‚¹å›¾"
                            patient_label = "Patient" if lang == 'en' else "æ‚£è€…"
                            chart_title = f"ğŸ“ˆ {selected_concept.upper()} - {patient_label} {patient_id}"
                            
                            if chart_type == line_type:
                                fig = px.line(
                                    patient_df, x=time_col, y=value_col,
                                    title=chart_title,
                                    markers=True
                                )
                            elif chart_type == scatter_type:
                                fig = px.scatter(
                                    patient_df, x=time_col, y=value_col,
                                    title=chart_title,
                                    size_max=10
                                )
                            else:  # é¢ç§¯å›¾
                                fig = px.area(
                                    patient_df, x=time_col, y=value_col,
                                    title=chart_title
                                )
                            
                            # ç¾åŒ–å›¾è¡¨
                            time_label = "Time (hours)" if lang == 'en' else "æ—¶é—´ (å°æ—¶)"
                            fig.update_layout(
                                template="plotly_white",
                                hovermode="x unified",
                                xaxis_title=time_label,
                                yaxis_title=value_col.upper(),
                                font=dict(size=12),
                                title_font_size=16,
                                showlegend=False,
                                margin=dict(l=50, r=30, t=50, b=50),
                            )
                            fig.update_traces(
                                line=dict(width=2, color='#1f77b4'),
                                marker=dict(size=6)
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            # ğŸ”§ åªæœ‰æ•°å€¼æ²¡æœ‰æ—¶é—´åˆ—ï¼ˆé™æ€æ•°æ®/å•ç‚¹æ•°æ®ï¼‰
                            st.info("â„¹ï¸ Static value (No time series data)" if lang == 'en' else "â„¹ï¸ é™æ€æ•°å€¼ï¼ˆæ— æ—¶é—´åºåˆ—æ•°æ®ï¼‰")
                            if len(patient_df) == 1:
                                val = patient_df[value_col].iloc[0]
                                st.metric(label=value_col.upper(), value=f"{val}")
                            else:
                                st.dataframe(patient_df[[value_col]], width="stretch")

                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        if show_stats:
                            stat_title = "#### ğŸ“Š Statistical Summary" if lang == 'en' else "#### ğŸ“Š ç»Ÿè®¡æ‘˜è¦"
                            st.markdown(stat_title)
                            stat_cols = st.columns(5)
                            values = patient_df[value_col]
                            if lang == 'en':
                                stats = [
                                    ("Min", f"{values.min():.2f}", "ğŸ“‰"),
                                    ("Max", f"{values.max():.2f}", "ğŸ“ˆ"),
                                    ("Mean", f"{values.mean():.2f}", "ğŸ“Š"),
                                    ("Std Dev", f"{values.std():.2f}", "ğŸ“"),
                                    ("Records", f"{len(values)}", "ğŸ“"),
                                ]
                            else:
                                stats = [
                                    ("æœ€å°å€¼", f"{values.min():.2f}", "ğŸ“‰"),
                                    ("æœ€å¤§å€¼", f"{values.max():.2f}", "ğŸ“ˆ"),
                                    ("å¹³å‡å€¼", f"{values.mean():.2f}", "ğŸ“Š"),
                                    ("æ ‡å‡†å·®", f"{values.std():.2f}", "ğŸ“"),
                                    ("è®°å½•æ•°", f"{len(values)}", "ğŸ“"),
                                ]
                            for i, (label, value, icon) in enumerate(stats):
                                with stat_cols[i]:
                                    st.metric(f"{icon} {label}", value)
                    else:
                        # ğŸ”§ FIX: æ£€æµ‹æ˜¯å¦æœ‰å¸ƒå°”åˆ—ï¼ˆåŒ…æ‹¬pandas booleanå’Œnumpy boolï¼‰
                        bool_cols = []
                        for col in patient_df.columns:
                            dtype_str = str(patient_df[col].dtype).lower()
                            if 'bool' in dtype_str:
                                bool_cols.append(col)
                        
                        if bool_cols:
                            if lang == 'en':
                                warn_msg = f"âš ï¸ **{selected_concept.upper()}** is a Boolean (True/False) feature. Time Series Analysis requires numeric values and cannot display boolean data as a chart."
                            else:
                                warn_msg = f"âš ï¸ **{selected_concept.upper()}** æ˜¯å¸ƒå°”ç±»å‹ï¼ˆTrue/Falseï¼‰ç‰¹å¾ã€‚æ—¶åºåˆ†æéœ€è¦æ•°å€¼å‹æ•°æ®ï¼Œæ— æ³•å°†å¸ƒå°”æ•°æ®æ˜¾ç¤ºä¸ºå›¾è¡¨ã€‚"
                        else:
                            warn_msg = f"âš ï¸ **{selected_concept.upper()}** is a Boolean (True/False) feature. Time Series Analysis requires numeric values and cannot display boolean data as a chart." if lang == 'en' else f"âš ï¸ **{selected_concept.upper()}** æ˜¯å¸ƒå°”ç±»å‹ï¼ˆTrue/Falseï¼‰ç‰¹å¾ã€‚æ—¶åºåˆ†æéœ€è¦æ•°å€¼å‹æ•°æ®ï¼Œæ— æ³•å°†å¸ƒå°”æ•°æ®æ˜¾ç¤ºä¸ºå›¾è¡¨ã€‚"
                        st.warning(warn_msg)
                        # ğŸ”§ æ˜¾ç¤ºæ•°æ®è¡¨æ ¼é¢„è§ˆï¼Œå°†å¸ƒå°”åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        display_patient_df = patient_df.head(20).copy()
                        for col in display_patient_df.columns:
                            dtype_str = str(display_patient_df[col].dtype).lower()
                            if 'bool' in dtype_str:
                                display_patient_df[col] = display_patient_df[col].astype(str)
                        st.dataframe(display_patient_df, use_container_width=True)
                        
                except Exception as e:
                    err_msg = f"Chart rendering failed: {e}" if lang == 'en' else f"å›¾è¡¨æ¸²æŸ“å¤±è´¥: {e}"
                    st.warning(err_msg)
                    if 'time' in patient_df.columns:
                        chart_df = patient_df.set_index('time')
                        value_cols = [c for c in chart_df.columns if c not in [id_col]]
                        if value_cols:
                            st.line_chart(chart_df[value_cols[0]])
            else:
                no_data_msg = f"â„¹ï¸ No {selected_concept} data for patient {patient_id}" if lang == 'en' else f"â„¹ï¸ æ‚£è€… {patient_id} æ—  {selected_concept} æ•°æ®"
                st.info(no_data_msg)
        
        # æ•°æ®è¡¨æ ¼é¢„è§ˆ
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        preview_label = "ğŸ“‹ Data Table Preview" if lang == 'en' else "ğŸ“‹ æ•°æ®è¡¨æ ¼é¢„è§ˆ"
        with st.expander(preview_label, expanded=True):  # ğŸ”§ FIX: é»˜è®¤å±•å¼€
            if selected_concept in st.session_state.loaded_concepts:
                df = st.session_state.loaded_concepts[selected_concept]
                if isinstance(df, pd.DataFrame):
                    if patient_id:
                        id_col = st.session_state.id_col
                        if id_col in df.columns:
                            df = df[df[id_col] == patient_id]
                    st.dataframe(df.head(50), width="stretch", hide_index=True)  # ğŸ”§ FIX: use width instead of use_container_width
                else:
                    format_msg = "Data format does not support preview" if lang == 'en' else "æ•°æ®æ ¼å¼ä¸æ”¯æŒé¢„è§ˆ"
                    st.info(format_msg)
    
    else:  # å¤šæ‚£è€…æ¯”è¾ƒæ¨¡å¼
        col1, col2, col3, col4 = st.columns([1, 1, 2, 1])
        
        with col1:
            # ğŸ”§ FIX: å…ˆé€‰æ‹©æ¨¡å—ï¼Œå†é€‰æ‹©ç‰¹å¾
            module_label = "ğŸ“‚ Select Module" if lang == 'en' else "ğŸ“‚ é€‰æ‹©æ¨¡å—"
            all_modules_opt = "All Modules" if lang == 'en' else "å…¨éƒ¨æ¨¡å—"
            
            # ğŸ”§ FIX (2026-02-05): åªæ˜¾ç¤ºæ”¯æŒæ—¶åºåˆ†æçš„æ¨¡å—ï¼ˆæ’é™¤é™æ€æ•°æ®æ¨¡å—ï¼‰
            module_options = [all_modules_opt]
            for grp_key in CONCEPT_GROUPS_INTERNAL:
                # è·³è¿‡ä¸æ”¯æŒæ—¶åºåˆ†æçš„æ¨¡å—ï¼ˆdemographics, outcomeï¼‰
                if grp_key not in TIME_SERIES_COMPATIBLE_MODULES:
                    continue
                grp_concepts = CONCEPT_GROUPS_INTERNAL[grp_key]
                if any(c in available_concepts for c in grp_concepts):
                    display_name = CONCEPT_GROUPS_DISPLAY.get(grp_key, grp_key)
                    module_options.append(display_name)
            
            selected_module_multi = st.selectbox(
                module_label,
                options=module_options,
                key="ts_module_multi"
            )
        
        with col2:
            # æ ¹æ®é€‰æ‹©çš„æ¨¡å—è¿‡æ»¤æ¦‚å¿µ
            if selected_module_multi == all_modules_opt:
                filtered_concepts_multi = available_concepts
            else:
                selected_grp_key = None
                for grp_key, display in CONCEPT_GROUPS_DISPLAY.items():
                    if display == selected_module_multi:
                        selected_grp_key = grp_key
                        break
                if selected_grp_key:
                    grp_concepts = CONCEPT_GROUPS_INTERNAL.get(selected_grp_key, [])
                    filtered_concepts_multi = [c for c in available_concepts if c in grp_concepts]
                else:
                    filtered_concepts_multi = available_concepts
            
            concept_label = "ğŸ“‹ Select Concept" if lang == 'en' else "ğŸ“‹ é€‰æ‹© Concept"
            selected_concept = st.selectbox(
                concept_label,
                options=filtered_concepts_multi if filtered_concepts_multi else available_concepts,
                key="ts_concept_multi"
            )
        
        with col3:
            if st.session_state.patient_ids:
                compare_label = "ğŸ‘¥ Select patients to compare (max 5)" if lang == 'en' else "ğŸ‘¥ é€‰æ‹©è¦æ¯”è¾ƒçš„æ‚£è€… (æœ€å¤š5ä¸ª)"
                compare_patients = st.multiselect(
                    compare_label,
                    options=st.session_state.patient_ids[:50],
                    default=st.session_state.patient_ids[:3],
                    max_selections=5,
                    key="ts_compare_patients"
                )
            else:
                compare_patients = []
        
        with col4:
            normalize_label = "Normalize" if lang == 'en' else "å½’ä¸€åŒ–æ¯”è¾ƒ"
            normalize_help = "Normalize values to 0-1 range for comparison" if lang == 'en' else "å°†æ•°å€¼å½’ä¸€åŒ–åˆ°0-1èŒƒå›´ä¾¿äºæ¯”è¾ƒ"
            normalize = st.checkbox(normalize_label, value=False, key="ts_normalize",
                                   help=normalize_help)
        
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        
        if selected_concept and compare_patients:
            try:
                import plotly.graph_objects as go
                
                df = st.session_state.loaded_concepts[selected_concept]
                
                # ç¡®ä¿æ˜¯ DataFrame
                if not isinstance(df, pd.DataFrame):
                    format_warn = f"Data format not supported for multi-patient comparison: {type(df).__name__}" if lang == 'en' else f"æ•°æ®æ ¼å¼ä¸æ”¯æŒå¤šæ‚£è€…æ¯”è¾ƒ: {type(df).__name__}"
                    st.warning(format_warn)
                    return
                
                id_col = st.session_state.id_col
                
                # ç¡®å®šæ•°å€¼åˆ—
                numeric_cols = df.select_dtypes(include=['number']).columns
                # æ’é™¤IDåˆ—å’Œæ‰€æœ‰å¯èƒ½çš„æ—¶é—´åˆ—
                exclude_cols = ['stay_id', 'hadm_id', 'icustay_id', 'index', 'time',
                               'charttime', 'starttime', 'endtime', 'datetime', 'timestamp',
                               'patientunitstayid', 'admissionid', 'patientid']
                value_cols = [c for c in numeric_cols if c not in exclude_cols]
                
                # æ£€æµ‹æ—¶é—´åˆ—
                time_candidates = ['time', 'charttime', 'starttime', 'endtime', 'datetime', 'timestamp']
                time_col = None
                for tc in time_candidates:
                    if tc in df.columns:
                        time_col = tc
                        break
                
                if value_cols and time_col and id_col in df.columns:
                    value_col = value_cols[0]
                    
                    fig = go.Figure()
                    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
                    
                    comparison_stats = []
                    
                    for i, pid in enumerate(compare_patients):
                        patient_df = df[df[id_col] == pid].sort_values(time_col)
                        
                        if len(patient_df) > 0:
                            y_values = patient_df[value_col].values
                            
                            # å½’ä¸€åŒ–
                            if normalize and len(y_values) > 0:
                                y_min, y_max = y_values.min(), y_values.max()
                                if y_max > y_min:
                                    y_values = (y_values - y_min) / (y_max - y_min)
                            
                            patient_label = f"Patient {pid}" if lang == 'en' else f"æ‚£è€… {pid}"
                            fig.add_trace(go.Scatter(
                                x=patient_df[time_col],
                                y=y_values,
                                mode='lines+markers',
                                name=patient_label,
                                line=dict(color=colors[i % len(colors)], width=2),
                                marker=dict(size=4)
                            ))
                            
                            # Build stats with language-aware column names
                            if lang == 'en':
                                comparison_stats.append({
                                    'Patient': pid,
                                    'Mean': f"{patient_df[value_col].mean():.2f}",
                                    'Max': f"{patient_df[value_col].max():.2f}",
                                    'Min': f"{patient_df[value_col].min():.2f}",
                                    'Records': len(patient_df)
                                })
                            else:
                                comparison_stats.append({
                                    'æ‚£è€…': pid,
                                    'å¹³å‡å€¼': f"{patient_df[value_col].mean():.2f}",
                                    'æœ€å¤§å€¼': f"{patient_df[value_col].max():.2f}",
                                    'æœ€å°å€¼': f"{patient_df[value_col].min():.2f}",
                                    'è®°å½•æ•°': len(patient_df)
                                })
                    
                    # Language-aware chart labels
                    chart_title = f"ğŸ“Š {selected_concept.upper()} Multi-Patient Comparison" if lang == 'en' else f"ğŸ“Š {selected_concept.upper()} å¤šæ‚£è€…æ¯”è¾ƒ"
                    x_axis_label = "Time (hours)" if lang == 'en' else "æ—¶é—´ (å°æ—¶)"
                    y_suffix = " (Normalized)" if lang == 'en' else " (å½’ä¸€åŒ–)"
                    fig.update_layout(
                        template="plotly_white",
                        title=chart_title,
                        xaxis_title=x_axis_label,
                        yaxis_title=f"{value_col}" + (y_suffix if normalize else ""),
                        hovermode="x unified",
                        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="center", x=0.5),
                        height=450,
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # æ¯”è¾ƒç»Ÿè®¡è¡¨
                    if comparison_stats:
                        compare_stats_title = "#### ğŸ“Š Comparison Statistics" if lang == 'en' else "#### ğŸ“Š æ¯”è¾ƒç»Ÿè®¡"
                        st.markdown(compare_stats_title)
                        st.dataframe(pd.DataFrame(comparison_stats), width="stretch", hide_index=True)
                else:
                    # ğŸ”§ FIX: æ£€æµ‹æ˜¯å¦æœ‰å¸ƒå°”åˆ—ï¼ˆåŒ…æ‹¬pandas booleanå’Œnumpy boolï¼‰
                    bool_cols = []
                    for col in df.columns:
                        dtype_str = str(df[col].dtype).lower()
                        if 'bool' in dtype_str:
                            bool_cols.append(col)
                    
                    if bool_cols:
                        if lang == 'en':
                            format_warn = f"âš ï¸ **{selected_concept.upper()}** is a Boolean (True/False) feature. Time Series Analysis requires numeric values and cannot display boolean data as a chart."
                        else:
                            format_warn = f"âš ï¸ **{selected_concept.upper()}** æ˜¯å¸ƒå°”ç±»å‹ï¼ˆTrue/Falseï¼‰ç‰¹å¾ã€‚æ—¶åºåˆ†æéœ€è¦æ•°å€¼å‹æ•°æ®ï¼Œæ— æ³•å°†å¸ƒå°”æ•°æ®æ˜¾ç¤ºä¸ºå›¾è¡¨ã€‚"
                    else:
                        format_warn = f"âš ï¸ **{selected_concept.upper()}** is a Boolean (True/False) feature. Time Series Analysis requires numeric values and cannot display boolean data as a chart." if lang == 'en' else f"âš ï¸ **{selected_concept.upper()}** æ˜¯å¸ƒå°”ç±»å‹ï¼ˆTrue/Falseï¼‰ç‰¹å¾ã€‚æ—¶åºåˆ†æéœ€è¦æ•°å€¼å‹æ•°æ®ï¼Œæ— æ³•å°†å¸ƒå°”æ•°æ®æ˜¾ç¤ºä¸ºå›¾è¡¨ã€‚"
                    st.warning(format_warn)
                    
            except Exception as e:
                err_msg = f"Comparison chart rendering failed: {e}" if lang == 'en' else f"æ¯”è¾ƒå›¾è¡¨æ¸²æŸ“å¤±è´¥: {e}"
                st.error(err_msg)


def render_patient_page():
    """æ¸²æŸ“æ‚£è€…è§†å›¾é¡µé¢ã€‚"""
    lang = st.session_state.get('language', 'en')
    
    page_title = "ğŸ¥ Patient Overview" if lang == 'en' else "ğŸ¥ æ‚£è€…ç»¼åˆè§†å›¾"
    st.markdown(f"## {page_title}")
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    if len(st.session_state.loaded_concepts) == 0:
        if lang == 'en':
            st.markdown('''
            <div class="info-box">
                <strong>ğŸ‘ˆ Please load data from the sidebar first</strong><br>
                ğŸ’¡ Tip: Select "Demo Mode" to quickly explore all features
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="info-box">
                <strong>ğŸ‘ˆ è¯·å…ˆåœ¨ä¾§è¾¹æ åŠ è½½æ•°æ®</strong><br>
                ğŸ’¡ æç¤ºï¼šå‹¾é€‰ã€Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ã€å¯å¿«é€Ÿä½“éªŒæ‰€æœ‰åŠŸèƒ½
            </div>
            ''', unsafe_allow_html=True)
        return
    
    if not st.session_state.patient_ids:
        warn_msg = "âš ï¸ No patient data found" if lang == 'en' else "âš ï¸ æœªæ‰¾åˆ°æ‚£è€…æ•°æ®"
        st.warning(warn_msg)
        return
    
    # æ‚£è€…é€‰æ‹©é¢æ¿
    select_title = "ğŸ›ï¸ Patient Selection" if lang == 'en' else "ğŸ›ï¸ æ‚£è€…é€‰æ‹©"
    st.markdown(f"### {select_title}")
    
    # å¿«é€Ÿå¯¼èˆªæŒ‰é’®
    first_btn = "â®ï¸ First" if lang == 'en' else "â®ï¸ é¦–ä½"
    prev_btn = "â¬…ï¸ Previous" if lang == 'en' else "â¬…ï¸ ä¸Šä¸€ä½"
    next_btn = "â¡ï¸ Next" if lang == 'en' else "â¡ï¸ ä¸‹ä¸€ä½"
    last_btn = "â­ï¸ Last" if lang == 'en' else "â­ï¸ æœ«ä½"
    rand_btn = "ğŸ² Random" if lang == 'en' else "ğŸ² éšæœº"
    first_help = "Jump to first patient" if lang == 'en' else "è·³è½¬åˆ°ç¬¬ä¸€ä½æ‚£è€…"
    prev_help = "Previous patient" if lang == 'en' else "ä¸Šä¸€ä½æ‚£è€…"
    next_help = "Next patient" if lang == 'en' else "ä¸‹ä¸€ä½æ‚£è€…"
    last_help = "Jump to last patient" if lang == 'en' else "è·³è½¬åˆ°æœ€åä¸€ä½æ‚£è€…"
    rand_help = "Random select a patient" if lang == 'en' else "éšæœºé€‰æ‹©ä¸€ä½æ‚£è€…"
    
    nav_cols = st.columns(6)
    with nav_cols[0]:
        if st.button(first_btn, width="stretch", help=first_help):
            st.session_state.patient_view_id = st.session_state.patient_ids[0]
            st.rerun()
    with nav_cols[1]:
        if st.button(prev_btn, width="stretch", help=prev_help):
            current_idx = st.session_state.patient_ids.index(st.session_state.get('patient_view_id', st.session_state.patient_ids[0]))
            if current_idx > 0:
                st.session_state.patient_view_id = st.session_state.patient_ids[current_idx - 1]
                st.rerun()
    with nav_cols[2]:
        if st.button(next_btn, width="stretch", help=next_help):
            current_idx = st.session_state.patient_ids.index(st.session_state.get('patient_view_id', st.session_state.patient_ids[0]))
            if current_idx < len(st.session_state.patient_ids) - 1:
                st.session_state.patient_view_id = st.session_state.patient_ids[current_idx + 1]
                st.rerun()
    with nav_cols[3]:
        if st.button(last_btn, width="stretch", help=last_help):
            st.session_state.patient_view_id = st.session_state.patient_ids[-1]
            st.rerun()
    with nav_cols[4]:
        if st.button(rand_btn, width="stretch", help=rand_help):
            import random
            st.session_state.patient_view_id = random.choice(st.session_state.patient_ids)
            st.rerun()
    with nav_cols[5]:
        # æ˜¾ç¤ºå½“å‰ä½ç½®
        current_idx = st.session_state.patient_ids.index(st.session_state.get('patient_view_id', st.session_state.patient_ids[0]))
        st.markdown(f"<div style='text-align:center;padding:0.5rem;background:rgba(30,40,50,0.6);border-radius:4px'>{current_idx + 1}/{len(st.session_state.patient_ids)}</div>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1, 1, 2])
    
    with col1:
        pat_id_label = "ğŸ‘¤ Patient ID" if lang == 'en' else "ğŸ‘¤ æ‚£è€… ID"
        patient_id = st.selectbox(
            pat_id_label,
            options=st.session_state.patient_ids[:100],
            key="patient_view_id"
        )
    
    with col2:
        view_label = "ğŸ“‹ View Mode" if lang == 'en' else "ğŸ“‹ æ˜¾ç¤ºæ¨¡å¼"
        view_options = ["Dashboard", "Category View", "Data Table"] if lang == 'en' else ["ç»¼åˆä»ªè¡¨ç›˜", "åˆ†ç±»è§†å›¾", "æ•°æ®è¡¨æ ¼"]
        view_mode = st.selectbox(
            view_label,
            options=view_options,
            key="patient_view_mode"
        )
    
    with col3:
        # æ•°æ®æ¦‚è§ˆ - æ˜¾ç¤ºæ›´è¯¦ç»†çš„å¯ç”¨æ•°æ®ä¿¡æ¯
        id_col = st.session_state.id_col
        available_concepts = [k for k, v in st.session_state.loaded_concepts.items() 
                             if isinstance(v, pd.DataFrame) and id_col in v.columns 
                             and patient_id in v[id_col].values]
        n_concepts = len(available_concepts)
        
        # ç»Ÿè®¡å„ç±»åˆ«æ•°æ®
        vitals_list = ['hr', 'map', 'sbp', 'dbp', 'resp', 'temp', 'spo2']
        labs_list = ['bili', 'crea', 'lac', 'plt', 'wbc', 'hgb', 'inr_pt', 'ptt']
        scores_list = ['sofa', 'sofa2', 'qsofa', 'sirs', 'gcs', 'sep3_sofa1', 'sep3_sofa2']
        
        n_vitals = len([c for c in available_concepts if c in vitals_list])
        n_labs = len([c for c in available_concepts if c in labs_list])
        n_scores = len([c for c in available_concepts if c in scores_list])
        
        data_label = "Available Data" if lang == 'en' else "å¯ç”¨æ•°æ®"
        st.markdown(f'''
        <div class="metric-card" style="padding:0.5rem 1rem">
            <div class="stat-label">{data_label}</div>
            <div style="display:flex;gap:1rem;font-size:0.9rem">
                <span>ğŸ“Š {n_concepts} total</span>
                <span>â¤ï¸ {n_vitals} vitals</span>
                <span>ğŸ§ª {n_labs} labs</span>
                <span>ğŸ“ˆ {n_scores} scores</span>
            </div>
        </div>
        ''', unsafe_allow_html=True)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # åˆ¤æ–­è§†å›¾æ¨¡å¼
    dashboard_mode = "Dashboard" if lang == 'en' else "ç»¼åˆä»ªè¡¨ç›˜"
    category_mode = "Category View" if lang == 'en' else "åˆ†ç±»è§†å›¾"
    table_mode = "Data Table" if lang == 'en' else "æ•°æ®è¡¨æ ¼"
    
    if patient_id:
        st.session_state.selected_patient = patient_id
        id_col = st.session_state.id_col
        
        if view_mode == dashboard_mode:
            # è‡ªå®šä¹‰ç»¼åˆä»ªè¡¨ç›˜
            dash_title = "### ğŸ“Š Dashboard" if lang == 'en' else "### ğŸ“Š ç»¼åˆä»ªè¡¨ç›˜"
            st.markdown(dash_title)
            
            try:
                import plotly.graph_objects as go
                from plotly.subplots import make_subplots
                
                # æ”¶é›†æ‰€æœ‰ç”Ÿå‘½ä½“å¾æ•°æ®
                vitals = ['hr', 'map', 'sbp', 'resp', 'spo2']
                vitals_data = {}
                time_candidates = ['time', 'charttime', 'starttime', 'endtime', 'datetime', 'timestamp']
                
                for v in vitals:
                    if v in st.session_state.loaded_concepts:
                        df = st.session_state.loaded_concepts[v]
                        if isinstance(df, pd.DataFrame) and id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                            if len(patient_df) > 0:
                                # æ£€æµ‹æ—¶é—´åˆ—
                                time_col = None
                                for tc in time_candidates:
                                    if tc in patient_df.columns:
                                        time_col = tc
                                        break
                                if time_col:
                                    vitals_data[v] = (patient_df, time_col)
                
                if vitals_data:
                    # åˆ›å»ºå¤šè¡Œå­å›¾
                    n_vitals = len(vitals_data)
                    fig = make_subplots(
                        rows=n_vitals, cols=1,
                        shared_xaxes=True,
                        vertical_spacing=0.05,
                        subplot_titles=[v.upper() for v in vitals_data.keys()]
                    )
                    
                    colors = ['#1f77b4', '#2ca02c', '#ff7f0e', '#d62728', '#9467bd']
                    
                    for i, (name, (df, time_col)) in enumerate(vitals_data.items(), 1):
                        value_col = name if name in df.columns else df.columns[-1]
                        fig.add_trace(
                            go.Scatter(
                                x=df[time_col], y=df[value_col],
                                mode='lines+markers',
                                name=name.upper(),
                                line=dict(color=colors[(i-1) % len(colors)], width=2),
                                marker=dict(size=4)
                            ),
                            row=i, col=1
                        )
                    
                    vitals_title = f"Patient {patient_id} Vital Signs Trend" if lang == 'en' else f"æ‚£è€… {patient_id} ç”Ÿå‘½ä½“å¾è¶‹åŠ¿"
                    fig.update_layout(
                        height=150 * n_vitals + 100,
                        template="plotly_white",
                        showlegend=False,
                        title_text=vitals_title,
                        title_font_size=16,
                        margin=dict(l=50, r=30, t=60, b=50),
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    no_vitals = "â„¹ï¸ No vital signs data available" if lang == 'en' else "â„¹ï¸ æ— å¯ç”¨çš„ç”Ÿå‘½ä½“å¾æ•°æ®"
                    st.info(no_vitals)
                
                # SOFA è¯„åˆ†è¶‹åŠ¿
                if 'sofa' in st.session_state.loaded_concepts:
                    sofa_df = st.session_state.loaded_concepts['sofa']
                    if isinstance(sofa_df, pd.DataFrame) and id_col in sofa_df.columns:
                        patient_sofa = sofa_df[sofa_df[id_col] == patient_id]
                        # æ£€æµ‹æ—¶é—´åˆ—
                        sofa_time_col = None
                        for tc in time_candidates:
                            if tc in patient_sofa.columns:
                                sofa_time_col = tc
                                break
                        
                        if len(patient_sofa) > 0 and sofa_time_col:
                            sofa_trend = "#### ğŸ“ˆ SOFA Score Trend" if lang == 'en' else "#### ğŸ“ˆ SOFA è¯„åˆ†è¶‹åŠ¿"
                            st.markdown(sofa_trend)
                            
                            # SOFA åˆ†è§£å †å å›¾
                            sofa_components = ['sofa_resp', 'sofa_coag', 'sofa_liver', 
                                             'sofa_cardio', 'sofa_cns', 'sofa_renal']
                            available_components = [c for c in sofa_components if c in patient_sofa.columns]
                            
                            if available_components:
                                fig = go.Figure()
                                colors = ['#ff6b6b', '#feca57', '#48dbfb', '#ff9ff3', '#54a0ff', '#5f27cd']
                                
                                for i, comp in enumerate(available_components):
                                    fig.add_trace(go.Bar(
                                        x=patient_sofa[sofa_time_col],
                                        y=patient_sofa[comp],
                                        name=comp.replace('sofa_', '').upper(),
                                        marker_color=colors[i]
                                    ))
                                
                                time_label = "Time" if lang == 'en' else "æ—¶é—´"
                                score_label = "SOFA Score" if lang == 'en' else "SOFA åˆ†æ•°"
                                fig.update_layout(
                                    barmode='stack',
                                    template="plotly_white",
                                    height=350,
                                    xaxis_title=time_label,
                                    yaxis_title=score_label,
                                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="center", x=0.5)
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
                
                # ============ SOFA-1 vs SOFA-2 å¯¹æ¯”å›¾è¡¨ ============
                has_sofa1 = 'sofa' in st.session_state.loaded_concepts
                has_sofa2 = 'sofa2' in st.session_state.loaded_concepts
                
                if has_sofa1 and has_sofa2:
                    compare_title = "#### ğŸ”„ SOFA-1 vs SOFA-2 Comparison" if lang == 'en' else "#### ğŸ”„ SOFA-1 ä¸ SOFA-2 å¯¹æ¯”"
                    st.markdown(compare_title)
                    
                    sofa1_df = st.session_state.loaded_concepts['sofa']
                    sofa2_df = st.session_state.loaded_concepts['sofa2']
                    
                    # è·å–æ‚£è€…æ•°æ®
                    if isinstance(sofa1_df, pd.DataFrame) and id_col in sofa1_df.columns:
                        patient_sofa1 = sofa1_df[sofa1_df[id_col] == patient_id].copy()
                    else:
                        patient_sofa1 = pd.DataFrame()
                    
                    if isinstance(sofa2_df, pd.DataFrame) and id_col in sofa2_df.columns:
                        patient_sofa2 = sofa2_df[sofa2_df[id_col] == patient_id].copy()
                    else:
                        patient_sofa2 = pd.DataFrame()
                    
                    if len(patient_sofa1) > 0 and len(patient_sofa2) > 0:
                        # æ£€æµ‹æ—¶é—´åˆ—
                        time_col1 = None
                        time_col2 = None
                        for tc in time_candidates:
                            if tc in patient_sofa1.columns and time_col1 is None:
                                time_col1 = tc
                            if tc in patient_sofa2.columns and time_col2 is None:
                                time_col2 = tc
                        
                        if time_col1 and time_col2:
                            # 1. æ€»åˆ†å¯¹æ¯”æŠ˜çº¿å›¾
                            total_compare = "**Total Score Comparison**" if lang == 'en' else "**æ€»åˆ†å¯¹æ¯”**"
                            st.markdown(total_compare)
                            
                            fig_total = go.Figure()
                            
                            # SOFA-1 æ€»åˆ†
                            if 'sofa' in patient_sofa1.columns:
                                fig_total.add_trace(go.Scatter(
                                    x=patient_sofa1[time_col1],
                                    y=patient_sofa1['sofa'],
                                    mode='lines+markers',
                                    name='SOFA-1 (Traditional)',
                                    line=dict(color='#1f77b4', width=3),
                                    marker=dict(size=8)
                                ))
                            
                            # SOFA-2 æ€»åˆ†
                            if 'sofa2' in patient_sofa2.columns:
                                fig_total.add_trace(go.Scatter(
                                    x=patient_sofa2[time_col2],
                                    y=patient_sofa2['sofa2'],
                                    mode='lines+markers',
                                    name='SOFA-2 (2025 New)',
                                    line=dict(color='#ff7f0e', width=3, dash='dash'),
                                    marker=dict(size=8, symbol='diamond')
                                ))
                            
                            time_label = "Time (hours from ICU admission)" if lang == 'en' else "æ—¶é—´ (ICUå…¥é™¢åå°æ—¶)"
                            score_label = "Total SOFA Score" if lang == 'en' else "SOFA æ€»åˆ†"
                            fig_total.update_layout(
                                template="plotly_white",
                                height=300,
                                xaxis_title=time_label,
                                yaxis_title=score_label,
                                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="center", x=0.5),
                                hovermode='x unified'
                            )
                            
                            st.plotly_chart(fig_total, use_container_width=True)
                            
                            # 2. å­å™¨å®˜è¯„åˆ†å¯¹æ¯”ï¼ˆ6ä¸ªå­å›¾ï¼‰
                            organ_compare = "**Organ-specific Score Comparison**" if lang == 'en' else "**å„å™¨å®˜è¯„åˆ†å¯¹æ¯”**"
                            st.markdown(organ_compare)
                            
                            # å®šä¹‰å™¨å®˜æ˜ å°„
                            organ_pairs = [
                                ('sofa_resp', 'sofa2_resp', 'Respiratory', 'å‘¼å¸'),
                                ('sofa_coag', 'sofa2_coag', 'Coagulation', 'å‡è¡€'),
                                ('sofa_liver', 'sofa2_liver', 'Liver', 'è‚è„'),
                                ('sofa_cardio', 'sofa2_cardio', 'Cardiovascular', 'å¿ƒè¡€ç®¡'),
                                ('sofa_cns', 'sofa2_cns', 'Neurological', 'ç¥ç»'),
                                ('sofa_renal', 'sofa2_renal', 'Renal', 'è‚¾è„'),
                            ]
                            
                            # ğŸ”§ æ£€æŸ¥å™¨å®˜è¯„åˆ†åˆ—æ˜¯å¦å­˜åœ¨äºå„è‡ªçš„ DataFrame ä¸­
                            # å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•ä»å…¶ä»–åŠ è½½çš„ concepts ä¸­è·å–
                            def get_organ_data(patient_df, organ_col, time_col, loaded_concepts, id_col, patient_id):
                                """è·å–å™¨å®˜è¯„åˆ†æ•°æ®ï¼Œä¼˜å…ˆä» sofa/sofa2 DataFrameï¼Œå¦åˆ™ä»å•ç‹¬åŠ è½½çš„ concept"""
                                try:
                                    if organ_col in patient_df.columns and time_col in patient_df.columns:
                                        return patient_df[[time_col, organ_col]].copy()
                                    # å°è¯•ä»å•ç‹¬åŠ è½½çš„ concept è·å–
                                    if organ_col in loaded_concepts:
                                        organ_df = loaded_concepts[organ_col]
                                        if isinstance(organ_df, pd.DataFrame) and id_col in organ_df.columns:
                                            patient_organ = organ_df[organ_df[id_col] == patient_id].copy()
                                            if len(patient_organ) > 0 and organ_col in patient_organ.columns:
                                                # æ‰¾æ—¶é—´åˆ—
                                                for tc in ['time', 'charttime', 'starttime']:
                                                    if tc in patient_organ.columns:
                                                        return patient_organ[[tc, organ_col]].rename(columns={tc: time_col})
                                except Exception:
                                    pass
                                return None
                            
                            # åˆ›å»º 2x3 å­å›¾
                            from plotly.subplots import make_subplots
                            
                            fig_organs = make_subplots(
                                rows=2, cols=3,
                                subplot_titles=[p[2] if lang == 'en' else p[3] for p in organ_pairs],
                                vertical_spacing=0.15,
                                horizontal_spacing=0.08
                            )
                            
                            has_any_data = False
                            for idx, (sofa1_col, sofa2_col, en_name, zh_name) in enumerate(organ_pairs):
                                row = idx // 3 + 1
                                col = idx % 3 + 1
                                
                                # SOFA-1 å™¨å®˜è¯„åˆ†
                                sofa1_organ = get_organ_data(patient_sofa1, sofa1_col, time_col1, 
                                                            st.session_state.loaded_concepts, id_col, patient_id)
                                if sofa1_organ is not None and len(sofa1_organ) > 0:
                                    has_any_data = True
                                    fig_organs.add_trace(
                                        go.Scatter(
                                            x=sofa1_organ[time_col1],
                                            y=sofa1_organ[sofa1_col],
                                            mode='lines+markers',
                                            name='SOFA-1' if idx == 0 else None,
                                            legendgroup='sofa1',
                                            showlegend=(idx == 0),
                                            line=dict(color='#1f77b4', width=2),
                                            marker=dict(size=5)
                                        ),
                                        row=row, col=col
                                    )
                                
                                # SOFA-2 å™¨å®˜è¯„åˆ†
                                sofa2_organ = get_organ_data(patient_sofa2, sofa2_col, time_col2,
                                                            st.session_state.loaded_concepts, id_col, patient_id)
                                if sofa2_organ is not None and len(sofa2_organ) > 0:
                                    has_any_data = True
                                    fig_organs.add_trace(
                                        go.Scatter(
                                            x=sofa2_organ[time_col2],
                                            y=sofa2_organ[sofa2_col],
                                            mode='lines+markers',
                                            name='SOFA-2' if idx == 0 else None,
                                            legendgroup='sofa2',
                                            showlegend=(idx == 0),
                                            line=dict(color='#ff7f0e', width=2, dash='dash'),
                                            marker=dict(size=5, symbol='diamond')
                                        ),
                                        row=row, col=col
                                    )
                            
                            if has_any_data:
                                fig_organs.update_layout(
                                    height=500,
                                    template="plotly_white",
                                    legend=dict(orientation="h", yanchor="bottom", y=1.08, xanchor="center", x=0.5),
                                    hovermode='x unified'
                                )
                                
                                # æ›´æ–° y è½´èŒƒå›´ (0-4)
                                for i in range(1, 7):
                                    fig_organs.update_yaxes(range=[0, 4.5], row=(i-1)//3+1, col=(i-1)%3+1)
                                
                                st.plotly_chart(fig_organs, use_container_width=True)
                            else:
                                no_organ_msg = "â„¹ï¸ Organ-specific scores not available in current data. Load individual organ concepts (e.g., sofa_resp, sofa2_resp) to see detailed comparison." if lang == 'en' else "â„¹ï¸ å½“å‰æ•°æ®ä¸­æ— æ³•è·å–å™¨å®˜å­è¯„åˆ†ã€‚è¯·åŠ è½½å•ç‹¬çš„å™¨å®˜æ¦‚å¿µï¼ˆå¦‚ sofa_resp, sofa2_respï¼‰ä»¥æŸ¥çœ‹è¯¦ç»†å¯¹æ¯”ã€‚"
                                st.info(no_organ_msg)
                            
                            # 3. å·®å¼‚åˆ†æè¡¨æ ¼
                            diff_title = "**Score Difference (SOFA-2 - SOFA-1)**" if lang == 'en' else "**è¯„åˆ†å·®å¼‚ (SOFA-2 - SOFA-1)**"
                            st.markdown(diff_title)
                            
                            # è®¡ç®—æœ€æ–°æ—¶é—´ç‚¹çš„å·®å¼‚
                            latest_sofa1 = patient_sofa1.iloc[-1] if len(patient_sofa1) > 0 else {}
                            latest_sofa2 = patient_sofa2.iloc[-1] if len(patient_sofa2) > 0 else {}
                            
                            diff_data = []
                            for sofa1_col, sofa2_col, en_name, zh_name in organ_pairs:
                                val1 = latest_sofa1.get(sofa1_col, 0) if isinstance(latest_sofa1, dict) or hasattr(latest_sofa1, 'get') else (latest_sofa1[sofa1_col] if sofa1_col in latest_sofa1.index else 0)
                                val2 = latest_sofa2.get(sofa2_col, 0) if isinstance(latest_sofa2, dict) or hasattr(latest_sofa2, 'get') else (latest_sofa2[sofa2_col] if sofa2_col in latest_sofa2.index else 0)
                                diff = val2 - val1
                                organ_name = en_name if lang == 'en' else zh_name
                                diff_data.append({
                                    'Organ' if lang == 'en' else 'å™¨å®˜': organ_name,
                                    'SOFA-1': int(val1),
                                    'SOFA-2': int(val2),
                                    'Diff' if lang == 'en' else 'å·®å¼‚': int(diff)
                                })
                            
                            # æ€»åˆ†å·®å¼‚
                            total1 = latest_sofa1.get('sofa', 0) if isinstance(latest_sofa1, dict) or hasattr(latest_sofa1, 'get') else (latest_sofa1['sofa'] if 'sofa' in latest_sofa1.index else 0)
                            total2 = latest_sofa2.get('sofa2', 0) if isinstance(latest_sofa2, dict) or hasattr(latest_sofa2, 'get') else (latest_sofa2['sofa2'] if 'sofa2' in latest_sofa2.index else 0)
                            diff_data.append({
                                'Organ' if lang == 'en' else 'å™¨å®˜': '**Total**' if lang == 'en' else '**æ€»åˆ†**',
                                'SOFA-1': int(total1),
                                'SOFA-2': int(total2),
                                'Diff' if lang == 'en' else 'å·®å¼‚': int(total2 - total1)
                            })
                            
                            diff_df = pd.DataFrame(diff_data)
                            st.dataframe(diff_df, width="stretch", hide_index=True)
                    else:
                        no_compare = "â„¹ï¸ Need both SOFA-1 and SOFA-2 data for comparison" if lang == 'en' else "â„¹ï¸ éœ€è¦åŒæ—¶æœ‰ SOFA-1 å’Œ SOFA-2 æ•°æ®æ‰èƒ½å¯¹æ¯”"
                        st.info(no_compare)
                
                # Dashboard å¿«é€Ÿæ‘˜è¦é¢æ¿
                summary_title = "#### ğŸ“‹ Quick Summary" if lang == 'en' else "#### ğŸ“‹ å¿«é€Ÿæ‘˜è¦"
                st.markdown(summary_title)
                
                summary_cols = st.columns(4)
                
                # Sepsis çŠ¶æ€
                with summary_cols[0]:
                    sepsis_status = "Not loaded âšª" if lang == 'en' else "æœªåŠ è½½ âšª"
                    sepsis_color = "#6c757d"
                    
                    found_sep = False
                    if 'sep3_sofa2' in st.session_state.loaded_concepts:
                        sep_df = st.session_state.loaded_concepts['sep3_sofa2']
                        concept_key = 'sep3_sofa2'
                        found_sep = True
                    elif 'sep3_sofa1' in st.session_state.loaded_concepts:
                        sep_df = st.session_state.loaded_concepts['sep3_sofa1']
                        concept_key = 'sep3_sofa1'
                        found_sep = True
                    
                    if found_sep:
                        sepsis_status = "Unknown"
                        if isinstance(sep_df, pd.DataFrame) and id_col in sep_df.columns:
                            patient_sep = sep_df[sep_df[id_col] == patient_id]
                            if len(patient_sep) > 0 and concept_key in patient_sep.columns:
                                if patient_sep[concept_key].max() == 1:
                                    sepsis_status = "Sepsis âš ï¸" if lang == 'en' else "è„“æ¯’ç—‡ âš ï¸"
                                    sepsis_color = "#dc3545"
                                else:
                                    sepsis_status = "No Sepsis âœ…" if lang == 'en' else "æ— è„“æ¯’ç—‡ âœ…"
                                    sepsis_color = "#28a745"
                            else:
                                sepsis_status = "No Records" if lang == 'en' else "æ— è®°å½•"

                    st.markdown(f"**Sepsis-3**" if lang == 'en' else f"**è„“æ¯’ç—‡-3**")
                    st.markdown(f"<span style='color:{sepsis_color};font-weight:bold'>{sepsis_status}</span>", unsafe_allow_html=True)
                
                # æœºæ¢°é€šæ°”
                with summary_cols[1]:
                    vent_status = "Not loaded âšª" if lang == 'en' else "æœªåŠ è½½ âšª"
                    vent_concepts = ['vent_ind', 'mech_vent', 'vent_start']
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³ concept è¢«åŠ è½½
                    found_vent = any(c in st.session_state.loaded_concepts for c in vent_concepts)
                    
                    if found_vent:
                        vent_status = "Unknown"
                        if 'vent_ind' in st.session_state.loaded_concepts:
                            vent_df = st.session_state.loaded_concepts['vent_ind']
                            if isinstance(vent_df, pd.DataFrame) and id_col in vent_df.columns:
                                patient_vent = vent_df[vent_df[id_col] == patient_id]
                                if len(patient_vent) > 0 and 'vent_ind' in patient_vent.columns:
                                    vent_status = "Yes âœ…" if patient_vent['vent_ind'].max() == 1 else "No âŒ"
                                else:
                                    vent_status = "No Records" if lang == 'en' else "æ— è®°å½•"
                    
                    st.markdown(f"**Mechanical Vent**" if lang == 'en' else f"**æœºæ¢°é€šæ°”**")
                    st.markdown(vent_status)
                
                # è¡€ç®¡æ´»æ€§è¯ç‰©
                with summary_cols[2]:
                    vaso_status = "Not loaded âšª" if lang == 'en' else "æœªåŠ è½½ âšª"
                    vaso_concepts = ['norepi_rate', 'epi_rate', 'dopa_rate', 'vaso_ind']
                    
                    found_vaso = any(c in st.session_state.loaded_concepts for c in vaso_concepts)
                    
                    if found_vaso:
                        vaso_status = "No âŒ"
                        for vc in vaso_concepts:
                            if vc in st.session_state.loaded_concepts:
                                vdf = st.session_state.loaded_concepts[vc]
                                if isinstance(vdf, pd.DataFrame) and id_col in vdf.columns:
                                    pvdf = vdf[vdf[id_col] == patient_id]
                                    if len(pvdf) > 0:
                                        val_col = vc if vc in pvdf.columns else pvdf.columns[-1]
                                        if pvdf[val_col].max() > 0:
                                            vaso_status = "Yes âœ…"
                                            break
                    
                    st.markdown(f"**Vasopressors**" if lang == 'en' else f"**è¡€ç®¡æ´»æ€§è¯**")
                    st.markdown(vaso_status)
                
                # GCS
                with summary_cols[3]:
                    gcs_val = "Not loaded" if lang == 'en' else "æœªåŠ è½½"
                    gcs_color = "#6c757d"
                    
                    if 'gcs' in st.session_state.loaded_concepts:
                        gcs_val = "N/A"
                        gcs_df = st.session_state.loaded_concepts['gcs']
                        if isinstance(gcs_df, pd.DataFrame) and id_col in gcs_df.columns:
                            patient_gcs = gcs_df[gcs_df[id_col] == patient_id]
                            if len(patient_gcs) > 0 and 'gcs' in patient_gcs.columns:
                                val = patient_gcs['gcs'].iloc[-1]
                                try:
                                    val_num = float(val)
                                    gcs_color = "#28a745" if val_num >= 13 else ("#ffc107" if val_num >= 9 else "#dc3545")
                                    gcs_val = safe_format_number(val_num, 0)
                                except (ValueError, TypeError):
                                    gcs_val = str(val)
                                    gcs_color = "#6c757d"
                            else:
                                gcs_val = "No Records" if lang == 'en' else "æ— è®°å½•"
                    # å°è¯•ä» sofa_cns æ¨æ–­
                    elif 'sofa_cns' in st.session_state.loaded_concepts or 'sofa2_cns' in st.session_state.loaded_concepts:
                        cns_col = 'sofa_cns' if 'sofa_cns' in st.session_state.loaded_concepts else 'sofa2_cns'
                        cns_df = st.session_state.loaded_concepts[cns_col]
                        if isinstance(cns_df, pd.DataFrame) and id_col in cns_df.columns:
                            patient_cns = cns_df[cns_df[id_col] == patient_id]
                            if len(patient_cns) > 0 and cns_col in patient_cns.columns:
                                cns_score = patient_cns[cns_col].iloc[-1]
                                # 0:15, 1:13-14, 2:10-12, 3:6-9, 4:<6
                                if cns_score == 0: gcs_val, gcs_color = "15 (est)", "#28a745"
                                elif cns_score == 1: gcs_val, gcs_color = "13-14 (est)", "#28a745"
                                elif cns_score == 2: gcs_val, gcs_color = "10-12 (est)", "#ffc107"
                                elif cns_score == 3: gcs_val, gcs_color = "6-9 (est)", "#dc3545"
                                elif cns_score == 4: gcs_val, gcs_color = "<6 (est)", "#dc3545"
                    
                    st.markdown("**GCS**")
                    st.markdown(f"<span style='color:{gcs_color};font-weight:bold;font-size:1.2rem'>{gcs_val}</span>", unsafe_allow_html=True)
                            
            except Exception as e:
                err_msg = f"Dashboard rendering failed: {e}" if lang == 'en' else f"ç»¼åˆä»ªè¡¨ç›˜æ¸²æŸ“å¤±è´¥: {e}"
                st.warning(err_msg)
                switch_msg = "Please try switching to 'Category View'" if lang == 'en' else "è¯·å°è¯•åˆ‡æ¢åˆ°ã€Œåˆ†ç±»è§†å›¾ã€"
                st.info(switch_msg)
        
        elif view_mode == category_mode:
            # æ—¶é—´åˆ—å€™é€‰ï¼ˆæå‰å®šä¹‰ï¼Œé¿å…UnboundLocalErrorï¼‰
            time_candidates = ['time', 'charttime', 'starttime', 'endtime', 'datetime', 'timestamp']
            
            # ç”Ÿå‘½ä½“å¾
            vitals_title = "### â¤ï¸ Vital Signs" if lang == 'en' else "### â¤ï¸ ç”Ÿå‘½ä½“å¾"
            st.markdown(vitals_title)
            vitals = ['hr', 'map', 'sbp', 'resp', 'temp', 'spo2']
            vitals_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                          if k in vitals and isinstance(v, pd.DataFrame)}
            
            if vitals_data:
                cols = st.columns(min(3, len(vitals_data)))
                
                for i, (concept, df) in enumerate(vitals_data.items()):
                    with cols[i % 3]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            # æ˜¾ç¤ºæœ€æ–°å€¼
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            latest_val = patient_df[value_col].iloc[-1]
                            st.metric(concept.upper(), safe_format_number(latest_val, 1))
                            
                            # å°å‹è¶‹åŠ¿å›¾ - æ£€æµ‹æ—¶é—´åˆ—
                            time_col = None
                            for tc in time_candidates:
                                if tc in patient_df.columns:
                                    time_col = tc
                                    break
                            if time_col:
                                st.line_chart(patient_df.set_index(time_col)[value_col], height=120)
            else:
                no_vitals = "â„¹ï¸ No vital signs data available" if lang == 'en' else "â„¹ï¸ æ— å¯ç”¨çš„ç”Ÿå‘½ä½“å¾æ•°æ®"
                st.info(no_vitals)
            
            # SOFA/SOFA2 è¯„åˆ†
            sofa_concepts = ['sofa', 'sofa2']
            sofa_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                        if k in sofa_concepts and isinstance(v, pd.DataFrame)}
            
            if sofa_data:
                sofa_title = "### ğŸ“Š SOFA Score" if lang == 'en' else "### ğŸ“Š SOFA è¯„åˆ†"
                st.markdown(sofa_title)
                
                for sofa_key, sofa_df in sofa_data.items():
                    if id_col in sofa_df.columns:
                        patient_sofa = sofa_df[sofa_df[id_col] == patient_id]
                    else:
                        patient_sofa = sofa_df
                    
                    if len(patient_sofa) > 0:
                        latest = patient_sofa.iloc[-1]
                        col1, col2 = st.columns([1, 2])
                        with col1:
                            sofa_val = latest.get(sofa_key, 0)
                            sofa_color = "#28a745" if sofa_val < 6 else ("#ffc107" if sofa_val < 10 else "#dc3545")
                            label = f"Latest {sofa_key.upper()}" if lang == 'en' else f"æœ€æ–° {sofa_key.upper()}"
                            st.markdown(f'''
                            <div class="metric-card" style="text-align:center">
                                <div class="stat-label">{label}</div>
                                <div class="stat-number" style="color:{sofa_color}">{sofa_val}</div>
                            </div>
                            ''', unsafe_allow_html=True)
                        
                        with col2:
                            sofa_time_col = None
                            for tc in time_candidates:
                                if tc in patient_sofa.columns:
                                    sofa_time_col = tc
                                    break
                            if sofa_key in patient_sofa.columns and sofa_time_col:
                                st.line_chart(patient_sofa.set_index(sofa_time_col)[sofa_key], height=150)
            
            # Sepsis-3 è¯Šæ–­çŠ¶æ€
            sepsis_concepts = ['sep3_sofa1', 'sep3_sofa2', 'susp_inf', 'infection_icd']
            sepsis_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                          if k in sepsis_concepts and isinstance(v, pd.DataFrame)}
            
            if sepsis_data:
                sepsis_title = "### ğŸ¦  Sepsis-3 Status" if lang == 'en' else "### ğŸ¦  Sepsis-3 è¯Šæ–­"
                st.markdown(sepsis_title)
                cols = st.columns(len(sepsis_data))
                for i, (concept, df) in enumerate(sepsis_data.items()):
                    with cols[i]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            val = patient_df[value_col].iloc[-1] if len(patient_df) > 0 else 0
                            if val == 1:
                                st.markdown(f"âœ… **{concept}**: Yes" if lang == 'en' else f"âœ… **{concept}**: æ˜¯")
                            else:
                                st.markdown(f"âŒ **{concept}**: No" if lang == 'en' else f"âŒ **{concept}**: å¦")
            
            # å®éªŒå®¤æ£€æŸ¥ - æ‰©å±•æ›´å¤šæŒ‡æ ‡
            labs = ['bili', 'crea', 'lac', 'lact', 'plt', 'wbc', 'hgb', 'hct', 'inr_pt', 'ptt', 'alb', 'glu', 'na', 'k', 'cl', 'bun']
            labs_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                        if k in labs and isinstance(v, pd.DataFrame)}
            
            if labs_data:
                labs_title = "### ğŸ§ª Laboratory Tests" if lang == 'en' else "### ğŸ§ª å®éªŒå®¤æ£€æŸ¥"
                st.markdown(labs_title)
                cols = st.columns(min(4, len(labs_data)))
                for i, (concept, df) in enumerate(labs_data.items()):
                    with cols[i % 4]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            st.metric(
                                label=concept.upper(),
                                value=f"{patient_df[value_col].iloc[-1]:.2f}",
                                delta=f"{patient_df[value_col].iloc[-1] - patient_df[value_col].iloc[0]:.2f}" if len(patient_df) > 1 else None
                            )
                            lab_time_col = None
                            for tc in time_candidates:
                                if tc in patient_df.columns:
                                    lab_time_col = tc
                                    break
                            if lab_time_col:
                                st.line_chart(patient_df.set_index(lab_time_col)[value_col], height=120)
            
            # è¡€æ°”åˆ†æ
            blood_gas = ['ph', 'pco2', 'po2', 'pafi', 'safi', 'be', 'hco3', 'bicar', 'fio2']
            bg_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                      if k in blood_gas and isinstance(v, pd.DataFrame)}
            
            if bg_data:
                bg_title = "### ğŸ©¸ Blood Gas Analysis" if lang == 'en' else "### ğŸ©¸ è¡€æ°”åˆ†æ"
                st.markdown(bg_title)
                cols = st.columns(min(4, len(bg_data)))
                for i, (concept, df) in enumerate(bg_data.items()):
                    with cols[i % 4]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            st.metric(label=concept.upper(), value=f"{patient_df[value_col].iloc[-1]:.2f}")
            
            # è¡€ç®¡æ´»æ€§è¯ç‰©
            vasopressors = ['norepi_rate', 'epi_rate', 'dopa_rate', 'dobu_rate', 'adh_rate', 'phn_rate', 'vaso_ind']
            vaso_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                        if k in vasopressors and isinstance(v, pd.DataFrame)}
            
            if vaso_data:
                vaso_title = "### ğŸ’‰ Vasopressors" if lang == 'en' else "### ğŸ’‰ è¡€ç®¡æ´»æ€§è¯ç‰©"
                st.markdown(vaso_title)
                cols = st.columns(min(4, len(vaso_data)))
                for i, (concept, df) in enumerate(vaso_data.items()):
                    with cols[i % 4]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            if concept == 'vaso_ind':
                                val = patient_df[value_col].max()
                                st.markdown(f"**{concept}**: {'Yes âœ…' if val == 1 else 'No âŒ'}")
                            else:
                                st.metric(label=concept.upper(), value=f"{patient_df[value_col].iloc[-1]:.3f}")
                                vaso_time_col = None
                                for tc in time_candidates:
                                    if tc in patient_df.columns:
                                        vaso_time_col = tc
                                        break
                                if vaso_time_col:
                                    st.line_chart(patient_df.set_index(vaso_time_col)[value_col], height=100)
            
            # å‘¼å¸æ”¯æŒ
            resp_support = ['vent_ind', 'fio2', 'spo2', 'pafi', 'safi', 'resp']
            resp_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                        if k in resp_support and isinstance(v, pd.DataFrame) and k not in bg_data}  # é¿å…é‡å¤
            
            if resp_data:
                resp_title = "### ğŸ’¨ Respiratory Support" if lang == 'en' else "### ğŸ’¨ å‘¼å¸æ”¯æŒ"
                st.markdown(resp_title)
                cols = st.columns(min(4, len(resp_data)))
                for i, (concept, df) in enumerate(resp_data.items()):
                    with cols[i % 4]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            if concept == 'vent_ind':
                                val = patient_df[value_col].max()
                                st.markdown(f"**Mechanical Vent**: {'Yes âœ…' if val == 1 else 'No âŒ'}" if lang == 'en' else f"**æœºæ¢°é€šæ°”**: {'æ˜¯ âœ…' if val == 1 else 'å¦ âŒ'}")
                            else:
                                st.metric(label=concept.upper(), value=safe_format_number(patient_df[value_col].iloc[-1], 1))
            
            # ç¥ç»ç³»ç»Ÿ
            neuro = ['gcs', 'egcs', 'mgcs', 'vgcs', 'rass', 'avpu']
            neuro_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                         if k in neuro and isinstance(v, pd.DataFrame)}
            
            if neuro_data:
                neuro_title = "### ğŸ§  Neurological" if lang == 'en' else "### ğŸ§  ç¥ç»ç³»ç»Ÿ"
                st.markdown(neuro_title)
                cols = st.columns(min(4, len(neuro_data)))
                for i, (concept, df) in enumerate(neuro_data.items()):
                    with cols[i % 4]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            val = patient_df[value_col].iloc[-1]
                            # GCS é¢œè‰²ç¼–ç 
                            if concept == 'gcs':
                                try:
                                    val_num = float(val)
                                    color = "#28a745" if val_num >= 13 else ("#ffc107" if val_num >= 9 else "#dc3545")
                                    st.markdown(f"<div style='color:{color};font-size:1.5rem;font-weight:bold'>GCS: {safe_format_number(val_num, 0)}</div>", unsafe_allow_html=True)
                                except (ValueError, TypeError):
                                    st.markdown(f"<div style='font-size:1.5rem;font-weight:bold'>GCS: {val}</div>", unsafe_allow_html=True)
                            else:
                                st.metric(label=concept.upper(), value=safe_format_number(val, 0))
            
            # è‚¾è„åŠŸèƒ½
            renal = ['urine', 'urine24', 'crea', 'bun', 'rrt']
            renal_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                         if k in renal and isinstance(v, pd.DataFrame) and k not in labs_data}
            
            if renal_data:
                renal_title = "### ğŸš° Renal Function" if lang == 'en' else "### ğŸš° è‚¾è„åŠŸèƒ½"
                st.markdown(renal_title)
                cols = st.columns(min(4, len(renal_data)))
                for i, (concept, df) in enumerate(renal_data.items()):
                    with cols[i % 4]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            if concept == 'rrt':
                                val = patient_df[value_col].max()
                                st.markdown(f"**RRT**: {'Yes âœ…' if val == 1 else 'No âŒ'}")
                            else:
                                st.metric(label=concept.upper(), value=safe_format_number(patient_df[value_col].iloc[-1], 1))
            
            # å…¶ä»–è¯„åˆ†
            other_scores = ['qsofa', 'sirs', 'mews', 'news']
            score_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                         if k in other_scores and isinstance(v, pd.DataFrame)}
            
            if score_data:
                score_title = "### ğŸ“ˆ Other Scores" if lang == 'en' else "### ğŸ“ˆ å…¶ä»–è¯„åˆ†"
                st.markdown(score_title)
                cols = st.columns(min(4, len(score_data)))
                for i, (concept, df) in enumerate(score_data.items()):
                    with cols[i % 4]:
                        if id_col in df.columns:
                            patient_df = df[df[id_col] == patient_id]
                        else:
                            patient_df = df
                        
                        if len(patient_df) > 0:
                            value_col = concept if concept in patient_df.columns else patient_df.columns[-1]
                            st.metric(label=concept.upper(), value=safe_format_number(patient_df[value_col].iloc[-1], 0))
        
        elif view_mode == table_mode:
            table_title = "### ğŸ“‹ Patient Data Table" if lang == 'en' else "### ğŸ“‹ æ‚£è€…æ•°æ®è¡¨æ ¼"
            st.markdown(table_title)
            for concept, df in st.session_state.loaded_concepts.items():
                if id_col in df.columns:
                    patient_df = df[df[id_col] == patient_id]
                else:
                    patient_df = df
                
                if len(patient_df) > 0:
                    records_label = "records" if lang == 'en' else "æ¡è®°å½•"
                    with st.expander(f"{concept} ({len(patient_df)} {records_label})", expanded=False):
                        st.dataframe(patient_df, width="stretch")


def render_data_table_subtab():
    """æ¸²æŸ“æ•°æ®å¤§è¡¨å­æ¨¡å— - è®©ç”¨æˆ·æŒ‰æ¨¡å—æŸ¥çœ‹å·²åŠ è½½çš„æ•°æ®ã€‚"""
    lang = st.session_state.get('language', 'en')
    
    page_title = "ğŸ“‹ Data Tables Explorer" if lang == 'en' else "ğŸ“‹ æ•°æ®å¤§è¡¨æµè§ˆ"
    st.markdown(f"## {page_title}")
    
    page_desc = "Browse and explore your loaded data by module. Select a module to view the complete data table." if lang == 'en' else "æŒ‰æ¨¡å—æµè§ˆå’Œæ¢ç´¢å·²åŠ è½½çš„æ•°æ®ã€‚é€‰æ‹©ä¸€ä¸ªæ¨¡å—æŸ¥çœ‹å®Œæ•´æ•°æ®è¡¨ã€‚"
    st.caption(page_desc)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    if len(st.session_state.loaded_concepts) == 0:
        no_data_msg = "Please load data first in the settings above." if lang == 'en' else "è¯·å…ˆåœ¨ä¸Šæ–¹è®¾ç½®ä¸­åŠ è½½æ•°æ®ã€‚"
        st.warning(no_data_msg)
        return
    
    # æŒ‰æ¨¡å—åˆ†ç»„å·²åŠ è½½çš„æ¦‚å¿µ
    concept_groups = get_concept_groups()
    
    # ğŸ”§ FIX (2026-02-12): ä½¿ç”¨å†…éƒ¨åˆ†ç»„å®šä¹‰æ¥æ„å»ºæ˜ å°„
    # ç”±äºåˆ—åå·²åœ¨ load_from_exported() ä¸­è§„èŒƒåŒ–ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨åˆ—åæŸ¥æ‰¾åˆ†ç»„
    concept_to_group = {}
    for group_key, concepts in CONCEPT_GROUPS_INTERNAL.items():
        # è·å–æ˜¾ç¤ºåç§°
        display_name = CONCEPT_GROUP_NAMES.get(group_key, (group_key, group_key))
        group_display = display_name[0] if lang == 'en' else display_name[1]
        
        for c in concepts:
            if c not in concept_to_group:
                concept_to_group[c] = group_display
    
    # ğŸ”§ FIX (2026-02-12): åˆ—åå·²åœ¨ load_from_exported() ä¸­è§„èŒƒåŒ–å¹¶å»é‡
    # æ¯ä¸ªåˆ—å°±æ˜¯ä¸€ä¸ªå”¯ä¸€çš„ conceptï¼Œç›´æ¥åˆ†ç»„å³å¯
    loaded_by_module = {}
    
    for column_name in st.session_state.loaded_concepts.keys():
        # ä½¿ç”¨åˆ—åæŸ¥æ‰¾åˆ†ç»„ï¼ˆåˆ—åå·²ç»æ˜¯è§„èŒƒåŒ–åçš„ï¼‰
        group = concept_to_group.get(column_name)
        if group:
            if group not in loaded_by_module:
                loaded_by_module[group] = []
            loaded_by_module[group].append(column_name)
    
    # ğŸ”§ FIX (2026-02-12): Features = Concepts = åˆ—æ•°ï¼ˆå·²å»é‡ï¼‰
    unique_feature_count = len(st.session_state.loaded_concepts)
    
    # æ˜¾ç¤ºæ¨¡å—ç»Ÿè®¡
    stats_cols = st.columns(4)
    with stats_cols[0]:
        modules_label = "Modules" if lang == 'en' else "æ¨¡å—æ•°"
        st.metric(modules_label, len(loaded_by_module))
    with stats_cols[1]:
        features_label = "Features" if lang == 'en' else "ç‰¹å¾æ•°"
        st.metric(features_label, unique_feature_count)  # ğŸ”§ ä½¿ç”¨å»é‡åçš„æ•°é‡
    with stats_cols[2]:
        patients_label = "Patients" if lang == 'en' else "æ‚£è€…æ•°"
        st.metric(patients_label, len(st.session_state.patient_ids) if st.session_state.patient_ids else 0)
    with stats_cols[3]:
        total_rows = sum(
            len(df) for df in st.session_state.loaded_concepts.values() 
            if isinstance(df, pd.DataFrame)
        )
        rows_label = "Total Rows" if lang == 'en' else "æ€»è¡Œæ•°"
        st.metric(rows_label, f"{total_rows:,}")
    
    st.markdown("---")
    
    # æ¨¡å—é€‰æ‹©å™¨ - ğŸ”§ æ”¾å¤§æ ‡é¢˜
    module_select_label = "Select Module to View" if lang == 'en' else "é€‰æ‹©è¦æŸ¥çœ‹çš„æ¨¡å—"
    st.markdown(f"### ğŸ“¦ {module_select_label}")
    module_options = list(loaded_by_module.keys())
    
    if not module_options:
        no_module_msg = "No modules found in loaded data." if lang == 'en' else "åŠ è½½çš„æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å—ã€‚"
        st.info(no_module_msg)
        return
    
    selected_module = st.selectbox(
        "Select Module",
        options=module_options,
        key="data_table_module_select",
        label_visibility="collapsed"
    )
    
    if selected_module:
        module_concepts = loaded_by_module[selected_module]
        
        # æ˜¾ç¤ºè¯¥æ¨¡å—åŒ…å«çš„ç‰¹å¾
        features_in_module = f"**Features in this module ({len(module_concepts)}):** " + ", ".join(sorted(module_concepts))
        st.markdown(features_in_module)
        
        st.markdown("---")
        
        # ç‰¹å¾é€‰æ‹©å™¨ï¼ˆå•é€‰æˆ–å¤šé€‰åˆå¹¶ï¼‰- é»˜è®¤åˆå¹¶å…¨éƒ¨æ”¾ç¬¬ä¸€ä¸ª
        # ğŸ”§ æ”¾å¤§æ ‡é¢˜
        view_mode_label = "View Mode" if lang == 'en' else "æŸ¥çœ‹æ¨¡å¼"
        st.markdown(f"### ğŸ‘ï¸ {view_mode_label}")
        view_modes = ["Merge All (Wide Table)", "Single Feature"] if lang == 'en' else ["åˆå¹¶å…¨éƒ¨ï¼ˆå®½è¡¨ï¼‰", "å•ä¸ªç‰¹å¾"]
        
        view_mode = st.radio("View Mode", view_modes, horizontal=True, key="data_table_view_mode", index=0, label_visibility="collapsed")
        
        if view_mode == view_modes[1]:
            # å•ä¸ªç‰¹å¾æ¨¡å¼ (ç°åœ¨æ˜¯ç¬¬äºŒä¸ªé€‰é¡¹)
            feature_select_label = "Select Feature" if lang == 'en' else "é€‰æ‹©ç‰¹å¾"
            selected_feature = st.selectbox(
                feature_select_label,
                options=sorted(module_concepts),
                key="data_table_feature_select"
            )
            
            if selected_feature and selected_feature in st.session_state.loaded_concepts:
                df = st.session_state.loaded_concepts[selected_feature]
                
                if isinstance(df, pd.DataFrame) and len(df) > 0:
                    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        rows_label = "Rows" if lang == 'en' else "è¡Œæ•°"
                        st.metric(rows_label, f"{len(df):,}")
                    with col2:
                        cols_label = "Columns" if lang == 'en' else "åˆ—æ•°"
                        st.metric(cols_label, len(df.columns))
                    with col3:
                        size_kb = df.memory_usage(deep=True).sum() / 1024
                        size_label = "Memory" if lang == 'en' else "å†…å­˜å ç”¨"
                        st.metric(size_label, f"{size_kb:.1f} KB")
                    
                    # æ˜¾ç¤ºåˆ—ä¿¡æ¯
                    cols_info_label = "Columns" if lang == 'en' else "åˆ—ä¿¡æ¯"
                    with st.expander(f"ğŸ“Š {cols_info_label}: {', '.join(df.columns.tolist())}", expanded=False):
                        col_info = pd.DataFrame({
                            'Column': df.columns,
                            'Type': [str(df[c].dtype) for c in df.columns],
                            'Non-Null': [df[c].notna().sum() for c in df.columns],
                            'Null %': [f"{df[c].isna().mean()*100:.1f}%" for c in df.columns]
                        })
                        st.dataframe(col_info, hide_index=True, use_container_width=True)
                    
                    # æ˜¾ç¤ºæ•°æ®è¡¨
                    st.markdown("---")
                    table_title = f"ğŸ“‹ {selected_feature} Data Table" if lang == 'en' else f"ğŸ“‹ {selected_feature} æ•°æ®è¡¨"
                    st.markdown(f"### {table_title}")
                    
                    # æ·»åŠ æœç´¢/è¿‡æ»¤é€‰é¡¹
                    filter_expander_label = "ğŸ” Filter Options" if lang == 'en' else "ğŸ” è¿‡æ»¤é€‰é¡¹"
                    with st.expander(filter_expander_label, expanded=False):
                        # æ‚£è€…è¿‡æ»¤
                        id_col = st.session_state.get('id_col', 'stay_id')
                        if id_col in df.columns:
                            unique_ids = df[id_col].unique().tolist()
                            filter_patient_label = "Filter by Patient ID" if lang == 'en' else "æŒ‰æ‚£è€…IDè¿‡æ»¤"
                            selected_ids = st.multiselect(
                                filter_patient_label,
                                options=unique_ids[:100],  # æœ€å¤šæ˜¾ç¤º100ä¸ªé€‰é¡¹
                                default=[],
                                key=f"filter_ids_{selected_feature}"
                            )
                            if selected_ids:
                                df = df[df[id_col].isin(selected_ids)]
                        
                        # è¡Œæ•°é™åˆ¶
                        max_rows_label = "Max rows to display" if lang == 'en' else "æœ€å¤§æ˜¾ç¤ºè¡Œæ•°"
                        max_rows = st.slider(max_rows_label, 100, 10000, 1000, step=100, key=f"max_rows_{selected_feature}")
                    
                    # æ˜¾ç¤ºæ•°æ®ï¼ˆé™åˆ¶è¡Œæ•°ä»¥é˜²å¡é¡¿ï¼‰
                    display_df = df.head(max_rows) if len(df) > max_rows else df
                    # ğŸ”§ FIX: å°†å¸ƒå°”åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²"True"/"False"æ˜¾ç¤ºï¼Œè€Œéå¤é€‰æ¡†å›¾æ ‡
                    display_df = display_df.copy()
                    converted_cols = []
                    for col in display_df.columns:
                        dtype_str = str(display_df[col].dtype).lower()
                        if 'bool' in dtype_str:
                            display_df[col] = display_df[col].astype(str)
                            converted_cols.append(col)
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºè½¬æ¢ä¿¡æ¯
                    if converted_cols:
                        st.caption(f"ğŸ”§ DEBUG: å·²å°†å¸ƒå°”åˆ— {converted_cols} è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ˜¾ç¤º")
                    st.dataframe(display_df, use_container_width=True, height=500)
                    
                    if len(df) > max_rows:
                        truncate_msg = f"âš ï¸ Showing first {max_rows:,} of {len(df):,} rows. Adjust 'Max rows' in Filter Options to see more." if lang == 'en' else f"âš ï¸ æ˜¾ç¤ºå‰ {max_rows:,} è¡Œï¼ˆå…± {len(df):,} è¡Œï¼‰ã€‚åœ¨è¿‡æ»¤é€‰é¡¹ä¸­è°ƒæ•´æœ€å¤§è¡Œæ•°å¯æŸ¥çœ‹æ›´å¤šã€‚"
                        st.caption(truncate_msg)
                    # ä¸æä¾›ä¸‹è½½æŒ‰é’®ï¼Œå› ä¸ºæ•°æ®æ˜¯ç”¨æˆ·å¯¼å…¥çš„
                else:
                    empty_msg = f"No data available for {selected_feature}" if lang == 'en' else f"{selected_feature} æ²¡æœ‰å¯ç”¨æ•°æ®"
                    st.info(empty_msg)
        
        else:
            # åˆå¹¶å…¨éƒ¨æ¨¡å¼ï¼ˆå®½è¡¨ï¼‰
            merge_info = "Merging all features in this module into a wide table (joined by patient ID and time)" if lang == 'en' else "å°†è¯¥æ¨¡å—çš„æ‰€æœ‰ç‰¹å¾åˆå¹¶ä¸ºå®½è¡¨ï¼ˆæŒ‰æ‚£è€…IDå’Œæ—¶é—´è¿æ¥ï¼‰"
            st.info(f"â„¹ï¸ {merge_info}")
            
            # ğŸ”§ æ·»åŠ é‡‡æ ·é€‰é¡¹ï¼Œé¿å…å¤§æ•°æ®é‡åˆå¹¶è¶…æ—¶
            sample_col1, sample_col2 = st.columns([3, 1])
            with sample_col1:
                sample_hint = "Large datasets will be sampled for performance" if lang == 'en' else "å¤§æ•°æ®é›†å°†è¢«é‡‡æ ·ä»¥ä¿è¯æ€§èƒ½"
                st.caption(f"ğŸ’¡ {sample_hint}")
            with sample_col2:
                max_rows_per_feature = st.selectbox(
                    "Max rows" if lang == 'en' else "æœ€å¤§è¡Œæ•°",
                    options=[1000, 2000, 5000, 10000],
                    index=1,
                    key="merge_max_rows"
                )
            
            # æ”¶é›†è¯¥æ¨¡å—çš„æ‰€æœ‰æ•°æ®
            dfs_to_merge = []
            id_col = st.session_state.get('id_col', 'stay_id')
            time_col = st.session_state.get('time_col', 'time')
            
            for concept_name in module_concepts:
                if concept_name in st.session_state.loaded_concepts:
                    df = st.session_state.loaded_concepts[concept_name]
                    if isinstance(df, pd.DataFrame) and len(df) > 0:
                        # é‡å‘½åå€¼åˆ—ä¸ºæ¦‚å¿µå
                        df_copy = df.copy()
                        value_cols = [c for c in df_copy.columns if c not in [id_col, time_col, 'charttime']]
                        if len(value_cols) == 1 and value_cols[0] != concept_name:
                            df_copy = df_copy.rename(columns={value_cols[0]: concept_name})
                        dfs_to_merge.append(df_copy)
            
            if len(dfs_to_merge) == 0:
                no_data_msg = "No data to merge in this module." if lang == 'en' else "è¯¥æ¨¡å—æ²¡æœ‰å¯åˆå¹¶çš„æ•°æ®ã€‚"
                st.warning(no_data_msg)
            elif len(dfs_to_merge) == 1:
                merged_df = dfs_to_merge[0]
                display_merged = merged_df.head(1000).copy()
                # ğŸ”§ FIX: å°†å¸ƒå°”åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²"True"/"False"æ˜¾ç¤º
                for col in display_merged.columns:
                    dtype_str = str(display_merged[col].dtype).lower()
                    if 'bool' in dtype_str:
                        display_merged[col] = display_merged[col].astype(str)
                st.dataframe(display_merged, use_container_width=True, height=500)
            else:
                # ä½¿ç”¨ reduce merge
                from functools import reduce
                
                # æ™ºèƒ½æ£€æµ‹åˆå¹¶åˆ—ï¼šæ£€æŸ¥æ‰€æœ‰ DataFrame å…±æœ‰çš„åˆ—
                # å¯èƒ½çš„æ—¶é—´åˆ—
                time_col_candidates = ['charttime', 'time', 'datetime', 'measuredat', 'starttime']
                
                # æ‰¾åˆ°æ‰€æœ‰ DataFrame å…±æœ‰çš„åˆ—
                common_cols = set(dfs_to_merge[0].columns)
                for df_check in dfs_to_merge[1:]:
                    common_cols &= set(df_check.columns)
                
                # ç¡®å®šåˆå¹¶åˆ—
                merge_cols = []
                if id_col in common_cols:
                    merge_cols.append(id_col)
                
                # æ£€æµ‹å…±æœ‰çš„æ—¶é—´åˆ—
                time_col_found = None
                for tc in time_col_candidates:
                    if tc in common_cols:
                        time_col_found = tc
                        merge_cols.append(tc)
                        break
                
                # å¦‚æœæ²¡æœ‰å…±åŒæ—¶é—´åˆ—ï¼Œåªä½¿ç”¨ ID åˆå¹¶
                if len(merge_cols) == 0:
                    # å®Œå…¨æ²¡æœ‰å…±åŒåˆ—ï¼Œæ— æ³•åˆå¹¶
                    no_common_msg = "Cannot merge: no common columns found across features." if lang == 'en' else "æ— æ³•åˆå¹¶ï¼šç‰¹å¾é—´æ²¡æœ‰å…±åŒåˆ—ã€‚"
                    st.warning(no_common_msg)
                else:
                    try:
                        merging_msg = "Merging data..." if lang == 'en' else "æ­£åœ¨åˆå¹¶æ•°æ®..."
                        with st.spinner(merging_msg):
                            # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æœ€å¤§è¡Œæ•°
                            MAX_ROWS_PER_DF = max_rows_per_feature
                            total_rows_before = sum(len(df) for df in dfs_to_merge)
                            
                            # åˆå¹¶å‰å…ˆç§»é™¤å„ DataFrame ä¸­çš„é‡å¤åˆ—åï¼ˆä¿ç•™ä¸åŒçš„å€¼åˆ—ï¼‰
                            # æ‰¾åˆ°å„ df çš„å€¼åˆ—ï¼ˆéåˆå¹¶åˆ—ï¼‰
                            processed_dfs = []
                            seen_value_cols = set()
                            
                            for df in dfs_to_merge:
                                df_proc = df.copy()
                                
                                # ğŸ”§ é™åˆ¶è¡Œæ•°ä»¥é¿å…åˆå¹¶è¶…æ—¶
                                if len(df_proc) > MAX_ROWS_PER_DF:
                                    df_proc = df_proc.head(MAX_ROWS_PER_DF)
                                
                                # è·å–æ­¤ df çš„å€¼åˆ—
                                value_cols_in_df = [c for c in df_proc.columns if c not in merge_cols]
                                
                                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤åˆ—å
                                for vc in value_cols_in_df:
                                    if vc in seen_value_cols:
                                        # é‡å¤åˆ—åï¼Œè·³è¿‡è¿™ä¸€åˆ—ï¼ˆæˆ–å¯ä»¥é‡å‘½åï¼‰
                                        df_proc = df_proc.drop(columns=[vc], errors='ignore')
                                    else:
                                        seen_value_cols.add(vc)
                                
                                if len(df_proc.columns) > len(merge_cols):
                                    processed_dfs.append(df_proc)
                            
                            if len(processed_dfs) == 0:
                                no_data_msg = "No unique data columns to merge." if lang == 'en' else "æ²¡æœ‰å”¯ä¸€çš„æ•°æ®åˆ—å¯åˆå¹¶ã€‚"
                                st.warning(no_data_msg)
                            elif len(processed_dfs) == 1:
                                merged_df = processed_dfs[0]
                            else:
                                merged_df = reduce(
                                    lambda left, right: pd.merge(left, right, on=merge_cols, how='outer'),
                                    processed_dfs
                                )
                                
                                # æ¸…ç†å¯èƒ½çš„ _x, _y åç¼€åˆ—ï¼ˆåˆå¹¶æ—¶å¯èƒ½äº§ç”Ÿï¼‰
                                cols_to_drop = [c for c in merged_df.columns if c.endswith('_x') or c.endswith('_y')]
                                if cols_to_drop:
                                    merged_df = merged_df.drop(columns=cols_to_drop)
                        
                        # ğŸ”§ æ˜¾ç¤ºæˆªæ–­æç¤º
                        if total_rows_before > MAX_ROWS_PER_DF * len(dfs_to_merge):
                            truncate_warn = f"âš ï¸ Data was sampled (max {MAX_ROWS_PER_DF:,} rows per feature) for performance. Total rows: {total_rows_before:,}" if lang == 'en' else f"âš ï¸ æ•°æ®å·²é‡‡æ ·ï¼ˆæ¯ç‰¹å¾æœ€å¤š {MAX_ROWS_PER_DF:,} è¡Œï¼‰ä»¥ä¿è¯æ€§èƒ½ã€‚åŸå§‹æ€»è¡Œæ•°ï¼š{total_rows_before:,}"
                            st.info(truncate_warn)
                        
                        # æ˜¾ç¤ºåˆå¹¶ç»“æœç»Ÿè®¡
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Rows" if lang == 'en' else "è¡Œæ•°", f"{len(merged_df):,}")
                        with col2:
                            st.metric("Columns" if lang == 'en' else "åˆ—æ•°", len(merged_df.columns))
                        with col3:
                            st.metric("Features" if lang == 'en' else "ç‰¹å¾æ•°", len(module_concepts))
                        
                        st.markdown("---")
                        
                        # æ˜¾ç¤ºæ•°æ®
                        max_rows = 1000
                        display_df = merged_df.head(max_rows).copy() if len(merged_df) > max_rows else merged_df.copy()
                        # ğŸ”§ FIX: å°†å¸ƒå°”åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²"True"/"False"æ˜¾ç¤º
                        for col in display_df.columns:
                            dtype_str = str(display_df[col].dtype).lower()
                            if 'bool' in dtype_str:
                                display_df[col] = display_df[col].astype(str)
                        st.dataframe(display_df, use_container_width=True, height=500)
                        
                        if len(merged_df) > max_rows:
                            truncate_msg = f"âš ï¸ Showing first {max_rows:,} of {len(merged_df):,} rows." if lang == 'en' else f"âš ï¸ æ˜¾ç¤ºå‰ {max_rows:,} è¡Œï¼ˆå…± {len(merged_df):,} è¡Œï¼‰ã€‚"
                            st.caption(truncate_msg)
                    # ä¸æä¾›ä¸‹è½½æŒ‰é’®ï¼Œå› ä¸ºæ•°æ®æ˜¯ç”¨æˆ·å¯¼å…¥çš„
                    except Exception as e:
                        err_msg = f"Error merging data: {e}" if lang == 'en' else f"åˆå¹¶æ•°æ®æ—¶å‡ºé”™: {e}"
                        st.error(err_msg)


def render_quality_page():
    """æ¸²æŸ“æ•°æ®è´¨é‡é¡µé¢ã€‚"""
    lang = st.session_state.get('language', 'en')
    
    page_title = "ğŸ“Š Data Quality Assessment" if lang == 'en' else "ğŸ“Š æ•°æ®è´¨é‡è¯„ä¼°"
    st.markdown(f"## {page_title}")
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    if len(st.session_state.loaded_concepts) == 0:
        if lang == 'en':
            st.markdown('''
            <div class="info-box">
                <strong>ğŸ‘ˆ Please load data from the sidebar first</strong><br>
                ğŸ’¡ Tip: Select "Demo Mode" to quickly explore all features
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="info-box">
                <strong>ğŸ‘ˆ è¯·å…ˆåœ¨ä¾§è¾¹æ åŠ è½½æ•°æ®</strong><br>
                ğŸ’¡ æç¤ºï¼šå‹¾é€‰ã€Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ã€å¯å¿«é€Ÿä½“éªŒæ‰€æœ‰åŠŸèƒ½
            </div>
            ''', unsafe_allow_html=True)
        return
    
    # æ€»ä½“æ•°æ®è´¨é‡æ¦‚è§ˆ
    quality_title = "ğŸ“‹ Data Quality Overview" if lang == 'en' else "ğŸ“‹ æ•°æ®è´¨é‡æ¦‚è§ˆ"
    st.markdown(f"### {quality_title}")
    
    total_records = 0
    total_missing = 0
    quality_data = []
    
    # ğŸ”§ æ”¹è¿›çš„ç¼ºå¤±ç‡è®¡ç®—ï¼ˆ2026-01-29 v3 é‡æ–°è®¾è®¡ï¼‰
    # æ ¸å¿ƒåŸåˆ™ï¼š
    # 1. äººå£ç»Ÿè®¡å­¦é™æ€æ¦‚å¿µï¼šæ¯æ‚£è€…ä¸€æ¡è®°å½•ï¼Œç¼ºå¤±ç‡ = NAå€¼æ¯”ä¾‹ï¼ˆè¿™äº›ç¡®å®åªéœ€è¦1æ¡ï¼‰
    # 2. æ‰€æœ‰å…¶ä»–æ¦‚å¿µï¼ˆåŒ…æ‹¬äº‹ä»¶å‹ï¼‰ï¼šç¼ºå¤±ç‡ = 1 - (å®é™…è®°å½•æ•°/æ‚£è€… / 72)
    #    72æ˜¯å®Œæ•´çš„æ—¶é—´ç½‘æ ¼ï¼ˆ72å°æ—¶=72ä¸ªæ—¶é—´ç‚¹ï¼‰
    #    ä¾‹å¦‚ï¼šabxæœ‰1æ¡ â†’ ç¼ºå¤±ç‡ = (72-1)/72 = 98.6%
    
    # åªæœ‰äººå£ç»Ÿè®¡å­¦æ•°æ®æ‰æ˜¯çœŸæ­£çš„"é™æ€"ï¼ˆæ¯æ‚£è€…åªéœ€è¦1æ¡è®°å½•ï¼‰
    demographic_static = [
        'death', 'los_icu', 'los_hosp', 'age', 'weight', 'height', 'sex', 'bmi'
    ]

    # äº‹ä»¶å‹æ—¶é—´åºåˆ—ï¼šåªç»Ÿè®¡äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´ç‚¹ï¼ˆé¿å…å…¨é‡0å¯¼è‡´0%ç¼ºå¤±ï¼‰
    # ğŸ”§ åŒ…å«æ‰€æœ‰å¸ƒå°”äº‹ä»¶å‹æ¦‚å¿µï¼šsepsisç›¸å…³ã€æ„ŸæŸ“ç›¸å…³ã€RRTã€å¾ªç¯è¡°ç«­ç­‰
    event_time_series = [
        # å¾ªç¯è¡°ç«­
        'circ_failure', 'circ_event',
        # Sepsis-3 è¯Šæ–­
        'sep3_sofa2', 'sep3_sofa1', 'sep3', 'sepsis_sofa2',
        # æ„ŸæŸ“ç›¸å…³
        'susp_inf', 'infection_icd', 'samp',
        # è‚¾æ›¿ä»£æ²»ç–—
        'rrt', 'rrt_criteria',
        # AKIæ ‡å¿—
        'aki', 'aki_stage', 'aki_stage_creat', 'aki_stage_uo', 'aki_stage_rrt',
        # æœºæ¢°é€šæ°”
        'mech_vent', 'vent_ind', 'vent_start', 'vent_end',
        # ECMO å’Œæœºæ¢°å¾ªç¯æ”¯æŒ
        'ecmo', 'ecmo_indication', 'mech_circ_support',
        # è¯ç‰©äº‹ä»¶
        'abx', 'cort',
        # è¡€ç®¡æ´»æ€§è¯ç‰©æŒ‡ç¤º
        'vaso_ind',
    ]
    
    # ğŸ”§ FIX (2026-02-04): é™æ€å¸ƒå°”äº‹ä»¶ï¼ˆæ¯æ‚£è€…æœ€å¤š1æ¡ï¼Œåªæœ‰å‘ç”Ÿæ—¶æ‰è®°å½•ï¼‰
    # ç¼ºå¤±ç‡ = 1 - (æœ‰è®°å½•çš„æ‚£è€…æ•° / æ€»æ‚£è€…æ•°)
    # ğŸ”§ mech_circ_support æ˜¯éå¸¸ç½•è§çš„æ²»ç–—ï¼ˆçº¦2-3%æ‚£è€…ï¼‰ï¼Œç¼ºå¤±ç‡åº”è¯¥çº¦97-98%
    static_boolean_events = [
        'ecmo', 'ecmo_indication', 'mech_circ_support',  # ECMO/æœºæ¢°å¾ªç¯æ”¯æŒï¼ˆç½•è§ï¼Œçº¦2-3%ï¼‰
        'cort',  # çš®è´¨ç±»å›ºé†‡ï¼ˆçº¦25-30%ï¼‰
        'abx',   # æŠ—ç”Ÿç´ ï¼ˆé™æ€ç‰ˆæœ¬ï¼Œçº¦70%ï¼‰
        'vaso_ind',  # è¡€ç®¡æ´»æ€§è¯ç‰©æŒ‡ç¤ºï¼ˆçº¦50-60%ï¼‰
    ]
    
    # ğŸ”§ å®Œæ•´æ—¶é—´ç½‘æ ¼å¤§å°ï¼šä¼˜å…ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®çš„æ—¶é•¿å‚æ•°ï¼Œå¦åˆ™é»˜è®¤72å°æ—¶
    mock_params = st.session_state.get('mock_params', {})
    time_grid_size = mock_params.get('hours', 72) if mock_params else 72

    def _detect_time_col(df: pd.DataFrame) -> Optional[str]:
        # ğŸ”§ æ·»åŠ  'time' ä½œä¸ºé¦–é€‰å€™é€‰ï¼ˆæ¨¡æ‹Ÿæ•°æ®ä½¿ç”¨ 'time' åˆ—è¡¨ç¤ºå°æ—¶æ•°ï¼‰
        time_candidates = [
            'time',  # ğŸ”§ æ¨¡æ‹Ÿæ•°æ®ä½¿ç”¨çš„æ—¶é—´åˆ—ï¼ˆå°æ—¶æ•°ï¼‰
            'charttime', 'datetime', 'measuredat', 'measuredat_minutes',
            'observationoffset', 'starttime', 'endtime', 'givenat', 'timestamp',
        ]
        for col in time_candidates:
            if col in df.columns:
                return col
        return None

    def _to_hour_bins(series: pd.Series, col_name: str) -> Optional[pd.Series]:
        if pd.api.types.is_datetime64_any_dtype(series):
            return series.dt.floor('H')
        if pd.api.types.is_object_dtype(series):
            parsed = pd.to_datetime(series, errors='coerce')
            if parsed.notna().any():
                return parsed.dt.floor('H')
            numeric = pd.to_numeric(series, errors='coerce')
            if numeric.notna().any():
                col_lower = col_name.lower()
                if 'second' in col_lower:
                    return (numeric / 3600).floordiv(1)
                if 'minute' in col_lower or 'offset' in col_lower:
                    return (numeric / 60).floordiv(1)
                return numeric.floordiv(1)
            return None
        if pd.api.types.is_numeric_dtype(series):
            col_lower = col_name.lower()
            if 'second' in col_lower:
                return (series / 3600).floordiv(1)
            if 'minute' in col_lower or 'offset' in col_lower:
                return (series / 60).floordiv(1)
            return series.floordiv(1)
        return None

    def _calc_time_missing(
        df: pd.DataFrame,
        id_col: str,
        time_col: Optional[str],
        time_grid_size: int,
        event_mask: Optional[pd.Series] = None,
    ) -> Optional[float]:
        if time_col is None or id_col not in df.columns:
            return None
        data = df.loc[event_mask] if event_mask is not None else df
        if data.empty:
            return 100.0
        time_series = data[time_col]
        hour_bins = _to_hour_bins(time_series, time_col)
        if hour_bins is None:
            return None
        tmp = data[[id_col]].copy()
        tmp['_hour_bin'] = hour_bins
        tmp = tmp.dropna(subset=['_hour_bin'])
        if tmp.empty:
            return None

        # ğŸ”§ ç®€åŒ–è®¡ç®—ï¼šç›´æ¥ç”¨ (1 - å®é™…è¦†ç›–ç‡) ä½œä¸ºç¼ºå¤±ç‡
        # æ¯ä¸ªæ‚£è€…çš„å”¯ä¸€å°æ—¶æ•°
        unique_hours_per_patient = tmp.groupby(id_col)['_hour_bin'].nunique()
        
        # æ€»æ‚£è€…æ•°
        n_patients_in_data = len(unique_hours_per_patient)
        if n_patients_in_data == 0:
            return 100.0
        
        # å¹³å‡æ¯æ‚£è€…çš„å”¯ä¸€å°æ—¶æ•°
        avg_unique_hours = unique_hours_per_patient.mean()
        
        # ç¼ºå¤±ç‡ = 1 - (å¹³å‡å”¯ä¸€å°æ—¶æ•° / æ—¶é—´ç½‘æ ¼å¤§å°)
        coverage = avg_unique_hours / time_grid_size
        missing_rate = max(0.0, 1.0 - coverage) * 100
        
        return float(missing_rate)
    
    # è·å–æ€»æ‚£è€…æ•°ï¼ˆç”¨äºè®¡ç®—æ‚£è€…è¦†ç›–ç‡ï¼‰
    # ğŸ”§ FIX (2026-02-04): æ”¹è¿›æ€»æ‚£è€…æ•°è·å–é€»è¾‘
    # å¯¹äºé™æ€å¸ƒå°”äº‹ä»¶ï¼Œéœ€è¦ä»éé™æ€å¸ƒå°”äº‹ä»¶çš„æ¦‚å¿µä¸­è·å–æ€»æ‚£è€…æ•°
    # å¦åˆ™ä¼šå¯¼è‡´ n_patients == total_patientsï¼Œç¼ºå¤±ç‡é”™è¯¯åœ°æ˜¾ç¤ºä¸º 0%
    
    # é¦–å…ˆå°è¯•ä» mock_params è·å–ï¼ˆDemo Mode æœ€å‡†ç¡®ï¼‰
    mock_params = st.session_state.get('mock_params', {})
    total_patients_in_session = mock_params.get('n_patients', 0)
    
    # å¦‚æœ mock_params æ²¡æœ‰ï¼Œå°è¯•ä» patient_limit è·å–
    if total_patients_in_session == 0:
        total_patients_in_session = st.session_state.get('patient_limit', 0)
    
    # å¦‚æœä»ç„¶ä¸º 0ï¼Œä»æ•°æ®ä¸­è·å–æœ€å¤§çš„æ‚£è€…æ•°
    if total_patients_in_session == 0:
        # å°è¯•ä»éé™æ€å¸ƒå°”äº‹ä»¶çš„æ¦‚å¿µä¸­è·å–æœ€å¤§æ‚£è€…æ•°
        max_patients_found = 0
        for concept, df in st.session_state.loaded_concepts.items():
            if isinstance(df, pd.DataFrame) and len(df) > 0 and st.session_state.id_col in df.columns:
                concept_patients = df[st.session_state.id_col].nunique()
                # ä¼˜å…ˆä½¿ç”¨éé™æ€å¸ƒå°”äº‹ä»¶çš„æ¦‚å¿µæ‚£è€…æ•°
                if concept not in static_boolean_events:
                    max_patients_found = max(max_patients_found, concept_patients)
        
        if max_patients_found > 0:
            total_patients_in_session = max_patients_found
        else:
            # å¦‚æœæ‰€æœ‰æ¦‚å¿µéƒ½æ˜¯é™æ€å¸ƒå°”äº‹ä»¶ï¼Œé»˜è®¤ä½¿ç”¨ 50
            total_patients_in_session = 50
    
    for concept, df in st.session_state.loaded_concepts.items():
        if isinstance(df, pd.DataFrame) and len(df) > 0:
            numeric_cols = df.select_dtypes(include=['number']).columns
            # æ’é™¤IDåˆ—å’Œæ‰€æœ‰å¯èƒ½çš„æ—¶é—´åˆ—ï¼Œåªä¿ç•™çœŸæ­£çš„æ•°å€¼åˆ—
            exclude_cols = ['stay_id', 'hadm_id', 'icustay_id', 'time', 'index',
                           'charttime', 'starttime', 'endtime', 'datetime', 'timestamp',
                           'patientunitstayid', 'admissionid', 'patientid', 'CaseID']
            value_cols = [c for c in numeric_cols if c not in exclude_cols]
            
            n_records = len(df)
            n_patients = df[st.session_state.id_col].nunique() if st.session_state.id_col in df.columns else 0
            
            # åªæœ‰äººå£ç»Ÿè®¡å­¦æ•°æ®æ‰æ˜¯çœŸæ­£çš„é™æ€æ¦‚å¿µ
            is_demographic = concept in demographic_static
            main_col = concept if concept in df.columns else (value_cols[0] if value_cols else None)
            time_col = _detect_time_col(df)
            
            # ğŸ”§ FIX (2026-02-03): åˆ¤æ–­æ˜¯å¦ä¸ºé™æ€å¸ƒå°”äº‹ä»¶
            is_static_boolean = concept in static_boolean_events
            
            # è®¡ç®—ç¼ºå¤±ç‡
            if is_demographic:
                # äººå£ç»Ÿè®¡å­¦é™æ€æ¦‚å¿µï¼šç¼ºå¤±ç‡ = NAå€¼æ¯”ä¾‹ï¼ˆè¿™äº›ç¡®å®åªéœ€è¦1æ¡/æ‚£è€…ï¼‰
                if value_cols:
                    main_col = concept if concept in df.columns else (value_cols[0] if value_cols else None)
                    if main_col and main_col in df.columns:
                        missing_rate = df[main_col].isna().mean() * 100
                    else:
                        missing_rate = df[value_cols].isna().mean().mean() * 100
                else:
                    missing_rate = 0
            elif is_static_boolean:
                # ğŸ”§ FIX (2026-02-03): é™æ€å¸ƒå°”äº‹ä»¶ï¼šåªæœ‰å‘ç”Ÿæ—¶æ‰è®°å½•
                # ç¼ºå¤±ç‡ = 1 - (æœ‰è®°å½•çš„æ‚£è€…æ•° / æ€»æ‚£è€…æ•°)
                # ä¾‹å¦‚ï¼š5%æ‚£è€…ä½¿ç”¨ECMO â†’ ç¼ºå¤±ç‡ = 95%
                patients_with_event = n_patients  # æœ‰è®°å½•çš„æ‚£è€…æ•°
                # æ€»æ‚£è€…æ•°ä»sessionè·å–
                total_patients = total_patients_in_session
                if total_patients > 0:
                    missing_rate = (1 - patients_with_event / total_patients) * 100
                else:
                    missing_rate = 0
            else:
                # ğŸ”§ FIX (2026-02-03): ä¿®å¤ä»å®½è¡¨å¯¼å…¥æ—¶çš„ç¼ºå¤±ç‡è®¡ç®—
                # æ ¸å¿ƒé—®é¢˜ï¼šå®½è¡¨å¯èƒ½æœ‰å®Œæ•´çš„æ—¶é—´ç½‘æ ¼ï¼ˆ72è¡Œ/æ‚£è€…ï¼‰ï¼Œä½†å€¼åˆ—æœ‰å¤§é‡NaN
                # è§£å†³æ–¹æ¡ˆï¼šä¼˜å…ˆæ£€æŸ¥å€¼åˆ—çš„NaNæ¯”ä¾‹
                
                if n_patients > 0:
                    # ğŸ”§ å…ˆæ£€æŸ¥å€¼åˆ—çš„NaNæ¯”ä¾‹ï¼ˆå¯¹äºä»å®½è¡¨å¯¼å…¥çš„æ•°æ®æ›´å‡†ç¡®ï¼‰
                    na_rate_in_column = None
                    if main_col and main_col in df.columns:
                        na_rate_in_column = df[main_col].isna().mean() * 100
                    
                    # è®¡ç®—æ¯æ‚£è€…å¹³å‡è®°å½•æ•°
                    records_per_patient = n_records / n_patients
                    
                    # å¯¹äºäº‹ä»¶å‹æ•°æ®ï¼Œåªç»Ÿè®¡éé›¶è®°å½•
                    if concept in event_time_series and main_col and main_col in df.columns:
                        col_data = df[main_col]
                        # æ£€æŸ¥æ•°æ®ç±»å‹ï¼Œåªå¯¹æ•°å€¼ç±»å‹è¿›è¡Œ > 0 æ¯”è¾ƒ
                        if pd.api.types.is_numeric_dtype(col_data):
                            event_count = (col_data.fillna(0) > 0).sum()
                        elif pd.api.types.is_bool_dtype(col_data):
                            event_count = col_data.fillna(False).sum()
                        else:
                            # å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹ï¼Œç»Ÿè®¡éç©ºéé›¶è®°å½•
                            event_count = col_data.notna().sum()
                        records_per_patient = event_count / n_patients if n_patients > 0 else 0
                    
                    # ğŸ”§ FIX: å¦‚æœå€¼åˆ—NaNæ¯”ä¾‹è¾ƒé«˜ï¼ˆ>5%ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨NaNæ¯”ä¾‹ä½œä¸ºç¼ºå¤±ç‡
                    # è¿™å¯¹ä»å®½è¡¨å¯¼å…¥çš„æ•°æ®æ›´å‡†ç¡®
                    if na_rate_in_column is not None and na_rate_in_column > 5:
                        missing_rate = na_rate_in_column
                    else:
                        # ç¼ºå¤±ç‡ = 1 - (æ¯æ‚£è€…è®°å½•æ•° / æ—¶é—´ç½‘æ ¼å¤§å°)
                        # ä¾‹å¦‚ï¼šæ¯æ‚£è€…9æ¡è®°å½•ï¼Œæ—¶é—´ç½‘æ ¼72 â†’ ç¼ºå¤±ç‡ = 1 - 9/72 = 87.5%
                        coverage = records_per_patient / time_grid_size
                        missing_rate = max(0, min(100, (1 - coverage) * 100))
                else:
                    # æ— æ‚£è€…æ•°æˆ–è®¡ç®—å¤±è´¥
                    missing_rate = 100
            
            total_records += n_records
            total_missing += n_records * (missing_rate / 100)
            
            # è´¨é‡ç­‰çº§
            if lang == 'en':
                if missing_rate < 5:
                    quality = "ğŸŸ¢ Excellent"
                elif missing_rate < 15:
                    quality = "ğŸŸ¡ Good"
                elif missing_rate < 30:
                    quality = "ğŸŸ  Fair"
                else:
                    quality = "ğŸ”´ Poor"
            else:
                if missing_rate < 5:
                    quality = "ğŸŸ¢ ä¼˜ç§€"
                elif missing_rate < 15:
                    quality = "ğŸŸ¡ è‰¯å¥½"
                elif missing_rate < 30:
                    quality = "ğŸŸ  ä¸€èˆ¬"
                else:
                    quality = "ğŸ”´ è¾ƒå·®"
            
            records_col = "Records" if lang == 'en' else "è®°å½•æ•°"
            patients_col = "Patients" if lang == 'en' else "æ‚£è€…æ•°"
            missing_col = "Missing %" if lang == 'en' else "ç¼ºå¤±ç‡"
            quality_col = "Quality" if lang == 'en' else "è´¨é‡"
            
            quality_data.append({
                'Concept': concept,
                records_col: f"{n_records:,}",
                patients_col: n_patients,
                missing_col: f"{missing_rate:.1f}%",
                quality_col: quality,
            })
    
    # æ€»ä½“ç»Ÿè®¡å¡ç‰‡ï¼ˆç§»é™¤Quality Scoreï¼‰
    overall_missing = (total_missing / total_records * 100) if total_records > 0 else 0
    
    col1, col2, col3 = st.columns(3)
    
    records_label = "Total Records" if lang == 'en' else "æ€»è®°å½•æ•°"
    missing_label = "Avg Missing %" if lang == 'en' else "å¹³å‡ç¼ºå¤±ç‡"
    items_label = "Data Items" if lang == 'en' else "æ•°æ®é¡¹æ•°"
    
    with col1:
        st.markdown(f'''
        <div class="metric-card" style="text-align:center">
            <div class="stat-label">{records_label}</div>
            <div class="stat-number">{total_records:,}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col2:
        st.markdown(f'''
        <div class="metric-card" style="text-align:center">
            <div class="stat-label">{missing_label}</div>
            <div class="stat-number" style="font-size:1.5rem">{overall_missing:.1f}%</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col3:
        st.markdown(f'''
        <div class="metric-card" style="text-align:center">
            <div class="stat-label">{items_label}</div>
            <div class="stat-number">{len(quality_data)}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # è¯¦ç»†æ•°æ®è¡¨
    detail_title = "### ğŸ“‹ Detailed Quality Report" if lang == 'en' else "### ğŸ“‹ è¯¦ç»†è´¨é‡æŠ¥å‘Š"
    st.markdown(detail_title)
    
    if quality_data:
        quality_df = pd.DataFrame(quality_data)
        st.dataframe(
            quality_df, 
            width="stretch", 
            hide_index=True,
        )
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # å¯è§†åŒ–åˆ†æ
    tab1_label = "ğŸ“Š Missing Rate Chart" if lang == 'en' else "ğŸ“Š ç¼ºå¤±ç‡å›¾è¡¨"
    tab2_label = "ğŸ“ˆ Value Distribution" if lang == 'en' else "ğŸ“ˆ æ•°å€¼åˆ†å¸ƒ"
    tab1, tab2 = st.tabs([tab1_label, tab2_label])
    
    with tab1:
        # ç¼ºå¤±ç‡æ¡å½¢å›¾
        try:
            import plotly.express as px
            
            missing_data = []
            # åªæœ‰äººå£ç»Ÿè®¡å­¦æ•°æ®æ‰æ˜¯çœŸæ­£çš„"é™æ€"
            demographic_static = [
                'death', 'los_icu', 'los_hosp', 'age', 'weight', 'height', 'sex', 'bmi'
            ]

            # äº‹ä»¶å‹æ—¶é—´åºåˆ—ï¼šåªç»Ÿè®¡äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´ç‚¹ï¼ˆé¿å…å…¨é‡0å¯¼è‡´0%ç¼ºå¤±ï¼‰
            # ğŸ”§ åŒ…å«æ‰€æœ‰å¸ƒå°”äº‹ä»¶å‹æ¦‚å¿µï¼šsepsisç›¸å…³ã€æ„ŸæŸ“ç›¸å…³ã€RRTã€å¾ªç¯è¡°ç«­ç­‰
            event_time_series = [
                # å¾ªç¯è¡°ç«­
                'circ_failure', 'circ_event',
                # Sepsis-3 è¯Šæ–­
                'sep3_sofa2', 'sep3_sofa1', 'sep3', 'sepsis_sofa2',
                # æ„ŸæŸ“ç›¸å…³
                'susp_inf', 'infection_icd', 'samp',
                # è‚¾æ›¿ä»£æ²»ç–—
                'rrt', 'rrt_criteria',
                # AKIæ ‡å¿—
                'aki', 'aki_stage', 'aki_stage_creat', 'aki_stage_uo', 'aki_stage_rrt',
                # æœºæ¢°é€šæ°”
                'mech_vent', 'vent_ind', 'vent_start', 'vent_end',
                # ECMO
                'ecmo', 'ecmo_indication',
                # è¯ç‰©äº‹ä»¶
                'abx', 'cort',
                # è¡€ç®¡æ´»æ€§è¯ç‰©æŒ‡ç¤º
                'vaso_ind',
            ]
            
            # ğŸ”§ FIX (2026-02-04): é™æ€å¸ƒå°”äº‹ä»¶ï¼ˆæ¯æ‚£è€…æœ€å¤š1æ¡ï¼Œåªæœ‰å‘ç”Ÿæ—¶æ‰è®°å½•ï¼‰
            # ç¼ºå¤±ç‡ = 1 - (æœ‰è®°å½•çš„æ‚£è€…æ•° / æ€»æ‚£è€…æ•°)
            # mech_circ_support æ˜¯éå¸¸ç½•è§çš„æ²»ç–—ï¼ˆçº¦2-3%æ‚£è€…ï¼‰ï¼Œç¼ºå¤±ç‡åº”è¯¥çº¦97-98%
            static_boolean_events_chart = [
                'ecmo', 'ecmo_indication', 'mech_circ_support',  # ECMO/æœºæ¢°å¾ªç¯æ”¯æŒï¼ˆç½•è§ï¼Œçº¦2-3%ï¼‰
                'cort',  # çš®è´¨ç±»å›ºé†‡ï¼ˆçº¦25-30%ï¼‰
                'abx',   # æŠ—ç”Ÿç´ ï¼ˆé™æ€ç‰ˆæœ¬ï¼Œçº¦70%ï¼‰
                'vaso_ind',  # è¡€ç®¡æ´»æ€§è¯ç‰©æŒ‡ç¤ºï¼ˆçº¦50-60%ï¼‰
            ]
            
            # ğŸ”§ å®Œæ•´æ—¶é—´ç½‘æ ¼å¤§å°ï¼šä¼˜å…ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®çš„æ—¶é•¿å‚æ•°ï¼Œå¦åˆ™é»˜è®¤72å°æ—¶
            mock_params = st.session_state.get('mock_params', {})
            time_grid_size = mock_params.get('hours', 72) if mock_params else 72

            def _detect_time_col(df: pd.DataFrame) -> Optional[str]:
                # ğŸ”§ æ·»åŠ  'time' ä½œä¸ºé¦–é€‰å€™é€‰ï¼ˆæ¨¡æ‹Ÿæ•°æ®ä½¿ç”¨ 'time' åˆ—è¡¨ç¤ºå°æ—¶æ•°ï¼‰
                time_candidates = [
                    'time',  # ğŸ”§ æ¨¡æ‹Ÿæ•°æ®ä½¿ç”¨çš„æ—¶é—´åˆ—ï¼ˆå°æ—¶æ•°ï¼‰
                    'charttime', 'datetime', 'measuredat', 'measuredat_minutes',
                    'observationoffset', 'starttime', 'endtime', 'givenat', 'timestamp',
                ]
                for col in time_candidates:
                    if col in df.columns:
                        return col
                return None

            def _to_hour_bins(series: pd.Series, col_name: str) -> Optional[pd.Series]:
                if pd.api.types.is_datetime64_any_dtype(series):
                    return series.dt.floor('H')
                if pd.api.types.is_object_dtype(series):
                    parsed = pd.to_datetime(series, errors='coerce')
                    if parsed.notna().any():
                        return parsed.dt.floor('H')
                    numeric = pd.to_numeric(series, errors='coerce')
                    if numeric.notna().any():
                        col_lower = col_name.lower()
                        if 'second' in col_lower:
                            return (numeric / 3600).floordiv(1)
                        if 'minute' in col_lower or 'offset' in col_lower:
                            return (numeric / 60).floordiv(1)
                        return numeric.floordiv(1)
                    return None
                if pd.api.types.is_numeric_dtype(series):
                    col_lower = col_name.lower()
                    if 'second' in col_lower:
                        return (series / 3600).floordiv(1)
                    if 'minute' in col_lower or 'offset' in col_lower:
                        return (series / 60).floordiv(1)
                    return series.floordiv(1)
                return None

            def _calc_time_missing(
                df: pd.DataFrame,
                id_col: str,
                time_col: Optional[str],
                time_grid_size: int,
                event_mask: Optional[pd.Series] = None,
            ) -> Optional[float]:
                if time_col is None or id_col not in df.columns:
                    return None
                data = df.loc[event_mask] if event_mask is not None else df
                if data.empty:
                    return 100.0
                time_series = data[time_col]
                hour_bins = _to_hour_bins(time_series, time_col)
                if hour_bins is None:
                    return None
                tmp = data[[id_col]].copy()
                tmp['_hour_bin'] = hour_bins
                tmp = tmp.dropna(subset=['_hour_bin'])
                if tmp.empty:
                    return None

                # ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨å‘é‡åŒ–æ“ä½œä»£æ›¿ groupby().apply()
                unique_hours_per_patient = tmp.groupby(id_col)['_hour_bin'].nunique()
                
                if pd.api.types.is_numeric_dtype(tmp['_hour_bin']):
                    total_hours = time_grid_size
                    missing_rates = 1.0 - (unique_hours_per_patient / total_hours)
                else:
                    time_ranges = tmp.groupby(id_col)['_hour_bin'].agg(lambda x: (x.max() - x.min()) / pd.Timedelta(hours=1) + 1)
                    time_ranges = time_ranges.clip(upper=time_grid_size)
                    missing_rates = 1.0 - (unique_hours_per_patient / time_ranges.clip(lower=1))
                
                return float(missing_rates.clip(lower=0).mean() * 100)
            
            # ğŸ”§ FIX (2026-02-04): æ”¹è¿›æ€»æ‚£è€…æ•°è·å–é€»è¾‘ï¼ˆå›¾è¡¨éƒ¨åˆ†ï¼‰
            # é¦–å…ˆå°è¯•ä» mock_params è·å–ï¼ˆDemo Mode æœ€å‡†ç¡®ï¼‰
            mock_params = st.session_state.get('mock_params', {})
            total_patients_chart = mock_params.get('n_patients', 0)
            
            # å¦‚æœ mock_params æ²¡æœ‰ï¼Œå°è¯•ä» patient_limit è·å–
            if total_patients_chart == 0:
                total_patients_chart = st.session_state.get('patient_limit', 0)
            
            # å¦‚æœä»ç„¶ä¸º 0ï¼Œä»æ•°æ®ä¸­è·å–æœ€å¤§çš„æ‚£è€…æ•°
            if total_patients_chart == 0:
                max_patients_found = 0
                for concept, df in st.session_state.loaded_concepts.items():
                    if isinstance(df, pd.DataFrame) and len(df) > 0 and st.session_state.id_col in df.columns:
                        concept_patients = df[st.session_state.id_col].nunique()
                        if concept not in static_boolean_events_chart:
                            max_patients_found = max(max_patients_found, concept_patients)
                
                if max_patients_found > 0:
                    total_patients_chart = max_patients_found
                else:
                    total_patients_chart = 50
            
            for concept, df in st.session_state.loaded_concepts.items():
                if isinstance(df, pd.DataFrame) and len(df) > 0:
                    numeric_cols = df.select_dtypes(include=['number']).columns
                    exclude_cols = ['stay_id', 'hadm_id', 'icustay_id', 'time', 'index',
                                   'charttime', 'starttime', 'endtime', 'datetime', 'timestamp',
                                   'patientunitstayid', 'admissionid', 'patientid', 'CaseID']
                    value_cols = [c for c in numeric_cols if c not in exclude_cols]
                    if value_cols:
                        n_records = len(df)
                        n_patients = df[st.session_state.id_col].nunique() if st.session_state.id_col in df.columns else 0
                        
                        # åªæœ‰äººå£ç»Ÿè®¡å­¦æ•°æ®æ‰æ˜¯é™æ€
                        is_demographic = concept in demographic_static
                        # ğŸ”§ FIX (2026-02-04): é™æ€å¸ƒå°”äº‹ä»¶éœ€è¦ç‰¹æ®Šå¤„ç†
                        is_static_boolean_chart = concept in static_boolean_events_chart
                        
                        main_col = concept if concept in df.columns else value_cols[0]

                        # è®¡ç®—ç¼ºå¤±ç‡
                        if is_demographic:
                            # äººå£ç»Ÿè®¡å­¦ï¼šåªçœ‹NAæ¯”ä¾‹
                            if main_col in df.columns:
                                final_missing_rate = df[main_col].isna().mean() * 100
                            else:
                                final_missing_rate = df[value_cols].isna().mean().mean() * 100
                        elif is_static_boolean_chart:
                            # ğŸ”§ FIX (2026-02-04): é™æ€å¸ƒå°”äº‹ä»¶ï¼šç¼ºå¤±ç‡ = 1 - (æœ‰è®°å½•çš„æ‚£è€…æ•° / æ€»æ‚£è€…æ•°)
                            # ä¾‹å¦‚ï¼š2.5%æ‚£è€…ä½¿ç”¨æœºæ¢°å¾ªç¯æ”¯æŒ â†’ ç¼ºå¤±ç‡ = 97.5%
                            patients_with_event = n_patients  # æœ‰è®°å½•çš„æ‚£è€…æ•°
                            total_patients = total_patients_chart
                            if total_patients > 0:
                                final_missing_rate = (1 - patients_with_event / total_patients) * 100
                            else:
                                final_missing_rate = 0
                                final_missing_rate = df[value_cols].isna().mean().mean() * 100
                        else:
                            # ğŸ”§ ç®€åŒ–çš„ç¼ºå¤±ç‡è®¡ç®—ï¼š1 - (æ¯æ‚£è€…è®°å½•æ•° / æ—¶é—´ç½‘æ ¼)
                            # ä¸è¯¦æƒ…è¡¨ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨æ¯ä¸ªæ¦‚å¿µå®é™…çš„æ‚£è€…æ•°
                            if n_patients > 0:
                                # æ¯æ‚£è€…å¹³å‡è®°å½•æ•°
                                records_per_patient = n_records / n_patients
                                
                                # å¯¹äºäº‹ä»¶å‹æ•°æ®ï¼Œåªè®¡ç®—äº‹ä»¶å‘ç”Ÿçš„è®°å½•
                                if concept in event_time_series and main_col in df.columns:
                                    event_count = (df[main_col].fillna(0) > 0).sum()
                                    records_per_patient = event_count / n_patients
                                
                                coverage = records_per_patient / time_grid_size
                                final_missing_rate = max(0, min(100, (1 - coverage) * 100))
                            else:
                                final_missing_rate = 100

                        missing_rate_label = "Missing Rate (%)" if lang == 'en' else "ç©ºå€¼æ¯”ä¾‹ (%)"
                        records_label_2 = "Records" if lang == 'en' else "è®°å½•æ•°"
                        
                        missing_data.append({
                            'Concept': concept, 
                            missing_rate_label: final_missing_rate,
                            records_label_2: len(df)
                        })
            
            if missing_data:
                missing_df = pd.DataFrame(missing_data)
                missing_rate_col = "Missing Rate (%)" if lang == 'en' else "ç©ºå€¼æ¯”ä¾‹ (%)"
                missing_df = missing_df.sort_values(missing_rate_col, ascending=True)
                
                # æ£€æŸ¥æ˜¯å¦å…¨æ˜¯0
                if missing_df[missing_rate_col].sum() == 0:
                    # æ‰€æœ‰æ•°æ®æ— ç¼ºå¤±ï¼Œæ˜¾ç¤ºæˆåŠŸä¿¡æ¯
                    good_msg = "âœ… Excellent data quality: No missing values in numeric columns" if lang == 'en' else "âœ… æ•°æ®è´¨é‡è‰¯å¥½ï¼šæ‰€æœ‰æ•°å€¼åˆ—å‡æ— ç©ºå€¼ (NA/NaN)"
                    st.success(good_msg)
                    
                    # æ˜¾ç¤ºæ¦‚å¿µåˆ—è¡¨
                    concepts_loaded = f"**Loaded Concepts ({len(missing_df)} total):**" if lang == 'en' else f"**å·²åŠ è½½æ¦‚å¿µ ({len(missing_df)} ä¸ª)ï¼š**"
                    st.markdown(concepts_loaded)
                    concept_list = ", ".join(missing_df['Concept'].tolist())
                    st.write(concept_list)
                else:
                    # æœ‰ç¼ºå¤±å€¼ï¼Œç»˜åˆ¶æ¡å½¢å›¾
                    chart_title = 'ğŸ“‰ Missing Rate Analysis by Concept' if lang == 'en' else 'ğŸ“‰ å„ Concept ç©ºå€¼æ¯”ä¾‹åˆ†æ'
                    fig = px.bar(
                        missing_df, x=missing_rate_col, y='Concept',
                        orientation='h',
                        title=chart_title,
                        color=missing_rate_col,
                        color_continuous_scale=['#28a745', '#ffc107', '#dc3545'],
                        hover_data=[records_label_2 if lang == 'en' else 'è®°å½•æ•°']
                    )
                    fig.update_layout(
                        template="plotly_white",
                        height=max(300, len(missing_data) * 40),
                        showlegend=False,
                        yaxis_title="",
                        margin=dict(l=100, r=30, t=50, b=50),
                    )
                    st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            err_msg = f"Chart rendering failed: {e}" if lang == 'en' else f"å›¾è¡¨æ¸²æŸ“å¤±è´¥: {e}"
            st.warning(err_msg)
    
    with tab2:
        col1, col2 = st.columns([1, 3])
        
        with col1:
            select_concept_label = "Select Concept" if lang == 'en' else "é€‰æ‹© Concept"
            concept = st.selectbox(
                select_concept_label,
                options=list(st.session_state.loaded_concepts.keys()),
                key="quality_concept"
            )
        
        with col2:
            if concept:
                df = st.session_state.loaded_concepts[concept]
                
                if isinstance(df, pd.DataFrame):
                    numeric_cols = df.select_dtypes(include=['number']).columns
                    non_id_cols = [c for c in numeric_cols if c not in ['stay_id', 'hadm_id', 'time', 'index']]
                    
                    if non_id_cols:
                        try:
                            import plotly.express as px
                            import plotly.graph_objects as go
                            
                            value_col = non_id_cols[0]
                            
                            dist_title = f"ğŸ“Š {concept.upper()} Value Distribution" if lang == 'en' else f"ğŸ“Š {concept.upper()} æ•°å€¼åˆ†å¸ƒ"
                            fig = px.histogram(
                                df, x=value_col, nbins=50,
                                title=dist_title,
                                marginal="box"
                            )
                            fig.update_layout(
                                template="plotly_white",
                                height=400,
                                showlegend=False,
                            )
                            fig.update_traces(marker_color='#1f77b4')
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # ç»Ÿè®¡æ‘˜è¦
                            summary_label = "**Statistical Summary:**" if lang == 'en' else "**ç»Ÿè®¡æ‘˜è¦:**"
                            st.markdown(summary_label)
                            col_a, col_b, col_c, col_d, col_e = st.columns(5)
                            col_a.metric("Min", f"{df[value_col].min():.2f}")
                            col_b.metric("Max", f"{df[value_col].max():.2f}")
                            col_c.metric("Mean", f"{df[value_col].mean():.2f}")
                            col_d.metric("Median", f"{df[value_col].median():.2f}")
                            col_e.metric("Std", f"{df[value_col].std():.2f}")
                            
                        except Exception as e:
                            err_msg = f"Distribution chart rendering failed: {e}" if lang == 'en' else f"åˆ†å¸ƒå›¾æ¸²æŸ“å¤±è´¥: {e}"
                            st.warning(err_msg)


def _generate_mock_demographics(n_patients: int, lang: str = 'en') -> pd.DataFrame:
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„äººå£ç»Ÿè®¡å­¦æ•°æ®ç”¨äºCohort Comparisonæ¼”ç¤ºã€‚
    
    ğŸ”§ æ”¹è¿›ï¼šå¤ç”¨ generate_mock_data çš„é€»è¾‘ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ã€‚
    
    Args:
        n_patients: æ‚£è€…æ•°é‡
        lang: è¯­è¨€
        
    Returns:
        åŒ…å«äººå£ç»Ÿè®¡å­¦æ•°æ®çš„DataFrame
    """
    # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€çš„ generate_mock_data å‡½æ•°ç”ŸæˆåŸºç¡€æ•°æ®
    # æ³¨æ„ï¼šgenerate_mock_data è¿”å› (data_dict, patient_ids) å…ƒç»„
    mock_data_tuple = generate_mock_data(n_patients=n_patients, hours=72)
    mock_data = mock_data_tuple[0] if isinstance(mock_data_tuple, tuple) else mock_data_tuple
    
    # æå–éœ€è¦çš„äººå£ç»Ÿè®¡å­¦å­—æ®µ
    age_df = mock_data.get('age', pd.DataFrame(columns=['stay_id', 'age']))
    sex_df = mock_data.get('sex', pd.DataFrame(columns=['stay_id', 'sex']))
    death_df = mock_data.get('death', pd.DataFrame(columns=['stay_id', 'death']))
    los_icu_df = mock_data.get('los_icu', pd.DataFrame(columns=['stay_id', 'los_icu']))
    sofa_df = mock_data.get('sofa', pd.DataFrame(columns=['stay_id', 'time', 'sofa']))
    
    # åˆ›å»ºåŸºç¡€ DataFrame
    patient_ids = age_df['stay_id'].tolist() if 'stay_id' in age_df.columns else list(range(1, n_patients + 1))
    
    df = pd.DataFrame({'stay_id': patient_ids})
    
    # åˆå¹¶å¹´é¾„
    if not age_df.empty and 'age' in age_df.columns:
        df = df.merge(age_df[['stay_id', 'age']], on='stay_id', how='left')
    else:
        df['age'] = np.clip(np.random.normal(65, 15, len(df)), 18, 95).astype(int)
    
    # åˆå¹¶æ€§åˆ«
    if not sex_df.empty and 'sex' in sex_df.columns:
        df = df.merge(sex_df[['stay_id', 'sex']], on='stay_id', how='left')
        df['gender'] = df['sex']
    else:
        df['gender'] = np.random.choice(['M', 'F'], len(df), p=[0.55, 0.45])
    
    # åˆå¹¶æ­»äº¡çŠ¶æ€
    if not death_df.empty and 'death' in death_df.columns:
        df = df.merge(death_df[['stay_id', 'death']], on='stay_id', how='left')
        df['survived'] = (1 - df['death']).astype(int)
    else:
        df['survived'] = np.random.choice([0, 1], len(df), p=[0.15, 0.85])
    
    # åˆå¹¶LOS
    if not los_icu_df.empty and 'los_icu' in los_icu_df.columns:
        df = df.merge(los_icu_df[['stay_id', 'los_icu']], on='stay_id', how='left')
        df['los_days'] = df['los_icu']
        df['los_hours'] = (df['los_icu'] * 24).astype(int)
    else:
        df['los_hours'] = np.clip(np.random.lognormal(4.5, 0.8, len(df)), 24, 1000).astype(int)
        df['los_days'] = df['los_hours'] / 24
    
    # è®¡ç®— SOFA max
    if not sofa_df.empty and 'sofa' in sofa_df.columns:
        sofa_max = sofa_df.groupby('stay_id')['sofa'].max().reset_index()
        sofa_max.columns = ['stay_id', 'sofa_max']
        df = df.merge(sofa_max, on='stay_id', how='left')
        df['sofa_max'] = df['sofa_max'].fillna(0).astype(int)
    else:
        df['sofa_max'] = np.random.choice(range(0, 20), len(df))
    
    # é¦–æ¬¡ICUå…¥ä½
    df['first_icu_stay'] = np.random.choice([True, False], len(df), p=[0.65, 0.35])
    
    # é€‰æ‹©éœ€è¦çš„åˆ—
    result_cols = ['stay_id', 'age', 'gender', 'los_hours', 'los_days', 'first_icu_stay', 'survived', 'sofa_max']
    available_cols = [c for c in result_cols if c in df.columns]
    
    return df[available_cols]


def find_database_path(root: str, db_name: str) -> str:
    """æ™ºèƒ½æ£€æµ‹æ•°æ®åº“è·¯å¾„ï¼Œæ”¯æŒå¤šç§ç›®å½•å‘½åæ–¹å¼
    
    Args:
        root: ICUæ•°æ®æ ¹ç›®å½•
        db_name: æ•°æ®åº“åç§°ï¼ˆmiiv, eicu, aumc, hirid, mimic, sicï¼‰
        
    Returns:
        å®Œæ•´çš„æ•°æ®åº“è·¯å¾„
    """
    # å®šä¹‰æ¯ä¸ªæ•°æ®åº“å¯èƒ½çš„ç›®å½•åç§°å’Œç‰ˆæœ¬å·
    db_aliases = {
        'miiv': ['mimiciv', 'mimic-iv', 'miiv', 'mimic_iv'],
        'eicu': ['eicu', 'eicu-crd', 'eicu_crd'],
        'aumc': ['aumc', 'amsterdamumc', 'amsterdam'],
        'hirid': ['hirid', 'hi-rid'],
        'mimic': ['mimiciii', 'mimic-iii', 'mimic3', 'mimic_iii'],
        'sic': ['sicdb', 'sic', 'sic-db'],
    }
    
    aliases = db_aliases.get(db_name, [db_name])
    
    # å°è¯•æ¯ä¸ªåˆ«å
    for alias in aliases:
        # å°è¯•ç›´æ¥ç›®å½•
        direct_path = os.path.join(root, alias)
        if os.path.isdir(direct_path):
            # æ£€æŸ¥æ˜¯å¦æœ‰ç‰ˆæœ¬å­ç›®å½•
            subdirs = [d for d in os.listdir(direct_path) 
                       if os.path.isdir(os.path.join(direct_path, d)) 
                       and d[0].isdigit()]  # ç‰ˆæœ¬å·ä»¥æ•°å­—å¼€å¤´
            if subdirs:
                # é€‰æ‹©æœ€é«˜ç‰ˆæœ¬
                subdirs.sort(reverse=True)
                return os.path.join(direct_path, subdirs[0])
            else:
                return direct_path
        
        # å°è¯•å¸¦ç‰ˆæœ¬çš„å›ºå®šè·¯å¾„
        default_versions = {
            'mimiciv': '3.1', 'mimic-iv': '3.1', 'miiv': '3.1',
            'eicu': '2.0.1', 'eicu-crd': '2.0.1',
            'aumc': '1.0.2',
            'hirid': '1.1.1',
            'mimiciii': '1.4', 'mimic-iii': '1.4',
            'sicdb': '1.0.6', 'sic': '1.0.6',
        }
        if alias in default_versions:
            versioned_path = os.path.join(root, alias, default_versions[alias])
            if os.path.isdir(versioned_path):
                return versioned_path
    
    # å›é€€ï¼šè¿”å›é»˜è®¤æ ¼å¼
    fallback_map = {
        'miiv': 'mimiciv/3.1',
        'eicu': 'eicu/2.0.1',
        'aumc': 'aumc/1.0.2',
        'hirid': 'hirid/1.1.1',
        'mimic': 'mimiciii/1.4',
        'sic': 'sicdb/1.0.6',
    }
    return os.path.join(root, fallback_map.get(db_name, db_name))


def render_directory_structure_guide(lang: str = 'en'):
    """æ¸²æŸ“ç›®å½•ç»“æ„æŒ‡å—å¼¹çª—"""
    with st.popover("ğŸ“‚ " + ("Directory Structure Guide" if lang == 'en' else "ç›®å½•ç»“æ„æŒ‡å—")):
        struct_info = """
**Expected directory structure:**

```
icudb/                    â† Your ICU Data Root
â”œâ”€â”€ mimiciv/              â† or mimic-iv/, miiv/
â”‚   â””â”€â”€ 3.1/              â† version folder (optional)
â”œâ”€â”€ eicu/
â”‚   â””â”€â”€ 2.0.1/
â”œâ”€â”€ aumc/
â”‚   â””â”€â”€ 1.0.2/
â”œâ”€â”€ hirid/
â”‚   â””â”€â”€ 1.1.1/
â”œâ”€â”€ mimiciii/             â† or mimic-iii/, mimic/
â”‚   â””â”€â”€ 1.4/
â””â”€â”€ sicdb/                â† or sic/
    â””â”€â”€ 1.0.6/
```

**Tips:**
- Version folders (3.1, 2.0.1, etc.) are optional
- Database folder names can vary (mimiciv, mimic-iv, miiv)
- System will auto-detect the correct path
""" if lang == 'en' else """
**æœŸæœ›çš„ç›®å½•ç»“æ„ï¼š**

```
icudb/                    â† ä½ çš„ICUæ•°æ®æ ¹ç›®å½•
â”œâ”€â”€ mimiciv/              â† æˆ– mimic-iv/, miiv/
â”‚   â””â”€â”€ 3.1/              â† ç‰ˆæœ¬æ–‡ä»¶å¤¹ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ eicu/
â”‚   â””â”€â”€ 2.0.1/
â”œâ”€â”€ aumc/
â”‚   â””â”€â”€ 1.0.2/
â”œâ”€â”€ hirid/
â”‚   â””â”€â”€ 1.1.1/
â”œâ”€â”€ mimiciii/             â† æˆ– mimic-iii/, mimic/
â”‚   â””â”€â”€ 1.4/
â””â”€â”€ sicdb/                â† æˆ– sic/
    â””â”€â”€ 1.0.6/
```

**æç¤ºï¼š**
- ç‰ˆæœ¬æ–‡ä»¶å¤¹ (3.1, 2.0.1 ç­‰) æ˜¯å¯é€‰çš„
- æ•°æ®åº“æ–‡ä»¶å¤¹åç§°å¯ä»¥å˜åŒ– (mimiciv, mimic-iv, miiv)
- ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ­£ç¡®çš„è·¯å¾„
"""
        st.markdown(struct_info)


def _generate_mock_multidb_data(lang: str = 'en') -> Dict[str, pd.DataFrame]:
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„å¤šæ•°æ®åº“ç‰¹å¾åˆ†å¸ƒæ•°æ®ç”¨äºæ¼”ç¤ºã€‚
    
    Args:
        lang: è¯­è¨€
        
    Returns:
        å­—å…¸ï¼Œé”®ä¸ºæ•°æ®åº“åï¼Œå€¼ä¸ºç‰¹å¾æ•°æ®DataFrameï¼ˆé•¿æ ¼å¼ï¼Œå«conceptå’Œvalueåˆ—ï¼‰
    """
    np.random.seed(42)
    
    # ğŸ”§ æ‰©å±•ç‰¹å¾åˆ—è¡¨ï¼Œæ¶µç›–æ›´å¤šä¸´åºŠæŒ‡æ ‡
    # ğŸ”§ FIX: æ¨¡æ‹Ÿ6ä¸ªæ•°æ®åº“ï¼ˆæ·»åŠ  MIMIC-III å’Œ SICdbï¼‰
    databases = {
        'miiv': {
            # Vital Signs
            'hr': (80, 15), 'sbp': (120, 20), 'dbp': (70, 12), 'map': (85, 15),
            'temp': (37.2, 0.5), 'resp': (18, 4), 'spo2': (96, 3),
            # Laboratory
            'glu': (140, 50), 'na': (140, 5), 'k': (4.2, 0.6), 'crea': (1.2, 0.8),
            'bili': (1.5, 1.2), 'lact': (2.2, 1.5),
            # Hematology
            'hgb': (11, 2), 'plt': (200, 80), 'wbc': (12, 5),
            # Blood Gas
            'ph': (7.38, 0.08), 'po2': (90, 20), 'pco2': (40, 8), 'fio2': (45, 20),
        },
        'eicu': {
            'hr': (85, 18), 'sbp': (125, 25), 'dbp': (72, 14), 'map': (88, 18),
            'temp': (37.0, 0.6), 'resp': (20, 5), 'spo2': (95, 4),
            'glu': (150, 60), 'na': (139, 6), 'k': (4.0, 0.7), 'crea': (1.4, 1.0),
            'bili': (1.8, 1.5), 'lact': (2.5, 1.8),
            'hgb': (10.5, 2.2), 'plt': (180, 90), 'wbc': (13, 6),
            'ph': (7.36, 0.09), 'po2': (85, 22), 'pco2': (42, 10), 'fio2': (50, 25),
        },
        'aumc': {
            'hr': (75, 12), 'sbp': (115, 18), 'dbp': (65, 10), 'map': (80, 12),
            'temp': (37.4, 0.4), 'resp': (16, 3), 'spo2': (97, 2),
            'glu': (130, 45), 'na': (141, 4), 'k': (4.3, 0.5), 'crea': (1.0, 0.6),
            'bili': (1.2, 1.0), 'lact': (1.8, 1.2),
            'hgb': (11.5, 1.8), 'plt': (220, 70), 'wbc': (11, 4),
            'ph': (7.40, 0.06), 'po2': (95, 18), 'pco2': (38, 6), 'fio2': (40, 18),
        },
        'hirid': {
            'hr': (78, 14), 'sbp': (118, 22), 'dbp': (68, 11), 'map': (83, 14),
            'temp': (37.3, 0.5), 'resp': (17, 4), 'spo2': (96, 3),
            'glu': (135, 48), 'na': (140, 5), 'k': (4.1, 0.6), 'crea': (1.1, 0.7),
            'bili': (1.4, 1.1), 'lact': (2.0, 1.4),
            'hgb': (11.2, 2.0), 'plt': (210, 75), 'wbc': (11.5, 4.5),
            'ph': (7.39, 0.07), 'po2': (92, 19), 'pco2': (39, 7), 'fio2': (42, 19),
        },
        # ğŸ†• MIMIC-III
        'mimic': {
            'hr': (82, 16), 'sbp': (122, 21), 'dbp': (71, 13), 'map': (86, 16),
            'temp': (37.1, 0.5), 'resp': (19, 4), 'spo2': (95, 3),
            'glu': (145, 55), 'na': (139, 5), 'k': (4.1, 0.6), 'crea': (1.3, 0.9),
            'bili': (1.6, 1.3), 'lact': (2.3, 1.6),
            'hgb': (10.8, 2.1), 'plt': (190, 85), 'wbc': (12.5, 5.5),
            'ph': (7.37, 0.08), 'po2': (88, 21), 'pco2': (41, 9), 'fio2': (48, 22),
        },
        # ğŸ†• SICdb
        'sic': {
            'hr': (77, 13), 'sbp': (116, 19), 'dbp': (67, 11), 'map': (82, 13),
            'temp': (37.3, 0.4), 'resp': (17, 3), 'spo2': (97, 2),
            'glu': (132, 46), 'na': (141, 4), 'k': (4.2, 0.5), 'crea': (1.05, 0.65),
            'bili': (1.3, 1.0), 'lact': (1.9, 1.3),
            'hgb': (11.3, 1.9), 'plt': (215, 72), 'wbc': (11.2, 4.2),
            'ph': (7.40, 0.06), 'po2': (93, 18), 'pco2': (38, 6), 'fio2': (41, 18),
        },
    }
    
    result = {}
    for db_name, features in databases.items():
        n_records_per_feat = np.random.randint(300, 600)
        
        # ç”Ÿæˆé•¿æ ¼å¼æ•°æ®ï¼ˆconcept + valueï¼‰
        rows = []
        for feat, (mean, std) in features.items():
            values = np.random.normal(mean, std, n_records_per_feat)
            patient_ids = np.random.randint(1000, 9999, n_records_per_feat)
            for pid, val in zip(patient_ids, values):
                rows.append({
                    'stay_id': pid,
                    'concept': feat,
                    'value': val,
                })
        
        result[db_name] = pd.DataFrame(rows)
    
    return result


def _generate_mock_cohort_dashboard_data(lang: str = 'en') -> pd.DataFrame:
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„é˜Ÿåˆ—ä»ªè¡¨ç›˜æ•°æ®ç”¨äºæ¼”ç¤ºã€‚
    
    Args:
        lang: è¯­è¨€
        
    Returns:
        åŒ…å«æ‚£è€…äººå£ç»Ÿè®¡å­¦å’Œç»“å±€æ•°æ®çš„DataFrame
    """
    np.random.seed(42)
    n_patients = 500
    
    # åŸºæœ¬äººå£ç»Ÿè®¡å­¦
    patient_ids = list(range(30000000, 30000000 + n_patients))
    ages = np.clip(np.random.normal(62, 16, n_patients), 18, 95).astype(int)
    genders = np.random.choice(['M', 'F'], n_patients, p=[0.56, 0.44])  # ä½¿ç”¨M/Fæ ¼å¼
    
    # å…¥ä½ç±»å‹
    admission_types = np.random.choice(
        ['EMERGENCY', 'ELECTIVE', 'URGENT', 'OBSERVATION'],
        n_patients,
        p=[0.55, 0.25, 0.15, 0.05]
    )
    
    # ä½é™¢æ—¶é•¿
    los_days = np.clip(np.random.lognormal(1.2, 0.9, n_patients), 0.5, 60)
    
    # æœºæ¢°é€šæ°”çŠ¶æ€ - çº¦35%éœ€è¦
    mech_vent = np.random.choice([True, False], n_patients, p=[0.35, 0.65])
    
    # è¡€ç®¡æ´»æ€§è¯ç‰© - çº¦25%ä½¿ç”¨
    vasopressors = np.random.choice([True, False], n_patients, p=[0.25, 0.75])
    
    # SOFAåˆ†æ•° - ä¸ç—…æƒ…ä¸¥é‡åº¦ç›¸å…³
    sofa_scores = np.clip(np.random.poisson(4, n_patients) + (mech_vent.astype(int) * 2), 0, 20)
    
    # æ­»äº¡ç»“å±€ - ä¸SOFAã€å¹´é¾„ã€ä½é™¢æ—¶é•¿ç›¸å…³
    mortality_prob = 0.08 + (sofa_scores / 100) + (ages / 500) + (los_days / 200)
    mortality_prob = np.clip(mortality_prob, 0, 0.6)
    mortality = np.random.random(n_patients) < mortality_prob
    
    # è¯Šæ–­ç±»åˆ«
    diagnoses = np.random.choice(
        ['Sepsis', 'Respiratory Failure', 'Cardiac', 'Neurological', 'Post-surgical', 'Trauma', 'Other'],
        n_patients,
        p=[0.25, 0.20, 0.15, 0.12, 0.15, 0.08, 0.05]
    )
    
    df = pd.DataFrame({
        'stay_id': patient_ids,
        'age': ages,
        'gender': genders,
        'admission_type': admission_types,
        'los_days': los_days,
        'los_hours': los_days * 24,  # æ·»åŠ los_hoursåˆ—
        'mech_vent': mech_vent,
        'vasopressors': vasopressors,
        'sofa_max': sofa_scores,
        'mortality': mortality,
        'survived': [1 if not m else 0 for m in mortality],  # æ·»åŠ survivedåˆ—ï¼ˆ1=å­˜æ´»ï¼Œ0=æ­»äº¡ï¼‰
        'first_icu_stay': np.random.choice([True, False], n_patients, p=[0.65, 0.35]),  # æ·»åŠ first_icu_stayåˆ—
        'diagnosis_group': diagnoses,
    })
    
    return df


def render_cohort_comparison_page():
    """æ¸²æŸ“é˜Ÿåˆ—å¯¹æ¯”å¯è§†åŒ–é¡µé¢ - åŒ…å«å¤šä¸ªå­æ ‡ç­¾é¡µ"""
    lang = st.session_state.get('language', 'en')
    
    page_title = "ğŸ“Š Cohort Analysis" if lang == 'en' else "ğŸ“Š é˜Ÿåˆ—åˆ†æ"
    st.markdown(f"## {page_title}")
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # å­æ ‡ç­¾é¡µ
    if lang == 'en':
        sub_tabs = st.tabs([
            "ğŸ‘¥ Group Comparison",
            "ğŸ“ˆ Multi-DB Distribution", 
            "ğŸ¯ Cohort Dashboard"
        ])
    else:
        sub_tabs = st.tabs([
            "ğŸ‘¥ åˆ†ç»„å¯¹æ¯”",
            "ğŸ“ˆ å¤šæ•°æ®åº“åˆ†å¸ƒ",
            "ğŸ¯ é˜Ÿåˆ—ä»ªè¡¨æ¿"
        ])
    
    with sub_tabs[0]:
        render_group_comparison_subtab(lang)
    
    with sub_tabs[1]:
        render_multidb_distribution_subtab(lang)
    
    with sub_tabs[2]:
        render_cohort_dashboard_subtab(lang)


def render_group_comparison_subtab(lang: str):
    """åˆ†ç»„å¯¹æ¯”å­æ ‡ç­¾é¡µ - å¸¦ç‹¬ç«‹æ•°æ®åŠ è½½é…ç½®"""
    
    st.markdown("### ğŸ‘¥ " + ("Group Comparison Analysis" if lang == 'en' else "åˆ†ç»„å¯¹æ¯”åˆ†æ"))
    
    # è·å–å½“å‰å…¥å£æ¨¡å¼
    entry_mode = st.session_state.get('entry_mode', 'none')
    
    # ========== Demoæ¨¡å¼ï¼šéœ€è¦ç”¨æˆ·ç‚¹å‡»ç”ŸæˆæŒ‰é’® ==========
    if entry_mode == 'demo':
        # æ£€æŸ¥æ˜¯å¦å·²ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        has_demo_data = 'grp_demographics' in st.session_state and st.session_state.get('grp_is_demo') == True
        
        if not has_demo_data:
            # å°šæœªç”Ÿæˆæ•°æ®ï¼Œæ˜¾ç¤ºç”Ÿæˆç•Œé¢
            st.markdown("---")
            
            # å±…ä¸­çš„é…ç½®å¡ç‰‡
            st.markdown("""
            <div style="text-align:center; padding:30px; background:linear-gradient(135deg,#1e3c72,#2a5298); 
                        border-radius:15px; margin:20px 0;">
                <div style="font-size:3rem; margin-bottom:10px;">ğŸ­</div>
                <h3 style="color:white; margin:0;">""" + ("Generate Demo Cohort Data" if lang == 'en' else "ç”Ÿæˆæ¼”ç¤ºé˜Ÿåˆ—æ•°æ®") + """</h3>
                <p style="color:#ccc; margin-top:10px;">""" + 
                ("Configure patient count and generate simulated demographics data" if lang == 'en' else "é…ç½®æ‚£è€…æ•°é‡å¹¶ç”Ÿæˆæ¨¡æ‹Ÿäººå£ç»Ÿè®¡å­¦æ•°æ®") + 
            """</p>
            </div>
            """, unsafe_allow_html=True)
            
            # é…ç½®åŒºåŸŸ
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                n_patients = st.slider(
                    "ğŸ‘¥ " + ("Number of Patients" if lang == 'en' else "æ‚£è€…æ•°é‡"),
                    min_value=50, max_value=500, value=100,
                    key="grp_demo_patients_init"
                )
                
                st.markdown("<div style='height:20px'></div>", unsafe_allow_html=True)
                
                if st.button(
                    "ğŸš€ " + ("Generate Demo Data" if lang == 'en' else "ç”Ÿæˆæ¼”ç¤ºæ•°æ®"),
                    type="primary",
                    use_container_width=True,
                    key="grp_generate_demo_btn"
                ):
                    st.session_state.mock_params['n_patients'] = n_patients
                    demographics_df = _generate_mock_demographics(n_patients, lang)
                    st.session_state['grp_demographics'] = demographics_df
                    st.session_state['grp_loaded_db'] = 'demo'
                    st.session_state['grp_is_demo'] = True
                    st.rerun()
            
            # æ˜¾ç¤ºæç¤ºä¿¡æ¯
            st.markdown("<div style='height:20px'></div>", unsafe_allow_html=True)
            st.info("ğŸ’¡ " + ("Click the button above to generate demo data for cohort analysis" if lang == 'en' else "ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ç”Ÿæˆé˜Ÿåˆ—åˆ†ææ¼”ç¤ºæ•°æ®"))
            return  # æœªç”Ÿæˆæ•°æ®æ—¶ä¸æ˜¾ç¤ºä¸‹æ–¹åˆ†æå†…å®¹
        
        # å·²ç”Ÿæˆæ•°æ®ï¼Œæ˜¾ç¤ºDemoæ¨¡å¼æç¤º
        demo_info = "ğŸ­ Using simulated demographics data for demonstration" if lang == 'en' else "ğŸ­ æ­£åœ¨ä½¿ç”¨æ¨¡æ‹Ÿäººå£ç»Ÿè®¡å­¦æ•°æ®è¿›è¡Œæ¼”ç¤º"
        st.info(demo_info)
        
        # å…è®¸è°ƒæ•´æ¨¡æ‹Ÿæ•°æ®å‚æ•°
        with st.expander("âš™ï¸ " + ("Demo Data Settings" if lang == 'en' else "æ¨¡æ‹Ÿæ•°æ®è®¾ç½®"), expanded=False):
            n_patients = st.slider(
                "Number of Patients" if lang == 'en' else "æ‚£è€…æ•°é‡",
                min_value=50, max_value=500, value=st.session_state.mock_params.get('n_patients', 100),
                key="grp_demo_patients"
            )
            if st.button("ğŸ”„ " + ("Regenerate Data" if lang == 'en' else "é‡æ–°ç”Ÿæˆæ•°æ®"), key="grp_regen_btn"):
                st.session_state.mock_params['n_patients'] = n_patients
                st.session_state['grp_demographics'] = _generate_mock_demographics(n_patients, lang)
                st.rerun()
    
    # ========== Real Dataæ¨¡å¼ï¼šæ˜¾ç¤ºå®Œæ•´æ•°æ®é…ç½® ==========
    else:
        with st.expander("âš™ï¸ " + ("Data Configuration" if lang == 'en' else "æ•°æ®é…ç½®"), expanded=True):
            col1, col2, col3 = st.columns([2, 1, 1])
            
            with col1:
                data_root = st.text_input(
                    "ğŸ“ " + ("ICU Data Root" if lang == 'en' else "ICUæ•°æ®æ ¹ç›®å½•"),
                    value=os.environ.get('RICU_DATA_PATH', '/home/zhuhb/icudb'),
                    key="grp_data_root",
                    help="Root directory containing database folders (mimiciv, eicu, aumc, hirid)" if lang == 'en' else "åŒ…å«æ•°æ®åº“æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•"
                )
                
                # ğŸ”§ ä½¿ç”¨é€šç”¨ç›®å½•ç»“æ„æŒ‡å—ç»„ä»¶
                render_directory_structure_guide(lang)
            
            with col2:
                db_options = {'miiv': 'MIMIC-IV', 'eicu': 'eICU', 'aumc': 'AUMC', 'hirid': 'HiRID', 'mimic': 'MIMIC-III', 'sic': 'SICdb'}
                selected_db = st.selectbox(
                    "ğŸ¥ " + ("Database" if lang == 'en' else "æ•°æ®åº“"),
                    options=list(db_options.keys()),
                    format_func=lambda x: db_options[x],
                    key="grp_db_select"
                )
            
            with col3:
                max_patients = st.number_input(
                    "ğŸ‘¥ " + ("Max Patients" if lang == 'en' else "æœ€å¤§æ‚£è€…æ•°"),
                    min_value=100,
                    max_value=10000,
                    value=1000,
                    step=100,
                    key="grp_max_patients"
                )
            
            # ä½¿ç”¨æ¨¡å—çº§æ™ºèƒ½è·¯å¾„æ£€æµ‹å‡½æ•°
            full_data_path = find_database_path(data_root, selected_db)
            
            # è·¯å¾„çŠ¶æ€æç¤º
            if os.path.exists(full_data_path):
                st.success(f"âœ… " + (f"Path valid: `{full_data_path}`" if lang == 'en' else f"è·¯å¾„æœ‰æ•ˆ: `{full_data_path}`"))
            else:
                st.warning(f"âš ï¸ " + (f"Path not found: `{full_data_path}`" if lang == 'en' else f"è·¯å¾„ä¸å­˜åœ¨: `{full_data_path}`"))
            
            # åŠ è½½æŒ‰é’®
            load_btn = st.button(
                "ğŸš€ " + ("Load Patient Demographics" if lang == 'en' else "åŠ è½½æ‚£è€…äººå£ç»Ÿè®¡å­¦æ•°æ®"),
                type="primary",
                key="grp_load_btn"
            )
            
            if load_btn:
                try:
                    from pyricu.patient_filter import PatientFilter
                    
                    with st.spinner("Loading demographics..." if lang == 'en' else "æ­£åœ¨åŠ è½½äººå£ç»Ÿè®¡å­¦æ•°æ®..."):
                        pf = PatientFilter(database=selected_db, data_path=full_data_path)
                        demographics_df = pf._load_demographics()
                        
                        # é™åˆ¶æ‚£è€…æ•°
                        if len(demographics_df) > max_patients:
                            demographics_df = demographics_df.head(max_patients)
                        
                        st.session_state['grp_demographics'] = demographics_df
                        st.session_state['grp_loaded_db'] = selected_db
                        st.session_state['grp_loaded_path'] = full_data_path
                        st.session_state['grp_is_demo'] = False
                        
                    st.success(f"âœ… Loaded {len(demographics_df):,} patients" if lang == 'en' else f"âœ… å·²åŠ è½½ {len(demographics_df):,} åæ‚£è€…")
                    st.rerun()
                except Exception as e:
                    st.error(f"Error: {e}")
    
    st.markdown("---")
    
    # ========== åˆ†ç»„å¯¹æ¯”åŒºåŸŸ ==========
    if 'grp_demographics' not in st.session_state:
        st.info("ğŸ‘† " + ("Configure data source and click 'Load' to start" if lang == 'en' else "é…ç½®æ•°æ®æºå¹¶ç‚¹å‡»'åŠ è½½'å¼€å§‹"))
        return
    
    demographics_df = st.session_state['grp_demographics']
    database = st.session_state.get('grp_loaded_db', 'miiv')
    data_path = st.session_state.get('grp_loaded_path', '')
    
    # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Patients" if lang == 'en' else "æ‚£è€…æ€»æ•°", f"{len(demographics_df):,}")
    with col2:
        avg_age = demographics_df['age'].mean() if 'age' in demographics_df.columns else 0
        st.metric("Mean Age" if lang == 'en' else "å¹³å‡å¹´é¾„", f"{avg_age:.1f}")
    with col3:
        male_pct = (demographics_df['gender'] == 'M').mean() * 100 if 'gender' in demographics_df.columns else 0
        st.metric("Male %" if lang == 'en' else "ç”·æ€§å æ¯”", f"{male_pct:.1f}%")
    with col4:
        mortality = (1 - demographics_df['survived'].mean()) * 100 if 'survived' in demographics_df.columns else 0
        st.metric("Mortality" if lang == 'en' else "æ­»äº¡ç‡", f"{mortality:.1f}%")
    
    st.markdown("---")
    
    # å¯¹æ¯”æ¨¡å¼é€‰æ‹©
    st.markdown("#### " + ("ğŸ”€ Select Comparison Mode" if lang == 'en' else "ğŸ”€ é€‰æ‹©å¯¹æ¯”æ¨¡å¼"))
    
    compare_options = {
        'survival': ('ğŸ’€ Survived vs Deceased', 'ğŸ’€ å­˜æ´» vs æ­»äº¡'),
        'age': ('ğŸ‘´ Age Groups', 'ğŸ‘´ å¹´é¾„åˆ†ç»„'),
        'gender': ('ğŸ‘« Male vs Female', 'ğŸ‘« ç”·æ€§ vs å¥³æ€§'),
        'los': ('ğŸ¥ Short vs Long Stay', 'ğŸ¥ çŸ­ä½é™¢ vs é•¿ä½é™¢'),
    }
    
    compare_mode = st.radio(
        "Comparison Mode" if lang == 'en' else "å¯¹æ¯”æ¨¡å¼",
        options=list(compare_options.keys()),
        format_func=lambda x: compare_options[x][0] if lang == 'en' else compare_options[x][1],
        horizontal=True,
        key="group_comp_mode"
    )
    
    # æ ¹æ®æ¨¡å¼æ˜¾ç¤ºé¢å¤–é…ç½®
    if compare_mode == 'age':
        age_threshold = st.slider(
            "Age Threshold" if lang == 'en' else "å¹´é¾„é˜ˆå€¼",
            min_value=30, max_value=90, value=65, step=5,
            key="group_comp_age_threshold"
        )
    elif compare_mode == 'los' and 'los_hours' in demographics_df.columns:
        median_los = demographics_df['los_hours'].median()
        los_threshold = st.slider(
            "LOS Threshold (hours)" if lang == 'en' else "ä½é™¢æ—¶é•¿é˜ˆå€¼ï¼ˆå°æ—¶ï¼‰",
            min_value=24,
            max_value=int(min(500, demographics_df['los_hours'].quantile(0.95))),
            value=int(median_los),
            step=12,
            key="group_comp_los_threshold"
        )
    
    st.markdown("---")
    
    # ========== ç‰¹å¾æ¨¡å—é€‰æ‹© ==========
    st.markdown("#### " + ("ğŸ“Š Select Feature Modules" if lang == 'en' else "ğŸ“Š é€‰æ‹©ç‰¹å¾æ¨¡å—"))
    
    # å®šä¹‰æ‰€æœ‰å¯ç”¨çš„ç‰¹å¾æ¨¡å—
    FEATURE_MODULES = {
        'demographic': {
            'name_en': 'ğŸ‘¤ Demographics',
            'name_zh': 'ğŸ‘¤ äººå£ç»Ÿè®¡å­¦',
            'features': [
                ('age', 'Age (years)', 'å¹´é¾„ (å²)', 'continuous'),
                ('gender', 'Male', 'ç”·æ€§', 'binary', 'M'),
                ('los_days', 'ICU LOS (days)', 'ICUä½é™¢æ—¶é•¿ (å¤©)', 'continuous'),
                ('first_icu_stay', 'First ICU Stay', 'é¦–æ¬¡ICUå…¥ä½', 'binary', True),
            ],
            'default': True
        },
        'outcome': {
            'name_en': 'ğŸ“ˆ Outcomes',
            'name_zh': 'ğŸ“ˆ ç»“å±€æŒ‡æ ‡',
            'features': [
                ('mortality', 'ICU Mortality', 'ICUæ­»äº¡ç‡', 'binary_survival'),
            ],
            'default': True
        },
        'vital': {
            'name_en': 'ğŸ’“ Vital Signs',
            'name_zh': 'ğŸ’“ ç”Ÿå‘½ä½“å¾',
            'features': [
                ('hr', 'Heart Rate (bpm)', 'å¿ƒç‡ (bpm)', 'continuous'),
                ('sbp', 'Systolic BP (mmHg)', 'æ”¶ç¼©å‹ (mmHg)', 'continuous'),
                ('dbp', 'Diastolic BP (mmHg)', 'èˆ’å¼ å‹ (mmHg)', 'continuous'),
                ('map', 'Mean Arterial Pressure (mmHg)', 'å¹³å‡åŠ¨è„‰å‹ (mmHg)', 'continuous'),
                ('resp', 'Respiratory Rate', 'å‘¼å¸é¢‘ç‡', 'continuous'),
                ('temp', 'Temperature (Â°C)', 'ä½“æ¸© (Â°C)', 'continuous'),
                ('o2sat', 'SpO2 (%)', 'è¡€æ°§é¥±å’Œåº¦ (%)', 'continuous'),
            ],
            'default': True
        },
        'lab': {
            'name_en': 'ğŸ§ª Laboratory',
            'name_zh': 'ğŸ§ª å®éªŒå®¤æ£€æŸ¥',
            'features': [
                ('glu', 'Glucose (mg/dL)', 'è¡€ç³– (mg/dL)', 'continuous'),
                ('na', 'Sodium (mEq/L)', 'é’  (mEq/L)', 'continuous'),
                ('k', 'Potassium (mEq/L)', 'é’¾ (mEq/L)', 'continuous'),
                ('crea', 'Creatinine (mg/dL)', 'è‚Œé… (mg/dL)', 'continuous'),
                ('bili', 'Bilirubin (mg/dL)', 'èƒ†çº¢ç´  (mg/dL)', 'continuous'),
                ('lact', 'Lactate (mmol/L)', 'ä¹³é…¸ (mmol/L)', 'continuous'),
            ],
            'default': False
        },
        'hematology': {
            'name_en': 'ğŸ©¸ Hematology',
            'name_zh': 'ğŸ©¸ è¡€æ¶²å­¦',
            'features': [
                ('hgb', 'Hemoglobin (g/dL)', 'è¡€çº¢è›‹ç™½ (g/dL)', 'continuous'),
                ('plt', 'Platelets (K/uL)', 'è¡€å°æ¿ (K/uL)', 'continuous'),
                ('wbc', 'WBC (K/uL)', 'ç™½ç»†èƒ (K/uL)', 'continuous'),
            ],
            'default': False
        },
        'blood_gas': {
            'name_en': 'ğŸ©¸ Blood Gas',
            'name_zh': 'ğŸ©¸ è¡€æ°”åˆ†æ',
            'features': [
                ('ph', 'pH', 'pHå€¼', 'continuous'),
                ('po2', 'PaO2 (mmHg)', 'PaO2 (mmHg)', 'continuous'),
                ('pco2', 'PaCO2 (mmHg)', 'PaCO2 (mmHg)', 'continuous'),
                ('fio2', 'FiO2 (%)', 'FiO2 (%)', 'continuous'),
            ],
            'default': False
        },
        'sofa': {
            'name_en': 'ğŸ¥ SOFA Scores',
            'name_zh': 'ğŸ¥ SOFAè¯„åˆ†',
            'features': [
                ('sofa', 'SOFA Score', 'SOFAè¯„åˆ†', 'continuous'),
                ('sofa_resp', 'SOFA Respiratory', 'SOFAå‘¼å¸', 'continuous'),
                ('sofa_coag', 'SOFA Coagulation', 'SOFAå‡è¡€', 'continuous'),
                ('sofa_liver', 'SOFA Liver', 'SOFAè‚è„', 'continuous'),
                ('sofa_cardio', 'SOFA Cardiovascular', 'SOFAå¿ƒè¡€ç®¡', 'continuous'),
                ('sofa_cns', 'SOFA CNS', 'SOFAç¥ç»', 'continuous'),
                ('sofa_renal', 'SOFA Renal', 'SOFAè‚¾è„', 'continuous'),
            ],
            'default': False
        },
    }
    
    # æ¨¡å—å¤šé€‰
    default_modules = [k for k, v in FEATURE_MODULES.items() if v.get('default', False)]
    selected_modules = st.multiselect(
        "Select feature modules" if lang == 'en' else "é€‰æ‹©ç‰¹å¾æ¨¡å—",
        options=list(FEATURE_MODULES.keys()),
        default=default_modules,
        format_func=lambda x: FEATURE_MODULES[x]['name_en'] if lang == 'en' else FEATURE_MODULES[x]['name_zh'],
        key="grp_feature_modules"
    )
    
    # æ˜¾ç¤ºå°†è¦åŠ è½½çš„ç‰¹å¾
    if selected_modules:
        concepts_to_load = []
        for mod in selected_modules:
            if mod not in ['demographic', 'outcome']:  # è¿™äº›ä» demographics è¡¨è·å–
                for feat in FEATURE_MODULES[mod]['features']:
                    concepts_to_load.append(feat[0])
        
        if concepts_to_load:
            with st.expander("ğŸ”¬ " + (f"Features to load: {len(concepts_to_load)}" if lang == 'en' else f"å¾…åŠ è½½ç‰¹å¾: {len(concepts_to_load)}ä¸ª"), expanded=False):
                st.caption(", ".join(concepts_to_load))
    
    st.markdown("---")
    
    # æ‰§è¡Œåˆ†ç»„
    try:
        base_df = demographics_df
        group1_ids, group2_ids = [], []
        group1_name, group2_name = "", ""
        show_mortality = True
        
        # æ£€æµ‹IDåˆ—åï¼ˆæ”¯æŒstay_idæˆ–patient_idï¼‰
        id_col = 'stay_id' if 'stay_id' in base_df.columns else 'patient_id'
        
        if compare_mode == 'survival':
            if 'survived' not in base_df.columns:
                st.warning("Survival data not available" if lang == 'en' else "æ— å­˜æ´»çŠ¶æ€æ•°æ®")
                return
            
            survived_df = base_df[base_df['survived'] == 1]
            deceased_df = base_df[base_df['survived'] == 0]
            group1_ids = survived_df[id_col].tolist()
            group2_ids = deceased_df[id_col].tolist()
            group1_name = 'Survived' if lang == 'en' else 'å­˜æ´»'
            group2_name = 'Deceased' if lang == 'en' else 'æ­»äº¡'
            show_mortality = False
            
        elif compare_mode == 'age':
            threshold = st.session_state.get('group_comp_age_threshold', 65)
            young_df = base_df[base_df['age'] < threshold]
            old_df = base_df[base_df['age'] >= threshold]
            group1_ids = young_df[id_col].tolist()
            group2_ids = old_df[id_col].tolist()
            group1_name = f'Age < {threshold}' if lang == 'en' else f'å¹´é¾„ < {threshold}'
            group2_name = f'Age â‰¥ {threshold}' if lang == 'en' else f'å¹´é¾„ â‰¥ {threshold}'
            
        elif compare_mode == 'gender':
            if 'gender' not in base_df.columns:
                st.warning("Gender data not available" if lang == 'en' else "æ— æ€§åˆ«æ•°æ®")
                return
            male_df = base_df[base_df['gender'] == 'M']
            female_df = base_df[base_df['gender'] == 'F']
            group1_ids = male_df[id_col].tolist()
            group2_ids = female_df[id_col].tolist()
            group1_name = 'Male' if lang == 'en' else 'ç”·æ€§'
            group2_name = 'Female' if lang == 'en' else 'å¥³æ€§'
            
        elif compare_mode == 'los':
            if 'los_hours' not in base_df.columns:
                st.warning("Length of stay data not available" if lang == 'en' else "æ— ä½é™¢æ—¶é•¿æ•°æ®")
                return
            threshold = st.session_state.get('group_comp_los_threshold', int(base_df['los_hours'].median()))
            short_df = base_df[base_df['los_hours'] < threshold]
            long_df = base_df[base_df['los_hours'] >= threshold]
            group1_ids = short_df[id_col].tolist()
            group2_ids = long_df[id_col].tolist()
            group1_name = f'LOS < {threshold}h' if lang == 'en' else f'ä½é™¢ < {threshold}h'
            group2_name = f'LOS â‰¥ {threshold}h' if lang == 'en' else f'ä½é™¢ â‰¥ {threshold}h'
        
        # åˆ†ç»„ç»Ÿè®¡æ¦‚è§ˆ
        st.markdown("#### " + ("ğŸ“Š Group Overview" if lang == 'en' else "ğŸ“Š åˆ†ç»„æ¦‚è§ˆ"))
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric(group1_name, f"{len(group1_ids):,}")
        with col2:
            st.metric(group2_name, f"{len(group2_ids):,}")
        with col3:
            total = len(group1_ids) + len(group2_ids)
            pct1 = len(group1_ids) / total * 100 if total > 0 else 0
            st.metric("Ratio" if lang == 'en' else "æ¯”ä¾‹", f"{pct1:.1f}% / {100-pct1:.1f}%")
        
        if len(group1_ids) == 0 or len(group2_ids) == 0:
            st.warning("One group is empty, please adjust criteria" if lang == 'en' else "å…¶ä¸­ä¸€ä¸ªåˆ†ç»„ä¸ºç©ºï¼Œè¯·è°ƒæ•´æ¡ä»¶")
            return
        
        st.markdown("---")
        
        # ========== åŸºçº¿ç‰¹å¾å¯¹æ¯”è¡¨ (Table One) ==========
        st.markdown("#### " + ("ğŸ“‹ Baseline Characteristics Comparison" if lang == 'en' else "ğŸ“‹ åŸºçº¿ç‰¹å¾å¯¹æ¯”è¡¨"))
        
        from scipy import stats
        
        # è·å–ä¸¤ç»„æ•°æ® - ä½¿ç”¨åŠ¨æ€IDåˆ—
        group1_df = base_df[base_df[id_col].isin(group1_ids)].copy()
        group2_df = base_df[base_df[id_col].isin(group2_ids)].copy()
        
        # ========== åŠ è½½é¢å¤–ç‰¹å¾æ•°æ® ==========
        # ç¡®å®šéœ€è¦åŠ è½½çš„æ¦‚å¿µ
        concepts_to_load = []
        for mod in selected_modules:
            if mod not in ['demographic', 'outcome']:  # è¿™äº›ä» demographics è¡¨è·å–
                for feat in FEATURE_MODULES[mod]['features']:
                    concepts_to_load.append(feat[0])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦åŠ è½½çš„ç‰¹å¾ä¸”å°šæœªåŠ è½½
        feature_data = st.session_state.get('grp_feature_data', {})
        
        # åˆå¹¶ä¸¤ç»„æ‚£è€…ID
        all_patient_ids = list(set(group1_ids + group2_ids))
        
        if concepts_to_load:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ¦‚å¿µéœ€è¦åŠ è½½
            missing_concepts = [c for c in concepts_to_load if c not in feature_data]
            
            if missing_concepts:
                # Demoæ¨¡å¼ï¼šè‡ªåŠ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼Œæ— éœ€ç”¨æˆ·ç‚¹å‡»
                if entry_mode == 'demo' or database == 'demo':
                    auto_load_msg = "Auto-loading simulated features for demo mode..." if lang == 'en' else "æ¼”ç¤ºæ¨¡å¼è‡ªåŠ¨åŠ è½½æ¨¡æ‹Ÿç‰¹å¾æ•°æ®..."
                    with st.spinner(auto_load_msg):
                        # ç‰¹å¾çš„æ¨¡æ‹Ÿå‚æ•° (å‡å€¼, æ ‡å‡†å·®)
                        mock_params = {
                            'hr': (80, 15), 'sbp': (120, 20), 'dbp': (70, 12), 'map': (85, 15),
                            'resp': (18, 4), 'temp': (37.0, 0.6), 'o2sat': (96, 3),
                            'glu': (120, 40), 'na': (140, 4), 'k': (4.2, 0.5),
                            'crea': (1.2, 0.8), 'bili': (1.5, 2.0), 'lact': (1.5, 1.0),
                            'hgb': (11, 2), 'plt': (200, 80), 'wbc': (10, 4),
                            'alb': (3.5, 0.6), 'pco2': (40, 8), 'po2': (90, 20),
                            'ph': (7.38, 0.08), 'fio2': (40, 20),
                        }
                        
                        for concept in missing_concepts:
                            mean, std = mock_params.get(concept, (50, 15))
                            values = np.random.normal(mean, std, len(all_patient_ids))
                            feature_data[concept] = pd.DataFrame({
                                id_col: all_patient_ids,
                                concept: values
                            })
                        
                        st.session_state['grp_feature_data'] = feature_data
                else:
                    # çœŸå®æ•°æ®æ¨¡å¼ï¼šæ˜¾ç¤ºåŠ è½½æç¤ºå’ŒæŒ‰é’®
                    st.info(f"ğŸ”¬ " + (f"{len(missing_concepts)} features need to be loaded: " if lang == 'en' else f"éœ€è¦åŠ è½½ {len(missing_concepts)} ä¸ªç‰¹å¾: ") + ", ".join(missing_concepts[:5]) + ("..." if len(missing_concepts) > 5 else ""))
                    
                    load_features_btn = st.button(
                        "ğŸš€ " + (f"Load {len(missing_concepts)} Features" if lang == 'en' else f"åŠ è½½ {len(missing_concepts)} ä¸ªç‰¹å¾"),
                        type="primary",
                        key="grp_load_features"
                    )
                    
                    if load_features_btn:
                        # Real Dataæ¨¡å¼ï¼šä»æ•°æ®åº“åŠ è½½
                        try:
                            from pyricu import load_concepts
                            
                            with st.spinner(f"Loading {len(missing_concepts)} features for {len(all_patient_ids)} patients..." if lang == 'en' else f"æ­£åœ¨åŠ è½½ {len(missing_concepts)} ä¸ªç‰¹å¾..."):
                                progress_bar = st.progress(0)
                                loaded_count = 0
                                
                                for i, concept in enumerate(missing_concepts):
                                    try:
                                        df_concept = load_concepts(
                                            concepts=[concept],
                                            database=database,
                                            data_path=data_path,
                                            patient_ids=all_patient_ids,
                                            verbose=False
                                        )
                                        if df_concept is not None and len(df_concept) > 0:
                                            # ç¡®å®šIDåˆ—
                                            feat_id_col = None
                                            for col in ['stay_id', 'patientunitstayid', 'admissionid', 'patientid', 'hadm_id']:
                                                if col in df_concept.columns:
                                                    feat_id_col = col
                                                    break
                                            if feat_id_col is None:
                                                feat_id_col = df_concept.columns[0]
                                            
                                            # å–æ¯ä¸ªæ‚£è€…çš„å¹³å‡å€¼
                                            if concept in df_concept.columns:
                                                agg_df = df_concept.groupby(feat_id_col)[concept].mean().reset_index()
                                                agg_df.columns = [id_col, concept]
                                                agg_df[id_col] = agg_df[id_col].astype(int)
                                                feature_data[concept] = agg_df
                                                loaded_count += 1
                                    except Exception:
                                        pass
                                    
                                    progress_bar.progress((i + 1) / len(missing_concepts))
                                
                                progress_bar.empty()
                                st.session_state['grp_feature_data'] = feature_data
                                st.success(f"âœ… " + (f"Loaded {loaded_count}/{len(missing_concepts)} features" if lang == 'en' else f"å·²åŠ è½½ {loaded_count}/{len(missing_concepts)} ä¸ªç‰¹å¾"))
                                st.rerun()
                        except Exception as e:
                            st.error(f"Error loading features: {e}")
        
        # åˆå¹¶å·²åŠ è½½çš„ç‰¹å¾æ•°æ®åˆ°åˆ†ç»„ DataFrame
        # ç¡®ä¿ ID ç±»å‹ä¸€è‡´
        group1_df[id_col] = group1_df[id_col].astype(int)
        group2_df[id_col] = group2_df[id_col].astype(int)
        
        for concept, feat_df in feature_data.items():
            if concept not in group1_df.columns and concept in concepts_to_load:
                try:
                    feat_df_copy = feat_df.copy()
                    # æ£€æµ‹ç‰¹å¾æ•°æ®ä¸­çš„IDåˆ—
                    feat_id_col = None
                    for col in ['stay_id', 'patient_id', 'patientunitstayid', 'admissionid', 'patientid', 'icustay_id', 'CaseID']:
                        if col in feat_df_copy.columns:
                            feat_id_col = col
                            break
                    if feat_id_col is None:
                        continue
                    feat_df_copy[feat_id_col] = feat_df_copy[feat_id_col].astype(int)
                    # é‡å‘½åä¸ºç»Ÿä¸€çš„id_col
                    if feat_id_col != id_col:
                        feat_df_copy[id_col] = feat_df_copy[feat_id_col]
                    group1_df = group1_df.merge(feat_df_copy[[id_col, concept]], on=id_col, how='left')
                    group2_df = group2_df.merge(feat_df_copy[[id_col, concept]], on=id_col, how='left')
                except Exception:
                    pass
        
        def format_continuous(series, name):
            """æ ¼å¼åŒ–è¿ç»­å˜é‡: mean Â± std (median [IQR])"""
            valid = series.dropna()
            if len(valid) == 0:
                return '-'
            mean, std = valid.mean(), valid.std()
            median = valid.median()
            q25, q75 = valid.quantile(0.25), valid.quantile(0.75)
            return f"{mean:.1f} Â± {std:.1f} ({median:.1f} [{q25:.1f}-{q75:.1f}])"
        
        def format_categorical(series, category, total):
            """æ ¼å¼åŒ–åˆ†ç±»å˜é‡: n (%)"""
            n = (series == category).sum()
            pct = n / total * 100 if total > 0 else 0
            return f"{n:,} ({pct:.1f}%)"
        
        def calc_pvalue_continuous(s1, s2):
            """è¿ç»­å˜é‡ p å€¼ (Mann-Whitney U)"""
            v1, v2 = s1.dropna(), s2.dropna()
            if len(v1) < 2 or len(v2) < 2:
                return '-'
            try:
                stat, p = stats.mannwhitneyu(v1, v2, alternative='two-sided')
                return f"{p:.3f}" if p >= 0.001 else "<0.001"
            except:
                return '-'
        
        def calc_pvalue_categorical(s1, s2, categories):
            """åˆ†ç±»å˜é‡ p å€¼ (Chi-square)"""
            try:
                obs1 = [int((s1 == c).sum()) for c in categories]
                obs2 = [int((s2 == c).sum()) for c in categories]
                # å»é™¤å…¨0çš„ç±»åˆ«
                valid_idx = [i for i in range(len(categories)) if obs1[i] + obs2[i] > 0]
                if len(valid_idx) < 2:
                    return '-'
                table = [[obs1[i], obs2[i]] for i in valid_idx]
                chi2, p, dof, expected = stats.chi2_contingency(table)
                return f"{p:.3f}" if p >= 0.001 else "<0.001"
            except:
                return '-'
        
        # æ„å»ºè¡¨æ ¼æ•°æ® - æ ¹æ®é€‰ä¸­çš„æ¨¡å—åŠ¨æ€ç”Ÿæˆ
        table_data = []
        
        # æ ·æœ¬é‡ (æ€»æ˜¯æ˜¾ç¤º)
        table_data.append({
            'Module': '',
            'Characteristic': 'N' if lang == 'en' else 'æ ·æœ¬é‡',
            group1_name: f"{len(group1_df):,}",
            group2_name: f"{len(group2_df):,}",
            'p-value': ''
        })
        
        # éå†é€‰ä¸­çš„æ¨¡å—
        for mod_key in selected_modules:
            mod_info = FEATURE_MODULES[mod_key]
            mod_name = mod_info['name_en'] if lang == 'en' else mod_info['name_zh']
            is_first_in_module = True
            
            for feat_info in mod_info['features']:
                feat_key = feat_info[0]
                feat_name_en = feat_info[1]
                feat_name_zh = feat_info[2]
                feat_type = feat_info[3]
                
                feat_display = feat_name_en if lang == 'en' else feat_name_zh
                module_display = mod_name if is_first_in_module else ''
                is_first_in_module = False
                
                # å¤„ç†ä¸åŒç±»å‹çš„ç‰¹å¾
                if mod_key == 'demographic':
                    if feat_key == 'age' and 'age' in group1_df.columns:
                        table_data.append({
                            'Module': module_display,
                            'Characteristic': feat_display,
                            group1_name: format_continuous(group1_df['age'], 'age'),
                            group2_name: format_continuous(group2_df['age'], 'age'),
                            'p-value': calc_pvalue_continuous(group1_df['age'], group2_df['age'])
                        })
                    elif feat_key == 'gender' and 'gender' in group1_df.columns:
                        table_data.append({
                            'Module': module_display,
                            'Characteristic': feat_display,
                            group1_name: format_categorical(group1_df['gender'], 'M', len(group1_df)),
                            group2_name: format_categorical(group2_df['gender'], 'M', len(group2_df)),
                            'p-value': calc_pvalue_categorical(group1_df['gender'], group2_df['gender'], ['M', 'F'])
                        })
                    elif feat_key == 'los_days' and 'los_hours' in group1_df.columns:
                        g1_los = group1_df['los_hours'] / 24
                        g2_los = group2_df['los_hours'] / 24
                        table_data.append({
                            'Module': module_display,
                            'Characteristic': feat_display,
                            group1_name: format_continuous(g1_los, 'los'),
                            group2_name: format_continuous(g2_los, 'los'),
                            'p-value': calc_pvalue_continuous(g1_los, g2_los)
                        })
                    elif feat_key == 'first_icu_stay' and 'first_icu_stay' in group1_df.columns:
                        table_data.append({
                            'Module': module_display,
                            'Characteristic': feat_display,
                            group1_name: format_categorical(group1_df['first_icu_stay'], True, len(group1_df)),
                            group2_name: format_categorical(group2_df['first_icu_stay'], True, len(group2_df)),
                            'p-value': calc_pvalue_categorical(group1_df['first_icu_stay'], group2_df['first_icu_stay'], [True, False])
                        })
                
                elif mod_key == 'outcome':
                    if feat_key == 'mortality' and 'survived' in group1_df.columns and show_mortality:
                        mort1 = (1 - group1_df['survived'].mean()) * 100
                        mort2 = (1 - group2_df['survived'].mean()) * 100
                        table_data.append({
                            'Module': module_display,
                            'Characteristic': feat_display,
                            group1_name: f"{int((group1_df['survived']==0).sum()):,} ({mort1:.1f}%)",
                            group2_name: f"{int((group2_df['survived']==0).sum()):,} ({mort2:.1f}%)",
                            'p-value': calc_pvalue_categorical(group1_df['survived'], group2_df['survived'], [0, 1])
                        })
                
                else:
                    # ä»åŠ è½½çš„ç‰¹å¾æ•°æ®è·å–
                    # é¦–å…ˆå°è¯•ä» group_df çš„åˆ—è·å–
                    if feat_key in group1_df.columns:
                        table_data.append({
                            'Module': module_display,
                            'Characteristic': feat_display,
                            group1_name: format_continuous(group1_df[feat_key], feat_key),
                            group2_name: format_continuous(group2_df[feat_key], feat_key),
                            'p-value': calc_pvalue_continuous(group1_df[feat_key], group2_df[feat_key])
                        })
                    # å¦‚æœæ²¡åœ¨ group_df ä¸­ï¼Œå°è¯•ç›´æ¥ä» feature_data è·å–
                    elif feat_key in feature_data:
                        feat_df = feature_data[feat_key]
                        # æ£€æµ‹IDåˆ—
                        feat_id_col = None
                        for col in ['stay_id', 'patient_id', 'patientunitstayid', 'admissionid', 'patientid', 'icustay_id', 'CaseID']:
                            if col in feat_df.columns:
                                feat_id_col = col
                                break
                        if feat_id_col is None:
                            feat_id_col = id_col
                        # æŒ‰ç»„ç­›é€‰
                        g1_ids_set = set(group1_df[id_col].astype(int).tolist())
                        g2_ids_set = set(group2_df[id_col].astype(int).tolist())
                        g1_vals = feat_df[feat_df[feat_id_col].astype(int).isin(g1_ids_set)][feat_key]
                        g2_vals = feat_df[feat_df[feat_id_col].astype(int).isin(g2_ids_set)][feat_key]
                        
                        if len(g1_vals) > 0 or len(g2_vals) > 0:
                            table_data.append({
                                'Module': module_display,
                                'Characteristic': feat_display,
                                group1_name: format_continuous(g1_vals, feat_key) if len(g1_vals) > 0 else 'N/A',
                                group2_name: format_continuous(g2_vals, feat_key) if len(g2_vals) > 0 else 'N/A',
                                'p-value': calc_pvalue_continuous(g1_vals, g2_vals) if len(g1_vals) > 0 and len(g2_vals) > 0 else '-'
                            })
                        else:
                            table_data.append({
                                'Module': module_display,
                                'Characteristic': feat_display,
                                group1_name: 'No data',
                                group2_name: 'No data',
                                'p-value': '-'
                            })
                    elif feat_key in concepts_to_load:
                        # ç‰¹å¾éœ€è¦åŠ è½½ä½†å°šæœªåŠ è½½
                        table_data.append({
                            'Module': module_display,
                            'Characteristic': feat_display,
                            group1_name: 'â³ å¾…åŠ è½½',
                            group2_name: 'â³ å¾…åŠ è½½',
                            'p-value': '-'
                        })
        
        # æ˜¾ç¤ºè¡¨æ ¼
        result_df = pd.DataFrame(table_data)
        
        # ä½¿ç”¨ Streamlit è¡¨æ ¼å¹¶åº”ç”¨æ ·å¼
        st.dataframe(
            result_df,
            width='stretch',
            hide_index=True,
            column_config={
                'Module': st.column_config.TextColumn('Module' if lang == 'en' else 'æ¨¡å—', width='small'),
                'Characteristic': st.column_config.TextColumn('Characteristic' if lang == 'en' else 'ç‰¹å¾', width='medium'),
                group1_name: st.column_config.TextColumn(group1_name, width='medium'),
                group2_name: st.column_config.TextColumn(group2_name, width='medium'),
                'p-value': st.column_config.TextColumn('p-value', width='small'),
            }
        )
        
        # ç»Ÿè®¡æ–¹æ³•è¯´æ˜
        st.markdown("---")
        stats_note = """**Statistical Methods:**
- Continuous variables: Mean Â± SD (Median [IQR]), Mann-Whitney U test
- Categorical variables: n (%), Chi-square test
- p < 0.05 considered statistically significant""" if lang == 'en' else """**ç»Ÿè®¡æ–¹æ³•è¯´æ˜ï¼š**
- è¿ç»­å˜é‡ï¼šMean Â± SD (Median [IQR])ï¼ŒMann-Whitney U æ£€éªŒ
- åˆ†ç±»å˜é‡ï¼šn (%)ï¼Œå¡æ–¹æ£€éªŒ
- p < 0.05 è®¤ä¸ºå…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§"""
        st.caption(stats_note)
        
        # ğŸ”§ FIX (2026-02-04): ç®€åŒ–å¯¼å‡ºé€»è¾‘ï¼Œä½¿ç”¨ UTF-8 BOM ç¼–ç ç¡®ä¿ Excel æ­£ç¡®æ˜¾ç¤º
        # æ— éœ€æ‰‹åŠ¨æ›¿æ¢ç‰¹æ®Šå­—ç¬¦ï¼Œutf-8-sig ç¼–ç å¯ä»¥æ­£ç¡®å¤„ç†
        export_df = result_df.copy()
        
        # åªæ¸…ç† emojiï¼ˆè¿™äº›å¯èƒ½å¯¼è‡´é—®é¢˜ï¼‰
        for col in export_df.columns:
            if export_df[col].dtype == 'object':
                export_df[col] = export_df[col].apply(lambda x: strip_emoji(str(x)) if pd.notna(x) else x)
        
        # ä½¿ç”¨ BytesIO ç¡®ä¿ç¼–ç æ­£ç¡®ä¼ é€’
        import io
        buffer = io.BytesIO()
        export_df.to_csv(buffer, index=False, encoding='utf-8-sig')
        csv_bytes = buffer.getvalue()
        
        st.download_button(
            label="ğŸ“¥ " + ("Download Table (CSV)" if lang == 'en' else "ä¸‹è½½è¡¨æ ¼ (CSV)"),
            data=csv_bytes,
            file_name=f"baseline_comparison_{group1_name}_vs_{group2_name}.csv",
            mime="text/csv"
        )
        
    except Exception as e:
        st.error(f"Error: {e}")
        import traceback
        st.code(traceback.format_exc())


def render_multidb_distribution_subtab(lang: str):
    """å¤šæ•°æ®åº“ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”å­æ ‡ç­¾é¡µ"""
    import plotly.graph_objects as go
    
    # ğŸ”§ FIX: ä½¿ç”¨å®¹å™¨åŒ…è£…æ ‡é¢˜ï¼Œç¡®ä¿ä¸ä¸‹æ–¹å†…å®¹åˆ†éš”ï¼Œå¢åŠ è¶³å¤Ÿçš„é—´è·
    st.markdown("""<div style="margin-bottom: 40px;">
        <h3 style="margin: 0 0 15px 0; padding: 0;">ğŸ“ˆ """ + ("Multi-Database Feature Distribution Comparison" if lang == 'en' else "å¤šæ•°æ®åº“ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”") + """</h3>
        <hr style="margin: 0 0 30px 0; border: none; border-top: 2px solid #e0e0e0;">
    </div>""", unsafe_allow_html=True)
    
    # è·å–å…¥å£æ¨¡å¼
    entry_mode = st.session_state.get('entry_mode', 'none')
    
    # ========== Demoæ¨¡å¼ï¼šéœ€è¦ç”¨æˆ·ç‚¹å‡»ç”ŸæˆæŒ‰é’® ==========
    if entry_mode == 'demo':
        # æ£€æŸ¥æ˜¯å¦å·²ç”Ÿæˆæ•°æ®
        has_demo_data = 'multidb_data' in st.session_state and st.session_state.get('multidb_is_demo') == True
        
        if not has_demo_data:
            # å°šæœªç”Ÿæˆæ•°æ®ï¼Œæ˜¾ç¤ºç”Ÿæˆç•Œé¢
            st.markdown("---")
            
            # å±…ä¸­çš„é…ç½®å¡ç‰‡
            st.markdown("""
            <div style="text-align:center; padding:30px; background:linear-gradient(135deg,#2d5016,#4a7c23); 
                        border-radius:15px; margin:20px 0;">
                <div style="font-size:3rem; margin-bottom:10px;">ğŸ“Š</div>
                <h3 style="color:white; margin:0;">""" + ("Generate Multi-DB Distribution Data" if lang == 'en' else "ç”Ÿæˆå¤šæ•°æ®åº“åˆ†å¸ƒæ•°æ®") + """</h3>
                <p style="color:#ccc; margin-top:10px;">""" + 
                ("Click below to generate simulated feature distribution across multiple databases" if lang == 'en' else "ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç”Ÿæˆå¤šæ•°æ®åº“ç‰¹å¾åˆ†å¸ƒæ¨¡æ‹Ÿæ•°æ®") + 
            """</p>
            </div>
            """, unsafe_allow_html=True)
            
            # ç”ŸæˆæŒ‰é’®
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.markdown("<div style='height:20px'></div>", unsafe_allow_html=True)
                
                if st.button(
                    "ğŸš€ " + ("Generate Demo Data" if lang == 'en' else "ç”Ÿæˆæ¼”ç¤ºæ•°æ®"),
                    type="primary",
                    use_container_width=True,
                    key="multidb_generate_demo_btn"
                ):
                    # ç”Ÿæˆæ¨¡æ‹Ÿçš„å¤šæ•°æ®åº“ç‰¹å¾æ•°æ®
                    mock_data = _generate_mock_multidb_data(lang)
                    st.session_state['multidb_data'] = mock_data
                    # ğŸ”§ æ‰©å±•é»˜è®¤æ˜¾ç¤ºçš„ç‰¹å¾ï¼ŒåŒ…å«æ›´å¤šä¸´åºŠæŒ‡æ ‡
                    st.session_state['multidb_concepts'] = [
                        'hr', 'sbp', 'dbp', 'map', 'temp', 'resp', 'spo2',  # Vitals
                        'glu', 'na', 'k', 'crea', 'bili', 'lact',  # Labs
                        'hgb', 'plt', 'wbc',  # Hematology
                        'ph', 'po2', 'pco2', 'fio2',  # Blood Gas
                    ]
                    st.session_state['multidb_is_demo'] = True
                    st.rerun()
            
            # æ˜¾ç¤ºæç¤ºä¿¡æ¯
            st.markdown("<div style='height:20px'></div>", unsafe_allow_html=True)
            st.info("ğŸ’¡ " + ("Click the button above to generate demo data for multi-database distribution analysis" if lang == 'en' else "ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ç”Ÿæˆå¤šæ•°æ®åº“åˆ†å¸ƒåˆ†ææ¼”ç¤ºæ•°æ®"))
            return  # æœªç”Ÿæˆæ•°æ®æ—¶ä¸æ˜¾ç¤ºä¸‹æ–¹åˆ†æå†…å®¹
        
        # å·²ç”Ÿæˆæ•°æ®ï¼Œæ˜¾ç¤ºDemoæ¨¡å¼æç¤º
        st.info("ğŸ­ " + ("Demo Mode: Showing simulated multi-database distribution" if lang == 'en' else "æ¼”ç¤ºæ¨¡å¼ï¼šæ˜¾ç¤ºæ¨¡æ‹Ÿçš„å¤šæ•°æ®åº“åˆ†å¸ƒ"))
    
    # ========== Real Dataæ¨¡å¼ ==========
    if entry_mode != 'demo':
        # é…ç½®åŒºåŸŸ
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            data_root = st.text_input(
                "ğŸ—‚ï¸ " + ("ICU Data Root" if lang == 'en' else "ICUæ•°æ®æ ¹ç›®å½•"),
                value=os.environ.get('RICU_DATA_PATH', '/home/zhuhb/icudb'),
                key="multidb_data_root"
            )
            # æ·»åŠ ç›®å½•ç»“æ„æŒ‡å—
            render_directory_structure_guide(lang)
        
        with col2:
            # æ•°æ®åº“é€‰æ‹©
            db_options = ['miiv', 'eicu', 'aumc', 'hirid', 'mimic', 'sic']
            db_labels = {'miiv': 'MIMIC-IV ğŸŸ¢', 'eicu': 'eICU ğŸŸ ', 'aumc': 'Amsterdam ğŸ”µ', 'hirid': 'HiRID ğŸ”´', 'mimic': 'MIMIC-III ğŸŸ£', 'sic': 'SICdb âš«'}
            selected_dbs = st.multiselect(
                "ğŸ¥ " + ("Databases" if lang == 'en' else "æ•°æ®åº“"),
                options=db_options,
                default=['miiv', 'eicu'],
                format_func=lambda x: db_labels.get(x, x),
                key="multidb_selected"
            )
        
        with col3:
            max_patients = st.number_input(
                "ğŸ‘¥ " + ("Max Patients" if lang == 'en' else "æœ€å¤§æ‚£è€…æ•°"),
                min_value=100,
                max_value=2000,
                value=500,
                step=100,
                key="multidb_max_patients"
            )
        
        # ç‰¹å¾é€‰æ‹©
        feature_groups = {
            "Vital Signs": ['hr', 'sbp', 'dbp', 'map', 'resp', 'temp', 'o2sat'],
            "Laboratory": ['glu', 'na', 'k', 'crea', 'bili', 'lact'],
            "Hematology": ['hgb', 'plt', 'wbc'],
            "Blood Gas": ['ph', 'po2', 'pco2', 'fio2'],
        }
        
        col1, col2 = st.columns([1, 3])
        with col1:
            selected_group = st.selectbox(
                "ğŸ“‹ " + ("Feature Group" if lang == 'en' else "ç‰¹å¾åˆ†ç»„"),
                options=list(feature_groups.keys()),
                key="multidb_group"
            )
        
        with col2:
            available_features = feature_groups.get(selected_group, [])
            selected_features = st.multiselect(
                "ğŸ”¬ " + ("Select Features" if lang == 'en' else "é€‰æ‹©ç‰¹å¾"),
                options=available_features,
                default=available_features[:4],
                key="multidb_features"
            )
        
        # åŠ è½½æŒ‰é’®
        load_btn = st.button(
            "ğŸš€ " + ("Load & Generate" if lang == 'en' else "åŠ è½½å¹¶ç”Ÿæˆ"),
            type="primary",
            key="multidb_load"
        )
        
        st.markdown("---")
        
        if load_btn and selected_dbs and selected_features:
            try:
                from pyricu.cohort_visualization import MultiDatabaseDistribution
                
                with st.spinner("Loading data from databases..." if lang == 'en' else "æ­£åœ¨ä»æ•°æ®åº“åŠ è½½æ•°æ®..."):
                    mdd = MultiDatabaseDistribution(data_root=data_root, language=lang)
                    data = mdd.load_feature_data(
                        concepts=selected_features,
                        databases=selected_dbs,
                        max_patients=max_patients,
                    )
                    st.session_state['multidb_data'] = data
                    st.session_state['multidb_concepts'] = selected_features
                    st.session_state['multidb_is_demo'] = False
            except Exception as e:
                st.error(f"Error loading data: {e}")
                return
    
    # æ˜¾ç¤ºç»“æœ
    if 'multidb_data' in st.session_state and st.session_state.get('multidb_data'):
        data = st.session_state['multidb_data']
        concepts = st.session_state.get('multidb_concepts', ['hr', 'sbp', 'temp', 'resp'])
        
        # æ•°æ®é‡ç»Ÿè®¡
        stat_cols = st.columns(len(data))
        db_colors = {'miiv': 'ğŸŸ¢', 'eicu': 'ğŸŸ ', 'aumc': 'ï¿½', 'hirid': 'ğŸ”´', 'mimic': 'ğŸŸ£', 'sic': 'âš«'}
        for i, (db, df) in enumerate(data.items()):
            with stat_cols[i]:
                st.metric(
                    label=f"{db_colors.get(db, '')} {db.upper()}",
                    value=f"{len(df):,}",
                    delta="records"
                )
        
        # ç”Ÿæˆåˆ†å¸ƒå›¾
        try:
            from pyricu.cohort_visualization import MultiDatabaseDistribution
            # Demoæ¨¡å¼ä½¿ç”¨é»˜è®¤è·¯å¾„
            _data_root = st.session_state.get('multidb_data_root', os.environ.get('RICU_DATA_PATH', '/home/zhuhb/icudb'))
            mdd = MultiDatabaseDistribution(data_root=_data_root, language=lang)
            
            # ç½‘æ ¼å›¾
            n_cols = min(4, len(concepts))
            fig = mdd.create_distribution_grid(data, concepts, cols=n_cols)
            st.plotly_chart(fig, use_container_width=True)
            
            # å•ç‰¹å¾è¯¦ç»†å¯¹æ¯”
            st.markdown("---")
            st.markdown("#### " + ("Detailed Single Feature View" if lang == 'en' else "å•ç‰¹å¾è¯¦ç»†è§†å›¾"))
            
            selected_single = st.selectbox(
                "Select feature" if lang == 'en' else "é€‰æ‹©ç‰¹å¾",
                options=concepts,
                key="multidb_single_feature"
            )
            
            if selected_single:
                fig_single, stats_df = mdd.create_single_feature_comparison(data, selected_single)
                
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.plotly_chart(fig_single, use_container_width=True)
                with col2:
                    st.markdown("**Statistics**" if lang == 'en' else "**ç»Ÿè®¡ä¿¡æ¯**")
                    st.dataframe(
                        stats_df.style.format({
                            'Mean': '{:.2f}',
                            'Std': '{:.2f}',
                            'Median': '{:.2f}',
                            'Q25': '{:.2f}',
                            'Q75': '{:.2f}',
                        }),
                        width='stretch',
                        hide_index=True
                    )
        except Exception as e:
            st.error(f"Error generating chart: {e}")
    else:
        # å ä½æç¤º
        st.info(
            "ğŸ‘† Select databases and features, then click 'Load & Generate'" 
            if lang == 'en' else 
            "ğŸ‘† é€‰æ‹©æ•°æ®åº“å’Œç‰¹å¾ï¼Œç„¶åç‚¹å‡»'åŠ è½½å¹¶ç”Ÿæˆ'"
        )


def render_cohort_dashboard_subtab(lang: str):
    """é˜Ÿåˆ—ä»ªè¡¨æ¿å­æ ‡ç­¾é¡µ - ä½¿ç”¨Plotlyå®ç°äº¤äº’å¼å¯è§†åŒ–"""
    
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    
    st.markdown("### ğŸ¯ " + ("Cohort Dashboard" if lang == 'en' else "é˜Ÿåˆ—ä»ªè¡¨æ¿"))
    
    # è·å–å…¥å£æ¨¡å¼
    entry_mode = st.session_state.get('entry_mode', 'none')
    
    # ========== Demoæ¨¡å¼ï¼šéœ€è¦ç”¨æˆ·ç‚¹å‡»ç”ŸæˆæŒ‰é’® ==========
    if entry_mode == 'demo':
        # æ£€æŸ¥æ˜¯å¦å·²ç”Ÿæˆæ•°æ®
        has_demo_data = 'dash_demographics' in st.session_state and st.session_state.get('dash_is_demo') == True
        
        if not has_demo_data:
            # å°šæœªç”Ÿæˆæ•°æ®ï¼Œæ˜¾ç¤ºç”Ÿæˆç•Œé¢
            st.markdown("---")
            
            # å±…ä¸­çš„é…ç½®å¡ç‰‡
            st.markdown("""
            <div style="text-align:center; padding:30px; background:linear-gradient(135deg,#5c2d91,#8e44ad); 
                        border-radius:15px; margin:20px 0;">
                <div style="font-size:3rem; margin-bottom:10px;">ğŸ¯</div>
                <h3 style="color:white; margin:0;">""" + ("Generate Cohort Dashboard Data" if lang == 'en' else "ç”Ÿæˆé˜Ÿåˆ—ä»ªè¡¨æ¿æ•°æ®") + """</h3>
                <p style="color:#ccc; margin-top:10px;">""" + 
                ("Click below to generate simulated cohort dashboard with interactive visualizations" if lang == 'en' else "ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç”Ÿæˆå¸¦æœ‰äº¤äº’å¼å¯è§†åŒ–çš„é˜Ÿåˆ—ä»ªè¡¨æ¿") + 
            """</p>
            </div>
            """, unsafe_allow_html=True)
            
            # ç”ŸæˆæŒ‰é’®
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.markdown("<div style='height:20px'></div>", unsafe_allow_html=True)
                
                if st.button(
                    "ğŸš€ " + ("Generate Demo Dashboard" if lang == 'en' else "ç”Ÿæˆæ¼”ç¤ºä»ªè¡¨æ¿"),
                    type="primary",
                    use_container_width=True,
                    key="dash_generate_demo_btn"
                ):
                    demo_df = _generate_mock_cohort_dashboard_data(lang)
                    st.session_state['dash_demographics'] = demo_df
                    st.session_state['dash_loaded_db'] = 'Demo'
                    st.session_state['dash_is_demo'] = True
                    st.rerun()
            
            # æ˜¾ç¤ºæç¤ºä¿¡æ¯
            st.markdown("<div style='height:20px'></div>", unsafe_allow_html=True)
            st.info("ğŸ’¡ " + ("Click the button above to generate demo data for cohort dashboard" if lang == 'en' else "ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ç”Ÿæˆé˜Ÿåˆ—ä»ªè¡¨æ¿æ¼”ç¤ºæ•°æ®"))
            return  # æœªç”Ÿæˆæ•°æ®æ—¶ä¸æ˜¾ç¤ºä¸‹æ–¹åˆ†æå†…å®¹
        
        # å·²ç”Ÿæˆæ•°æ®ï¼Œæ˜¾ç¤ºDemoæ¨¡å¼æç¤º
        st.info("ğŸ­ " + ("Demo Mode: Showing simulated cohort dashboard" if lang == 'en' else "æ¼”ç¤ºæ¨¡å¼ï¼šæ˜¾ç¤ºæ¨¡æ‹Ÿçš„é˜Ÿåˆ—ä»ªè¡¨æ¿"))
    
    # ========== Real Dataæ¨¡å¼ï¼šæ˜¾ç¤ºæ•°æ®é…ç½® ==========
    else:
        with st.expander("âš™ï¸ " + ("Data Configuration" if lang == 'en' else "æ•°æ®é…ç½®"), expanded=True):
            col1, col2, col3 = st.columns([2, 1, 1])
            
            with col1:
                data_root = st.text_input(
                    "ğŸ“ " + ("ICU Data Root" if lang == 'en' else "ICUæ•°æ®æ ¹ç›®å½•"),
                    value=os.environ.get('RICU_DATA_PATH', '/home/zhuhb/icudb'),
                    key="dash_data_root",
                    help="Root directory containing database folders" if lang == 'en' else "åŒ…å«æ•°æ®åº“æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•"
                )
                # æ·»åŠ ç›®å½•ç»“æ„æŒ‡å—
                render_directory_structure_guide(lang)
            
            with col2:
                db_options = {'miiv': 'MIMIC-IV', 'eicu': 'eICU', 'aumc': 'AUMC', 'hirid': 'HiRID', 'mimic': 'MIMIC-III', 'sic': 'SICdb'}
                selected_db = st.selectbox(
                    "ğŸ¥ " + ("Database" if lang == 'en' else "æ•°æ®åº“"),
                    options=list(db_options.keys()),
                    format_func=lambda x: db_options[x],
                    key="dash_db_select"
                )
            
            with col3:
                max_patients = st.number_input(
                    "ğŸ‘¥ " + ("Max Patients" if lang == 'en' else "æœ€å¤§æ‚£è€…æ•°"),
                    min_value=100,
                    max_value=10000,
                    value=1000,
                    step=100,
                    key="dash_max_patients"
                )
            
            # ä½¿ç”¨æ™ºèƒ½è·¯å¾„æ£€æµ‹
            full_data_path = find_database_path(data_root, selected_db)
            
            # è·¯å¾„çŠ¶æ€
            if os.path.exists(full_data_path):
                st.success(f"âœ… Path valid: `{full_data_path}`" if lang == 'en' else f"âœ… è·¯å¾„æœ‰æ•ˆ: `{full_data_path}`")
            else:
                st.warning(f"âš ï¸ Path not found: `{full_data_path}`" if lang == 'en' else f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨: `{full_data_path}`")
            
            load_btn = st.button(
                "ğŸš€ " + ("Load Dashboard Data" if lang == 'en' else "åŠ è½½ä»ªè¡¨æ¿æ•°æ®"),
                type="primary",
                key="dash_load_btn"
            )
            
            if load_btn:
                try:
                    from pyricu.patient_filter import PatientFilter
                    
                    with st.spinner("Loading demographics..." if lang == 'en' else "æ­£åœ¨åŠ è½½..."):
                        pf = PatientFilter(database=selected_db, data_path=full_data_path)
                        demographics_df = pf._load_demographics()
                        
                        if len(demographics_df) > max_patients:
                            demographics_df = demographics_df.head(max_patients)
                        
                        st.session_state['dash_demographics'] = demographics_df
                        st.session_state['dash_loaded_db'] = selected_db
                        st.session_state['dash_loaded_path'] = full_data_path
                        st.session_state['dash_is_demo'] = False
                        
                    st.success(f"âœ… Loaded {len(demographics_df):,} patients" if lang == 'en' else f"âœ… å·²åŠ è½½ {len(demographics_df):,} åæ‚£è€…")
                    st.rerun()
                except Exception as e:
                    st.error(f"Error: {e}")
    
    st.markdown("---")
    
    # ========== ä»ªè¡¨æ¿å†…å®¹ ==========
    if 'dash_demographics' not in st.session_state:
        st.info("ğŸ‘† " + ("Configure data source and click 'Load' to view dashboard" if lang == 'en' else "é…ç½®æ•°æ®æºå¹¶ç‚¹å‡»'åŠ è½½'æŸ¥çœ‹ä»ªè¡¨æ¿"))
        return
    
    df = st.session_state['dash_demographics']
    
    try:
        # ========== é¡¶éƒ¨æŒ‡æ ‡å¡ç‰‡ ==========
        st.markdown("#### " + ("ğŸ“Š Key Metrics" if lang == 'en' else "ğŸ“Š å…³é”®æŒ‡æ ‡"))
        
        metric_cols = st.columns(6)
        
        def metric_card(value, label, bg_gradient):
            st.markdown(f"""
            <div style="background: {bg_gradient}; 
                        padding: 15px 5px; border-radius: 12px; text-align: center; color: white;">
                <div style="font-size: 1.8rem; font-weight: bold;">{value}</div>
                <div style="font-size: 0.8rem; opacity: 0.9;">{label}</div>
            </div>
            """, unsafe_allow_html=True)

        with metric_cols[0]:
            metric_card(
                f"{len(df):,}", 
                "Total Patients" if lang == 'en' else "æ‚£è€…æ€»æ•°",
                "linear-gradient(135deg, #667eea 0%, #764ba2 100%)"
            )
        
        with metric_cols[1]:
            avg_age = df['age'].mean() if 'age' in df.columns else 0
            metric_card(
                f"{avg_age:.1f}", 
                "Mean Age" if lang == 'en' else "å¹³å‡å¹´é¾„",
                "linear-gradient(135deg, #11998e 0%, #38ef7d 100%)"
            )
        
        with metric_cols[2]:
            male_pct = (df['gender'] == 'M').mean() * 100 if 'gender' in df.columns else 0
            metric_card(
                f"{male_pct:.1f}%", 
                "Male %" if lang == 'en' else "ç”·æ€§å æ¯”",
                "linear-gradient(135deg, #4facfe 0%, #00f2fe 100%)"
            )
        
        with metric_cols[3]:
            median_los = df['los_hours'].median() / 24 if 'los_hours' in df.columns else 0
            metric_card(
                f"{median_los:.1f}", 
                "Median LOS (days)" if lang == 'en' else "ä¸­ä½ä½é™¢(å¤©)",
                "linear-gradient(135deg, #fa709a 0%, #fee140 100%)"
            )
        
        with metric_cols[4]:
            mortality = (1 - df['survived'].mean()) * 100 if 'survived' in df.columns else 0
            metric_card(
                f"{mortality:.1f}%", 
                "Mortality" if lang == 'en' else "æ­»äº¡ç‡",
                "linear-gradient(135deg, #f093fb 0%, #f5576c 100%)"
            )
        
        with metric_cols[5]:
            first_icu_pct = df['first_icu_stay'].mean() * 100 if 'first_icu_stay' in df.columns else 0
            metric_card(
                f"{first_icu_pct:.1f}%", 
                "First ICU Stay" if lang == 'en' else "é¦–æ¬¡ICU",
                "linear-gradient(135deg, #a18cd1 0%, #fbc2eb 100%)"
            )
        
        st.markdown("---")
        
        # ========== å›¾è¡¨è¡Œ1: å¹´é¾„åˆ†å¸ƒå’Œæ€§åˆ«/ç”Ÿå­˜ ==========
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            st.markdown("##### " + ("Age Distribution" if lang == 'en' else "å¹´é¾„åˆ†å¸ƒ"))
            if 'age' in df.columns:
                fig = px.histogram(
                    df, 
                    x='age',
                    nbins=20,
                    color_discrete_sequence=['#667eea'],
                    labels={'age': "Age" if lang == 'en' else "å¹´é¾„", 'count': "Count" if lang == 'en' else "äººæ•°"},
                    template="plotly_white"
                )
                fig.update_layout(bargap=0.1, margin=dict(l=20, r=20, t=20, b=20), height=320)
                st.plotly_chart(fig, use_container_width=True, key="dash_age_dist")
            else:
                st.warning("No 'age' column found" if lang == 'en' else "æœªæ‰¾åˆ°'age'åˆ—")
        
        with chart_col2:
            st.markdown("##### " + ("Gender & Survival Breakdown" if lang == 'en' else "æ€§åˆ«ä¸å­˜æ´»åˆ†å¸ƒ"))
            if 'gender' in df.columns and 'survived' in df.columns:
                # é¢„å¤„ç†æ•°æ®ä»¥è¿›è¡Œå¯è§†åŒ–
                df_pie_gender = df['gender'].value_counts().reset_index()
                df_pie_gender.columns = ['label', 'value']
                
                df_pie_survival = df['survived'].value_counts().reset_index()
                df_pie_survival.columns = ['label', 'value']
                # è½¬æ¢æ ‡ç­¾
                survived_label = "Survived" if lang == 'en' else "å­˜æ´»"
                deceased_label = "Deceased" if lang == 'en' else "æ­»äº¡"
                df_pie_survival['label'] = df_pie_survival['label'].map({1: survived_label, 0: deceased_label})
                
                # åˆ›å»ºå­å›¾
                fig = make_subplots(rows=1, cols=2, specs=[[{'type': 'domain'}, {'type': 'domain'}]],
                                   subplot_titles=("Gender" if lang == 'en' else "æ€§åˆ«", 
                                                   "Survival" if lang == 'en' else "å­˜æ´»"))
                
                fig.add_trace(go.Pie(labels=df_pie_gender['label'], values=df_pie_gender['value'], 
                                    name="Gender", marker_colors=['#4facfe', '#fa709a']), 1, 1)
                
                fig.add_trace(go.Pie(labels=df_pie_survival['label'], values=df_pie_survival['value'], 
                                    name="Survival", marker_colors=['#38ef7d', '#f5576c']), 1, 2)
                
                fig.update_traces(hole=.4, hoverinfo="label+percent+name")
                fig.update_layout(margin=dict(l=20, r=20, t=30, b=20), height=320, showlegend=True,
                                 legend=dict(orientation="h", yanchor="bottom", y=-0.2, xanchor="center", x=0.5))
                st.plotly_chart(fig, use_container_width=True, key="dash_pie_charts")
            else:
                st.warning("Data mismatch for pie charts" if lang == 'en' else "é¥¼å›¾æ•°æ®ç¼ºå¤±")
        
        # ========== å›¾è¡¨è¡Œ2: ä½é™¢æ—¶é•¿å’Œæ­»äº¡ç‡è¶‹åŠ¿ ==========
        chart_col3, chart_col4 = st.columns(2)
        
        with chart_col3:
            st.markdown("##### " + ("Length of Stay Distribution" if lang == 'en' else "ä½é™¢æ—¶é•¿åˆ†å¸ƒ"))
            if 'los_hours' in df.columns:
                # æˆªæ–­æå€¼ä»¥ä¾¿æ›´å¥½å±•ç¤º
                los_days = df['los_hours'] / 24
                p95 = los_days.quantile(0.95)
                df_filtered = df[los_days <= p95].copy()
                df_filtered['los_days'] = df_filtered['los_hours'] / 24
                
                median_los = los_days.median()
                
                fig = px.histogram(
                    df_filtered, 
                    x='los_days',
                    nbins=30,
                    color_discrete_sequence=['#11998e'],
                    labels={'los_days': "LOS (Days)" if lang == 'en' else "ä½é™¢å¤©æ•°"},
                    template="plotly_white"
                )
                
                # å¢åŠ ä¸­ä½æ•°çº¿
                fig.add_vline(x=median_los, line_width=3, line_dash="dash", line_color="#f5576c",
                             annotation_text=f"Median: {median_los:.1f}d", 
                             annotation_position="top right")
                
                fig.update_layout(bargap=0.1, margin=dict(l=20, r=20, t=20, b=20), height=320)
                st.plotly_chart(fig, use_container_width=True, key="dash_los_chart")
            else:
                st.warning("No 'los_hours' column" if lang == 'en' else "æœªæ‰¾åˆ°'los_hours'åˆ—")
        
        with chart_col4:
            st.markdown("##### " + ("Mortality by Age Group" if lang == 'en' else "å„å¹´é¾„æ®µæ­»äº¡ç‡è¶‹åŠ¿"))
            if 'age' in df.columns and 'survived' in df.columns:
                # é¢„å¤„ç†æ•°æ®
                df_age = df.copy()
                age_bins = [0, 30, 40, 50, 60, 70, 80, 90, 120]
                age_labels = ['<30', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', 'â‰¥90']
                df_age['age_group'] = pd.cut(df_age['age'], bins=age_bins, labels=age_labels, right=False)
                
                stats = df_age.groupby('age_group', observed=True).agg(
                    total=('survived', 'count'),
                    deaths=('survived', lambda x: (x == 0).sum())
                ).reset_index()
                stats['mortality'] = (stats['deaths'] / stats['total'] * 100).round(1)
                
                # åŒè½´å›¾ï¼šæŸ±çŠ¶å›¾ï¼ˆäººæ•°ï¼‰+æŠ˜çº¿å›¾ï¼ˆæ­»äº¡ç‡ï¼‰
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                
                # æŸ±çŠ¶å›¾ - æ‚£è€…æ•°
                fig.add_trace(
                    go.Bar(x=stats['age_group'].astype(str), y=stats['total'], name="Patients" if lang == 'en' else "æ‚£è€…æ•°",
                          marker_color='rgba(102, 126, 234, 0.6)'),
                    secondary_y=False,
                )
                
                # æŠ˜çº¿å›¾ - æ­»äº¡ç‡
                fig.add_trace(
                    go.Scatter(x=stats['age_group'].astype(str), y=stats['mortality'], name="Mortality %" if lang == 'en' else "æ­»äº¡ç‡ %",
                              mode='lines+markers', marker_color='#f5576c', line=dict(width=3)),
                    secondary_y=True,
                )
                
                fig.update_layout(
                    template="plotly_white",
                    margin=dict(l=20, r=20, t=20, b=40),
                    height=320,
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                )
                
                fig.update_yaxes(title_text="Count" if lang == 'en' else "äººæ•°", secondary_y=False)
                fig.update_yaxes(title_text="Mortality %" if lang == 'en' else "æ­»äº¡ç‡ %", secondary_y=True, range=[0, 100])
                
                st.plotly_chart(fig, use_container_width=True, key="dash_mortality_chart")
            else:
                st.warning("Data not available" if lang == 'en' else "æ•°æ®ç¼ºå¤±")
                
    except Exception as e:
        st.error(f"Render error: {e}")
        import traceback
        st.code(traceback.format_exc())

def render_convert_dialog():
    """Render CSV to Parquet conversion dialog."""

    lang = st.session_state.get('language', 'en')
    source_path = st.session_state.get('convert_source_path', '')
    
    dialog_title = "## ğŸ”„ CSV to Parquet Conversion" if lang == 'en' else "## ğŸ”„ CSV è½¬æ¢ä¸º Parquet"
    st.markdown(dialog_title)
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    source_info = f"ğŸ“ Source directory: `{source_path}`" if lang == 'en' else f"ğŸ“ æºç›®å½•: `{source_path}`"
    st.info(source_info)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ç›®æ ‡ç›®å½•ï¼ˆé»˜è®¤åŒç›®å½•ï¼‰
        target_label = "Parquet Output Directory" if lang == 'en' else "Parquetè¾“å‡ºç›®å½•"
        target_help = "Converted Parquet files will be saved to this directory" if lang == 'en' else "è½¬æ¢åçš„Parquetæ–‡ä»¶å°†ä¿å­˜åˆ°æ­¤ç›®å½•"
        target_path = st.text_input(
            target_label,
            value=source_path,
            help=target_help
        )
    
    with col2:
        # è½¬æ¢é€‰é¡¹
        overwrite_label = "Overwrite existing Parquet files" if lang == 'en' else "è¦†ç›–å·²å­˜åœ¨çš„Parquetæ–‡ä»¶"
        overwrite = st.checkbox(overwrite_label, value=False)
    
    # æ‰«æå¯è½¬æ¢æ–‡ä»¶
    if source_path and Path(source_path).exists():
        csv_files = list(Path(source_path).rglob('*.csv')) + list(Path(source_path).rglob('*.csv.gz'))
        found_msg = f"**Found {len(csv_files)} CSV files to convert**" if lang == 'en' else f"**å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶å¯è½¬æ¢**"
        st.markdown(found_msg)
        
        view_label = "View file list" if lang == 'en' else "æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨"
        with st.expander(view_label, expanded=False):
            for f in csv_files[:20]:
                size_mb = f.stat().st_size / (1024 * 1024)
                st.caption(f"â€¢ {f.name} ({size_mb:.1f} MB)")
            if len(csv_files) > 20:
                more_msg = f"... and {len(csv_files) - 20} more files" if lang == 'en' else f"... åŠå…¶ä»– {len(csv_files) - 20} ä¸ªæ–‡ä»¶"
                st.caption(more_msg)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        start_label = "ğŸš€ Start Conversion" if lang == 'en' else "ğŸš€ å¼€å§‹è½¬æ¢"
        if st.button(start_label, type="primary", width="stretch"):
            if not target_path or not Path(target_path).exists():
                err_msg = "âŒ Please set a valid output directory" if lang == 'en' else "âŒ è¯·è®¾ç½®æœ‰æ•ˆçš„è¾“å‡ºç›®å½•"
                st.error(err_msg)
            else:
                spinner_msg = "Converting..." if lang == 'en' else "æ­£åœ¨è½¬æ¢..."
                with st.spinner(spinner_msg):
                    success, failed = convert_csv_to_parquet(source_path, target_path, overwrite)
                
                # åªæœ‰åœ¨æœ‰æˆåŠŸè½¬æ¢æˆ–æ— å¤±è´¥æ—¶æ‰å…³é—­å¯¹è¯æ¡†
                if success > 0:
                    success_msg = f"âœ… Successfully converted {success} files" if lang == 'en' else f"âœ… æˆåŠŸè½¬æ¢ {success} ä¸ªæ–‡ä»¶"
                    st.success(success_msg)
                    st.session_state.path_validated = True
                    st.session_state.data_path = target_path
                    st.session_state.show_convert_dialog = False
                    st.rerun()
                elif failed > 0:
                    # æœ‰å¤±è´¥ä½†æ— æˆåŠŸï¼Œä¿æŒå¯¹è¯æ¡†æ‰“å¼€è®©ç”¨æˆ·æŸ¥çœ‹é”™è¯¯
                    fail_msg = f"âš ï¸ {failed} files failed to convert. Please check the error messages above." if lang == 'en' else f"âš ï¸ {failed} ä¸ªæ–‡ä»¶è½¬æ¢å¤±è´¥ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹é”™è¯¯ä¿¡æ¯ã€‚"
                    st.warning(fail_msg)
                    # ä¸å…³é—­å¯¹è¯æ¡†ï¼Œè®©ç”¨æˆ·çœ‹åˆ°é”™è¯¯ä¿¡æ¯
                else:
                    # success=0, failed=0 - å¯èƒ½æ˜¯ HiRID é”™è¯¯æƒ…å†µ
                    no_files_msg = "âš ï¸ No files were converted. Please check your data path." if lang == 'en' else "âš ï¸ æ²¡æœ‰æ–‡ä»¶è¢«è½¬æ¢ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„ã€‚"
                    st.warning(no_files_msg)
    
    with col2:
        cancel_label = "âŒ Cancel" if lang == 'en' else "âŒ å–æ¶ˆ"
        if st.button(cancel_label, width="stretch"):
            st.session_state.show_convert_dialog = False
            st.rerun()


def convert_csv_to_parquet(source_dir: str, target_dir: str, overwrite: bool = False) -> tuple:
    """å°†ç›®å½•ä¸‹çš„CSVæ–‡ä»¶è½¬æ¢ä¸ºParquetæ ¼å¼ã€‚
    
    å¤§è¡¨è‡ªåŠ¨ä½¿ç”¨åˆ†æ¡¶è½¬æ¢ï¼Œæ™®é€šè¡¨ä½¿ç”¨ DuckDB ç›´æ¥è½¬æ¢ã€‚
    HiRID ç‰¹æ®Šå¤„ç†ï¼šå·²ç»æ˜¯ parquet æ ¼å¼ï¼Œåªéœ€åˆ†æ¡¶è½¬æ¢ã€‚
    """
    import gc
    import time
    
    # è·å–æ•°æ®åº“ç±»å‹
    database = st.session_state.get('database', 'miiv')
    
    # HiRID ç‰¹æ®Šå¤„ç†ï¼šæ•°æ®å·²ç»æ˜¯ parquet æ ¼å¼ï¼Œåªéœ€åˆ†æ¡¶
    if database == 'hirid':
        return _convert_hirid_data(source_dir, target_dir, overwrite)
    
    # å®šä¹‰éœ€è¦åˆ†æ¡¶è½¬æ¢çš„å¤§è¡¨
    BUCKET_TABLES = {
        'miiv': {
            'chartevents': ('itemid', 100),
            'labevents': ('itemid', 100),
            'inputevents': ('itemid', 50),
        },
        'eicu': {
            'nursecharting': ('nursingchartcelltypevalname', 30),
            'lab': ('labname', 50),
        },
        'aumc': {
            'numericitems': ('itemid', 100),
            'listitems': ('itemid', 50),
        },
        'hirid': {
            'observations': ('variableid', 100),
            'pharma': ('pharmaid', 50),
        },
        'mimic': {
            'chartevents': ('itemid', 100),
            'labevents': ('itemid', 100),
        },
        'sic': {
            'data_float_h': ('dataid', 50),
            'laboratory': ('laboratoryid', 50),
        },
    }
    
    try:
        from pyricu.duckdb_converter import DuckDBConverter
        from pyricu.bucket_converter import convert_to_buckets, BucketConfig
        import time
    except ImportError as e:
        st.error(f"Converter not available: {e}")
        return 0, 0
    
    source_path = Path(source_dir)
    target_path = Path(target_dir)
    
    csv_files = list(source_path.rglob('*.csv')) + list(source_path.rglob('*.csv.gz'))
    
    # åˆ†ç±»æ–‡ä»¶ï¼šå¤§è¡¨ç”¨åˆ†æ¡¶ï¼Œå°è¡¨ç”¨æ™®é€šè½¬æ¢
    bucket_tables_config = BUCKET_TABLES.get(database, {})
    bucket_files = []
    normal_files = []
    
    # è®¡ç®—æ€»å¤§å°ç”¨äºé¢„ä¼°æ—¶é—´
    total_size_mb = 0
    for csv_file in csv_files:
        stem = csv_file.stem.lower().replace('.csv', '')
        file_size = csv_file.stat().st_size / (1024 * 1024)
        total_size_mb += file_size
        if stem in bucket_tables_config:
            bucket_files.append((csv_file, bucket_tables_config[stem]))
        else:
            normal_files.append(csv_file)
    
    success = 0
    failed = 0
    total = len(normal_files) + len(bucket_files)
    current = 0
    processed_size_mb = 0
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    eta_text = st.empty()
    details = st.container()
    
    # è½¬æ¢é€Ÿåº¦è·Ÿè¸ª
    start_time = time.time()
    
    def update_eta(processed_mb: float, elapsed_seconds: float):
        """æ›´æ–°é¢„ä¼°å‰©ä½™æ—¶é—´"""
        if elapsed_seconds > 0 and processed_mb > 0:
            speed_mb_per_sec = processed_mb / elapsed_seconds
            remaining_mb = total_size_mb - processed_mb
            if speed_mb_per_sec > 0:
                eta_seconds = remaining_mb / speed_mb_per_sec
                if eta_seconds < 60:
                    eta_str = f"{eta_seconds:.0f}s"
                elif eta_seconds < 3600:
                    eta_str = f"{eta_seconds/60:.1f}min"
                else:
                    eta_str = f"{eta_seconds/3600:.1f}h"
                eta_text.markdown(f"â±ï¸ **Speed**: {speed_mb_per_sec:.1f} MB/s | **ETA**: {eta_str} | **Total**: {total_size_mb:.0f} MB")
    
    # åˆ›å»º DuckDB è½¬æ¢å™¨ï¼ˆä¼˜åŒ–é…ç½®ï¼‰
    converter = DuckDBConverter(
        data_path=str(source_path),
        memory_limit_gb=12.0,
        verbose=False
    )
    
    # 1. è½¬æ¢æ™®é€šè¡¨
    for csv_file in normal_files:
        current += 1
        file_size_mb = csv_file.stat().st_size / (1024 * 1024)
        try:
            rel_path = csv_file.relative_to(source_path)
            parquet_name = rel_path.stem.replace('.csv', '') + '.parquet'
            parquet_file = target_path / rel_path.parent / parquet_name
            
            if parquet_file.exists() and not overwrite:
                with details:
                    st.caption(f"â­ï¸ {csv_file.name} (exists)")
                processed_size_mb += file_size_mb
                progress_bar.progress(current / total)
                update_eta(processed_size_mb, time.time() - start_time)
                continue
            
            parquet_file.parent.mkdir(parents=True, exist_ok=True)
            
            status_text.markdown(f"**Converting**: `{csv_file.name}` ({file_size_mb:.1f}MB) [{current}/{total}]")
            
            result = converter.convert_file(csv_file)
            
            processed_size_mb += file_size_mb
            
            if result['status'] == 'success':
                success += 1
                with details:
                    st.caption(f"âœ… {csv_file.name}: {result['row_count']:,} rows")
            else:
                failed += 1
                with details:
                    st.caption(f"âŒ {csv_file.name}: {result.get('error', 'unknown')[:40]}")
            
            gc.collect()
            update_eta(processed_size_mb, time.time() - start_time)
            
        except Exception as e:
            failed += 1
            processed_size_mb += file_size_mb
            with details:
                st.caption(f"âŒ {csv_file.name}: {str(e)[:40]}")
        
        progress_bar.progress(current / total)
    
    # 2. åˆ†æ¡¶è½¬æ¢å¤§è¡¨
    for csv_file, (partition_col, num_buckets) in bucket_files:
        current += 1
        stem = csv_file.stem.lower().replace('.csv', '')
        bucket_dir = target_path / f"{stem}_bucket"
        file_size_mb = csv_file.stat().st_size / (1024 * 1024)
        
        try:
            if bucket_dir.exists() and list(bucket_dir.glob('*.parquet')) and not overwrite:
                with details:
                    st.caption(f"â­ï¸ {csv_file.name} (bucket exists)")
                processed_size_mb += file_size_mb
                progress_bar.progress(current / total)
                update_eta(processed_size_mb, time.time() - start_time)
                continue
            
            status_text.markdown(f"**Bucketing**: `{csv_file.name}` ({file_size_mb:.1f}MB) â†’ {num_buckets} buckets [{current}/{total}]")
            
            # ä½¿ç”¨ä¼˜åŒ–é…ç½®ï¼šè·³è¿‡æ’åºå¯åŠ é€Ÿ2-3å€
            config = BucketConfig(
                num_buckets=num_buckets,
                partition_col=partition_col,
                memory_limit='12GB',
                threads=0,  # è‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°
                row_group_size=1_000_000,
                compression='zstd',
                skip_sorting=True  # è·³è¿‡æ’åºï¼Œå¤§å¹…åŠ é€Ÿ
            )
            result = convert_to_buckets(
                source_path=csv_file,
                output_dir=bucket_dir,
                config=config,
                overwrite=overwrite
            )
            
            processed_size_mb += file_size_mb
            
            if result.success:
                success += 1
                with details:
                    st.caption(f"âœ… {csv_file.name} â†’ {result.num_buckets} buckets, {result.total_rows:,} rows")
            else:
                failed += 1
                with details:
                    st.caption(f"âŒ {csv_file.name}: {result.error[:40] if result.error else 'unknown'}")
            
            gc.collect()
            update_eta(processed_size_mb, time.time() - start_time)
            
        except Exception as e:
            failed += 1
            processed_size_mb += file_size_mb
            with details:
                st.caption(f"âŒ {csv_file.name}: {str(e)[:40]}")
        
        progress_bar.progress(current / total)
    
    # å®Œæˆåæ˜¾ç¤ºæ€»è€—æ—¶
    total_time = time.time() - start_time
    if total_time < 60:
        time_str = f"{total_time:.1f}s"
    elif total_time < 3600:
        time_str = f"{total_time/60:.1f}min"
    else:
        time_str = f"{total_time/3600:.1f}h"
    
    progress_bar.progress(1.0)
    status_text.empty()
    eta_text.markdown(f"âœ… **Completed** in {time_str} | **Avg Speed**: {total_size_mb/total_time:.1f} MB/s")
    
    return success, failed


def _convert_hirid_data(source_dir: str, target_dir: str, overwrite: bool = False) -> tuple:
    """HiRID ä¸“ç”¨è½¬æ¢ï¼šæ•°æ®å·²ç»æ˜¯ parquet æ ¼å¼ï¼Œåªéœ€åˆ†æ¡¶è½¬æ¢ã€‚
    
    HiRID ç›®å½•ç»“æ„å¯èƒ½æ˜¯:
    1. å·²è§£å‹: observations/, pharma/ æˆ– pharma_records/
    2. åŸå§‹ä¸‹è½½: raw_stage/observation_tables_parquet.tar.gz
    """
    import time
    
    lang = st.session_state.get('language', 'en')
    
    try:
        from pyricu.bucket_converter import (
            convert_hirid_observations, 
            convert_hirid_pharma,
            convert_parquet_directory_to_buckets
        )
    except ImportError as e:
        st.error(f"Converter not available: {e}")
        return 0, 0
    
    source_path = Path(source_dir)
    
    # æ£€æŸ¥ observations ç›®å½• - æ”¯æŒå¤šç§å¯èƒ½çš„ä½ç½®
    obs_dir = None
    pharma_dir = None
    
    # å¯èƒ½çš„ observations ç›®å½•ä½ç½®
    # HiRID è§£å‹åå¯èƒ½çš„ç›®å½•ç»“æ„ï¼š
    # 1. observations/ æˆ– observation_tables/ (ç›´æ¥åŒ…å« parquet)
    # 2. observations/parquet/ æˆ– observation_tables/parquet/ (parquet åœ¨å­ç›®å½•)
    obs_candidates = [
        source_path / 'observations',
        source_path / 'observations' / 'parquet',
        source_path / 'observation_tables',
        source_path / 'observation_tables' / 'parquet',
    ]
    for cand in obs_candidates:
        if cand.exists() and cand.is_dir():
            # æ£€æŸ¥æ˜¯å¦æœ‰ parquet æ–‡ä»¶ï¼ˆç›´æ¥æˆ–åœ¨å­ç›®å½•ï¼‰
            if list(cand.glob('*.parquet')):
                obs_dir = cand
                break
    
    # å¯èƒ½çš„ pharma ç›®å½•ä½ç½®
    pharma_candidates = [
        source_path / 'pharma',
        source_path / 'pharma' / 'parquet',
        source_path / 'pharma_records',
        source_path / 'pharma_records' / 'parquet',
    ]
    for cand in pharma_candidates:
        if cand.exists() and cand.is_dir():
            if list(cand.glob('*.parquet')):
                pharma_dir = cand
                break
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è§£å‹
    raw_stage = source_path / 'raw_stage'
    if raw_stage.exists():
        obs_tar = raw_stage / 'observation_tables_parquet.tar.gz'
        pharma_tar = raw_stage / 'pharma_records_parquet.tar.gz'
        
        # å¦‚æœæ‰¾åˆ°å‹ç¼©æ–‡ä»¶ä¸”è¿˜æ²¡æœ‰è§£å‹çš„ç›®å½•ï¼Œè‡ªåŠ¨è§£å‹
        if (obs_tar.exists() or pharma_tar.exists()) and not obs_dir:
            import tarfile
            
            info_msg = "ğŸ”„ Detected compressed HiRID data. Auto-extracting tar.gz files..." if lang == 'en' else "ğŸ”„ æ£€æµ‹åˆ°å‹ç¼©çš„ HiRID æ•°æ®ï¼Œè‡ªåŠ¨è§£å‹ä¸­..."
            st.info(info_msg)
            
            extraction_success = True
            
            # è§£å‹ observations
            if obs_tar.exists() and not obs_dir:
                try:
                    spinner_msg = f"Extracting {obs_tar.name}... (this may take 5-10 minutes)" if lang == 'en' else f"æ­£åœ¨è§£å‹ {obs_tar.name}... (å¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿ)"
                    with st.spinner(spinner_msg):
                        with tarfile.open(obs_tar, 'r:gz') as tar:
                            tar.extractall(path=source_path)
                    
                    success_msg = f"âœ… Extracted {obs_tar.name}" if lang == 'en' else f"âœ… å·²è§£å‹ {obs_tar.name}"
                    st.success(success_msg)
                    
                    # é‡æ–°æ£€æŸ¥ç›®å½•
                    for cand in obs_candidates:
                        if cand.exists() and cand.is_dir():
                            if list(cand.glob('*.parquet')) or list(cand.rglob('*.parquet')):
                                obs_dir = cand
                                break
                except Exception as e:
                    error_msg = f"âŒ Failed to extract {obs_tar.name}: {e}" if lang == 'en' else f"âŒ è§£å‹ {obs_tar.name} å¤±è´¥: {e}"
                    st.error(error_msg)
                    extraction_success = False
            
            # è§£å‹ pharma
            if pharma_tar.exists() and not pharma_dir:
                try:
                    spinner_msg = f"Extracting {pharma_tar.name}..." if lang == 'en' else f"æ­£åœ¨è§£å‹ {pharma_tar.name}..."
                    with st.spinner(spinner_msg):
                        with tarfile.open(pharma_tar, 'r:gz') as tar:
                            tar.extractall(path=source_path)
                    
                    success_msg = f"âœ… Extracted {pharma_tar.name}" if lang == 'en' else f"âœ… å·²è§£å‹ {pharma_tar.name}"
                    st.success(success_msg)
                    
                    # é‡æ–°æ£€æŸ¥ç›®å½•
                    for cand in pharma_candidates:
                        if cand.exists() and cand.is_dir():
                            if list(cand.glob('*.parquet')) or list(cand.rglob('*.parquet')):
                                pharma_dir = cand
                                break
                except Exception as e:
                    error_msg = f"âŒ Failed to extract {pharma_tar.name}: {e}" if lang == 'en' else f"âŒ è§£å‹ {pharma_tar.name} å¤±è´¥: {e}"
                    st.error(error_msg)
                    extraction_success = False
            
            if not extraction_success:
                manual_msg = "You can try manual extraction:" if lang == 'en' else "æ‚¨å¯ä»¥å°è¯•æ‰‹åŠ¨è§£å‹ï¼š"
                st.error(f"âŒ {manual_msg}")
                st.code(f"cd {raw_stage}\ntar -xzf observation_tables_parquet.tar.gz\ntar -xzf pharma_records_parquet.tar.gz")
                return 0, 1
    
    # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†æ•°æ®ç›®å½•
    if not obs_dir and not pharma_dir:
        if lang == 'en':
            st.error(f"""
            âŒ **HiRID data directories not found!**
            
            Expected directory structure:
            ```
            {source_dir}/
            â”œâ”€â”€ observations/       â† Parquet files
            â”‚   â”œâ”€â”€ part-0.parquet
            â”‚   â””â”€â”€ ...
            â””â”€â”€ pharma_records/     â† Parquet files
                â”œâ”€â”€ part-0.parquet
                â””â”€â”€ ...
            ```
            
            Please check your data path or extract the data first.
            """)
        else:
            st.error(f"""
            âŒ **æœªæ‰¾åˆ° HiRID æ•°æ®ç›®å½•ï¼**
            
            é¢„æœŸç›®å½•ç»“æ„ï¼š
            ```
            {source_dir}/
            â”œâ”€â”€ observations/       â† Parquet æ–‡ä»¶
            â”‚   â”œâ”€â”€ part-0.parquet
            â”‚   â””â”€â”€ ...
            â””â”€â”€ pharma_records/     â† Parquet æ–‡ä»¶
                â”œâ”€â”€ part-0.parquet
                â””â”€â”€ ...
            ```
            
            è¯·æ£€æŸ¥æ•°æ®è·¯å¾„æˆ–å…ˆè§£å‹æ•°æ®ã€‚
            """)
        return 0, 1
    
    # å¼€å§‹è½¬æ¢
    info_msg = "ğŸ”„ HiRID uses pre-built parquet files. Converting to bucketed format..." if lang == 'en' else "ğŸ”„ HiRID ä½¿ç”¨é¢„æ„å»ºçš„ parquet æ–‡ä»¶ï¼Œæ­£åœ¨è½¬æ¢ä¸ºåˆ†æ¡¶æ ¼å¼..."
    st.info(info_msg)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    details = st.container()
    
    success = 0
    failed = 0
    start_time = time.time()
    
    obs_bucket_dir = source_path / 'observations_bucket'
    pharma_bucket_dir = source_path / 'pharma_bucket'
    
    tasks = []
    if obs_dir:
        tasks.append(('observations', obs_dir, obs_bucket_dir, 'variableid', 100))
    if pharma_dir:
        tasks.append(('pharma', pharma_dir, pharma_bucket_dir, 'pharmaid', 50))
    
    total = len(tasks)
    
    for idx, (name, src_dir, bucket_dir, partition_col, num_buckets) in enumerate(tasks):
        status_msg = f"**Bucketing**: `{name}` â†’ {num_buckets} buckets [{idx+1}/{total}]" if lang == 'en' else f"**åˆ†æ¡¶ä¸­**: `{name}` â†’ {num_buckets} ä¸ªæ¡¶ [{idx+1}/{total}]"
        status_text.markdown(status_msg)
        
        try:
            if bucket_dir.exists() and list(bucket_dir.rglob('*.parquet')) and not overwrite:
                with details:
                    skip_msg = f"â­ï¸ {name} (bucket exists, skipped)" if lang == 'en' else f"â­ï¸ {name} (åˆ†æ¡¶å·²å­˜åœ¨ï¼Œè·³è¿‡)"
                    st.caption(skip_msg)
                success += 1  # å·²å­˜åœ¨ä¹Ÿç®—æˆåŠŸ
                progress_bar.progress((idx + 1) / total)
                continue
            
            result = convert_parquet_directory_to_buckets(
                source_dir=src_dir,
                output_dir=bucket_dir,
                partition_col=partition_col,
                num_buckets=num_buckets,
                overwrite=overwrite
            )
            
            if result.success:
                success += 1
                with details:
                    st.caption(f"âœ… {name} â†’ {result.num_buckets} buckets, {result.total_rows:,} rows")
            else:
                failed += 1
                with details:
                    st.caption(f"âŒ {name}: {result.error[:60] if result.error else 'unknown'}")
        except Exception as e:
            failed += 1
            with details:
                st.caption(f"âŒ {name}: {str(e)[:60]}")
        
        progress_bar.progress((idx + 1) / total)
    
    total_time = time.time() - start_time
    progress_bar.progress(1.0)
    status_text.empty()
    
    # è‡ªåŠ¨è§£å‹ reference_data.tar.gzï¼ˆåŒ…å« general_table.csvï¼‰
    reference_tar = source_path / 'reference_data.tar.gz'
    if reference_tar.exists():
        general_table = source_path / 'general_table.csv'
        if not general_table.exists():
            try:
                import tarfile
                info_msg = "ğŸ”„ Extracting reference_data.tar.gz (general_table.csv)..." if lang == 'en' else "ğŸ”„ æ­£åœ¨è§£å‹ reference_data.tar.gz (general_table.csv)..."
                with st.spinner(info_msg):
                    with tarfile.open(reference_tar, 'r:gz') as tar:
                        tar.extractall(path=source_path)
                
                extract_msg = "âœ… Extracted reference data files" if lang == 'en' else "âœ… å·²è§£å‹å‚è€ƒæ•°æ®æ–‡ä»¶"
                st.success(extract_msg)
            except Exception as e:
                warn_msg = f"âš ï¸ Failed to extract reference_data.tar.gz: {e}" if lang == 'en' else f"âš ï¸ è§£å‹ reference_data.tar.gz å¤±è´¥: {e}"
                st.warning(warn_msg)
    
    if success > 0:
        success_msg = f"âœ… HiRID conversion completed in {total_time:.1f}s ({success} tables)" if lang == 'en' else f"âœ… HiRID è½¬æ¢å®Œæˆï¼Œè€—æ—¶ {total_time:.1f}ç§’ ({success} ä¸ªè¡¨)"
        st.success(success_msg)
    
    return success, failed


def _generate_cohort_prefix() -> str:
    """æ ¹æ®é˜Ÿåˆ—ç­›é€‰æ¡ä»¶ç”Ÿæˆæ–‡ä»¶åå‰ç¼€ã€‚
    
    Returns:
        ç­›é€‰æ¡ä»¶å‰ç¼€å­—ç¬¦ä¸²ï¼Œå¦‚ "age18-80_firstICU_los24h"ï¼Œæ— ç­›é€‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not st.session_state.get('cohort_enabled', False):
        return ""
    
    cf = st.session_state.get('cohort_filter', {})
    parts = []
    
    # å¹´é¾„
    age_min = cf.get('age_min')
    age_max = cf.get('age_max')
    if age_min is not None or age_max is not None:
        age_str = f"age{int(age_min) if age_min else 0}-{int(age_max) if age_max else 'inf'}"
        parts.append(age_str)
    
    # é¦–æ¬¡å…¥ICU
    first_icu = cf.get('first_icu_stay')
    if first_icu is True:
        parts.append("firstICU")
    elif first_icu is False:
        parts.append("readmit")
    
    # ä½é™¢æ—¶é•¿
    los_min = cf.get('los_min')
    if los_min is not None and los_min > 0:
        parts.append(f"los{int(los_min)}h")
    
    # æ€§åˆ«
    gender = cf.get('gender')
    if gender is not None:
        parts.append(f"sex{gender}")
    
    # å­˜æ´»çŠ¶æ€
    survived = cf.get('survived')
    if survived is True:
        parts.append("survived")
    elif survived is False:
        parts.append("deceased")
    
    # Sepsis
    has_sepsis = cf.get('has_sepsis')
    if has_sepsis is True:
        parts.append("sepsis")
    elif has_sepsis is False:
        parts.append("noSepsis")
    
    return "_".join(parts)


def execute_sidebar_export():
    """æ‰§è¡Œä¾§è¾¹æ è§¦å‘çš„æ•°æ®å¯¼å‡ºï¼ˆç›´æ¥å¯¼å‡ºåˆ°æœ¬åœ°ç›®å½•ï¼Œå¸¦è¿›åº¦æ¡ï¼‰ã€‚
    
    ğŸ”§ è¿›åº¦æ˜¾ç¤ºåœ¨ä¸»å†…å®¹åŒºçš„ä¸“ç”¨å®¹å™¨ä¸­ã€‚
    ğŸ”§ æ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
        1. æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼ (use_mock_data=True)
        2. çœŸå®æ•°æ®æ¨¡å¼ (æœ‰æœ‰æ•ˆçš„ data_path)
        3. å¯è§†åŒ–å¯¼å…¥æ¨¡å¼ (æœ‰ loaded_concepts ä½†æ— æœ‰æ•ˆ data_path) - ç›´æ¥å¯¼å‡ºå·²åŠ è½½çš„æ•°æ®
    """
    from datetime import datetime
    
    lang = st.session_state.get('language', 'en')
    export_path = st.session_state.get('export_path', '')
    export_format = st.session_state.get('export_format', 'Parquet').lower()
    selected_concepts = st.session_state.get('selected_concepts', [])
    use_mock = st.session_state.get('use_mock_data', False)
    
    # ğŸ”§ FIX (2026-02-03): æ£€æµ‹æ˜¯å¦æ˜¯ä»å¯è§†åŒ–æ¨¡å¼å¯¼å…¥æ•°æ®çš„åœºæ™¯
    loaded_concepts = st.session_state.get('loaded_concepts', {})
    data_path_str = st.session_state.get('data_path', '')
    has_valid_data_path = data_path_str and Path(data_path_str).exists()
    has_loaded_data = len(loaded_concepts) > 0
    
    # åˆ¤æ–­æ•°æ®æ¥æºæ¨¡å¼
    # ğŸ”§ FIX: å¦‚æœå·²ç»æœ‰åŠ è½½çš„æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨å®ƒï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    is_viz_import_mode = has_loaded_data
    
    # ğŸ”§ FIX (2026-02-03): åœ¨å¯è§†åŒ–å¯¼å…¥æ¨¡å¼ä¸‹ï¼Œå¦‚æœ selected_concepts ä¸ºç©ºï¼Œ
    # ä½¿ç”¨ loaded_concepts çš„ keys ä½œä¸ºè¦å¯¼å‡ºçš„æ¦‚å¿µ
    if is_viz_import_mode and not selected_concepts:
        selected_concepts = list(loaded_concepts.keys())
        st.session_state.selected_concepts = selected_concepts
        print(f"[DEBUG] Auto-set selected_concepts from loaded_concepts: {len(selected_concepts)} concepts")
    
    if not export_path or not Path(export_path).exists():
        err_msg = "âŒ Please set a valid export path first" if lang == 'en' else "âŒ è¯·å…ˆè®¾ç½®æœ‰æ•ˆçš„å¯¼å‡ºè·¯å¾„"
        st.error(err_msg)
        return
    
    if not selected_concepts:
        err_msg = "âŒ Please select features to export first" if lang == 'en' else "âŒ è¯·å…ˆé€‰æ‹©è¦å¯¼å‡ºçš„ç‰¹å¾"
        st.error(err_msg)
        return
    
    try:
        export_title = "ğŸ“¤ Export Progress" if lang == 'en' else "ğŸ“¤ å¯¼å‡ºè¿›åº¦"
        st.markdown(f"### {export_title}")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç›´æ¥ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å¯¼å‡ºè·¯å¾„ï¼ˆå·²åŒ…å«æ•°æ®åº“å­ç›®å½•ï¼‰
        export_dir = Path(export_path)
        export_dir.mkdir(parents=True, exist_ok=True)
        
        exported_files = []
        total_concepts = len(selected_concepts)
        
        # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ğŸ”§ æ·»åŠ å–æ¶ˆæŒ‰é’®
        import time as time_module
        cancel_placeholder = st.empty()
        cancel_key = f"cancel_export_{int(time_module.time() * 1000)}"
        
        # åˆå§‹åŒ–å–æ¶ˆçŠ¶æ€
        if '_export_cancelled' not in st.session_state:
            st.session_state._export_cancelled = False
        
        def check_cancelled():
            """æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆå¯¼å‡º"""
            return st.session_state.get('_export_cancelled', False)
        
        # ============================================================
        # ğŸ”§ æ­¥éª¤0ï¼šæ£€æµ‹å·²å­˜åœ¨çš„æ–‡ä»¶ï¼ˆé€‚ç”¨äºæ¨¡æ‹Ÿæ•°æ®å’ŒçœŸå®æ•°æ®ï¼‰
        # ============================================================
        # æ„å»º concept -> group_key çš„æ˜ å°„
        concept_to_group = {}
        for group_key in CONCEPT_GROUPS_INTERNAL.keys():
            for c in CONCEPT_GROUPS_INTERNAL[group_key]:
                if c not in concept_to_group:
                    concept_to_group[c] = group_key
        
        # æ‰¾å‡ºç”¨æˆ·é€‰æ‹©çš„æ¯ä¸ªæ¨¡å—
        selected_modules = {}  # group_key -> [concepts]
        for c in selected_concepts:
            group_key = concept_to_group.get(c, 'other')
            if group_key not in selected_modules:
                selected_modules[group_key] = []
            selected_modules[group_key].append(c)
        
        # æ£€æµ‹å“ªäº›æ¨¡å—çš„æ–‡ä»¶å·²å­˜åœ¨
        # ğŸ”§ FIX (2026-02-05): ä½¿ç”¨æ¨¡å—åå¼€å¤´åŒ¹é…ï¼Œcohortæ¡ä»¶åœ¨åç¼€
        existing_modules = {}  # group_key -> file_path
        cohort_suffix = _generate_cohort_prefix()
        
        for group_key, group_concepts in selected_modules.items():
            # ğŸ”§ æŒ‰æ¨¡å—åå¼€å¤´æŸ¥æ‰¾å·²å­˜åœ¨çš„æ–‡ä»¶
            search_prefix = f"{group_key}_"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…è¯¥æ¨¡å—çš„æ–‡ä»¶å­˜åœ¨
            for ext in ['.parquet', '.csv', '.xlsx']:
                matching_files = list(export_dir.glob(f"{search_prefix}*{ext}"))
                if matching_files:
                    # æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶
                    existing_modules[group_key] = matching_files[0]
                    break
        
        # å¦‚æœæœ‰å·²å­˜åœ¨çš„æ¨¡å—ï¼Œæ˜¾ç¤ºè®©ç”¨æˆ·é€‰æ‹©
        # ğŸ”§ FIX (2026-02-03): åœ¨ viz_import_mode ä¸‹è‡ªåŠ¨è¦†ç›–ï¼Œè·³è¿‡å¯¹è¯æ¡†
        if existing_modules and not is_viz_import_mode:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²åšå‡ºæ‰€æœ‰å†³å®š
            skipped_modules = st.session_state.get('_skipped_modules', set())
            overwrite_modules = st.session_state.get('_overwrite_modules', set())
            
            # ğŸ”§ DEBUG: æ‰“å°çŠ¶æ€ä»¥ä¾¿è°ƒè¯•
            print(f"[DEBUG] existing_modules: {list(existing_modules.keys())}")
            print(f"[DEBUG] skipped_modules: {skipped_modules}")
            print(f"[DEBUG] overwrite_modules: {overwrite_modules}")
            
            # æ‰¾å‡ºå°šæœªå†³å®šçš„æ¨¡å—
            pending_modules = [m for m in existing_modules.keys() 
                               if m not in skipped_modules and m not in overwrite_modules]
            
            print(f"[DEBUG] pending_modules: {pending_modules}")
            
            if pending_modules:
                # ğŸ”§ FIX: æ˜¾ç¤ºå†²çªæ—¶æ¸…é™¤ _exporting_in_progressï¼Œé¿å…æ˜¾ç¤º "Export in Progress"
                st.session_state['_exporting_in_progress'] = False
                
                # æ˜¾ç¤ºæ‰€æœ‰å†²çªæ¨¡å—
                conflict_title = "âš ï¸ Existing Files Detected" if lang == 'en' else "âš ï¸ æ£€æµ‹åˆ°å·²å­˜åœ¨çš„æ–‡ä»¶"
                st.warning(conflict_title)
                
                # ğŸ”§ ç®€åŒ–ï¼šåªæ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                file_list_html = "<ul style='margin: 10px 0; padding-left: 20px;'>"
                for group_key in pending_modules:
                    file_path = existing_modules[group_key]
                    file_list_html += f"<li style='margin: 5px 0;'><b>{group_key}</b>: <code>{file_path.name}</code></li>"
                file_list_html += "</ul>"
                st.markdown(file_list_html, unsafe_allow_html=True)
                
                # ğŸ”§ ä½¿ç”¨é†’ç›®çš„å¤§æŒ‰é’®
                st.markdown("---")
                st.markdown("<p style='font-size: 1.1rem; font-weight: bold; margin-bottom: 15px;'>How do you want to handle these files?</p>" if lang == 'en' else "<p style='font-size: 1.1rem; font-weight: bold; margin-bottom: 15px;'>è¯·é€‰æ‹©å¦‚ä½•å¤„ç†è¿™äº›æ–‡ä»¶ï¼š</p>", unsafe_allow_html=True)
                
                # ğŸ”§ FIX: ä½¿ç”¨ on_click å›è°ƒè€Œä¸æ˜¯ if st.buttonï¼Œé¿å…é¡µé¢è·³è½¬
                def on_overwrite_all():
                    """è¦†ç›–å…¨éƒ¨çš„å›è°ƒå‡½æ•°"""
                    # å°†æ‰€æœ‰ existing_modules æ·»åŠ åˆ° overwrite åˆ—è¡¨
                    all_modules = set(st.session_state.get('_existing_modules_list', []))
                    st.session_state['_overwrite_modules'] = all_modules
                    st.session_state['_exporting_in_progress'] = True
                    # ğŸ”§ FIX: è®¾ç½® trigger_export å¹¶è®©å®ƒrerunæ¥ç»§ç»­æ‰§è¡Œ
                    st.session_state.trigger_export = True
                
                def on_skip_all():
                    """è·³è¿‡å…¨éƒ¨çš„å›è°ƒå‡½æ•°"""
                    all_modules = set(st.session_state.get('_existing_modules_list', []))
                    st.session_state['_skipped_modules'] = all_modules
                    st.session_state['_exporting_in_progress'] = True
                    # ğŸ”§ FIX: è®¾ç½® trigger_export å¹¶è®©å®ƒrerunæ¥ç»§ç»­æ‰§è¡Œ
                    st.session_state.trigger_export = True
                
                # ğŸ”§ ä¿å­˜ pending_modules åˆ° session_state è®©å›è°ƒèƒ½è®¿é—®
                st.session_state['_existing_modules_list'] = list(existing_modules.keys())
                
                col_all_overwrite, col_all_skip = st.columns(2)
                with col_all_overwrite:
                    all_overwrite_btn = "ğŸ”„ OVERWRITE ALL" if lang == 'en' else "ğŸ”„ å…¨éƒ¨è¦†ç›–"
                    st.markdown("<style>.stButton button[kind='primary'] { font-size: 1.2rem !important; padding: 15px !important; }</style>", unsafe_allow_html=True)
                    st.button(all_overwrite_btn, key="file_overwrite_all", type="primary", 
                             use_container_width=True, on_click=on_overwrite_all)
                with col_all_skip:
                    all_skip_btn = "â­ï¸ SKIP ALL" if lang == 'en' else "â­ï¸ å…¨éƒ¨è·³è¿‡"
                    st.button(all_skip_btn, key="file_skip_all", use_container_width=True,
                             on_click=on_skip_all)
                
                # ğŸ”§ FIX: é‡æ–°æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²åšå‡ºå†³å®šï¼ˆå›è°ƒå¯èƒ½å·²æ›´æ–° session_stateï¼‰
                overwrite_modules = st.session_state.get('_overwrite_modules', set())
                skipped_modules = st.session_state.get('_skipped_modules', set())
                pending_modules = [m for m in existing_modules.keys() 
                                   if m not in skipped_modules and m not in overwrite_modules]
                
                if pending_modules:
                    # ç”¨æˆ·å°šæœªåšå‡ºå†³å®šï¼Œæš‚åœå¯¼å‡º
                    return
        
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©ï¼Œç¡®å®šè¦è·³è¿‡çš„æ¨¡å—
        skipped_modules = st.session_state.get('_skipped_modules', set())
        concepts_to_skip = set()
        for group_key in skipped_modules:
            if group_key in selected_modules:
                for c in selected_modules[group_key]:
                    concepts_to_skip.add(c)
        
        # è¿‡æ»¤æ‰å°†è·³è¿‡çš„æ¦‚å¿µ
        concepts_to_export = [c for c in selected_concepts if c not in concepts_to_skip]
        
        if not concepts_to_export:
            if concepts_to_skip:
                skip_msg = f"â­ï¸ All selected modules already exist, nothing to export" if lang == 'en' else "â­ï¸ æ‰€æœ‰é€‰ä¸­çš„æ¨¡å—éƒ½å·²å­˜åœ¨ï¼Œæ— éœ€å¯¼å‡º"
                st.info(skip_msg)
            # æ¸…ç†çŠ¶æ€
            if '_skipped_modules' in st.session_state:
                del st.session_state['_skipped_modules']
            if '_overwrite_modules' in st.session_state:
                del st.session_state['_overwrite_modules']
            return
        
        # æ˜¾ç¤ºè·³è¿‡ä¿¡æ¯
        if concepts_to_skip:
            skip_count = len(concepts_to_skip)
            load_count = len(concepts_to_export)
            skip_info = f"â­ï¸ Skipping {skip_count} concepts (files exist), exporting {load_count} concepts" if lang == 'en' else f"â­ï¸ è·³è¿‡ {skip_count} ä¸ªæ¦‚å¿µï¼ˆæ–‡ä»¶å·²å­˜åœ¨ï¼‰ï¼Œå¯¼å‡º {load_count} ä¸ªæ¦‚å¿µ"
            st.info(skip_info)
        
        if use_mock:
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å¹¶å¯¼å‡º
            gen_msg = "**Generating mock data...**" if lang == 'en' else "**æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...**"
            status_text.markdown(gen_msg)
            # ğŸ”§ ä½¿ç”¨ get_mock_params_with_cohort è·å–å®Œæ•´å‚æ•°ï¼ˆåŒ…å«æœ€æ–°çš„ cohort_filterï¼‰
            params = get_mock_params_with_cohort()
            all_mock_data, patient_ids = generate_mock_data(**params)
            
            # ä¿å­˜æ‚£è€…IDåˆ—è¡¨ï¼ˆç”¨äºå…¶ä»–åŠŸèƒ½ï¼‰
            st.session_state.patient_ids = patient_ids
            
            # ğŸ”§ æ ¹æ®è¦å¯¼å‡ºçš„ concepts è¿‡æ»¤æ•°æ®ï¼ˆæ’é™¤è·³è¿‡çš„ï¼‰
            data = {}
            for concept in concepts_to_export:
                if concept in all_mock_data:
                    data[concept] = all_mock_data[concept]
            
            # æ˜¾ç¤ºåŠ è½½æƒ…å†µ
            loaded_count = len(data)
            if loaded_count < len(concepts_to_export):
                missing = [c for c in concepts_to_export if c not in all_mock_data]
                skip_msg = f"âš ï¸ {len(missing)} concepts not in mock data: {', '.join(missing[:5])}" if lang == 'en' else f"âš ï¸ æ¨¡æ‹Ÿæ•°æ®ä¸­ä¸å­˜åœ¨ {len(missing)} ä¸ªæ¦‚å¿µ: {', '.join(missing[:5])}"
                st.warning(skip_msg)
            
            progress_bar.progress(0.3)
        else:
            # åŠ è½½çœŸå®æ•°æ®å¹¶å¯¼å‡ºï¼ˆæ‰¹é‡å¹¶è¡ŒåŠ è½½ï¼‰
            from pyricu import load_concepts
            import os
            
            # ğŸ”§ FIX: æ£€æŸ¥ data_path æ˜¯å¦æœ‰æ•ˆï¼ˆå¯è§†åŒ–æ¨¡å¼å¯¼å…¥æ•°æ®åå¯èƒ½æ— æ•ˆï¼‰
            data_path_str = st.session_state.get('data_path', '')
            if not data_path_str or not Path(data_path_str).exists():
                err_msg = "âŒ Data path is not set or invalid. Please go back to Tutorial tab and configure a valid database path first." if lang == 'en' else "âŒ æ•°æ®è·¯å¾„æœªè®¾ç½®æˆ–æ— æ•ˆã€‚è¯·è¿”å›Tutorialæ ‡ç­¾é¡µå…ˆé…ç½®æœ‰æ•ˆçš„æ•°æ®åº“è·¯å¾„ã€‚"
                st.error(err_msg)
                st.session_state['_exporting_in_progress'] = False
                return
            
            # æ‰¹é‡å¹¶è¡ŒåŠ è½½æ‰€æœ‰ç‰¹å¾
            patient_limit_display = st.session_state.get('patient_limit', 100)
            patient_info = f"({patient_limit_display} patients)" if patient_limit_display else "(all patients)"
            patient_info_cn = f"ï¼ˆ{patient_limit_display}æ‚£è€…ï¼‰" if patient_limit_display else "ï¼ˆå…¨éƒ¨æ‚£è€…ï¼‰"
            batch_msg = f"**Loading concepts {patient_info}...**" if lang == 'en' else f"**æ­£åœ¨åŠ è½½æ¦‚å¿µ {patient_info_cn}...**"
            status_text.markdown(batch_msg)
            
            # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šå‚ç…§ extract_baseline_features.py çš„é…ç½®
            patient_limit = st.session_state.get('patient_limit', 0)  # å¯¼å‡ºé»˜è®¤ä¸é™åˆ¶
            
            # è·å–æ‚£è€…IDè¿‡æ»¤å™¨
            patient_ids_filter = None
            id_col = 'stay_id'
            if patient_limit and patient_limit > 0:
                try:
                    data_path = Path(data_path_str)
                    database = st.session_state.get('database', 'miiv')
                    id_col_map = {'miiv': 'stay_id', 'eicu': 'patientunitstayid', 'aumc': 'admissionid', 'hirid': 'patientid', 'mimic': 'icustay_id', 'sic': 'CaseID'}
                    id_col = id_col_map.get(database, 'stay_id')
                    
                    for f in ['icustays.parquet', 'patient.parquet', 'admissions.parquet']:
                        fp = data_path / f
                        if fp.exists():
                            icustays_df = pd.read_parquet(fp, columns=[id_col] if id_col else None)
                            if id_col in icustays_df.columns:
                                all_ids = icustays_df[id_col].unique().tolist()
                                sample_ids = all_ids[:patient_limit] if len(all_ids) > patient_limit else all_ids
                                patient_ids_filter = {id_col: sample_ids}
                                break
                except Exception:
                    pass
            
            # ğŸš€ æ™ºèƒ½å¹¶è¡Œé…ç½®ï¼šæ ¹æ®ç³»ç»Ÿèµ„æºå’Œæ‚£è€…æ•°é‡åŠ¨æ€è°ƒæ•´
            num_patients = len(patient_ids_filter.get(id_col, [])) if patient_ids_filter else None
            parallel_workers, parallel_backend = get_optimal_parallel_config(num_patients, task_type='export')
            
            # æ˜¾ç¤ºç³»ç»Ÿèµ„æºä¿¡æ¯ï¼ˆåŒ…å«æ€§èƒ½å±‚çº§ï¼‰
            resources = get_system_resources()
            perf_tier = resources.get('performance_tier', 'unknown')
            # ğŸ”§ ä½¿ç”¨ parallel_config çš„ recommended_workersï¼Œç¡®ä¿æ˜¾ç¤ºä¸å®é™…ä¸€è‡´
            actual_workers = resources.get('recommended_workers', parallel_workers)
            tier_emoji = {
                'high-performance': 'ğŸš€',
                'server': 'ğŸ’»',
                'workstation': 'ğŸ–¥ï¸',
                'standard': 'ğŸ’»',
                'limited': 'âš ï¸'
            }.get(perf_tier, 'ğŸ’»')
            
            if lang == 'en':
                perf_msg = f"{tier_emoji} System: {resources['cpu_count']} cores, {resources['total_memory_gb']}GB RAM ({perf_tier}) â†’ Using {actual_workers} workers ({parallel_backend})"
            else:
                tier_cn = {
                    'high-performance': 'é«˜æ€§èƒ½æœåŠ¡å™¨',
                    'server': 'æœåŠ¡å™¨',
                    'workstation': 'å·¥ä½œç«™',
                    'standard': 'æ ‡å‡†é…ç½®',
                    'limited': 'å†…å­˜å—é™'
                }.get(perf_tier, perf_tier)
                perf_msg = f"{tier_emoji} ç³»ç»Ÿ: {resources['cpu_count']} æ ¸å¿ƒ, {resources['total_memory_gb']}GB å†…å­˜ ({tier_cn}) â†’ ä½¿ç”¨ {actual_workers} å¹¶è¡Œ ({parallel_backend})"
            st.info(perf_msg)
            
            try:
                # ğŸ“ æ‰¹é‡åŠ è½½æ‰€æœ‰æ¦‚å¿µï¼ˆè§¦å‘å®½è¡¨æ‰¹é‡åŠ è½½ä¼˜åŒ–ï¼‰
                data = {}
                failed_concepts = []
                empty_concepts = []  # ğŸ†• è·Ÿè¸ªè¿”å›ç©ºç»“æœçš„æ¦‚å¿µ
                
                # ğŸš€ ä¼˜åŒ–ï¼šå…ˆè¿‡æ»¤æ‰å½“å‰æ•°æ®åº“ä¸æ”¯æŒçš„æ¦‚å¿µï¼Œé¿å…æ‰¹é‡åŠ è½½å¤±è´¥
                from pyricu.concept import load_dictionary
                cd = load_dictionary(include_sofa2=True)  # ğŸ”§ FIX: åŒ…å« SOFA2 æ¦‚å¿µå­—å…¸
                database = st.session_state.get('database', 'eicu')
                valid_concepts = []
                unsupported_concepts = []
                special_concepts_to_load = []  # ğŸ†• ç‰¹æ®Šæ¦‚å¿µï¼ˆAKI, circ_failureç­‰ï¼‰
                
                # ğŸ”§ ä½¿ç”¨ concepts_to_export è€Œä¸æ˜¯ selected_conceptsï¼ˆè·³è¿‡å·²å­˜åœ¨æ¨¡å—çš„æ¦‚å¿µï¼‰
                for c in concepts_to_export:
                    # ğŸ†• å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šæ¦‚å¿µ
                    if c in SPECIAL_CONCEPTS:
                        special_concepts_to_load.append(c)
                        continue
                    
                    concept_def = cd.get(c)
                    if concept_def:
                        # ğŸ”§ FIX 2025-01-23: SOFA ç­‰å›è°ƒæ¦‚å¿µæ²¡æœ‰ç›´æ¥çš„ sourcesï¼Œä½†æœ‰ sub_concepts
                        # è¿™äº›æ¦‚å¿µæ˜¯æœ‰æ•ˆçš„ï¼Œå› ä¸ºå®ƒä»¬ä¼šé€’å½’åŠ è½½å­æ¦‚å¿µ
                        has_sources = concept_def.sources.get(database) if hasattr(concept_def, 'sources') else False
                        has_sub_concepts = bool(concept_def.sub_concepts) if hasattr(concept_def, 'sub_concepts') else False
                        has_callback = bool(concept_def.callback) if hasattr(concept_def, 'callback') else False
                        
                        if has_sources or has_sub_concepts or has_callback:
                            valid_concepts.append(c)
                        else:
                            unsupported_concepts.append(c)
                    else:
                        unsupported_concepts.append(c)
                
                # ğŸ”§ FIX: unsupported_concepts è­¦å‘Šç§»åˆ° failed_concepts å¤„ç»Ÿä¸€æ˜¾ç¤ºï¼Œé¿å…é‡å¤
                # è¿™é‡Œåªè®°å½•ï¼Œä¸ç«‹å³æ˜¾ç¤º
                pass  # unsupported_concepts will be merged with failed_concepts later
                
                if not valid_concepts and not special_concepts_to_load:
                    st.error("âŒ æ‰€é€‰æ¦‚å¿µåœ¨å½“å‰æ•°æ®åº“ä¸­éƒ½ä¸å¯ç”¨")
                    return
                
                # ğŸš€ æ™ºèƒ½å¹¶è¡Œï¼šæ ¹æ®æ¦‚å¿µæ•°é‡å’Œç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´ concept_workers
                smart_concept_workers = min(len(valid_concepts), actual_workers) if len(valid_concepts) > 1 else 1
                
                load_kwargs = {
                    'data_path': st.session_state.data_path,
                    'database': database,
                    'concepts': valid_concepts,  # ğŸš€ åªä¼ å…¥æœ‰æ•ˆæ¦‚å¿µ
                    'verbose': False,
                    'merge': False,  # è¿”å› dictï¼Œæ¯ä¸ªæ¦‚å¿µå•ç‹¬çš„DataFrame
                    'concept_workers': smart_concept_workers,  # ğŸš€ æ™ºèƒ½å¹¶è¡Œ
                    # ä¸ä¼  parallel_workersï¼Œé¿å…è§¦å‘åˆ†æ‰¹åŠ è½½è·¯å¾„
                }
                if patient_ids_filter:
                    load_kwargs['patient_ids'] = patient_ids_filter
                
                progress_bar.progress(0.2)
                
                try:
                    result = load_concepts(**load_kwargs)
                    
                    # å¤„ç†è¿”å›ç»“æœï¼ˆdict of DataFramesï¼‰
                    if isinstance(result, dict):
                        for cname, df in result.items():
                            # ğŸ”§ å¤„ç†å„ç§è¿”å›ç±»å‹
                            if hasattr(df, 'to_pandas'):
                                df = df.to_pandas()
                            elif hasattr(df, 'dataframe'):
                                df = df.dataframe()
                            elif hasattr(df, 'data') and isinstance(df.data, pd.DataFrame):
                                df = df.data
                            
                            if isinstance(df, pd.DataFrame) and len(df) > 0:
                                data[cname] = df
                            elif isinstance(df, pd.Series):
                                data[cname] = df.to_frame().reset_index()
                            else:
                                # ğŸ†• ç©ºç»“æœï¼ˆæœªé…ç½®æˆ–æ— æ•°æ®ï¼‰
                                empty_concepts.append(cname)
                    elif isinstance(result, pd.DataFrame):
                        # å¦‚æœè¿”å›å•ä¸ªDataFrameï¼ˆmergedæ¨¡å¼ï¼‰ï¼Œæ‹†åˆ†æˆå„åˆ—
                        for concept in selected_concepts:
                            if concept in result.columns:
                                data[concept] = result
                                break  # mergedæ¨¡å¼åªéœ€è¦ä¸€ä¸ª
                    
                    # æ£€æŸ¥å“ªäº›æ¦‚å¿µæ²¡æœ‰åŠ è½½æˆåŠŸï¼ˆğŸ†• åŒºåˆ†å¤±è´¥å’Œç©ºç»“æœï¼‰
                    for c in valid_concepts:
                        if c not in data and c not in empty_concepts:
                            empty_concepts.append(c)
                    
                except Exception as batch_e:
                    # æ‰¹é‡åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªåŠ è½½
                    st.warning(f"âš ï¸ æ‰¹é‡åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªåŠ è½½: {batch_e}")
                    for i, concept in enumerate(selected_concepts):
                        try:
                            single_kwargs = {
                                'data_path': st.session_state.data_path,
                                'database': st.session_state.get('database'),
                                'concepts': [concept],
                                'verbose': False,
                                'merge': False,
                                'concept_workers': 1,
                            }
                            if patient_ids_filter:
                                single_kwargs['patient_ids'] = patient_ids_filter
                            
                            result = load_concepts(**single_kwargs)
                            
                            if isinstance(result, dict):
                                for cname, df in result.items():
                                    if hasattr(df, 'data') and isinstance(df.data, pd.DataFrame):
                                        df = df.data
                                    if isinstance(df, pd.DataFrame) and len(df) > 0:
                                        data[cname] = df
                            elif isinstance(result, pd.DataFrame) and len(result) > 0:
                                data[concept] = result
                            
                            progress_bar.progress(0.1 + 0.4 * (i + 1) / total_concepts)
                            
                        except Exception:
                            failed_concepts.append(concept)
                            continue
                
                progress_bar.progress(0.5)
                
                # ğŸ†• åŠ è½½ç‰¹æ®Šæ¦‚å¿µï¼ˆAKI, circ_failureç­‰ï¼‰
                if special_concepts_to_load:
                    special_msg = f"**Loading special concepts (AKI, CircFailure)...**" if lang == 'en' else f"**æ­£åœ¨åŠ è½½ç‰¹æ®Šæ¦‚å¿µ (AKI, å¾ªç¯è¡°ç«­)...**"
                    status_text.markdown(special_msg)
                    
                    try:
                        special_data = load_special_concepts(
                            concepts=special_concepts_to_load,
                            database=database,
                            data_path=st.session_state.data_path,
                            patient_ids=patient_ids_filter,
                            max_patients=patient_limit if patient_limit and patient_limit > 0 else None,
                            verbose=False
                        )
                        
                        # åˆå¹¶ç‰¹æ®Šæ¦‚å¿µæ•°æ®
                        for cname, df in special_data.items():
                            if isinstance(df, pd.DataFrame) and not df.empty:
                                data[cname] = df
                        
                        # è®°å½•æœªæˆåŠŸåŠ è½½çš„ç‰¹æ®Šæ¦‚å¿µ
                        failed_special = [c for c in special_concepts_to_load if c not in data]
                        failed_concepts.extend(failed_special)
                        
                    except Exception as special_e:
                        st.warning(f"âš ï¸ Failed to load special concepts: {special_e}" if lang == 'en' else f"âš ï¸ åŠ è½½ç‰¹æ®Šæ¦‚å¿µå¤±è´¥: {special_e}")
                        failed_concepts.extend(special_concepts_to_load)
                    
                    progress_bar.progress(0.55)
                
                # ğŸ”§ FIX: åˆå¹¶ unsupported å’Œ failed æ¦‚å¿µï¼Œåªæ˜¾ç¤ºä¸€æ¬¡è­¦å‘Š
                all_skipped = list(set(unsupported_concepts + failed_concepts))
                if all_skipped:
                    skip_list = ', '.join(all_skipped[:5])
                    more_text = f'... +{len(all_skipped)-5}' if len(all_skipped) > 5 else ''
                    skip_msg = f"âš ï¸ Skipped {len(all_skipped)} unavailable: {skip_list}{more_text}" if lang == 'en' else f"âš ï¸ è·³è¿‡ {len(all_skipped)} ä¸ªä¸å¯ç”¨: {skip_list}{more_text}"
                    st.warning(skip_msg)
                
                # ğŸ†• æ˜¾ç¤ºç©ºç»“æœæ¦‚å¿µæç¤º
                if empty_concepts:
                    empty_list = ', '.join(empty_concepts[:8])
                    more_text = f'... +{len(empty_concepts)-8}' if len(empty_concepts) > 8 else ''
                    empty_msg = f"â„¹ï¸ {len(empty_concepts)} concepts returned empty (not configured or no data): {empty_list}{more_text}" if lang == 'en' else f"â„¹ï¸ {len(empty_concepts)} ä¸ªæ¦‚å¿µè¿”å›ç©ºç»“æœï¼ˆæœªé…ç½®æˆ–æ— æ•°æ®ï¼‰: {empty_list}{more_text}"
                    st.info(empty_msg)
                
                # ğŸ”§ FIX (2026-02-04): åªæ˜¾ç¤ºå®é™…åŠ è½½çš„æ•°é‡ï¼Œä¸æ˜¾ç¤º /total_concepts
                loaded_msg = f"âœ… Loaded {len(data)} concepts" if lang == 'en' else f"âœ… å·²åŠ è½½ {len(data)} ä¸ªæ¦‚å¿µ"
                status_text.markdown(loaded_msg)
                
            except Exception as e:
                warn_msg = f"âš ï¸ Batch loading failed: {e}" if lang == 'en' else f"âš ï¸ æ‰¹é‡åŠ è½½å¤±è´¥: {e}"
                st.warning(warn_msg)
                data = {}
        
        # æŒ‰æ¨¡å—åˆ†ç»„å¯¼å‡ºï¼ˆå°†åŒä¸€åˆ†ç»„çš„ç‰¹å¾åˆå¹¶ä¸ºå®½è¡¨ï¼‰
        merge_msg = "**Merging and exporting by module...**" if lang == 'en' else "**æ­£åœ¨æŒ‰æ¨¡å—åˆå¹¶å¯¼å‡º...**"
        status_text.markdown(merge_msg)
        
        # ğŸš€ è®°å½•å¯¼å‡ºå¼€å§‹æ—¶é—´å’Œå„æ¨¡å—è€—æ—¶
        import time as time_module
        export_start_time = time_module.time()
        module_times = {}
        
        # åå‘æ˜ å°„ï¼šconcept -> group_keyï¼ˆè‹±æ–‡keyç”¨äºæ–‡ä»¶åï¼‰
        concept_to_group = {}
        
        # ğŸ”§ æ™ºèƒ½è°ƒæ•´åˆ†ç»„ä¼˜å…ˆçº§
        # é»˜è®¤ä½¿ç”¨ å®šä¹‰é¡ºåºï¼Œä½†å¦‚æœæ£€æµ‹åˆ°ç”¨æˆ·åªä½¿ç”¨äº† SOFA-1 ç›¸å…³çš„ Sepsis
        # åˆ™è°ƒæ•´ä¼˜å…ˆçº§ï¼Œç¡®ä¿å…±äº«æ¦‚å¿µè¢«å½’ç±»åˆ° Sepsis-3 (SOFA-1) ç»„
        group_priority = list(CONCEPT_GROUPS_INTERNAL.keys())
        loaded_keys = set(data.keys())
        if 'sep3_sofa1' in loaded_keys and 'sep3_sofa2' not in loaded_keys:
            # Sepsis-3 SOFA-1 å­˜åœ¨ä½† SOFA-2 ä¸å­˜åœ¨ => ä¼˜å…ˆä½¿ç”¨ SOFA-1 ç»„
            if 'sepsis3_sofa1' in group_priority and 'sepsis3_sofa2' in group_priority:
                # äº¤æ¢ä½ç½®æˆ–é‡å»ºåˆ—è¡¨ï¼Œè®© sofa1 æ’åœ¨ sofa2 å‰é¢
                group_priority.remove('sepsis3_sofa1')
                idx_sofa2 = group_priority.index('sepsis3_sofa2')
                group_priority.insert(idx_sofa2, 'sepsis3_sofa1')
        
        for group_key in group_priority:
            concepts = CONCEPT_GROUPS_INTERNAL[group_key]
            for c in concepts:
                if c not in concept_to_group:  # ä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªåˆ†ç»„
                    concept_to_group[c] = group_key
        
        # æŒ‰åˆ†ç»„èšåˆæ•°æ®
        grouped_data = {}
        for concept_name, df in data.items():
            # ğŸ”§ ä¿ç•™æ‰€æœ‰DataFrameï¼ˆåŒ…æ‹¬ç©ºçš„ï¼‰ï¼Œç¡®ä¿ç”¨æˆ·é€‰æ‹©çš„ç‰¹å¾éƒ½è¢«å¯¼å‡º
            if not isinstance(df, pd.DataFrame):
                continue
            
            group_key = concept_to_group.get(concept_name, 'other')
            
            if group_key not in grouped_data:
                grouped_data[group_key] = {}
            
            grouped_data[group_key][concept_name] = df
        
        # å¯¼å‡ºåˆå¹¶åçš„åˆ†ç»„æ•°æ®ï¼ˆå®½è¡¨æ ¼å¼ï¼‰
        total_groups = len(grouped_data)
        
        # ğŸ†• æ”¶é›†æ‰€æœ‰å¯¼å‡ºæ•°æ®ä¸­çš„å”¯ä¸€æ‚£è€…ID
        all_exported_patient_ids = set()
        
        # ğŸ”§ æ£€æŸ¥æ˜¯å¦æœ‰å·²å­˜åœ¨çš„æ–‡ä»¶éœ€è¦è¦†ç›–
        skipped_modules = st.session_state.get('_skipped_modules', set())
        
        for idx, (group_name, concept_dfs) in enumerate(grouped_data.items()):
            # ğŸ”§ æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
            if check_cancelled():
                cancel_msg = "ğŸ›‘ Export cancelled by user" if lang == 'en' else "ğŸ›‘ ç”¨æˆ·å·²å–æ¶ˆå¯¼å‡º"
                st.warning(cancel_msg)
                st.session_state._export_cancelled = False  # é‡ç½®çŠ¶æ€
                cancel_placeholder.empty()
                break
            
            module_start_time = time_module.time()
            
            # ğŸš€ æ˜¾ç¤ºè¯¦ç»†è¿›åº¦ï¼šæ¨¡å—å + åŒ…å«çš„ç‰¹å¾åˆ—è¡¨
            concept_list = list(concept_dfs.keys())
            concepts_str = ', '.join(concept_list[:5]) + (f'... +{len(concept_list)-5}' if len(concept_list) > 5 else '')
            export_group_msg = f"**Exporting**: `{group_name}` ({idx+1}/{total_groups})\n\nğŸ“‹ Features: {concepts_str}" if lang == 'en' else f"**æ­£åœ¨å¯¼å‡º**: `{group_name}` ({idx+1}/{total_groups})\n\nğŸ“‹ ç‰¹å¾: {concepts_str}"
            
            # ğŸ”§ FIX (2026-02-03): ç®€åŒ–è¿›åº¦æ˜¾ç¤ºï¼Œç§»é™¤å¾ªç¯å†…æŒ‰é’®é¿å… key å†²çªå¯¼è‡´ç™½å±
            cancel_placeholder.markdown(export_group_msg)
            
            # å°†åŒä¸€åˆ†ç»„çš„æ‰€æœ‰ concept åˆå¹¶ä¸ºå®½è¡¨
            # æ‰¾åˆ°å…±åŒçš„ ID åˆ—å’Œæ—¶é—´åˆ—
            id_candidates = ['stay_id', 'hadm_id', 'icustay_id', 'patientunitstayid', 'admissionid', 'patientid']
            time_candidates = ['time', 'charttime', 'starttime', 'endtime', 'itemtime']
            
            # ğŸ”§ å…ˆç»Ÿä¸€æ‰€æœ‰ DataFrame çš„æ—¶é—´åˆ—åç§°
            # ä¸åŒæ¦‚å¿µå¯èƒ½ä½¿ç”¨ä¸åŒçš„æ—¶é—´åˆ—åï¼ˆcharttime, starttimeç­‰ï¼‰
            # æ³¨æ„ï¼šPyRICU çš„æ—¶é—´æ˜¯ç›¸å¯¹äº ICU å…¥é™¢çš„å°æ—¶æ•°ï¼Œä¸æ˜¯ datetime
            unified_time_col = 'charttime'  # ç»Ÿä¸€ä½¿ç”¨ charttime ä½œä¸ºæ—¶é—´åˆ—å
            normalized_concept_dfs = {}
            for cname, cdf in concept_dfs.items():
                cdf = cdf.copy()
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç»Ÿä¸€çš„æ—¶é—´åˆ—
                if unified_time_col in cdf.columns:
                    # åˆ é™¤å…¶ä»–æ—¶é—´åˆ—ä»¥é¿å…é‡å¤
                    other_time_cols = [tc for tc in time_candidates if tc in cdf.columns and tc != unified_time_col]
                    if other_time_cols:
                        cdf = cdf.drop(columns=other_time_cols)
                else:
                    # æ‰¾åˆ°å½“å‰ DataFrame çš„ç¬¬ä¸€ä¸ªæ—¶é—´åˆ—å¹¶é‡å‘½å
                    for tc in time_candidates:
                        if tc in cdf.columns:
                            cdf = cdf.rename(columns={tc: unified_time_col})
                            # åˆ é™¤å…¶ä»–æ—¶é—´åˆ—
                            other_time_cols = [t for t in time_candidates if t in cdf.columns and t != unified_time_col]
                            if other_time_cols:
                                cdf = cdf.drop(columns=other_time_cols)
                            break
                
                # ğŸ”§ ä¸å†å¼ºåˆ¶è½¬æ¢æ—¶é—´åˆ—ç±»å‹ï¼Œä¿æŒåŸå§‹çš„å°æ—¶æ•°æ ¼å¼
                # PyRICU çš„æ—¶é—´æ˜¯ç›¸å¯¹äº ICU å…¥é™¢çš„å°æ—¶æ•°ï¼ˆ0, 1, 2, 3...ï¼‰
                
                normalized_concept_dfs[cname] = cdf
            concept_dfs = normalized_concept_dfs
            
            # ç¡®å®šè¿™ä¸ªåˆ†ç»„çš„ä¸»é”®åˆ—
            merge_cols = []
            id_col = None
            time_col = None
            
            # ğŸ”§ æ”¹è¿›ï¼šéå†æ‰€æœ‰ DataFrame ç¡®å®šæœ€å®Œæ•´çš„ merge_cols
            # å¿…é¡»ä»æ‰€æœ‰ DataFrame ä¸­å¯»æ‰¾å¯èƒ½çš„ ID åˆ—å’Œ Time åˆ—ï¼Œé˜²æ­¢å› ç¬¬ä¸€ä¸ª DataFrame æ˜¯é™æ€å˜é‡è€Œæ¼æ‰ Time åˆ—
            potential_id_cols = set()
            potential_time_cols = set()
            
            for cname, cdf in concept_dfs.items():
                for col in id_candidates:
                    if col in cdf.columns:
                        potential_id_cols.add(col)
                        break 
                for col in time_candidates:
                    if col in cdf.columns:
                        potential_time_cols.add(col)
                        break
            
            for col in id_candidates:
                if col in potential_id_cols:
                    id_col = col
                    merge_cols.append(col)
                    break
            for col in time_candidates:
                if col in potential_time_cols:
                    time_col = col
                    merge_cols.append(col)
                    break
            
            if not merge_cols:
                # æ²¡æœ‰å…±åŒçš„åˆå¹¶é”®ï¼Œç®€å•æ‹¼æ¥
                all_dfs = []
                for cname, cdf in concept_dfs.items():
                    cdf = cdf.copy()
                    cdf['_concept'] = cname
                    all_dfs.append(cdf)
                merged_df = pd.concat(all_dfs, ignore_index=True)
            else:
                # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨ concat + pivot æ›¿ä»£è¿­ä»£å¼ mergeï¼Œé¿å…æ•°æ®è†¨èƒ€
                all_concept_dfs = []
                
                for concept_name, df in concept_dfs.items():
                    # ğŸ”§ ç¡®ä¿å½“å‰ df åŒ…å« ID åˆ—
                    if id_col and id_col not in df.columns:
                        continue 
                    
                    # ğŸ”§ è¿™é‡Œä¸å†è·³è¿‡ç¼ºå°‘ Time åˆ—çš„ DataFrame (Staticå˜é‡)ï¼Œè€Œæ˜¯ä¼šè¡¥å…… Time=NaN
                    
                    # åªä¿ç•™åˆå¹¶é”®å’Œå½“å‰ concept çš„å€¼åˆ—
                    # ğŸ”§ åˆ é™¤éæ ¸å¿ƒåˆ—ï¼ˆå¦‚ valueuom ç­‰å…ƒæ•°æ®åˆ—ï¼‰
                    metadata_cols = ['valueuom', 'unit', 'units', 'category', 'type']
                    cols_to_drop = [c for c in df.columns if c in metadata_cols]
                    if cols_to_drop:
                        df = df.drop(columns=cols_to_drop)
                    
                    value_cols = [c for c in df.columns if c not in merge_cols]
                    
                    # å‡†å¤‡è¦ä¿ç•™çš„åˆ—
                    df_to_add = df.copy()
                    
                    # ğŸ”§ ä¿®å¤ï¼šåªä¿ç•™ä¸»æ¦‚å¿µåˆ—ï¼Œé¿å…æ•°æ®é‡å¤
                    # å¯¹äºå¤šåˆ—DataFrameï¼ˆå¦‚sofaåŒ…å«sofa_respç­‰ï¼‰ï¼Œåªå–ä¸»åˆ—
                    if len(value_cols) == 1:
                        # åªæœ‰ä¸€ä¸ªå€¼åˆ—ï¼Œç”¨ concept åé‡å‘½å
                        df_to_add = df_to_add.rename(columns={value_cols[0]: concept_name})
                    elif len(value_cols) > 1:
                        # å¤šä¸ªå€¼åˆ—ï¼šåªä¿ç•™ä¸»æ¦‚å¿µåˆ—ï¼ˆä¸concept_nameç›¸åŒæˆ–æœ€ç›¸å…³çš„åˆ—ï¼‰
                        if concept_name in value_cols:
                            # å­˜åœ¨ä¸æ¦‚å¿µåŒåçš„åˆ—ï¼Œåªä¿ç•™å®ƒ
                            keep_val_cols = [concept_name]
                        else:
                            # ä¸å­˜åœ¨åŒååˆ—ï¼Œä¿ç•™æ‰€æœ‰å€¼åˆ—ä½†æ·»åŠ å‰ç¼€
                            keep_val_cols = value_cols
                        
                        # åªä¿ç•™éœ€è¦çš„å€¼åˆ—
                        cols_to_keep = merge_cols + keep_val_cols
                        df_to_add = df_to_add[[c for c in cols_to_keep if c in df_to_add.columns]]
                        
                        # å¦‚æœåªä¿ç•™äº†ä¸€ä¸ªå€¼åˆ—ä¸”ä¸æ˜¯concept_nameï¼Œé‡å‘½å
                        remaining_val_cols = [c for c in df_to_add.columns if c not in merge_cols]
                        if len(remaining_val_cols) == 1 and remaining_val_cols[0] != concept_name:
                            df_to_add = df_to_add.rename(columns={remaining_val_cols[0]: concept_name})
                        elif len(remaining_val_cols) > 1:
                            # å¤šåˆ—æ—¶æ·»åŠ å‰ç¼€ï¼ˆä»…å¯¹ä¸ä»¥concept_nameå¼€å¤´çš„åˆ—ï¼‰
                            rename_map = {}
                            for c in remaining_val_cols:
                                if c != concept_name and not c.startswith(f"{concept_name}_"):
                                    rename_map[c] = f"{concept_name}_{c}"
                            if rename_map:
                                df_to_add = df_to_add.rename(columns=rename_map)
                    
                    # è¡¥å……ç¼ºå¤±çš„ merge_cols (ä¾‹å¦‚ Static å˜é‡ç¼ºå¤± charttime)
                    for mc in merge_cols:
                        if mc not in df_to_add.columns:
                            df_to_add[mc] = np.nan
                            
                    # åªä¿ç•™ç›¸å…³åˆ—
                    keep_cols = merge_cols + [c for c in df_to_add.columns if c not in merge_cols]
                    all_concept_dfs.append(df_to_add[keep_cols])
                
                # ğŸš€ æ™ºèƒ½åˆå¹¶ç­–ç•¥ï¼šæ ¹æ®DataFrameç‰¹æ€§é€‰æ‹©æœ€ä¼˜æ–¹æ³•
                if len(all_concept_dfs) == 0:
                    merged_df = None
                elif len(all_concept_dfs) == 1:
                    merged_df = all_concept_dfs[0]
                else:
                    # ğŸ”§ ç»Ÿä¸€ merge_cols çš„ç±»å‹ï¼Œé¿å… object å’Œ float64 åˆå¹¶é”™è¯¯
                    # æ³¨æ„ï¼šç»Ÿä¸€åçš„æ—¶é—´åˆ—æ˜¯ 'charttime'ï¼Œä¸æ˜¯ time_col å˜é‡
                    time_related_cols = {'charttime', 'time', 'starttime', 'endtime', 'itemtime'}
                    id_related_cols = {'stay_id', 'hadm_id', 'icustay_id', 'patientunitstayid', 'admissionid', 'patientid', 'CaseID'}
                    
                    for i, df in enumerate(all_concept_dfs):
                        for col in merge_cols:
                            if col in df.columns:
                                col_dtype = df[col].dtype
                                if col in time_related_cols:
                                    # ğŸ”§ æ—¶é—´åˆ—ï¼šç»Ÿä¸€è½¬ä¸º float64ï¼ˆPyRICU çš„æ—¶é—´æ˜¯ç›¸å¯¹å°æ—¶æ•°ï¼‰
                                    if col_dtype == 'object' or not pd.api.types.is_numeric_dtype(col_dtype):
                                        all_concept_dfs[i][col] = pd.to_numeric(df[col], errors='coerce')
                                elif col in id_related_cols:
                                    # ğŸ”§ IDåˆ—ï¼šç»Ÿä¸€è½¬ä¸º Int64
                                    if col_dtype == 'object':
                                        all_concept_dfs[i][col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')
                                    elif pd.api.types.is_numeric_dtype(col_dtype):
                                        all_concept_dfs[i][col] = df[col].astype('Int64')
                                else:
                                    # å…¶ä»–åˆ—ï¼šå¦‚æœæ˜¯ object ç±»å‹ä½†åº”è¯¥æ˜¯æ•°å€¼ï¼Œè½¬æ¢
                                    if col_dtype == 'object':
                                        all_concept_dfs[i][col] = pd.to_numeric(df[col], errors='coerce')
                    
                    # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šæ£€æµ‹è¡Œæ•°ç›¸è¿‘çš„DataFrameï¼Œä½¿ç”¨concat+pivoté¿å…outer join
                    row_counts = [len(df) for df in all_concept_dfs]
                    avg_rows = sum(row_counts) / max(len(row_counts), 1)
                    max_deviation = max(abs(count - avg_rows) / (avg_rows + 1) for count in row_counts) if row_counts else 0
                    
                    # ğŸ”§ å¢å¼ºï¼šä¸ºæ—¶é—´åˆ—æ·»åŠ å››èˆäº”å…¥ï¼Œå¢åŠ  Fast Path å‘½ä¸­ç‡å¹¶é¿å… merge è†¨èƒ€
                    for i, df in enumerate(all_concept_dfs):
                        for col in merge_cols:
                            if col in time_related_cols and pd.api.types.is_float_dtype(df[col]):
                                all_concept_dfs[i][col] = df[col].round(2)

                    # å¼ºåˆ¶ä½¿ç”¨ Fast Path (Concat+Pivot) 
                    # é™¤éæ•°æ®é‡æå¤§(>2M total rows)æ‰å›é€€ï¼Œæˆ–è€…Fast Pathå‡ºé”™
                    # concat+pivot é€šå¸¸æ¯”å¤šæ¬¡ outer join æ›´å¿«ä¸”æ›´ç¨³å®š
                    total_rows_sum = sum(row_counts)
                    use_fast_path = (total_rows_sum < 2_000_000)
                    
                    if use_fast_path:
                        try:
                            # ğŸ”¥ å¿«é€Ÿè·¯å¾„ï¼šconcat + pivotï¼ˆé¿å…å¤šæ¬¡outer joinï¼‰
                            # ğŸ”§ ä¿®å¤ï¼šåˆ†ç¦»é™æ€æ¦‚å¿µï¼ˆæ— timeåˆ—ï¼‰å’Œæ—¶é—´åºåˆ—æ¦‚å¿µ
                            # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®å¤„ç†å¤šåˆ—æ¦‚å¿µ
                            processed_dfs = []
                            static_dfs = []  # é™æ€æ¦‚å¿µå•ç‹¬å¤„ç†
                            empty_concepts = []  # è®°å½•ç©ºDataFrameçš„æ¦‚å¿µå
                            
                            for df in all_concept_dfs:
                                df_temp = df.copy()
                                
                                val_cols = [c for c in df_temp.columns if c not in merge_cols]
                                if not val_cols: 
                                    continue
                                
                                # ğŸ”§ æ£€æµ‹é™æ€æ¦‚å¿µï¼štimeåˆ—å…¨ä¸ºNaNæˆ–ä¸å­˜åœ¨æœ‰æ•ˆæ—¶é—´æ•°æ®
                                is_static = False
                                if time_col and time_col in df_temp.columns:
                                    if df_temp[time_col].isna().all():
                                        is_static = True
                                
                                if is_static:
                                    # é™æ€æ¦‚å¿µï¼šåªä¿ç•™ id_col å’Œæ‰€æœ‰ value_colsï¼Œåç»­é€šè¿‡ merge åˆå¹¶
                                    if id_col and id_col in df_temp.columns:
                                        static_cols = [id_col] + val_cols
                                        static_df = df_temp[static_cols].drop_duplicates(subset=[id_col], keep='last')
                                        static_dfs.append(static_df)
                                else:
                                    # æ—¶é—´åºåˆ—æ¦‚å¿µï¼šå¯¹æ¯ä¸ªå€¼åˆ—å•ç‹¬å¤„ç†å¹¶pivot
                                    # ç§»é™¤é‡å¤é”®ï¼Œé˜²æ­¢ pivot å¤±è´¥ 
                                    df_temp = df_temp.drop_duplicates(subset=merge_cols, keep='last')
                                    
                                    # ğŸ”§ å¤„ç†æ¯ä¸ªå€¼åˆ—
                                    for value_col in val_cols:
                                        # ğŸ”§ å³ä½¿DataFrameä¸ºç©ºï¼Œä¹Ÿè®°å½•æ¦‚å¿µå
                                        if len(df_temp) == 0:
                                            empty_concepts.append(value_col)
                                            continue
                                        
                                        # ä¸ºæ¯ä¸ªå€¼åˆ—åˆ›å»ºå•ç‹¬çš„å¤„ç†DataFrame
                                        single_val_df = df_temp[merge_cols + [value_col]].copy()
                                        single_val_df['_concept'] = str(value_col) # ç¡®ä¿åˆ—åä¸ºå­—ç¬¦ä¸²
                                        single_val_df['_value'] = single_val_df[value_col]
                                        single_val_df.drop(columns=[value_col], inplace=True)
                                        processed_dfs.append(single_val_df)
                            
                            if not processed_dfs and not static_dfs:
                                merged_df = None
                            else:
                                # å…ˆå¤„ç†æ—¶é—´åºåˆ—æ¦‚å¿µ
                                if processed_dfs:
                                    # Concatæ‰€æœ‰æ•°æ®
                                    stacked = pd.concat(processed_dfs, ignore_index=True)
                                    
                                    # Pivotæˆå®½è¡¨
                                    merged_df = stacked.pivot_table(
                                        index=merge_cols,
                                        columns='_concept',
                                        values='_value',
                                        aggfunc='first'  # å–ç¬¬ä¸€ä¸ªéç©ºå€¼
                                    ).reset_index()
                                    
                                    # ğŸ”§ ä¸ºç©ºæ¦‚å¿µæ·»åŠ NaNåˆ—
                                    for empty_concept in empty_concepts:
                                        if empty_concept not in merged_df.columns:
                                            merged_df[empty_concept] = np.nan
                                else:
                                    # åªæœ‰é™æ€æ¦‚å¿µï¼Œåˆ›å»ºåŸºç¡€æ¡†æ¶
                                    merged_df = None
                                
                                # ğŸ”§ åˆå¹¶é™æ€æ¦‚å¿µ
                                if static_dfs:
                                    # åˆå¹¶æ‰€æœ‰é™æ€æ¦‚å¿µä¸ºä¸€ä¸ªå®½è¡¨
                                    from functools import reduce
                                    static_merged = reduce(
                                        lambda left, right: pd.merge(left, right, on=id_col, how='outer'),
                                        static_dfs
                                    )
                                    
                                    if merged_df is not None and id_col in merged_df.columns:
                                        # å°†é™æ€æ¦‚å¿µmergeåˆ°æ—¶é—´åºåˆ—æ•°æ®ä¸Š
                                        merged_df = pd.merge(merged_df, static_merged, on=id_col, how='left')
                                    else:
                                        # åªæœ‰é™æ€æ•°æ®
                                        merged_df = static_merged
                                        
                        except Exception as fast_path_error:
                            # print(f"Fast path failed: {fast_path_error}, falling back...")
                            use_fast_path = False
                    
                    if not use_fast_path:
                        # ğŸ”§ æ ‡å‡†è·¯å¾„ï¼šreduce + mergeï¼ˆä½†é™åˆ¶æœ€å¤§æ¦‚å¿µæ•°é¿å…è¿‡æ…¢ï¼‰
                        if len(all_concept_dfs) > 10:
                            # è¶…è¿‡10ä¸ªæ¦‚å¿µï¼Œåˆ†æ‰¹mergeå†åˆå¹¶
                            batch_size = 5
                            batches = []
                            for i in range(0, len(all_concept_dfs), batch_size):
                                batch = all_concept_dfs[i:i+batch_size]
                                from functools import reduce
                                try:
                                    batch_merged = reduce(
                                        lambda left, right: pd.merge(left, right, on=merge_cols, how='outer'),
                                        batch
                                    )
                                    # æ¯ä¸€æ‰¹åˆå¹¶åä¹Ÿå»é‡ï¼Œå‡å°‘ä¸­é—´æ•°æ®é‡
                                    if len(batch_merged) > 0:
                                        batch_merged = batch_merged.drop_duplicates(subset=merge_cols)
                                    batches.append(batch_merged)
                                except Exception:
                                    # å¦‚æœæŸä¸ªbatchå¤±è´¥ï¼Œè·³è¿‡å®ƒï¼ˆå¾ˆå°‘è§ï¼‰
                                    continue
                            
                            # æœ€ååˆå¹¶å„æ‰¹æ¬¡
                            if not batches:
                                merged_df = None
                            else:
                                merged_df = reduce(
                                    lambda left, right: pd.merge(left, right, on=merge_cols, how='outer'),
                                    batches
                                )
                        else:
                            # æ¦‚å¿µæ•°<=10ï¼Œç›´æ¥reduce
                            from functools import reduce
                            merged_df = reduce(
                                lambda left, right: pd.merge(left, right, on=merge_cols, how='outer'),
                                all_concept_dfs
                            )
                        
                        # æ ‡å‡†è·¯å¾„æœ€åä¹Ÿå»é‡
                        if merged_df is not None and len(merged_df) > 0:
                            merged_df = merged_df.drop_duplicates(subset=merge_cols)
            
            # ğŸ”§ ä¿®å¤ï¼šå³ä½¿merged_dfä¸ºç©ºä¹Ÿè¦å¯¼å‡ºï¼Œä¿ç•™åˆ—ç»“æ„
            if merged_df is None:
                # å¦‚æœå®Œå…¨æ²¡æœ‰æ•°æ®ï¼Œåˆ›å»ºä¸€ä¸ªåªæœ‰merge_colsçš„ç©ºDataFrame
                if merge_cols:
                    merged_df = pd.DataFrame(columns=merge_cols + list(concept_dfs.keys()))
                else:
                    continue
            
            # ç”Ÿæˆæ–‡ä»¶åï¼šæ¨¡å—å_ç‰¹å¾1_ç‰¹å¾2_...[_ç­›é€‰æ¡ä»¶åç¼€]
            concept_names = sorted(list(concept_dfs.keys()))  # ğŸ”§ FIX: æ’åºç¡®ä¿æ–‡ä»¶åä¸€è‡´
            # é™åˆ¶ç‰¹å¾åé•¿åº¦ï¼Œé¿å…æ–‡ä»¶åè¿‡é•¿
            if len(concept_names) <= 5:
                concepts_suffix = '_'.join(concept_names)
            else:
                concepts_suffix = '_'.join(concept_names[:4]) + f'_etc{len(concept_names)}'
            
            # ğŸš€ æ·»åŠ é˜Ÿåˆ—ç­›é€‰æ¡ä»¶åç¼€
            cohort_suffix = _generate_cohort_prefix()
            
            # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
            if cohort_suffix:
                safe_filename = f"{group_name}_{concepts_suffix}_{cohort_suffix}".replace('/', '_').replace('\\', '_')
            else:
                safe_filename = f"{group_name}_{concepts_suffix}".replace('/', '_').replace('\\', '_')
            # é™åˆ¶æ–‡ä»¶åæ€»é•¿åº¦
            if len(safe_filename) > 150:
                safe_filename = safe_filename[:150]
            
            # ç¡®å®šæ–‡ä»¶è·¯å¾„
            if export_format == 'csv':
                file_path = export_dir / f"{safe_filename}.csv"
            elif export_format == 'parquet':
                file_path = export_dir / f"{safe_filename}.parquet"
            elif export_format == 'excel':
                file_path = export_dir / f"{safe_filename}.xlsx"
            else:
                file_path = export_dir / f"{safe_filename}.parquet"
            
            # ğŸ”§ FIX (2026-02-05): è¦†ç›–æ¨¡å¼æ—¶ï¼Œå…ˆåˆ é™¤è¯¥æ¨¡å—çš„æ‰€æœ‰æ—§æ–‡ä»¶
            overwrite_modules = st.session_state.get('_overwrite_modules', set())
            if group_name in overwrite_modules or is_viz_import_mode:
                # åˆ é™¤åŒ¹é…è¯¥æ¨¡å—çš„æ‰€æœ‰æ—§æ–‡ä»¶ï¼ˆæ¨¡å—åå¼€å¤´ï¼‰
                for ext in ['.parquet', '.csv', '.xlsx']:
                    pattern = f"{group_name}_*{ext}"
                    old_files = list(export_dir.glob(pattern))
                    for old_file in old_files:
                        try:
                            old_file.unlink()
                        except Exception:
                            pass
            
            # ğŸ”§ æ£€æŸ¥æ–‡ä»¶æ˜¯å¦éœ€è¦è·³è¿‡ï¼ˆåŸºäºé¢„æ£€æµ‹é˜¶æ®µçš„ç”¨æˆ·é€‰æ‹©ï¼‰
            # æ³¨æ„ï¼šæ¨¡æ‹Ÿæ•°æ®æ¨¡å¼ä¸æ£€æŸ¥å·²å­˜åœ¨æ–‡ä»¶ï¼ˆç›´æ¥è¦†ç›–ï¼‰
            if not use_mock and not is_viz_import_mode and file_path.exists():
                # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²é€‰æ‹©è·³è¿‡æ­¤æ¨¡å—
                if group_name in skipped_modules:
                    skip_msg = f"â­ï¸ Skipped (file exists): `{group_name}`" if lang == 'en' else f"â­ï¸ å·²è·³è¿‡ï¼ˆæ–‡ä»¶å·²å­˜åœ¨ï¼‰: `{group_name}`"
                    st.info(skip_msg)
                    continue
                # å¦‚æœä¸åœ¨ skipped_modules ä¸­ï¼Œè¯´æ˜ç”¨æˆ·é€‰æ‹©äº†è¦†ç›–ï¼Œç›´æ¥ç»§ç»­å¯¼å‡º
            
            # ğŸ†• æ”¶é›†è¿™ä¸ªæ¨¡å—ä¸­çš„æ‚£è€…ID
            if merged_df is not None and len(merged_df) > 0:
                for id_candidate in ['stay_id', 'hadm_id', 'icustay_id', 'patientunitstayid', 'admissionid', 'patientid', 'CaseID']:
                    if id_candidate in merged_df.columns:
                        all_exported_patient_ids.update(merged_df[id_candidate].dropna().unique())
                        break
            
            # å†™å…¥æ–‡ä»¶
            if export_format == 'csv':
                merged_df.to_csv(file_path, index=False, encoding='utf-8-sig')  # ğŸ”§ FIX: ä½¿ç”¨ BOM ç¼–ç é˜²æ­¢ä¸­æ–‡ä¹±ç 
            elif export_format == 'parquet':
                merged_df.to_parquet(file_path, index=False)
            elif export_format == 'excel':
                merged_df.to_excel(file_path, index=False)
            else:
                merged_df.to_parquet(file_path, index=False)
            
            exported_files.append(str(file_path))
            
            # ğŸš€ è®°å½•æ¨¡å—è€—æ—¶
            module_elapsed = time_module.time() - module_start_time
            module_times[group_name] = module_elapsed
            
            # æ›´æ–°å¯¼å‡ºè¿›åº¦ï¼ˆä»50%åˆ°100%ï¼‰
            if use_mock:
                progress_bar.progress(0.3 + 0.7 * (idx + 1) / total_groups)
            else:
                progress_bar.progress(0.5 + 0.5 * (idx + 1) / total_groups)
        
        # å®Œæˆ
        progress_bar.progress(1.0)
        status_text.empty()
        cancel_placeholder.empty()  # ğŸ”§ æ¸…ç†å–æ¶ˆæŒ‰é’®
        
        # ğŸ”§ æ¸…ç†ä¸´æ—¶çŠ¶æ€
        if '_skipped_modules' in st.session_state:
            del st.session_state['_skipped_modules']
        if '_overwrite_modules' in st.session_state:
            del st.session_state['_overwrite_modules']
        if '_export_cancelled' in st.session_state:
            del st.session_state['_export_cancelled']
        
        if exported_files:
            st.session_state.export_completed = True
            st.session_state.trigger_export = False  # ğŸ”§ FIX (2026-02-03): å¯¼å‡ºå®Œæˆåé‡ç½®è§¦å‘çŠ¶æ€
            st.session_state['_exporting_in_progress'] = False  # æ¸…é™¤å¯¼å‡ºè¿›è¡Œä¸­æ ‡è®°
            st.session_state.last_export_dir = str(export_dir)  # ä¿å­˜å®é™…å¯¼å‡ºç›®å½•
            st.session_state.last_export_full_dir = str(export_dir)  # ä¿å­˜å®Œæ•´è·¯å¾„ï¼ˆå«cohortå­ç›®å½•ï¼‰
            st.session_state.viz_export_path = str(export_dir)  # æ›´æ–°viz_export_path
            # ğŸ”§ FIX: æ›´æ–°å¿«é€Ÿå¯è§†åŒ–çš„ç¡®è®¤è·¯å¾„ï¼Œè¿™æ ·åˆ‡æ¢åˆ°å¯è§†åŒ–é¡µé¢æ—¶ä¼šè‡ªåŠ¨å¡«å……
            st.session_state.viz_confirmed_path = str(export_dir)
            # ğŸ”§ FIX: å¼ºåˆ¶é‡ç½® text_input çš„ç‰ˆæœ¬å·ï¼Œç¡®ä¿æ˜¾ç¤ºæ–°è·¯å¾„
            if '_viz_export_path_version' not in st.session_state:
                st.session_state._viz_export_path_version = 0
            st.session_state._viz_export_path_version += 1
            
            # ğŸ†• ä¿å­˜å®é™…å¯¼å‡ºçš„æ‚£è€…æ•°é‡ï¼ˆä»æ•°æ®ä¸­ç»Ÿè®¡ï¼Œæ˜¯ cohort filter åçš„çœŸå®æ•°é‡ï¼‰
            actual_patient_count = len(all_exported_patient_ids)
            st.session_state['_exported_patient_count'] = actual_patient_count
            
            # ğŸ”§ FIX (2026-02-12): ç»Ÿè®¡å®é™…å¯¼å‡ºçš„æ¦‚å¿µæ•°é‡
            # éå†å¯¼å‡ºçš„ parquet æ–‡ä»¶ï¼Œæ”¶é›†æ‰€æœ‰åˆ—åï¼Œç„¶åè§„èŒƒåŒ–å»é‡
            # è¿™ä¸ load_from_exported() çš„ç»Ÿè®¡æ–¹å¼å®Œå…¨ä¸€è‡´
            all_exported_columns = set()
            id_cols_set = {'stay_id', 'hadm_id', 'icustay_id', 'patientunitstayid', 'admissionid', 'patientid'}
            time_cols_set = {'time', 'charttime', 'starttime', 'endtime', 'datetime', 'timestamp', 'index'}
            meta_cols_set = {'_concept'}
            exclude_cols_set = id_cols_set | time_cols_set | meta_cols_set
            
            for file_path in exported_files:
                try:
                    if file_path.endswith('.parquet'):
                        temp_df = pd.read_parquet(file_path)
                    elif file_path.endswith('.csv'):
                        # åªè¯»å–åˆ—åï¼Œä¸è¯»å–å…¨éƒ¨æ•°æ®
                        temp_df = pd.read_csv(file_path, nrows=0)
                    else:
                        continue
                    for col in temp_df.columns:
                        if col not in exclude_cols_set:
                            # è§„èŒƒåŒ–åˆ—å
                            norm_col = normalize_column_name(col)
                            all_exported_columns.add(norm_col)
                except Exception:
                    pass  # å¿½ç•¥è¯»å–é”™è¯¯çš„æ–‡ä»¶
            
            exported_concept_count = len(all_exported_columns)
            
            # ğŸ”§ DEBUG: æ‰“å°å®é™…æ”¶é›†åˆ°çš„æ‚£è€…æ•°é‡å’Œæ¦‚å¿µæ•°é‡
            print(f"[DEBUG] Exported patient count: {actual_patient_count}, concept count: {exported_concept_count}")
            
            # ğŸ†• è®¡ç®—è¢«é€‰æ‹©ä½†æœªèƒ½æå–çš„æ¦‚å¿µåˆ—è¡¨
            # è¿™ä¸æ˜¯é”™è¯¯ï¼Œåªæ˜¯ä¸€äº›æ¦‚å¿µåœ¨å½“å‰æ•°æ®åº“ä¸­ä¸å¯ç”¨
            selected_but_not_exported = []
            selected_concepts_set = set(selected_concepts) if selected_concepts else set()
            for c in selected_concepts_set:
                # å¦‚æœæ¦‚å¿µä¸åœ¨æˆåŠŸå¯¼å‡ºçš„åˆ—ä¸­ï¼Œåˆ™æ·»åŠ åˆ°æœªæå–åˆ—è¡¨
                norm_c = normalize_column_name(c)
                if norm_c not in all_exported_columns:
                    selected_but_not_exported.append(c)
            
            # ğŸ†• ä¿å­˜å¯¼å‡ºç»“æœåˆ° session stateï¼Œrerun ååœ¨ Guide: Complete ä¸­æ˜¾ç¤º
            total_elapsed = time_module.time() - export_start_time
            st.session_state['_export_success_result'] = {
                'files': exported_files,
                'export_dir': str(export_dir),
                'total_time': total_elapsed,
                'module_times': module_times.copy(),
                'patient_count': actual_patient_count,  # ğŸ†• ä¿å­˜å®é™…æ‚£è€…æ•°
                'concept_count': exported_concept_count,  # ğŸ†• ä¿å­˜å®é™…æ¦‚å¿µæ•°
                'unavailable_concepts': selected_but_not_exported,  # ğŸ†• è¢«é€‰æ‹©ä½†æœªèƒ½æå–çš„æ¦‚å¿µ
            }
            st.rerun()  # ğŸ†• ç«‹å³åˆ·æ–°é¡µé¢ï¼Œè®© Step 4 å˜ä¸º DONE
        else:
            st.session_state['_exporting_in_progress'] = False  # ğŸ†• æ¸…é™¤å¯¼å‡ºè¿›è¡Œä¸­æ ‡è®°
            no_data_msg = "âš ï¸ No data was exported" if lang == 'en' else "âš ï¸ æ²¡æœ‰æ•°æ®è¢«å¯¼å‡º"
            st.warning(no_data_msg)
                
    except Exception as e:
        st.session_state['_exporting_in_progress'] = False  # ğŸ†• æ¸…é™¤å¯¼å‡ºè¿›è¡Œä¸­æ ‡è®°
        fail_msg = f"âŒ Export failed: {e}" if lang == 'en' else f"âŒ å¯¼å‡ºå¤±è´¥: {e}"
        st.error(fail_msg)


def render_export_page():
    """æ¸²æŸ“æ•°æ®å¯¼å‡ºé¡µé¢ã€‚"""
    lang = st.session_state.get('language', 'en')
    export_title = "ğŸ’¾ Data Export" if lang == 'en' else "ğŸ’¾ æ•°æ®å¯¼å‡º"
    st.markdown(f"## {export_title}")
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    if len(st.session_state.loaded_concepts) == 0:
        if lang == 'en':
            st.markdown('''
            <div class="info-box">
                <strong>ğŸ‘ˆ Please load data from the sidebar first</strong><br>
                ğŸ’¡ Tip: Select "Demo Mode" to quickly explore all features
            </div>
            ''', unsafe_allow_html=True)
        else:
            st.markdown('''
            <div class="info-box">
                <strong>ğŸ‘ˆ è¯·å…ˆåœ¨ä¾§è¾¹æ åŠ è½½æ•°æ®</strong><br>
                ğŸ’¡ æç¤ºï¼šå‹¾é€‰ã€Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ã€å¯å¿«é€Ÿä½“éªŒæ‰€æœ‰åŠŸèƒ½
            </div>
            ''', unsafe_allow_html=True)
        return
    
    # å¿«é€Ÿå¯¼å‡ºé¢æ¿
    quick_title = "âš¡ Quick Export" if lang == 'en' else "âš¡ å¿«é€Ÿå¯¼å‡º"
    st.markdown(f"### {quick_title}")
    quick_cols = st.columns(4)
    
    import io
    from datetime import datetime
    
    with quick_cols[0]:
        # ä¸€é”®å¯¼å‡ºæ‰€æœ‰CSV
        df_list = [df.assign(concept=name) for name, df in st.session_state.loaded_concepts.items() 
                   if isinstance(df, pd.DataFrame) and len(df) > 0]
        if df_list:
            all_data = pd.concat(df_list, ignore_index=True)
            csv_all = all_data.to_csv(index=False, encoding='utf-8-sig')  # ğŸ”§ FIX: æ·»åŠ  BOM ç¼–ç é˜²æ­¢ä¸­æ–‡ä¹±ç 
            all_csv_label = "ğŸ“„ All CSV" if lang == 'en' else "ğŸ“„ å…¨éƒ¨CSV"
            all_csv_help = "Export all data as CSV" if lang == 'en' else "ä¸€é”®å¯¼å‡ºæ‰€æœ‰æ•°æ®ä¸ºCSV"
            st.download_button(
                label=all_csv_label,
                data=csv_all,
                file_name=f"easyicu_all_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                width="stretch",
                help=all_csv_help
            )
        else:
            no_data_label = "ğŸ“„ No Data" if lang == 'en' else "ğŸ“„ æ— æ•°æ®"
            st.button(no_data_label, disabled=True, width="stretch")
    
    with quick_cols[1]:
        # å½“å‰é€‰ä¸­æ‚£è€…
        if st.session_state.get('selected_patient'):
            patient_id = st.session_state.selected_patient
            patient_data = {}
            for name, df in st.session_state.loaded_concepts.items():
                if isinstance(df, pd.DataFrame) and st.session_state.id_col in df.columns:
                    patient_df = df[df[st.session_state.id_col] == patient_id]
                    if len(patient_df) > 0:
                        patient_data[name] = patient_df
            
            if patient_data:
                patient_combined = pd.concat(
                    [df.assign(concept=name) for name, df in patient_data.items()],
                    ignore_index=True
                )
                patient_csv = patient_combined.to_csv(index=False, encoding='utf-8-sig')  # ğŸ”§ FIX: BOMç¼–ç 
                st.download_button(
                    label=f"ğŸ‘¤ æ‚£è€…{patient_id}",
                    data=patient_csv,
                    file_name=f"patient_{patient_id}_{datetime.now().strftime('%H%M%S')}.csv",
                    mime="text/csv",
                    width="stretch",
                    help=f"Export all data for patient {patient_id}" if lang == 'en' else f"å¯¼å‡ºæ‚£è€… {patient_id} çš„æ‰€æœ‰æ•°æ®"
                )
            else:
                no_pat = "ğŸ‘¤ No Patient" if lang == 'en' else "ğŸ‘¤ æ— æ‚£è€…"
                st.button(no_pat, disabled=True, width="stretch")
        else:
            no_sel = "ğŸ‘¤ No Selection" if lang == 'en' else "ğŸ‘¤ æœªé€‰æ‚£è€…"
            no_sel_help = "Please select a patient in Patient View first" if lang == 'en' else "è¯·å…ˆåœ¨æ‚£è€…è§†å›¾ä¸­é€‰æ‹©ä¸€ä½æ‚£è€…"
            st.button(no_sel, disabled=True, width="stretch", help=no_sel_help)
    
    with quick_cols[2]:
        # ç”Ÿå‘½ä½“å¾å¿«é€Ÿå¯¼å‡º
        vitals = ['hr', 'map', 'sbp', 'resp', 'spo2', 'temp']
        vitals_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                      if k in vitals and isinstance(v, pd.DataFrame) and len(v) > 0}
        if vitals_data:
            vitals_combined = pd.concat(
                [df.assign(concept=name) for name, df in vitals_data.items()],
                ignore_index=True
            )
            vitals_csv = vitals_combined.to_csv(index=False, encoding='utf-8-sig')  # ğŸ”§ FIX: BOMç¼–ç 
            vitals_label = "ğŸ’“ Vitals" if lang == 'en' else "ğŸ’“ ç”Ÿå‘½ä½“å¾"
            vitals_help = "Export all vital signs data" if lang == 'en' else "å¯¼å‡ºæ‰€æœ‰ç”Ÿå‘½ä½“å¾æ•°æ®"
            st.download_button(
                label=vitals_label,
                data=vitals_csv,
                file_name=f"vitals_{datetime.now().strftime('%H%M%S')}.csv",
                mime="text/csv",
                width="stretch",
                help=vitals_help
            )
        else:
            no_vitals = "ğŸ’“ No Vitals" if lang == 'en' else "ğŸ’“ æ— ä½“å¾æ•°æ®"
            st.button(no_vitals, disabled=True, width="stretch")
    
    with quick_cols[3]:
        # å®éªŒå®¤æ•°æ®å¿«é€Ÿå¯¼å‡º
        labs = ['bili', 'crea', 'plt', 'lac', 'wbc', 'hgb']
        labs_data = {k: v for k, v in st.session_state.loaded_concepts.items() 
                    if k in labs and isinstance(v, pd.DataFrame) and len(v) > 0}
        if labs_data:
            labs_combined = pd.concat(
                [df.assign(concept=name) for name, df in labs_data.items()],
                ignore_index=True
            )
            labs_csv = labs_combined.to_csv(index=False, encoding='utf-8-sig')  # ğŸ”§ FIX: BOMç¼–ç 
            labs_label = "ğŸ§ª Labs" if lang == 'en' else "ğŸ§ª å®éªŒå®¤"
            labs_help = "Export all laboratory data" if lang == 'en' else "å¯¼å‡ºæ‰€æœ‰å®éªŒå®¤æ•°æ®"
            st.download_button(
                label=labs_label,
                data=labs_csv,
                file_name=f"labs_{datetime.now().strftime('%H%M%S')}.csv",
                mime="text/csv",
                width="stretch",
                help=labs_help
            )
        else:
            no_labs = "ğŸ§ª No Labs Data" if lang == 'en' else "ğŸ§ª æ— å®éªŒå®¤æ•°æ®"
            st.button(no_labs, disabled=True, width="stretch")
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # å¯¼å‡ºé…ç½®é¢æ¿
    custom_title = "### ğŸ›ï¸ Custom Export" if lang == 'en' else "### ğŸ›ï¸ è‡ªå®šä¹‰å¯¼å‡º"
    st.markdown(custom_title)
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        concepts_label = "ğŸ“‹ Select Concepts" if lang == 'en' else "ğŸ“‹ é€‰æ‹© Concepts"
        concepts_help = "Select data types to export" if lang == 'en' else "é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®ç±»å‹"
        concepts_to_export = st.multiselect(
            concepts_label,
            options=list(st.session_state.loaded_concepts.keys()),
            default=list(st.session_state.loaded_concepts.keys()),
            help=concepts_help
        )
    
    with col2:
        format_label = "ğŸ“ Export Format" if lang == 'en' else "ğŸ“ å¯¼å‡ºæ ¼å¼"
        format_help = "CSV: Universal format\nExcel: Multi-sheet support\nParquet: Efficient storage" if lang == 'en' else "CSV: é€šç”¨æ ¼å¼\nExcel: æ”¯æŒå¤šSheet\nParquet: é«˜æ•ˆå­˜å‚¨"
        export_format = st.selectbox(
            format_label,
            options=['CSV', 'Excel', 'Parquet'],
            help=format_help
        )
        
        format_icons = {'CSV': 'ğŸ“„', 'Excel': 'ğŸ“Š', 'Parquet': 'âš¡'}
        selected_text = "Selected" if lang == 'en' else "å·²é€‰æ‹©"
        st.markdown(f"<small>{format_icons.get(export_format, '')} {selected_text} {export_format}</small>", unsafe_allow_html=True)
    
    with col3:
        merge_label = "ğŸ“¦ Merge Mode" if lang == 'en' else "ğŸ“¦ åˆå¹¶æ¨¡å¼"
        merge_options = ['Separate Files', 'Merge Into One'] if lang == 'en' else ['åˆ†å¼€ä¿å­˜', 'åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶']
        merge_help = "Separate: One file per Concept\nMerge: All data in one file" if lang == 'en' else "åˆ†å¼€: æ¯ä¸ªConceptä¸€ä¸ªæ–‡ä»¶\nåˆå¹¶: æ‰€æœ‰æ•°æ®åˆå¹¶"
        merge_mode = st.selectbox(
            merge_label,
            options=merge_options,
            help=merge_help
        )
    
    # é«˜çº§é€‰é¡¹
    adv_label = "âš™ï¸ Advanced Options" if lang == 'en' else "âš™ï¸ é«˜çº§é€‰é¡¹"
    with st.expander(adv_label, expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            filter_label = "Filter by Patient" if lang == 'en' else "æŒ‰æ‚£è€…è¿‡æ»¤"
            filter_patient = st.checkbox(filter_label, value=False)
            if filter_patient and st.session_state.patient_ids:
                select_patients_label = "Select Patients" if lang == 'en' else "é€‰æ‹©æ‚£è€…"
                selected_patients = st.multiselect(
                    select_patients_label,
                    options=st.session_state.patient_ids[:100],
                    default=st.session_state.patient_ids[:5]
                )
            else:
                selected_patients = None
        
        with col2:
            index_label = "Include Row Index" if lang == 'en' else "åŒ…å«è¡Œç´¢å¼•"
            include_index = st.checkbox(index_label, value=False)
            timestamp_label = "Add Timestamp to Filename" if lang == 'en' else "æ–‡ä»¶åæ·»åŠ æ—¶é—´æˆ³"
            add_timestamp = st.checkbox(timestamp_label, value=True)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # å¯¼å‡ºé¢„è§ˆ
    preview_title = "### ğŸ“‹ Export Preview" if lang == 'en' else "### ğŸ“‹ å¯¼å‡ºé¢„è§ˆ"
    st.markdown(preview_title)
    
    preview_data = {}
    total_rows = 0
    total_cols = 0
    
    for name in concepts_to_export:
        df = st.session_state.loaded_concepts[name]
        
        # ç¡®ä¿æ˜¯ DataFrame
        if not isinstance(df, pd.DataFrame):
            continue
        
        if selected_patients and st.session_state.id_col in df.columns:
            df = df[df[st.session_state.id_col].isin(selected_patients)]
        
        preview_data[name] = df
        total_rows += len(df)
        total_cols = max(total_cols, len(df.columns))
    
    # é¢„è§ˆç»Ÿè®¡å¡ç‰‡
    col1, col2, col3, col4 = st.columns(4)
    
    total_records_label = "Total Records" if lang == 'en' else "æ€»è®°å½•æ•°"
    est_size_label = "Est. Size" if lang == 'en' else "é¢„ä¼°å¤§å°"
    format_label_2 = "Format" if lang == 'en' else "æ ¼å¼"
    
    with col1:
        st.markdown(f'''
        <div class="metric-card" style="text-align:center">
            <div class="stat-label">Concepts</div>
            <div class="stat-number">{len(concepts_to_export)}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col2:
        st.markdown(f'''
        <div class="metric-card" style="text-align:center">
            <div class="stat-label">{total_records_label}</div>
            <div class="stat-number">{total_rows:,}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col3:
        # ä¼°ç®—æ–‡ä»¶å¤§å°
        est_size = total_rows * total_cols * 10 / 1024  # ç²—ç•¥ä¼°ç®— KB
        size_str = f"{est_size:.0f} KB" if est_size < 1024 else f"{est_size/1024:.1f} MB"
        st.markdown(f'''
        <div class="metric-card" style="text-align:center">
            <div class="stat-label">{est_size_label}</div>
            <div class="stat-number" style="font-size:1.5rem">{size_str}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    with col4:
        st.markdown(f'''
        <div class="metric-card" style="text-align:center">
            <div class="stat-label">{format_label_2}</div>
            <div class="stat-number" style="font-size:1.5rem">{export_format}</div>
        </div>
        ''', unsafe_allow_html=True)
    
    # æ•°æ®é¢„è§ˆè¡¨æ ¼
    if concepts_to_export:
        preview_exp_label = "ğŸ‘ï¸ Preview Data" if lang == 'en' else "ğŸ‘ï¸ é¢„è§ˆæ•°æ®"
        with st.expander(preview_exp_label, expanded=False):
            select_preview_label = "Select Preview" if lang == 'en' else "é€‰æ‹©é¢„è§ˆ"
            preview_concept = st.selectbox(select_preview_label, concepts_to_export)
            if preview_concept in preview_data:
                st.dataframe(preview_data[preview_concept].head(20), width="stretch", hide_index=True)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # å¯¼å‡ºæŒ‰é’®
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        export_btn_label = "ğŸ“¥ Export Data" if lang == 'en' else "ğŸ“¥ å¯¼å‡ºæ•°æ®"
        spinner_text = "Preparing export..." if lang == 'en' else "æ­£åœ¨å‡†å¤‡å¯¼å‡º..."
        merge_single = "Merge Into One" if lang == 'en' else "åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶"
        
        if st.button(export_btn_label, type="primary", width="stretch"):
            with st.spinner(spinner_text):
                import io
                from datetime import datetime
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") if add_timestamp else ""
                
                try:
                    filename_base = f"easyicu_export_{timestamp}" if timestamp else "easyicu_export"
                    
                    if export_format == 'CSV':
                        if merge_mode == merge_single:
                            combined = pd.concat(
                                [df.assign(concept=name) for name, df in preview_data.items()],
                                ignore_index=True
                            )
                            csv = combined.to_csv(index=include_index, encoding='utf-8-sig')  # ğŸ”§ FIX: BOMç¼–ç é˜²æ­¢ä¸­æ–‡ä¹±ç 
                            dl_csv = "â¬‡ï¸ Download CSV" if lang == 'en' else "â¬‡ï¸ ä¸‹è½½ CSV"
                            st.download_button(
                                label=dl_csv,
                                data=csv,
                                file_name=f"{filename_base}.csv",
                                mime="text/csv",
                            )
                        else:
                            # åˆ†å¼€ä¿å­˜ - åˆ›å»º ZIP
                            import zipfile
                            zip_buffer = io.BytesIO()
                            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                                for name, df in preview_data.items():
                                    csv_data = df.to_csv(index=include_index, encoding='utf-8-sig')  # ğŸ”§ FIX: BOMç¼–ç 
                                    zf.writestr(f"{name}.csv", csv_data)
                            
                            dl_zip = "â¬‡ï¸ Download ZIP (Multiple CSVs)" if lang == 'en' else "â¬‡ï¸ ä¸‹è½½ ZIP (å¤šä¸ªCSV)"
                            st.download_button(
                                label=dl_zip,
                                data=zip_buffer.getvalue(),
                                file_name=f"{filename_base}.zip",
                                mime="application/zip",
                            )
                    
                    elif export_format == 'Excel':
                        output = io.BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            if merge_mode == merge_single:
                                combined = pd.concat(
                                    [df.assign(concept=name) for name, df in preview_data.items()],
                                    ignore_index=True
                                )
                                combined.to_excel(writer, sheet_name='all_data', index=include_index)
                            else:
                                for name, df in preview_data.items():
                                    sheet_name = name[:31]  # Excel sheet name limit
                                    df.to_excel(writer, sheet_name=sheet_name, index=include_index)
                        
                        dl_excel = "â¬‡ï¸ Download Excel" if lang == 'en' else "â¬‡ï¸ ä¸‹è½½ Excel"
                        st.download_button(
                            label=dl_excel,
                            data=output.getvalue(),
                            file_name=f"{filename_base}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        )
                    
                    elif export_format == 'Parquet':
                        combined = pd.concat(
                            [df.assign(concept=name) for name, df in preview_data.items()],
                            ignore_index=True
                        )
                        output = io.BytesIO()
                        combined.to_parquet(output, index=include_index)
                        dl_parquet = "â¬‡ï¸ Download Parquet" if lang == 'en' else "â¬‡ï¸ ä¸‹è½½ Parquet"
                        st.download_button(
                            label=dl_parquet,
                            data=output.getvalue(),
                            file_name=f"{filename_base}.parquet",
                            mime="application/octet-stream",
                        )
                    
                    success_msg = "âœ… Export ready! Click the button above to download" if lang == 'en' else "âœ… å¯¼å‡ºå‡†å¤‡å®Œæˆï¼ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ä¸‹è½½"
                    st.markdown(f'''
                    <div class="success-box">
                        {success_msg}
                    </div>
                    ''', unsafe_allow_html=True)
                    
                except Exception as e:
                    err_msg = f"âŒ Export failed: {e}" if lang == 'en' else f"âŒ å¯¼å‡ºå¤±è´¥: {e}"
                    st.error(err_msg)


def main():
    """ä¸»å‡½æ•°ã€‚"""
    init_session_state()
    
    # è·å–å…¥å£æ¨¡å¼
    entry_mode = st.session_state.get('entry_mode', 'none')
    
    # ============ å…¥å£é¡µé¢ï¼šé€‰æ‹©Demoæˆ–Real Dataæ¨¡å¼ ============
    if entry_mode == 'none':
        render_entry_page()
        return
    
    # ============ è¿›å…¥å…·ä½“æ¨¡å¼åï¼Œæ˜¾ç¤ºå®Œæ•´åº”ç”¨ ============
    render_sidebar()
    
    # å¤„ç†CSVè½¬æ¢å¯¹è¯æ¡†
    if st.session_state.get('show_convert_dialog', False):
        render_convert_dialog()
    
    # ğŸ”§ å¯¼å‡ºè¿›åº¦åŒºåŸŸï¼šä¼˜å…ˆä½¿ç”¨ Guide: Complete ä¸­åˆ›å»ºçš„å®¹å™¨ï¼Œå¦åˆ™åˆ›å»ºå¤‡ç”¨å®¹å™¨
    # ï¼ˆå®é™…å¯¼å‡ºåœ¨æ¸²æŸ“ Home é¡µé¢åæ‰§è¡Œï¼Œç¡®ä¿ container å·²åˆ›å»ºï¼‰
    default_export_container = st.container()
    
    # ============ é¡¶éƒ¨æ ‡é¢˜ï¼ˆæ”¾åœ¨å¯¼èˆªæ ä¸Šæ–¹ï¼‰ ============
    lang = st.session_state.get('language', 'en')
    
    # æ ¹æ®æ¨¡å¼æ˜¾ç¤ºä¸åŒæ ‡é¢˜
    if entry_mode == 'demo':
        mode_indicator = " (Demo)" if lang == 'en' else " (æ¼”ç¤º)"
    else:
        mode_indicator = ""
    
    if lang == 'en':
        st.markdown(f'<div class="main-header">ğŸ¥ EasyICU Data Explorer{mode_indicator}</div>', unsafe_allow_html=True)
        st.markdown('<div class="sub-header">Local ICU Data Analytics Platform</div>', unsafe_allow_html=True)
    else:
        st.markdown(f'<div class="main-header">ğŸ¥ EasyICU æ•°æ®æ¢ç´¢å™¨{mode_indicator}</div>', unsafe_allow_html=True)
        st.markdown('<div class="sub-header">æœ¬åœ° ICU æ•°æ®åˆ†æä¸å¯è§†åŒ–å¹³å°</div>', unsafe_allow_html=True)
    
    # ä¸»é¡µé¢æ ‡ç­¾ï¼šTutorial, Quick Visualization, Cohort Analysis
    tab1, tab2, tab3 = st.tabs([
        get_text('home'),
        get_text('quick_visualization'),
        get_text('cohort_compare'),
    ])
    
    with tab1:
        render_home()
    
    with tab2:
        render_quick_visualization_page()
    
    with tab3:
        render_cohort_comparison_page()
    
    # ğŸ”§ å¤„ç†ä¾§è¾¹æ è§¦å‘çš„å¯¼å‡ºï¼ˆåœ¨æ ‡ç­¾é¡µæ¸²æŸ“åæ‰§è¡Œï¼Œç¡®ä¿ Guide: Complete ä¸­çš„ container å·²åˆ›å»ºï¼‰
    if st.session_state.get('trigger_export', False):
        st.session_state.trigger_export = False
        # ğŸ”§ FIX: æ·»åŠ  try-except é˜²æ­¢ç™½å±å´©æºƒ
        try:
            # ğŸ”§ FIX: æ£€æŸ¥æ˜¯å¦æœ‰å·²åŠ è½½çš„å¯è§†åŒ–æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰é€‰æ‹©æ¦‚å¿µåˆ™æ˜¾ç¤ºè­¦å‘Šä½†ä¸é˜»æ­¢å¯¼å‡º
            if len(st.session_state.get('loaded_concepts', {})) > 0:
                if not st.session_state.get('selected_concepts'):
                    lang = st.session_state.get('language', 'en')
                    loaded_concepts = list(st.session_state.loaded_concepts.keys())
                    warn_msg = f"âš ï¸ No concepts selected. Please select features in sidebar first." if lang == 'en' else f"âš ï¸ æœªé€‰æ‹©ç‰¹å¾ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ é€‰æ‹©è¦å¯¼å‡ºçš„ç‰¹å¾ã€‚"
                    st.warning(warn_msg)
                    st.session_state['_exporting_in_progress'] = False
                    # ğŸ”§ FIX: ä¸å† returnï¼Œè®©ç”¨æˆ·çœ‹åˆ°è­¦å‘Šä½†ä¸ç»§ç»­æ‰§è¡Œå¯¼å‡º
                    pass  # ä»…æ˜¾ç¤ºè­¦å‘Šï¼Œä¸‹é¢ä¼šå› ä¸º selected_concepts ä¸ºç©ºè€Œè·³è¿‡å¯¼å‡º
                else:
                    # ğŸ”§ FIX: æœ‰é€‰æ‹©çš„æ¦‚å¿µï¼Œæ‰§è¡Œå¯¼å‡º
                    pass
            
            # ğŸ”§ FIX: ä½¿ç”¨ JavaScript åˆ‡æ¢åˆ° Tutorial æ ‡ç­¾é¡µï¼ˆç¬¬1ä¸ªæ ‡ç­¾ï¼‰ä»¥æ˜¾ç¤ºå¯¼å‡ºè¿›åº¦
            js_switch_to_tutorial = '''
            <script>
                (function() {
                    // æ»šåŠ¨åˆ°é¡µé¢é¡¶éƒ¨
                    var mainContainer = window.parent.document.querySelector('section.main');
                    if (mainContainer) mainContainer.scrollTop = 0;
                    window.parent.document.documentElement.scrollTop = 0;
                    window.parent.document.body.scrollTop = 0;
                    
                    // ç‚¹å‡»ç¬¬ä¸€ä¸ªæ ‡ç­¾é¡µ (Tutorial)
                    setTimeout(function() {
                        var tabs = window.parent.document.querySelectorAll('button[data-baseweb="tab"]');
                        if (tabs && tabs.length >= 1) {
                            tabs[0].click();
                        }
                    }, 100);
                })();
            </script>
            '''
            st.components.v1.html(js_switch_to_tutorial, height=0)
            
            # ğŸ”§ FIX (2026-02-03): å¦‚æœæœ‰ loaded_concepts ä½†æ²¡æœ‰ selected_conceptsï¼Œ
            # è‡ªåŠ¨ä½¿ç”¨ loaded_concepts çš„ keys
            if not st.session_state.get('selected_concepts'):
                loaded_concepts = st.session_state.get('loaded_concepts', {})
                if loaded_concepts:
                    st.session_state.selected_concepts = list(loaded_concepts.keys())
                    print(f"[DEBUG] main(): Auto-set selected_concepts from loaded_concepts: {len(st.session_state.selected_concepts)} concepts")
            
            # ğŸ”§ åªæœ‰åœ¨æœ‰é€‰æ‹©çš„æ¦‚å¿µæ—¶æ‰æ‰§è¡Œå¯¼å‡º
            if st.session_state.get('selected_concepts'):
                # ä¼˜å…ˆä½¿ç”¨ Guide: Complete ä¸­åˆ›å»ºçš„å®¹å™¨
                export_container = st.session_state.get('_export_progress_container', default_export_container)
                with export_container:
                    execute_sidebar_export()
            else:
                # æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®
                lang = st.session_state.get('language', 'en')
                st.warning("âš ï¸ No data to export. Please load data first." if lang == 'en' else "âš ï¸ æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®ï¼Œè¯·å…ˆåŠ è½½æ•°æ®ã€‚")
                st.session_state['_exporting_in_progress'] = False
        except Exception as e:
            import traceback
            lang = st.session_state.get('language', 'en')
            # ğŸ”§ FIX: æ‰“å°è¯¦ç»†é”™è¯¯å †æ ˆä¾¿äºè°ƒè¯•
            error_detail = traceback.format_exc()
            print(f"[ERROR] Export failed with exception:\n{error_detail}")
            st.session_state['_exporting_in_progress'] = False
            if lang == 'en':
                st.error(f"âŒ Export failed: {e}")
            else:
                st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            st.session_state['_exporting_in_progress'] = False
    
    # ğŸ†• å¤„ç†é¡µé¢è·³è½¬è¯·æ±‚ - åœ¨æ¸²æŸ“å®Œæˆåæ‰§è¡Œ JavaScript
    scroll_to_tab = st.session_state.pop('_scroll_to_tab', None)
    scroll_to_top = st.session_state.pop('_scroll_to_top', None)
    
    if scroll_to_tab == 'viz':
        # è·³è½¬åˆ° Quick Visualization æ ‡ç­¾é¡µï¼ˆç¬¬2ä¸ªæ ‡ç­¾ï¼Œç´¢å¼•1ï¼‰å¹¶æ»šåŠ¨åˆ°é¡¶éƒ¨
        js_code = '''
        <script>
            (function() {
                // æ»šåŠ¨åˆ°é¡µé¢é¡¶éƒ¨
                var mainContainer = window.parent.document.querySelector('section.main');
                if (mainContainer) mainContainer.scrollTop = 0;
                window.parent.document.documentElement.scrollTop = 0;
                window.parent.document.body.scrollTop = 0;
                
                // ç‚¹å‡»ç¬¬äºŒä¸ªæ ‡ç­¾é¡µ
                setTimeout(function() {
                    var tabs = window.parent.document.querySelectorAll('button[data-baseweb="tab"]');
                    if (tabs && tabs.length >= 2) {
                        tabs[1].click();
                        // å†æ¬¡æ»šåŠ¨ç¡®ä¿åœ¨é¡¶éƒ¨
                        setTimeout(function() {
                            var mainContainer = window.parent.document.querySelector('section.main');
                            if (mainContainer) mainContainer.scrollTop = 0;
                            window.parent.document.documentElement.scrollTop = 0;
                        }, 100);
                    }
                }, 200);
            })();
        </script>
        '''
        st.components.v1.html(js_code, height=0)
    elif scroll_to_tab == 'cohort':
        # è·³è½¬åˆ° Cohort Analysis æ ‡ç­¾é¡µï¼ˆç¬¬3ä¸ªæ ‡ç­¾ï¼Œç´¢å¼•2ï¼‰å¹¶æ»šåŠ¨åˆ°é¡¶éƒ¨
        js_code = '''
        <script>
            (function() {
                var mainContainer = window.parent.document.querySelector('section.main');
                if (mainContainer) mainContainer.scrollTop = 0;
                window.parent.document.documentElement.scrollTop = 0;
                window.parent.document.body.scrollTop = 0;
                
                setTimeout(function() {
                    var tabs = window.parent.document.querySelectorAll('button[data-baseweb="tab"]');
                    if (tabs && tabs.length >= 3) {
                        tabs[2].click();
                        setTimeout(function() {
                            var mainContainer = window.parent.document.querySelector('section.main');
                            if (mainContainer) mainContainer.scrollTop = 0;
                            window.parent.document.documentElement.scrollTop = 0;
                        }, 100);
                    }
                }, 200);
            })();
        </script>
        '''
        st.components.v1.html(js_code, height=0)
    elif scroll_to_top:
        # æ»šåŠ¨åˆ°é¡µé¢æœ€é¡¶éƒ¨
        js_code = '''
        <script>
            (function() {
                // å°è¯•å¤šç§æ»šåŠ¨æ–¹å¼ç¡®ä¿ç”Ÿæ•ˆ
                var mainContainer = window.parent.document.querySelector('section.main');
                if (mainContainer) mainContainer.scrollTop = 0;
                window.parent.document.documentElement.scrollTop = 0;
                window.parent.document.body.scrollTop = 0;
                
                // å»¶è¿Ÿå†æ¬¡æ»šåŠ¨ä»¥ç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½åä¹Ÿåœ¨é¡¶éƒ¨
                setTimeout(function() {
                    var mainContainer = window.parent.document.querySelector('section.main');
                    if (mainContainer) mainContainer.scrollTop = 0;
                    window.parent.document.documentElement.scrollTop = 0;
                    window.parent.document.body.scrollTop = 0;
                }, 100);
            })();
        </script>
        '''
        st.components.v1.html(js_code, height=0)
    
    # åº•éƒ¨çŠ¶æ€æ 
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    footer_cols = st.columns([2, 2, 1])
    
    with footer_cols[0]:
        if st.session_state.language == 'en':
            data_status = "âœ… Data Loaded" if len(st.session_state.loaded_concepts) > 0 else "â³ No Data"
            patients_label = "Patients"
        else:
            data_status = "âœ… æ•°æ®å·²åŠ è½½" if len(st.session_state.loaded_concepts) > 0 else "â³ æœªåŠ è½½æ•°æ®"
            patients_label = "æ‚£è€…"
        # ğŸ”§ FIX (2026-02-04): ç»Ÿè®¡å”¯ä¸€æ¦‚å¿µæ•°
        n_concepts = count_unique_concepts(list(st.session_state.loaded_concepts.keys()))
        n_patients = len(st.session_state.patient_ids) if st.session_state.patient_ids else 0
        st.markdown(
            f"<small style='color:#888'>{data_status} | ğŸ“‹ {n_concepts} Concepts | ğŸ‘¥ {n_patients} {patients_label}</small>",
            unsafe_allow_html=True
        )
    
    with footer_cols[1]:
        if st.session_state.get('selected_patient'):
            patient_label = "Current Patient" if st.session_state.language == 'en' else "å½“å‰æ‚£è€…"
            st.markdown(
                f"<small style='color:#888'>ğŸ¯ {patient_label}: {st.session_state.selected_patient}</small>",
                unsafe_allow_html=True
            )
    
    with footer_cols[2]:
        # å¸®åŠ©æŒ‰é’®
        help_btn_text = "â“ Help" if st.session_state.language == 'en' else "â“ å¸®åŠ©"
        with st.popover(help_btn_text):
            if st.session_state.language == 'en':
                st.markdown("""
                ### ğŸš€ Quick Start
                
                **ğŸ“¤ Data Extraction Mode**
                - **Step 1**: Select database & data path
                - **Step 2**: Filter cohort (age, LOS, etc.)
                - **Step 3**: Choose feature groups
                - **Step 4**: Export to CSV/Parquet/Excel
                
                **ğŸ“Š Quick Visualization Mode**
                - Browse exported data folders
                - ğŸ“ˆ **Time Series**: Multi-patient trends
                - ğŸ¥ **Patient View**: Single patient details
                - ğŸ“Š **Data Quality**: Completeness report
                
                **ğŸ”¬ Cohort Analysis Mode**
                - Compare patient subgroups
                - Statistical analysis & hypothesis testing
                
                ---
                
                ğŸ’¡ **Tips**: 
                - Use sidebar tabs to extract features
                - Supports MIMIC-IV, eICU, AUMC, HiRID, MIMIC-III, SICdb
                - You can choose Demo Mode to explore EasyICU with simulated ICU data (no real data required)
                """)
            else:
                st.markdown("""
                ### ğŸš€ å¿«é€Ÿä¸Šæ‰‹
                
                **ğŸ“¤ æ•°æ®æå–æ¨¡å¼**
                - **æ­¥éª¤1**: é€‰æ‹©æ•°æ®åº“å’Œæ•°æ®è·¯å¾„
                - **æ­¥éª¤2**: ç­›é€‰é˜Ÿåˆ—ï¼ˆå¹´é¾„ã€ä½é™¢æ—¶é•¿ç­‰ï¼‰
                - **æ­¥éª¤3**: é€‰æ‹©ç‰¹å¾ç»„
                - **æ­¥éª¤4**: å¯¼å‡ºä¸º CSV/Parquet/Excel
                
                **ğŸ“Š å¿«é€Ÿå¯è§†åŒ–æ¨¡å¼**
                - æµè§ˆå·²å¯¼å‡ºçš„æ•°æ®æ–‡ä»¶å¤¹
                - ğŸ“ˆ **æ—¶åºåˆ†æ**: å¤šæ‚£è€…è¶‹åŠ¿å¯¹æ¯”
                - ğŸ¥ **æ‚£è€…è§†å›¾**: å•æ‚£è€…è¯¦æƒ…
                - ğŸ“Š **æ•°æ®è´¨é‡**: å®Œæ•´æ€§æŠ¥å‘Š
                
                **ğŸ”¬ é˜Ÿåˆ—åˆ†ææ¨¡å¼**
                - æ¯”è¾ƒæ‚£è€…äºšç»„
                - ç»Ÿè®¡åˆ†æä¸å‡è®¾æ£€éªŒ
                
                ---
                
                ğŸ’¡ **æç¤º**: 
                - ä½¿ç”¨ä¾§è¾¹æ æ ‡ç­¾æå–ç‰¹å¾
                - æ”¯æŒ MIMIC-IVã€eICUã€AUMCã€HiRIDã€MIMIC-IIIã€SICdb
                - å¯é€‰æ‹©æ¼”ç¤ºæ¨¡å¼ï¼Œä½¿ç”¨æ¨¡æ‹ŸICUæ•°æ®å¿«é€Ÿä½“éªŒEasyICUï¼ˆæ— éœ€çœŸå®æ•°æ®ï¼‰
                """)


if __name__ == "__main__":
    main()
