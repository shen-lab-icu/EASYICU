"""å¤šæ•°æ®åº“è¿ç»­ç‰¹å¾åˆ†å¸ƒå·®å¼‚å¯è§†åŒ–

ç”Ÿæˆç±»ä¼¼è®ºæ–‡ä¸­çš„å¤šå˜é‡å¯†åº¦åˆ†å¸ƒå¯¹æ¯”å›¾ï¼Œå±•ç¤ºä¸åŒICUæ•°æ®åº“é—´çš„ç‰¹å¾åˆ†å¸ƒå·®å¼‚ã€‚
æ”¯æŒ MIIV, eICU, AUMC, HiRID å››ä¸ªæ•°æ®åº“çš„å¯¹æ¯”ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from scipy import stats
from typing import List, Dict, Optional, Tuple
import json
from pathlib import Path
import os
import warnings
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ICU Database Feature Distribution Comparison",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# æ•°æ®åº“é¢œè‰²é…ç½® - ä¸å‚è€ƒå›¾ä¸€è‡´
DB_COLORS = {
    'aumc': '#1f77b4',      # è“è‰² - Amsterdam
    'eicu': '#ff7f0e',      # æ©™è‰² - eICU
    'miiv': '#2ca02c',      # ç»¿è‰² - MIMIC
    'hirid': '#d62728',     # çº¢è‰² - HiRID
}

DB_LABELS = {
    'aumc': 'Amsterdam (AUMC)',
    'eicu': 'eICU-CRD',
    'miiv': 'MIMIC-IV',
    'hirid': 'HiRID',
}

# ç‰¹å¾åˆ†ç»„å’Œæ˜¾ç¤ºé…ç½®
FEATURE_GROUPS = {
    "Vital Signs": {
        'hr': {'name': 'Heart rate', 'unit': '/min', 'range': (30, 200)},
        'sbp': {'name': 'Invasive systolic arterial pressure', 'unit': 'mmHg', 'range': (40, 220)},
        'dbp': {'name': 'Invasive diastolic arterial pressure', 'unit': 'mmHg', 'range': (20, 140)},
        'map': {'name': 'Invasive mean arterial pressure', 'unit': 'mmHg', 'range': (30, 160)},
        'nbps': {'name': 'Non-invasive systolic arterial pressure', 'unit': 'mmHg', 'range': (60, 220)},
        'nbpd': {'name': 'Non-invasive diastolic arterial pressure', 'unit': 'mmHg', 'range': (20, 140)},
        'nbpm': {'name': 'Non-invasive mean arterial pressure', 'unit': 'mmHg', 'range': (30, 160)},
        'o2sat': {'name': 'Oxygen saturation in Arterial blood', 'unit': '%', 'range': (70, 100)},
        'temp': {'name': 'Core body temperature', 'unit': 'Cel', 'range': (34, 42)},
        'resp': {'name': 'Respiratory rate', 'unit': '/min', 'range': (5, 50)},
    },
    "Respiratory": {
        'tv': {'name': 'Expiratory tidal volume', 'unit': 'mL/kg', 'range': (0, 1000)},
        'pplat': {'name': 'Plateau pressure', 'unit': 'cmH2O', 'range': (0, 50)},
        'vent': {'name': 'Ventilator rate', 'unit': '/min', 'range': (0, 40)},
        'tv_set': {'name': 'Tidal volume setting', 'unit': 'mL/kg', 'range': (200, 800)},
        'fio2': {'name': 'Inspired oxygen concentration', 'unit': '%', 'range': (21, 100)},
        'peep': {'name': 'Positive end expiratory pressure setting', 'unit': 'cmH2O', 'range': (0, 25)},
    },
    "Laboratory - Metabolic": {
        'lact': {'name': 'Lactate [Mass/volume] in Arterial blood', 'unit': 'mg/mL', 'range': (0, 15)},
        'glu': {'name': 'Glucose [Moles/volume] in Serum or Plasma', 'unit': 'mg/dL', 'range': (40, 500)},
        'mg': {'name': 'Magnesium [Moles/volume] in Blood', 'unit': 'mmol/L', 'range': (0.5, 2.0)},
        'na': {'name': 'Sodium [Moles/volume] in Blood', 'unit': 'mmol/L', 'range': (120, 160)},
        'crea': {'name': 'Creatinine [Moles/volume] in Blood', 'unit': 'umol/L', 'range': (20, 500)},
        'ca': {'name': 'Calcium [Moles/volume] in Blood', 'unit': 'umol/L', 'range': (1.5, 3.0)},
        'cl': {'name': 'Chloride [Moles/volume] in Blood', 'unit': '%', 'range': (80, 130)},
        'k': {'name': 'Potassium [Moles/volume] in Blood', 'unit': 'mmol/L', 'range': (2.5, 7.0)},
    },
    "Laboratory - Coagulation": {
        'ptt': {'name': 'aPTT in Blood by Coagulation assay', 'unit': 's', 'range': (15, 150)},
        'bili': {'name': 'Bilirubin.total [Moles/volume] in Serum or Plasma', 'unit': 'umol/L', 'range': (0, 200)},
        'alt': {'name': 'Alanine aminotransferase [Enzymatic activity/volume]', 'unit': 'U/L', 'range': (0, 2500)},
        'ast': {'name': 'Aspartate aminotransferase [Enzymatic activity/volume]', 'unit': 'U/L', 'range': (0, 3500)},
        'alp': {'name': 'Alkaline phosphatase [Enzymatic activity/volume]', 'unit': 'U/L', 'range': (0, 600)},
    },
    "Laboratory - Other": {
        'alb': {'name': 'Albumin [Mass/volume] in Serum or Plasma', 'unit': 'g/L', 'range': (10, 50)},
        'phos': {'name': 'Phosphate [Moles/volume] in Blood', 'unit': 'mg/dL', 'range': (0.5, 3.0)},
        'bicar': {'name': 'Bicarbonate [Moles/volume] in Arterial blood', 'unit': 'mmol/L', 'range': (10, 40)},
        'bun': {'name': 'Urea [Moles/volume] in Venous blood', 'unit': 'mg/dL', 'range': (0, 150)},
    },
    "Blood Gas": {
        'ph': {'name': 'pH of Arterial blood', 'unit': 'pH', 'range': (6.8, 7.8)},
        'po2': {'name': 'Oxygen [Partial pressure] in Arterial blood', 'unit': 'pH', 'range': (30, 400)},
        'pco2': {'name': 'Carbon dioxide [Partial pressure] in Arterial blood', 'unit': 'pH', 'range': (15, 100)},
    },
    "Hematology": {
        'hgb': {'name': 'Hemoglobin [Mass/volume] in Blood', 'unit': 'g/dL', 'range': (5, 18)},
        'wbc': {'name': 'Leukocytes [#/volume] in Blood', 'unit': 'U', 'range': (0, 50)},
        'plt': {'name': 'Platelets [#/volume] in Blood', 'unit': 'U', 'range': (0, 600)},
    },
    "Urine & Consciousness": {
        'urine': {'name': 'Hourly urine volume', 'unit': 'mL/h', 'range': (0, 600)},
        'gcs': {'name': 'Glasgow coma score', 'unit': '', 'range': (3, 15)},
        'egcs': {'name': 'Glasgow Coma Score eye opening subscore', 'unit': '', 'range': (1, 4)},
        'vgcs': {'name': 'Glasgow Coma Score verbal response subscore', 'unit': '', 'range': (1, 5)},
        'mgcs': {'name': 'Glasgow Coma Score motor response subscore', 'unit': '', 'range': (1, 6)},
    },
}


def get_flat_features() -> Dict[str, dict]:
    """è·å–æ‰å¹³åŒ–çš„ç‰¹å¾å­—å…¸"""
    flat = {}
    for group, features in FEATURE_GROUPS.items():
        for code, config in features.items():
            flat[code] = {**config, 'group': group}
    return flat


@st.cache_data(ttl=3600)
def load_feature_data(
    data_path: str,
    concepts: List[str],
    databases: List[str],
    max_patients: int = 1000,
    sample_per_patient: int = 10,
) -> Dict[str, pd.DataFrame]:
    """
    ä»å„æ•°æ®åº“åŠ è½½ç‰¹å¾æ•°æ®
    
    Args:
        data_path: ICUæ•°æ®æ ¹ç›®å½•
        concepts: è¦åŠ è½½çš„æ¦‚å¿µåˆ—è¡¨
        databases: è¦åŠ è½½çš„æ•°æ®åº“åˆ—è¡¨
        max_patients: æ¯ä¸ªæ•°æ®åº“æœ€å¤§æ‚£è€…æ•°
        sample_per_patient: æ¯ä¸ªæ‚£è€…é‡‡æ ·çš„è®°å½•æ•°
    
    Returns:
        å­—å…¸ {database: DataFrame with columns [concept, value]}
    """
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))
    
    from pyricu import load_concepts
    
    result = {}
    
    for db in databases:
        db_path = _get_db_path(data_path, db)
        if not db_path or not os.path.exists(db_path):
            st.warning(f"æ•°æ®åº“ {db} è·¯å¾„ä¸å­˜åœ¨: {db_path}")
            continue
            
        try:
            all_data = []
            for concept in concepts:
                try:
                    df = load_concepts(
                        concepts=[concept],
                        database=db,
                        data_path=db_path,
                        max_patients=max_patients,
                        verbose=False,
                    )
                    
                    if df is not None and not df.empty and concept in df.columns:
                        # é‡‡æ ·ä»¥å‡å°‘æ•°æ®é‡
                        if len(df) > max_patients * sample_per_patient:
                            df = df.sample(n=max_patients * sample_per_patient, random_state=42)
                        
                        values = df[concept].dropna()
                        if len(values) > 0:
                            all_data.append(pd.DataFrame({
                                'concept': concept,
                                'value': values.values
                            }))
                except Exception as e:
                    st.write(f"  âš ï¸ {concept}: {str(e)[:50]}")
                    continue
            
            if all_data:
                result[db] = pd.concat(all_data, ignore_index=True)
                
        except Exception as e:
            st.error(f"åŠ è½½ {db} å¤±è´¥: {e}")
    
    return result


def _get_db_path(base_path: str, db: str) -> str:
    """æ ¹æ®æ•°æ®åº“åè·å–å®Œæ•´è·¯å¾„"""
    db_paths = {
        'miiv': 'mimiciv/3.1',
        'eicu': 'eicu/2.0.1',
        'aumc': 'aumc/1.0.2',
        'hirid': 'hirid/1.1.1',
    }
    return os.path.join(base_path, db_paths.get(db, db))


def compute_kde(
    values: np.ndarray, 
    x_range: Tuple[float, float],
    n_points: int = 200,
) -> Tuple[np.ndarray, np.ndarray]:
    """è®¡ç®—æ ¸å¯†åº¦ä¼°è®¡"""
    if len(values) < 10:
        return np.array([]), np.array([])
    
    # ç§»é™¤å¼‚å¸¸å€¼
    q1, q99 = np.percentile(values, [1, 99])
    values = values[(values >= q1) & (values <= q99)]
    
    if len(values) < 10:
        return np.array([]), np.array([])
    
    try:
        kde = stats.gaussian_kde(values, bw_method='scott')
        x = np.linspace(x_range[0], x_range[1], n_points)
        y = kde(x)
        return x, y
    except Exception:
        return np.array([]), np.array([])


def create_distribution_subplot(
    data: Dict[str, pd.DataFrame],
    concept: str,
    config: dict,
    row: int,
    col: int,
    fig: go.Figure,
    show_legend: bool = False,
) -> None:
    """ä¸ºå•ä¸ªç‰¹å¾åˆ›å»ºåˆ†å¸ƒå­å›¾"""
    
    x_range = config.get('range', (0, 100))
    
    for db, df in data.items():
        concept_data = df[df['concept'] == concept]['value'].values
        if len(concept_data) < 10:
            continue
            
        x, y = compute_kde(concept_data, x_range)
        if len(x) == 0:
            continue
        
        fig.add_trace(
            go.Scatter(
                x=x,
                y=y,
                mode='lines',
                name=DB_LABELS.get(db, db),
                line=dict(color=DB_COLORS.get(db, '#888888'), width=2),
                fill='tozeroy',
                fillcolor=f"rgba{tuple(list(int(DB_COLORS.get(db, '#888888').lstrip('#')[i:i+2], 16) for i in (0, 2, 4)) + [0.3])}",
                showlegend=show_legend,
                legendgroup=db,
            ),
            row=row,
            col=col,
        )
    
    # è®¾ç½®å­å›¾æ ‡é¢˜å’Œè½´æ ‡ç­¾
    fig.update_xaxes(
        title_text=config.get('unit', ''),
        title_font_size=10,
        row=row,
        col=col,
    )
    fig.update_yaxes(
        title_text='Density' if col == 1 else '',
        title_font_size=10,
        row=row,
        col=col,
    )


def create_full_distribution_figure(
    data: Dict[str, pd.DataFrame],
    selected_features: List[str],
    cols: int = 5,
) -> go.Figure:
    """åˆ›å»ºå®Œæ•´çš„å¤šç‰¹å¾åˆ†å¸ƒå›¾"""
    
    flat_features = get_flat_features()
    n_features = len(selected_features)
    rows = (n_features + cols - 1) // cols
    
    # è·å–ç‰¹å¾æ ‡é¢˜
    titles = [flat_features.get(f, {}).get('name', f) for f in selected_features]
    
    fig = make_subplots(
        rows=rows,
        cols=cols,
        subplot_titles=titles,
        vertical_spacing=0.08,
        horizontal_spacing=0.05,
    )
    
    for idx, feature in enumerate(selected_features):
        row = idx // cols + 1
        col = idx % cols + 1
        config = flat_features.get(feature, {'range': (0, 100), 'unit': ''})
        
        # åªåœ¨ç¬¬ä¸€ä¸ªå­å›¾æ˜¾ç¤ºå›¾ä¾‹
        show_legend = (idx == 0)
        
        create_distribution_subplot(data, feature, config, row, col, fig, show_legend)
    
    # æ›´æ–°æ•´ä½“å¸ƒå±€
    fig.update_layout(
        height=280 * rows,
        width=1400,
        title_text="Multi-Database Feature Distribution Comparison",
        title_x=0.5,
        title_font_size=20,
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="center",
            x=0.5,
            font=dict(size=12),
        ),
        margin=dict(t=100, b=50, l=50, r=50),
    )
    
    # æ›´æ–°å­å›¾æ ‡é¢˜å­—ä½“å¤§å°
    for annotation in fig.layout.annotations:
        annotation.font.size = 11
    
    return fig


def create_single_feature_comparison(
    data: Dict[str, pd.DataFrame],
    concept: str,
    config: dict,
) -> go.Figure:
    """åˆ›å»ºå•ç‰¹å¾è¯¦ç»†å¯¹æ¯”å›¾"""
    
    fig = go.Figure()
    x_range = config.get('range', (0, 100))
    
    stats_data = []
    
    for db, df in data.items():
        concept_data = df[df['concept'] == concept]['value'].values
        if len(concept_data) < 10:
            continue
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats_data.append({
            'Database': DB_LABELS.get(db, db),
            'N': len(concept_data),
            'Mean': np.mean(concept_data),
            'Std': np.std(concept_data),
            'Median': np.median(concept_data),
            'Q25': np.percentile(concept_data, 25),
            'Q75': np.percentile(concept_data, 75),
            'Min': np.min(concept_data),
            'Max': np.max(concept_data),
        })
        
        x, y = compute_kde(concept_data, x_range)
        if len(x) == 0:
            continue
        
        fig.add_trace(
            go.Scatter(
                x=x,
                y=y,
                mode='lines',
                name=DB_LABELS.get(db, db),
                line=dict(color=DB_COLORS.get(db, '#888888'), width=2.5),
                fill='tozeroy',
                fillcolor=f"rgba{tuple(list(int(DB_COLORS.get(db, '#888888').lstrip('#')[i:i+2], 16) for i in (0, 2, 4)) + [0.25])}",
            )
        )
    
    fig.update_layout(
        title=f"{config.get('name', concept)}",
        xaxis_title=config.get('unit', ''),
        yaxis_title='Density',
        height=400,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="center",
            x=0.5,
        ),
    )
    
    return fig, pd.DataFrame(stats_data)


# ==================== Streamlit UI ====================

def main():
    st.markdown("""
    <style>
        .main-header {
            font-size: 2.5rem;
            font-weight: 800;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-align: center;
            margin-bottom: 1rem;
        }
        .sub-header {
            font-size: 1.1rem;
            color: #666;
            text-align: center;
            margin-bottom: 2rem;
        }
        .stats-card {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            border-radius: 10px;
            padding: 15px;
            margin: 10px 0;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown('<h1 class="main-header">ğŸ“Š ICU Database Feature Distribution</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Multi-database continuous feature distribution comparison across MIMIC-IV, eICU, AUMC, and HiRID</p>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.markdown("## âš™ï¸ Configuration")
        
        # æ•°æ®è·¯å¾„
        data_path = st.text_input(
            "ğŸ“ ICU Data Root Path",
            value=os.environ.get('RICU_DATA_PATH', '/home/zhuhb/icudb'),
            help="Root directory containing all ICU databases",
        )
        
        st.divider()
        
        # æ•°æ®åº“é€‰æ‹©
        st.markdown("### ğŸ¥ Databases")
        selected_dbs = []
        for db, label in DB_LABELS.items():
            color = DB_COLORS[db]
            if st.checkbox(
                f":{color[1:]} [{label}]",
                value=True,
                key=f"db_{db}",
            ):
                selected_dbs.append(db)
        
        st.divider()
        
        # ç‰¹å¾ç»„é€‰æ‹©
        st.markdown("### ğŸ“‹ Feature Groups")
        selected_groups = st.multiselect(
            "Select groups",
            list(FEATURE_GROUPS.keys()),
            default=["Vital Signs", "Laboratory - Metabolic"],
        )
        
        # è·å–é€‰ä¸­ç»„çš„æ‰€æœ‰ç‰¹å¾
        available_features = []
        for group in selected_groups:
            available_features.extend(list(FEATURE_GROUPS[group].keys()))
        
        # ç‰¹å¾é€‰æ‹©
        if available_features:
            selected_features = st.multiselect(
                "Select specific features",
                available_features,
                default=available_features[:10],
            )
        else:
            selected_features = []
        
        st.divider()
        
        # é‡‡æ ·é…ç½®
        st.markdown("### ğŸ¯ Sampling")
        max_patients = st.slider(
            "Max patients per database",
            min_value=100,
            max_value=5000,
            value=500,
            step=100,
        )
        
        sample_per_patient = st.slider(
            "Samples per patient",
            min_value=1,
            max_value=50,
            value=10,
        )
        
        st.divider()
        
        # å¯è§†åŒ–é…ç½®
        st.markdown("### ğŸ“ Layout")
        n_cols = st.slider("Columns", min_value=3, max_value=6, value=5)
        
        load_button = st.button("ğŸš€ Load Data & Generate", type="primary", use_container_width=True)
    
    # ä¸»åŒºåŸŸ
    if not selected_dbs:
        st.warning("âš ï¸ Please select at least one database")
        return
    
    if not selected_features:
        st.warning("âš ï¸ Please select at least one feature")
        return
    
    # æ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š Distribution Grid", "ğŸ” Single Feature Detail", "ğŸ“ˆ Summary Statistics"])
    
    with tab1:
        if load_button or 'feature_data' in st.session_state:
            if load_button:
                with st.spinner("Loading data from databases..."):
                    st.session_state.feature_data = load_feature_data(
                        data_path,
                        selected_features,
                        selected_dbs,
                        max_patients,
                        sample_per_patient,
                    )
            
            if 'feature_data' in st.session_state and st.session_state.feature_data:
                data = st.session_state.feature_data
                
                # æ˜¾ç¤ºåŠ è½½çš„æ•°æ®é‡
                cols = st.columns(len(data))
                for i, (db, df) in enumerate(data.items()):
                    with cols[i]:
                        st.metric(
                            label=DB_LABELS.get(db, db),
                            value=f"{len(df):,}",
                            delta="records",
                        )
                
                # ç”Ÿæˆåˆ†å¸ƒå›¾
                fig = create_full_distribution_figure(data, selected_features, n_cols)
                st.plotly_chart(fig, use_container_width=True)
                
                # ä¸‹è½½æŒ‰é’®
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    # å¯¼å‡ºä¸ºHTML
                    html_bytes = fig.to_html().encode()
                    st.download_button(
                        "ğŸ“¥ Download as HTML",
                        html_bytes,
                        file_name="feature_distribution.html",
                        mime="text/html",
                    )
            else:
                st.info("ğŸ‘† Click 'Load Data & Generate' to create the distribution plot")
        else:
            st.info("ğŸ‘† Click 'Load Data & Generate' in the sidebar to start")
    
    with tab2:
        if 'feature_data' in st.session_state and st.session_state.feature_data:
            data = st.session_state.feature_data
            flat_features = get_flat_features()
            
            selected_single = st.selectbox(
                "Select a feature for detailed view",
                selected_features,
                format_func=lambda x: f"{x} - {flat_features.get(x, {}).get('name', x)}",
            )
            
            if selected_single:
                config = flat_features.get(selected_single, {'range': (0, 100), 'unit': ''})
                fig, stats_df = create_single_feature_comparison(data, selected_single, config)
                
                st.plotly_chart(fig, use_container_width=True)
                
                if not stats_df.empty:
                    st.markdown("### ğŸ“Š Statistics Summary")
                    st.dataframe(
                        stats_df.style.format({
                            'Mean': '{:.2f}',
                            'Std': '{:.2f}',
                            'Median': '{:.2f}',
                            'Q25': '{:.2f}',
                            'Q75': '{:.2f}',
                            'Min': '{:.2f}',
                            'Max': '{:.2f}',
                        }),
                        use_container_width=True,
                    )
        else:
            st.info("Please load data first from the Distribution Grid tab")
    
    with tab3:
        if 'feature_data' in st.session_state and st.session_state.feature_data:
            data = st.session_state.feature_data
            flat_features = get_flat_features()
            
            st.markdown("### ğŸ“ˆ Cross-Database Summary Statistics")
            
            all_stats = []
            for feature in selected_features:
                config = flat_features.get(feature, {})
                for db, df in data.items():
                    concept_data = df[df['concept'] == feature]['value'].values
                    if len(concept_data) > 0:
                        all_stats.append({
                            'Feature': config.get('name', feature),
                            'Code': feature,
                            'Database': DB_LABELS.get(db, db),
                            'N': len(concept_data),
                            'Mean': np.mean(concept_data),
                            'Std': np.std(concept_data),
                            'Median': np.median(concept_data),
                        })
            
            if all_stats:
                stats_df = pd.DataFrame(all_stats)
                
                # åˆ›å»ºé€è§†è¡¨
                pivot_mean = stats_df.pivot(index='Code', columns='Database', values='Mean')
                pivot_n = stats_df.pivot(index='Code', columns='Database', values='N')
                
                st.markdown("#### Mean Values by Database")
                st.dataframe(pivot_mean.style.format('{:.2f}'), use_container_width=True)
                
                st.markdown("#### Sample Sizes by Database")
                st.dataframe(pivot_n.style.format('{:,.0f}'), use_container_width=True)
                
                # ğŸ”§ FIX: å¯¼å‡ºæ—¶ä½¿ç”¨ utf-8-sig ç¼–ç å¹¶æ›¿æ¢ç‰¹æ®Šå­—ç¬¦
                export_stats = stats_df.copy()
                for col in export_stats.columns:
                    if export_stats[col].dtype == 'object':
                        export_stats[col] = export_stats[col].astype(str).str.replace('Â±', '+/-', regex=False)
                        export_stats[col] = export_stats[col].str.replace('â‰¥', '>=', regex=False)
                        export_stats[col] = export_stats[col].str.replace('â‰¤', '<=', regex=False)
                csv = export_stats.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    "ğŸ“¥ Download Full Statistics (CSV)",
                    csv,
                    file_name="feature_statistics.csv",
                    mime="text/csv",
                )
        else:
            st.info("Please load data first from the Distribution Grid tab")


if __name__ == "__main__":
    main()
