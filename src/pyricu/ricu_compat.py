"""
ricuå…¼å®¹å±‚ - å®ç°ä¸R ricuä¸€è‡´çš„æ•°æ®æå–è¡Œä¸º

è¯¥æ¨¡å—æä¾›äº†ä¸R ricuåŒ…load_conceptså‡½æ•°å®Œå…¨ä¸€è‡´çš„æ•°æ®æå–é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
1. æ—¶é—´ç½‘æ ¼å¯¹é½ - æ‰€æœ‰æ¦‚å¿µå¯¹é½åˆ°å…±åŒçš„æ—¶é—´ç½‘æ ¼ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
2. çª—å£å±•å¼€ - å°†start/endæ—¶é—´çª—å£å±•å¼€ä¸ºé€å°æ—¶è®°å½•
3. æ¦‚å¿µåˆå¹¶ - ä½¿ç”¨outer joinåˆå¹¶å¤šä¸ªæ¦‚å¿µ
4. é™æ€æ¦‚å¿µå¡«å…… - é™æ€å€¼ï¼ˆage, sexç­‰ï¼‰å¡«å……åˆ°æ‰€æœ‰æ—¶é—´ç‚¹

ç”¨æ³•ç¤ºä¾‹:
    >>> from pyricu import load_concepts
    >>> 
    >>> # æå–ç”Ÿå‘½ä½“å¾ï¼ˆä¸ricu.Rä¸€è‡´ï¼‰
    >>> vitals = load_concepts(
    ...     ['hr', 'sbp', 'dbp', 'temp'],
    ...     database='miiv',
    ...     patient_ids=[30041748, 30046525],
    ...     interval='1h',  # é»˜è®¤å€¼ï¼Œä¸ricuçš„hours(1L)ä¸€è‡´
    ...     ricu_compatible=True  # å¯ç”¨å®Œæ•´çš„ricuå…¼å®¹æ¨¡å¼
    ... )
"""

from __future__ import annotations

import math
import logging
from dataclasses import dataclass
from typing import Dict, List, Optional

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)


# ============================================================================
# æ¦‚å¿µæ¨¡å—å®šä¹‰ï¼ˆä¸ricu.Rä¸­çš„æ¨¡å—å¯¹åº”ï¼‰
# ============================================================================

@dataclass
class ConceptModule:
    """æ¦‚å¿µæ¨¡å—å®šä¹‰ï¼Œå¯¹åº”ricu.Rä¸­çš„æ•°æ®æå–åˆ†ç»„"""
    name: str
    concepts: List[str]
    id_column: str = "stay_id"
    time_column: Optional[str] = "charttime"  # Noneè¡¨ç¤ºé™æ€æ¦‚å¿µï¼ˆæ— æ—¶é—´ç»´åº¦ï¼‰
    description: str = ""


# ä¸ricu.Rä¸­extract_dataå‡½æ•°çš„æ¨¡å—å¯¹åº”
RICU_MODULES: Dict[str, ConceptModule] = {
    "demo": ConceptModule(
        name="demo",
        concepts=["age", "bmi", "height", "sex", "weight"],
        time_column=None,  # é™æ€æ¦‚å¿µ
        description="åŸºç¡€äººå£ç»Ÿè®¡å­¦",
    ),
    "outcome": ConceptModule(
        name="outcome",
        concepts=[
            "death", "los_icu", "qsofa", "sirs", "sofa", 
            "sofa_cardio", "sofa_cns", "sofa_coag", "sofa_liver", 
            "sofa_renal", "sofa_resp"
        ],
        time_column="index_var",
        description="ç»“å±€å’ŒSOFAè¯„åˆ†",
    ),
    "vital": ConceptModule(
        name="vital",
        concepts=["dbp", "etco2", "hr", "map", "sbp", "temp"],
        description="ç”Ÿå‘½ä½“å¾",
    ),
    "neu": ConceptModule(
        name="neu",
        concepts=["avpu", "egcs", "gcs", "mgcs", "rass", "vgcs"],
        description="ç¥ç»ç³»ç»Ÿè¯„ä¼°",
    ),
    "output": ConceptModule(
        name="output",
        concepts=["urine", "urine24"],
        description="å°¿é‡",
    ),
    "resp": ConceptModule(
        name="resp",
        concepts=[
            "ett_gcs", "mech_vent", "o2sat", "sao2", "pafi", 
            "resp", "safi", "supp_o2", "vent_ind"
        ],
        description="å‘¼å¸ç³»ç»Ÿ",
    ),
    "lab": ConceptModule(
        name="lab",
        concepts=[
            "alb", "alp", "alt", "ast", "bicar", "bili", "bili_dir", 
            "bun", "ca", "ck", "ckmb", "cl", "crea", "crp", "glu",
            "k", "mg", "na", "phos", "tnt"
        ],
        description="å®éªŒå®¤æ£€æŸ¥",
    ),
    "blood": ConceptModule(
        name="blood",
        concepts=["be", "cai", "fio2", "hbco", "lact", "methb", "pco2", "ph", "po2", "tco2"],
        description="è¡€æ°”åˆ†æ",
    ),
    "hematology": ConceptModule(
        name="hematology",
        concepts=[
            "bnd", "esr", "fgn", "hgb", "inr_pt", "lymph", "mch", 
            "mchc", "mcv", "neut", "plt", "ptt", "wbc"
        ],
        description="è¡€æ¶²å­¦æ£€æŸ¥",
    ),
    "med": ConceptModule(
        name="med",
        concepts=[
            "abx", "adh_rate", "cort", "dex", "dobu_dur", "dobu_rate", 
            "dobu60", "epi_dur", "epi_rate", "ins", "norepi_dur", 
            "norepi_equiv", "norepi_rate", "vaso_ind"
        ],
        time_column="starttime",
        description="è¯ç‰©æ²»ç–—",
    ),
}


# é™æ€æ¦‚å¿µåˆ—è¡¨ï¼ˆtarget=id_tblï¼Œéœ€è¦å¡«å……åˆ°æ‰€æœ‰æ—¶é—´ç‚¹çš„æ¦‚å¿µï¼‰
# æ³¨æ„ï¼šdeath ä¸æ˜¯é™æ€æ¦‚å¿µï¼Œå®ƒæ˜¯ lgl_cncptï¼Œåªåœ¨æ­»äº¡æ—¶åˆ»æœ‰å€¼
STATIC_CONCEPTS = {"age", "sex", "bmi", "height", "weight", "los_icu"}

# çª—å£å‹æ¦‚å¿µï¼ˆéœ€è¦å±•å¼€start/endæ—¶é—´çš„æ¦‚å¿µï¼‰
# åŒ…æ‹¬ï¼š
# - æœºæ¢°é€šæ°”æŒ‡æ ‡: mech_vent, vent_ind, supp_o2
# - è¡€ç®¡æ´»æ€§è¯ç‰©é€Ÿç‡: *_rate, vaso_ind
# - dex: è¾“æ¶²æ¦‚å¿µï¼Œæœ‰ dur_varï¼ˆaumc ä½¿ç”¨ stopï¼‰
# - ett_gcs: ä½¿ç”¨ ts_to_win_tbl(mins(360L)) å±•å¼€ä¸º 6 å°æ—¶çª—å£
# æ³¨æ„ï¼šins ä¸åœ¨è¿™é‡Œï¼Œå› ä¸º ricu ä¸­å®ƒæ˜¯ ts_tbl è€Œä¸æ˜¯ win_tbl
WINDOW_CONCEPTS = {
    "mech_vent", "vent_ind", "supp_o2",
    "norepi_rate", "epi_rate", "dobu_rate", "adh_rate",
    "dopa_rate", "phn_rate", "vaso_ind",
    "dex",  # dex åœ¨ aumc/eicu æœ‰ dur_varï¼Œéœ€è¦å±•å¼€
    "ett_gcs",     # FIX: ett_gcs ä½¿ç”¨ ts_to_win_tbl å±•å¼€çª—å£
}

# ç‚¹äº‹ä»¶æ¦‚å¿µï¼ˆä¸åº”å±•å¼€ä¸ºè¿ç»­æ—¶é—´åºåˆ—ï¼‰
POINT_EVENT_CONCEPTS = {
    "abx", "samp", "cort", "dobu60", "susp_inf", "sep3", "avpu",
    "rrt",  # Renal replacement therapy: uses set_val(TRUE), point events from chartevents + procedureevents
    "vent_end", "vent_start",  # Ventilation events: uses set_val(TRUE), point events
}

# æ—¶é•¿æ¦‚å¿µï¼ˆå·²ç¼–ç æŒç»­æ—¶é—´ï¼Œä¸éœ€è¦å±•å¼€ï¼‰
DURATION_CONCEPTS = {
    "norepi_dur", "epi_dur", "dobu_dur", "dopa_dur"
}


# ============================================================================
# æ—¶é—´å¤„ç†å·¥å…·
# ============================================================================

def time_to_hours(
    series: pd.Series, 
    id_series: Optional[pd.Series] = None,
    intime_lookup: Optional[pd.DataFrame] = None,
) -> pd.Series:
    """å°†æ—¶é—´åˆ—è½¬æ¢ä¸ºç›¸å¯¹å°æ—¶æ•°
    
    Args:
        series: æ—¶é—´åºåˆ—ï¼ˆdatetime64æˆ–å·²æ˜¯æ•°å€¼ï¼‰
        id_series: å¯¹åº”çš„IDåºåˆ—ï¼ˆç”¨äºåˆ†ç»„è®¡ç®—ç›¸å¯¹æ—¶é—´ï¼‰
        intime_lookup: åŒ…å«stay_idå’Œintimeçš„æŸ¥æ‰¾è¡¨
        
    Returns:
        ç›¸å¯¹äºICUå…¥é™¢çš„å°æ—¶æ•°
    """
    if series.empty:
        return series
    
    # å·²ç»æ˜¯æ•°å€¼ç±»å‹
    if pd.api.types.is_numeric_dtype(series):
        return series
    
    # timedeltaç±»å‹
    if pd.api.types.is_timedelta64_dtype(series):
        return series.dt.total_seconds() / 3600.0
    
    # datetimeç±»å‹
    if pd.api.types.is_datetime64_any_dtype(series):
        # ç§»é™¤æ—¶åŒºä¿¡æ¯
        clean = series.copy()
        if hasattr(clean.dtype, 'tz') and clean.dt.tz is not None:
            clean = clean.dt.tz_localize(None)
        
        # å¦‚æœæœ‰intimeæŸ¥æ‰¾è¡¨ï¼Œä½¿ç”¨å®ƒ
        if intime_lookup is not None and id_series is not None:
            # éœ€è¦è¿”å›ç›¸å¯¹äºæ¯ä¸ªæ‚£è€…intimeçš„å°æ—¶æ•°
            # è¿™éœ€è¦åœ¨è°ƒç”¨æ–¹å¤„ç†
            pass
        
        # æŒ‰IDåˆ†ç»„è®¡ç®—ç›¸å¯¹æ—¶é—´
        if id_series is not None:
            return clean.groupby(id_series).transform(
                lambda s: (s - s.min()).dt.total_seconds() / 3600.0
            )
        
        # å…¨å±€ç›¸å¯¹æ—¶é—´
        return (clean - clean.min()).dt.total_seconds() / 3600.0
    
    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
    return pd.to_numeric(series, errors="coerce")


def round_to_interval(time_series: pd.Series, interval_hours: float = 1.0) -> pd.Series:
    """å°†æ—¶é—´å››èˆäº”å…¥åˆ°æŒ‡å®šé—´éš”
    
    Args:
        time_series: æ—¶é—´åºåˆ—ï¼ˆå°æ—¶æ•°ï¼‰
        interval_hours: é—´éš”ï¼ˆå°æ—¶ï¼‰
        
    Returns:
        å››èˆäº”å…¥åçš„æ—¶é—´åºåˆ—
    """
    if time_series.empty:
        return time_series
    
    # ä½¿ç”¨floorè€Œéroundï¼Œä¸ricuè¡Œä¸ºä¸€è‡´
    return np.floor(time_series / interval_hours) * interval_hours


# ============================================================================
# çª—å£å±•å¼€
# ============================================================================

def expand_interval_rows(
    df: pd.DataFrame,
    concept_name: str,
    id_col: str = "id",
    time_col: str = "time",
    value_col: str = "value",
    endtime_col: str = "endtime",
    duration_col: str = "duration",
    interval_hours: float = 1.0,
    max_span_hours: float = 24 * 365,  # æœ€å¤§å±•å¼€èŒƒå›´
) -> pd.DataFrame:
    """å±•å¼€æ—¶é—´çª—å£ä¸ºé€å°æ—¶è®°å½•
    
    å°†æœ‰start/endæ—¶é—´çš„è®°å½•å±•å¼€ä¸ºæ¯å°æ—¶ä¸€æ¡è®°å½•ï¼Œä¸ricuçš„expand()è¡Œä¸ºä¸€è‡´ã€‚
    
    Args:
        df: è¾“å…¥DataFrame
        concept_name: æ¦‚å¿µåç§°ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦å±•å¼€ï¼‰
        id_col: IDåˆ—å
        time_col: å¼€å§‹æ—¶é—´åˆ—å
        value_col: å€¼åˆ—å
        endtime_col: ç»“æŸæ—¶é—´åˆ—å
        duration_col: æŒç»­æ—¶é—´åˆ—å
        interval_hours: æ—¶é—´é—´éš”ï¼ˆå°æ—¶ï¼‰
        max_span_hours: æœ€å¤§å±•å¼€æ—¶é•¿
        
    Returns:
        å±•å¼€åçš„DataFrame
    """
    concept_lower = concept_name.lower()
    
    # æ—¶é•¿æ¦‚å¿µä¸å±•å¼€
    if concept_lower.endswith("_dur") or concept_lower in DURATION_CONCEPTS:
        return df.drop(columns=[endtime_col, duration_col], errors="ignore")
    
    # ç‚¹äº‹ä»¶æ¦‚å¿µä¸å±•å¼€
    if concept_lower in POINT_EVENT_CONCEPTS:
        return df.drop(columns=[endtime_col, duration_col], errors="ignore")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åˆ—
    if time_col not in df.columns:
        return df.drop(columns=[endtime_col, duration_col], errors="ignore")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æŸæ—¶é—´æˆ–æŒç»­æ—¶é—´
    has_end = endtime_col in df.columns and df[endtime_col].notna().any()
    has_duration = duration_col in df.columns and df[duration_col].notna().any()
    
    # æ²¡æœ‰çª—å£ä¿¡æ¯ï¼Œä¸å±•å¼€
    if not has_end and not has_duration:
        return df.drop(columns=[endtime_col, duration_col], errors="ignore")
    
    # åªå¤„ç†æœ‰å€¼çš„è¡Œ
    working = df.copy()
    if value_col in working.columns:
        has_value = working[value_col].notna()
        working = working[has_value].copy()
        if working.empty:
            return pd.DataFrame(columns=[id_col, time_col, value_col])
    
    # ç¡®ä¿æ—¶é—´æ˜¯æ•°å€¼ç±»å‹
    if not pd.api.types.is_numeric_dtype(working[time_col]):
        working[time_col] = time_to_hours(working[time_col])
    
    # å¤„ç†ç»“æŸæ—¶é—´
    if has_end and not pd.api.types.is_numeric_dtype(working[endtime_col]):
        working[endtime_col] = time_to_hours(working[endtime_col])
    
    # å¤„ç†æŒç»­æ—¶é—´
    if has_duration:
        if pd.api.types.is_timedelta64_dtype(working[duration_col]):
            working[duration_col] = working[duration_col].dt.total_seconds() / 3600.0
        working[duration_col] = pd.to_numeric(working[duration_col], errors="coerce")
    
    # è®¡ç®—ç»“æŸæ—¶é—´
    starts = pd.to_numeric(working[time_col], errors="coerce")
    if has_end:
        ends = pd.to_numeric(working[endtime_col], errors="coerce")
    elif has_duration:
        ends = starts + working[duration_col].fillna(0)
    else:
        ends = starts
    
    # ğŸ”§ æ³¨æ„ï¼šR ricu ä¸å¯¹åŸå§‹ endtime åš floor
    # åªæœ‰åœ¨ endtime ä¸åœ¨åˆ—ä¸­æ—¶ï¼ŒR ricu æ‰ä¼šç”¨ re_time(start + dur, interval) è®¡ç®—
    # å¯¹äº MIIV inputeventsï¼Œendtime å·²ç»åœ¨åˆ—ä¸­ï¼Œæ‰€ä»¥ç›´æ¥ä½¿ç”¨åŸå§‹å€¼
    # seq(start, end, step) ä¼šäº§ç”Ÿæ‰€æœ‰ <= end çš„æ—¶é—´ç‚¹
    
    # å±•å¼€
    records = []
    for idx, (start, end, value, stay_id) in enumerate(
        zip(starts, ends, working.get(value_col), working.get(id_col))
    ):
        if pd.isna(start) or pd.isna(stay_id):
            continue
        if pd.isna(end):
            end = start
        if end < start:
            end = start
        
        span = min(end - start, max_span_hours)
        if span <= 0:
            records.append({id_col: stay_id, time_col: float(math.floor(start)), value_col: value})
            continue
        
        # ğŸ”§ FIX: ä½¿ç”¨ R seq(start, end, step) çš„è¡Œä¸º
        # R çš„ seq(17.84, 20, 1) äº§ç”Ÿ [17.84, 18.84, 19.84]
        # ç„¶åå– floor å¾—åˆ° [17, 18, 19]
        # 
        # å®ç°ï¼šä» start å¼€å§‹ï¼Œæ¯æ¬¡åŠ  1ï¼Œç›´åˆ°è¶…è¿‡ end
        time_points = []
        current = start
        while current <= end + 1e-9:  # åŠ å°é‡é¿å…æµ®ç‚¹è¯¯å·®
            time_points.append(math.floor(current))
            current += interval_hours
        
        # å»é‡ï¼ˆå› ä¸º floor å¯èƒ½äº§ç”Ÿé‡å¤ï¼‰
        time_points = sorted(set(time_points))
        
        for hour in time_points:
            records.append({id_col: stay_id, time_col: float(hour), value_col: value})
    
    if not records:
        return df.drop(columns=[endtime_col, duration_col], errors="ignore")
    
    expanded = pd.DataFrame.from_records(records)
    
    # ğŸ”§ FIX: æŒ‰(id, time)èšåˆï¼Œæ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©èšåˆå‡½æ•°
    # å‚è€ƒ: ricu/R/tbl-utils.R ç¬¬ 741-751 è¡Œ:
    #   - numeric â†’ median
    #   - logical â†’ sum (æˆ– any)  
    #   - character â†’ first
    value_dtype = expanded[value_col].dtype
    if pd.api.types.is_numeric_dtype(value_dtype):
        agg_func = 'median'
    elif pd.api.types.is_bool_dtype(value_dtype):
        agg_func = 'any'
    else:
        # object/string/category â†’ first
        agg_func = 'first'
    
    expanded = expanded.groupby([id_col, time_col], as_index=False).agg({value_col: agg_func})
    
    return expanded


# ============================================================================
# æ—¶é—´ç½‘æ ¼å¯¹é½
# ============================================================================

def build_time_grid(
    series_dict: Dict[str, pd.DataFrame],
    id_col: str = "id",
    time_col: str = "time",
) -> Optional[pd.DataFrame]:
    """æ„å»ºæ‰€æœ‰æ¦‚å¿µçš„ç»Ÿä¸€æ—¶é—´ç½‘æ ¼
    
    æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°ç¡®ä¿åŒ…å«æ‰€æœ‰æ‚£è€…ï¼Œå³ä½¿ä»–ä»¬åªæœ‰é™æ€æ¦‚å¿µæ•°æ®ï¼ˆæ— æ—¶é—´åˆ—ï¼‰ã€‚
    å¯¹äºåªæœ‰é™æ€æ•°æ®çš„æ‚£è€…ï¼Œåœ¨ç½‘æ ¼ä¸­åˆ›å»ºä¸€ä¸ª time=NaN çš„å ä½è¡Œã€‚
    
    Args:
        series_dict: æ¦‚å¿µåç§°åˆ°DataFrameçš„æ˜ å°„
        id_col: IDåˆ—å
        time_col: æ—¶é—´åˆ—å
        
    Returns:
        åŒ…å«æ‰€æœ‰(id, time)ç»„åˆçš„DataFrameï¼Œæˆ–Noneï¼ˆå¦‚æœæ²¡æœ‰æ•°æ®ï¼‰
    """
    time_frames = []
    static_ids = set()
    
    for name, df in series_dict.items():
        if not isinstance(df, pd.DataFrame) or df.empty:
            continue
        if id_col not in df.columns:
            continue
            
        if time_col in df.columns:
            # æœ‰æ—¶é—´æ•°æ®çš„æ¦‚å¿µ
            time_frames.append(df[[id_col, time_col]])
        else:
            # é™æ€æ¦‚å¿µï¼šæ”¶é›†æ‚£è€…ID
            static_ids.update(df[id_col].dropna().unique())
    
    if not time_frames and not static_ids:
        return None
    
    if time_frames:
        grid = (
            pd.concat(time_frames, ignore_index=True)
            .dropna(subset=[id_col, time_col])
            .drop_duplicates()
            .sort_values([id_col, time_col])
            .reset_index(drop=True)
        )
        # ç¡®ä¿é™æ€æ¦‚å¿µçš„æ‚£è€…ä¹Ÿåœ¨ç½‘æ ¼ä¸­
        grid_ids = set(grid[id_col].unique())
        missing_ids = static_ids - grid_ids
        if missing_ids:
            # ä¸ºç¼ºå¤±çš„æ‚£è€…æ·»åŠ ä¸€ä¸ª time=NaN çš„å ä½è¡Œ
            # è¿™æ ·åœ¨åç»­çš„ left join ä¸­ï¼Œä»–ä»¬çš„é™æ€æ•°æ®å¯ä»¥è¢«ä¿ç•™
            missing_rows = pd.DataFrame({
                id_col: list(missing_ids),
                time_col: [np.nan] * len(missing_ids)
            })
            grid = pd.concat([grid, missing_rows], ignore_index=True)
            grid = grid.sort_values([id_col, time_col]).reset_index(drop=True)
    else:
        # åªæœ‰é™æ€æ•°æ®ï¼Œåˆ›å»ºä¸€ä¸ªåªæœ‰IDçš„ç½‘æ ¼ï¼ˆtime=NaNï¼‰
        grid = pd.DataFrame({
            id_col: list(static_ids),
            time_col: [np.nan] * len(static_ids)
        })
    
    return grid if not grid.empty else None


def align_to_grid(
    concept_data: Dict[str, pd.DataFrame],
    grid: pd.DataFrame,
    id_col: str = "id",
    time_col: str = "time",
    value_col: str = "value",
) -> Dict[str, pd.DataFrame]:
    """å°†æ‰€æœ‰æ¦‚å¿µå¯¹é½åˆ°ç»Ÿä¸€çš„æ—¶é—´ç½‘æ ¼
    
    Args:
        concept_data: æ¦‚å¿µåç§°åˆ°DataFrameçš„æ˜ å°„
        grid: æ—¶é—´ç½‘æ ¼DataFrame
        id_col: IDåˆ—å
        time_col: æ—¶é—´åˆ—å
        value_col: å€¼åˆ—å
        
    Returns:
        å¯¹é½åçš„æ¦‚å¿µæ•°æ®å­—å…¸
    """
    if grid is None or grid.empty:
        return concept_data
    
    aligned = {}
    grid_copy = grid.copy()
    grid_copy[id_col] = pd.to_numeric(grid_copy[id_col], errors="coerce")
    grid_copy[time_col] = pd.to_numeric(grid_copy[time_col], errors="coerce")
    grid_copy = grid_copy.dropna(subset=[id_col, time_col]).drop_duplicates()
    
    for name, df in concept_data.items():
        if df is None or df.empty:
            # åˆ›å»ºç©ºå ä½ç¬¦
            placeholder = grid_copy.copy()
            placeholder[value_col] = np.nan
            aligned[name] = placeholder
            continue
        
        if time_col not in df.columns:
            # é™æ€æ¦‚å¿µï¼Œä¸éœ€è¦æ—¶é—´å¯¹é½
            aligned[name] = df
            continue
        
        df_copy = df.copy()
        df_copy[id_col] = pd.to_numeric(df_copy[id_col], errors="coerce")
        df_copy[time_col] = pd.to_numeric(df_copy[time_col], errors="coerce")
        df_copy = df_copy.dropna(subset=[id_col, time_col])
        
        # å·¦è¿æ¥åˆ°ç½‘æ ¼
        result = grid_copy.merge(df_copy, on=[id_col, time_col], how="left")
        
        # é™æ€æ¦‚å¿µå¡«å…… - ä½¿ç”¨æ¦‚å¿µåç§°ä½œä¸ºå€¼åˆ—ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„ value_col
        concept_value_col = name if name in result.columns else value_col
        if name in STATIC_CONCEPTS and concept_value_col in result.columns:
            for patient_id in result[id_col].unique():
                if pd.isna(patient_id):
                    continue
                patient_mask = result[id_col] == patient_id
                patient_values = result.loc[patient_mask, concept_value_col]
                non_na = patient_values.dropna()
                if len(non_na) > 0 and non_na.nunique() == 1:
                    result.loc[patient_mask, concept_value_col] = non_na.iloc[0]
        
        aligned[name] = result
    
    return aligned


# ============================================================================
# ä¸»è¦æ¥å£
# ============================================================================

def merge_concepts_ricu_style(
    concept_data: Dict[str, pd.DataFrame],
    id_col: str = "stay_id",
    time_col: str = "charttime",
    interval_hours: float = 1.0,
) -> pd.DataFrame:
    """ä»¥ricué£æ ¼åˆå¹¶å¤šä¸ªæ¦‚å¿µæ•°æ®
    
    å®ç°ä¸R ricuçš„load_concepts(..., interval=hours(1L))ä¸€è‡´çš„è¡Œä¸ºï¼š
    1. æ„å»ºç»Ÿä¸€æ—¶é—´ç½‘æ ¼
    2. å¯¹é½æ‰€æœ‰æ¦‚å¿µåˆ°ç½‘æ ¼
    3. ä½¿ç”¨outer joinåˆå¹¶
    
    Args:
        concept_data: æ¦‚å¿µåç§°åˆ°DataFrameçš„æ˜ å°„
        id_col: IDåˆ—å
        time_col: æ—¶é—´åˆ—å
        interval_hours: æ—¶é—´é—´éš”ï¼ˆå°æ—¶ï¼‰
        
    Returns:
        åˆå¹¶åçš„å®½æ ¼å¼DataFrame
    """
    if not concept_data:
        return pd.DataFrame()
    
    # æ ‡å‡†åŒ–åˆ—å
    normalized = {}
    for name, df in concept_data.items():
        if df is None or df.empty:
            normalized[name] = pd.DataFrame(columns=["id", "time", name])
            continue
        
        df_copy = df.copy()
        
        # æ£€æµ‹å’Œé‡å‘½åIDåˆ—
        id_candidates = [id_col, "stay_id", "subject_id", "patientunitstayid", "admissionid", "patientid"]
        found_id = None
        for cand in id_candidates:
            if cand in df_copy.columns:
                found_id = cand
                break
        
        if found_id and found_id != "id":
            df_copy = df_copy.rename(columns={found_id: "id"})
        
        # æ£€æµ‹å’Œé‡å‘½åæ—¶é—´åˆ—
        # ğŸ”§ FIX: æ·»åŠ  eICU çš„æ—¶é—´åˆ—ï¼ˆåŒ…æ‹¬ intakeoutputoffsetï¼‰å’Œ death çš„ deathtime
        # ğŸ”§ FIX: æ·»åŠ  start åˆ—ï¼ˆåŒºé—´æ ¼å¼æ•°æ®çš„å¼€å§‹æ—¶é—´ï¼‰
        # ğŸ”§ FIX: æ·»åŠ  measuredat_minutesï¼ˆAUMC DuckDBèšåˆåè¿”å›çš„æ—¶é—´åˆ—ï¼‰
        # ğŸ”§ FIX 2025-01-30: measuredat_minutes åº”è¯¥åœ¨ measuredat ä¹‹å‰ï¼Œå› ä¸º DuckDB èšåˆåè¿”å›çš„æ˜¯ measuredat_minutes
        time_candidates = [time_col, "charttime", "time", "starttime", "start", "index_var", 
                          "datetime", "givenat",  # HiRID time columns
                          "nursingchartoffset", "labresultoffset", "observationoffset",
                          "measuredat_minutes", "measuredat",  # AUMC time columns: measuredat_minutes first!
                          "respchartoffset", "intakeoutputoffset",
                          "infusionoffset", "drugstartoffset", "deathtime",
                          "unitdischargeoffset", "dateofdeath"]
        found_time = None
        for cand in time_candidates:
            if cand in df_copy.columns:
                found_time = cand
                break
        
        if found_time and found_time != "time":
            df_copy = df_copy.rename(columns={found_time: "time"})
        
        # ğŸ”§ FIX: åˆ é™¤å…¶ä»–å¯èƒ½å¯¼è‡´ç¬›å¡å°”ç§¯çš„é¢å¤–æ—¶é—´åˆ—
        extra_time_cols = ["intakeoutputentryoffset"]
        for col in extra_time_cols:
            if col in df_copy.columns and col != found_time:
                df_copy = df_copy.drop(columns=[col])
        
        # è½¬æ¢æ—¶é—´ä¸ºå°æ—¶æ•°
        if "time" in df_copy.columns and not pd.api.types.is_numeric_dtype(df_copy["time"]):
            df_copy["time"] = time_to_hours(df_copy["time"], df_copy.get("id"))
        
        # ğŸ”§ FIX: çª—å£æ¦‚å¿µä¸å–æ•´æ—¶é—´ï¼Œä¿ç•™åŸå§‹å€¼ç»™ expand_interval_rows å¤„ç†
        # R ricu çš„ expand() ä½¿ç”¨åŸå§‹æµ®ç‚¹æ—¶é—´æ¥è®¡ç®— seq()
        # å–æ•´å°†åœ¨ expand_interval_rows å†…éƒ¨è¿›è¡Œ
        is_window_concept = name in WINDOW_CONCEPTS or name.endswith("_rate")
        if "time" in df_copy.columns and not is_window_concept:
            df_copy["time"] = round_to_interval(df_copy["time"], interval_hours)
        
        # ğŸ”§ NOTE: Duration æ¦‚å¿µçš„å€¼ï¼ˆå¦‚ dobu_durï¼‰å·²ç»åœ¨ calc_dur ä¸­ä½¿ç”¨ floor(end_h) - floor(start_h) è®¡ç®—
        # ä¸éœ€è¦å†å¯¹ duration å€¼åšé¢å¤–å¤„ç†
        # R ricu çš„ calc_dur åœ¨æ—¶é—´å·²ç»è¢« floor åˆ°å°æ—¶åè®¡ç®— max(end) - min(start)
        
        # ç¡®ä¿æœ‰å€¼åˆ—
        if name not in df_copy.columns:
            value_candidates = ["value", "valuenum", name]
            for cand in value_candidates:
                if cand in df_copy.columns and cand != name:
                    df_copy = df_copy.rename(columns={cand: name})
                    break
        
        # ğŸ”§ FIX: æ ‡å‡†åŒ–çª—å£æ¦‚å¿µçš„åˆ—å
        # mech_vent ç­‰æ¦‚å¿µè¿”å› start/stop/{name}_durï¼Œéœ€è¦é‡å‘½åä¸º time/endtime/duration
        if name in WINDOW_CONCEPTS or name.endswith("_rate"):
            # é‡å‘½å start -> time (å¦‚æœè¿˜æ²¡æœ‰ time åˆ—)
            if "start" in df_copy.columns and "time" not in df_copy.columns:
                df_copy = df_copy.rename(columns={"start": "time"})
            # é‡å‘½å stop -> endtime
            if "stop" in df_copy.columns:
                df_copy = df_copy.rename(columns={"stop": "endtime"})
            # é‡å‘½å {name}_dur -> duration
            dur_col = f"{name}_dur"
            if dur_col in df_copy.columns:
                df_copy = df_copy.rename(columns={dur_col: "duration"})
        
        # çª—å£å±•å¼€
        if name in WINDOW_CONCEPTS or name.endswith("_rate"):
            df_copy = expand_interval_rows(
                df_copy, name, 
                id_col="id", time_col="time", value_col=name,
                interval_hours=interval_hours
            )
        
        normalized[name] = df_copy
    
    # æ„å»ºæ—¶é—´ç½‘æ ¼
    grid = build_time_grid(normalized, id_col="id", time_col="time")
    
    if grid is None or grid.empty:
        # æ²¡æœ‰æ—¶é—´æ•°æ®ï¼Œç®€å•åˆå¹¶
        if len(normalized) == 1:
            name = list(normalized.keys())[0]
            df = list(normalized.values())[0]
            # é‡å‘½ååˆ—ä»¥åŒ¹é…è¾“å‡º
            if "id" in df.columns and id_col != "id":
                df = df.rename(columns={"id": id_col})
            if "time" in df.columns and time_col != "time":
                df = df.rename(columns={"time": time_col})
            return df
        
        # å¤šä¸ªæ¦‚å¿µéƒ½ä¸ºç©ºçš„æƒ…å†µ
        all_empty = all(df.empty if df is not None else True for df in normalized.values())
        if all_empty:
            # è¿”å›åŒ…å«æ‰€æœ‰æ¦‚å¿µåçš„ç©º DataFrame
            return pd.DataFrame(columns=[id_col, time_col] + list(normalized.keys()))
        
        merged = None
        for name, df in normalized.items():
            if df is None or df.empty:
                continue
            if merged is None:
                merged = df.copy()
            else:
                # æŒ‰IDåˆå¹¶ï¼Œé¿å…é‡å¤åˆ—
                merge_cols = ["id"] if "id" in merged.columns and "id" in df.columns else []
                if merge_cols:
                    # åªé€‰æ‹©éœ€è¦çš„åˆ—ï¼šID + æ¦‚å¿µå
                    cols_to_add = [c for c in df.columns if c not in merged.columns or c in merge_cols]
                    df_subset = df[cols_to_add].copy()
                    merged = merged.merge(df_subset, on=merge_cols, how="outer", suffixes=('', '_dup'))
                    # åˆ é™¤é‡å¤åˆ—
                    merged = merged[[c for c in merged.columns if not c.endswith('_dup')]]
                else:
                    # æ²¡æœ‰å…¬å…±IDåˆ—ï¼Œæ·»åŠ æ¦‚å¿µåˆ—
                    if name in df.columns and name not in merged.columns:
                        merged[name] = np.nan
        
        if merged is not None:
            # é‡å‘½ååˆ—ä»¥åŒ¹é…è¾“å‡º
            if "id" in merged.columns and id_col != "id":
                merged = merged.rename(columns={"id": id_col})
            if "time" in merged.columns and time_col != "time":
                merged = merged.rename(columns={"time": time_col})
            return merged
        
        return pd.DataFrame(columns=[id_col, time_col] + list(normalized.keys()))
    
    # å¯¹é½åˆ°ç½‘æ ¼å¹¶åˆå¹¶
    aligned = align_to_grid(normalized, grid, id_col="id", time_col="time")
    
    # æŒ‰æ—¶é—´ç½‘æ ¼åˆå¹¶
    merged = grid.copy()
    boolean_concepts = []  # è·Ÿè¸ªå¸ƒå°”æ¦‚å¿µï¼Œä»¥ä¾¿åç»­ fillna(False)
    for name, df in aligned.items():
        if df is None or df.empty:
            merged[name] = np.nan
            continue
        
        if "time" not in df.columns:
            # é™æ€æ¦‚å¿µï¼Œç›´æ¥æŒ‰IDåˆå¹¶
            if "id" in df.columns and name in df.columns:
                static = df[["id", name]].drop_duplicates()
                merged = merged.merge(static, on="id", how="left", suffixes=('', '_drop'))
                # åˆ é™¤é‡å¤åˆ—
                merged = merged[[c for c in merged.columns if not c.endswith('_drop')]]
            continue
        
        # é€‰æ‹©éœ€è¦çš„åˆ—ï¼šåªä¿ç•™ id, time, å’Œæ¦‚å¿µååˆ—
        keep_cols = ["id", "time"]
        if name in df.columns:
            keep_cols.append(name)
        
        keep_cols = [c for c in keep_cols if c in df.columns]
        if len(keep_cols) <= 2:  # åªæœ‰idå’Œtimeï¼Œæ²¡æœ‰å€¼
            merged[name] = np.nan
            continue
        
        # FIX: å¯¹äºå¸ƒå°”å‹æ¦‚å¿µï¼ˆå¦‚ ett_gcsï¼‰ï¼Œä½¿ç”¨ any() èšåˆè€Œä¸æ˜¯ drop_duplicates(keep="last")
        # å› ä¸ºåŒä¸€æ—¶é—´ç‚¹å¯èƒ½æœ‰å¤šä¸ªå€¼ï¼ˆTRUE å’Œ FALSEï¼‰ï¼Œåº”è¯¥å– any(TRUE) = TRUE
        # æ³¨æ„ï¼šleft join å dtype å¯èƒ½ä» bool å˜ä¸º objectï¼ˆå› ä¸º NaNï¼‰ï¼Œéœ€è¦ç‰¹æ®Šæ£€æµ‹
        is_boolean_col = False
        if name in df.columns:
            col = df[name]
            # æ£€æŸ¥ dtype æˆ–è€…æ£€æŸ¥é NA å€¼æ˜¯å¦éƒ½æ˜¯å¸ƒå°”
            if col.dtype == bool or col.dtype == 'boolean':
                is_boolean_col = True
            elif col.dtype == object:
                # æ£€æŸ¥é NA å€¼æ˜¯å¦ä¸ºå¸ƒå°”å‹
                non_na = col.dropna()
                if len(non_na) > 0:
                    is_boolean_col = all(isinstance(v, (bool, np.bool_)) for v in non_na.head(100))
        
        if is_boolean_col:
            # é‡æ–°èšåˆï¼šå¦‚æœåŒä¸€ (id, time) æœ‰ä»»ä½• TRUEï¼Œåˆ™ä¸º TRUE
            # ä½†è¦ä¿ç•™å…¨ NA ç»„ä¸º NAï¼ˆä¸è½¬ä¸º FALSEï¼‰
            def bool_agg_with_na(x):
                """å¸ƒå°”èšåˆï¼Œä¿ç•™å…¨ NA ä¸º NA"""
                non_na = x.dropna()
                if len(non_na) == 0:
                    return np.nan
                return non_na.any()
            
            to_merge = df[keep_cols].groupby(["id", "time"], as_index=False).agg({name: bool_agg_with_na})
            boolean_concepts.append(name)  # è®°å½•å¸ƒå°”æ¦‚å¿µ
        else:
            to_merge = df[keep_cols].drop_duplicates(subset=["id", "time"], keep="last")
        
        merged = merged.merge(to_merge, on=["id", "time"], how="left", suffixes=('', '_drop'))
        # åˆ é™¤é‡å¤åˆ—
        merged = merged[[c for c in merged.columns if not c.endswith('_drop')]]
    
    # é‡å‘½ååˆ—ä»¥åŒ¹é…ricuè¾“å‡º
    merged = merged.rename(columns={"id": id_col, "time": time_col})
    
    return merged


def get_module_concepts(module_name: str) -> List[str]:
    """è·å–æ¨¡å—ä¸­çš„æ‰€æœ‰æ¦‚å¿µ"""
    module = RICU_MODULES.get(module_name)
    if module:
        return module.concepts
    return []


def find_module_for_concept(concept_name: str) -> Optional[str]:
    """æŸ¥æ‰¾æ¦‚å¿µæ‰€å±çš„æ¨¡å—"""
    for module_name, module in RICU_MODULES.items():
        if concept_name in module.concepts:
            return module_name
    return None
