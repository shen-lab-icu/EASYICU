"""
å®Œæ•´çš„æ¦‚å¿µåŠ è½½ç³»ç»Ÿ
å®ç° R ricu çš„ load_concepts åŠŸèƒ½
"""
from typing import List, Optional, Union, Dict, Any, Iterable, Sequence, Mapping
import logging
from datetime import timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd

from .concept import Concept, load_dictionary
from .config import DataSourceConfig, TableConfig, load_src_cfg
from .datasource import ICUDataSource
from .table import load_table
from .ts_utils import change_interval

# DataSource åˆ«åç”¨äºå‘åå…¼å®¹
DataSource = ICUDataSource

# å¸¸è§åˆ—åé›†åˆï¼Œç”¨äºæ¨æµ‹å¯èƒ½éœ€è¦çš„åˆ—
COMMON_ID_COLUMNS = [
    'stay_id', 'icustay_id', 'subject_id', 'hadm_id',
    'patientunitstayid', 'patientid', 'patient_id', 'admissionid',
    'admission_id', 'patienthealthsystemstayid', 'uniquepid',
    'encounter', 'encounter_id', 'visit_id', 'visitid', 'episode_id',
]

ID_TYPE_HINTS = {
    'patient': ['subject_id', 'patientid', 'patient_id', 'uniquepid'],
    'hadm': ['hadm_id', 'admissionid', 'admission_id', 'visit_id', 'encounter_id'],
    'icustay': ['stay_id', 'icustay_id', 'patientunitstayid'],
}

COMMON_TIME_COLUMNS = [
    'charttime', 'time', 'datetime', 'timestamp', 'starttime', 'endtime',
    'intime', 'outtime', 'admittime', 'dischtime', 'createtime',
    'observationoffset', 'chartoffset', 'eventtime', 'realtime'
]

COMMON_VALUE_COLUMNS = [
    'valuenum', 'value', 'valuetext', 'valueasnumber', 'value_as_number',
    'amount', 'totalamount', 'rate', 'dose', 'doseamount', 'dose_val_rx',
    'volume', 'chartvalue', 'resultvalue', 'value1', 'value2', 'value3',
    'drugname', 'amountuom'
]

# ğŸš€ è¡¨ç‰¹å®šçš„æœ€å°åˆ—é›† - åªåŠ è½½å¿…è¦çš„åˆ—ä»¥æå‡æ€§èƒ½
MINIMAL_COLUMNS_MAP = {
    # MIMIC-IV chartevents: åªéœ€è¦6åˆ—è€Œéå…¨éƒ¨11åˆ—
    # åŒ…å«valueåˆ—ä»¥æ”¯æŒå­—ç¬¦ä¸²å‹æ•°æ®ï¼ˆå¦‚è¯ç‰©åç§°ç­‰ï¼‰
    'chartevents': ['stay_id', 'charttime', 'itemid', 'value', 'valuenum', 'valueuom'],
    
    # ğŸ”§ FIX 2026-01-26: MIMIC-III ä½¿ç”¨ icustay_id è€Œé stay_id
    # ç³»ç»Ÿä¼šè‡ªåŠ¨æ ¹æ®æ•°æ®åº“ç±»å‹é€‰æ‹©æ­£ç¡®çš„åˆ—ï¼ˆè§ datasource.py ä¸­çš„åˆ—æ£€æµ‹é€»è¾‘ï¼‰
    'chartevents_mimic': ['icustay_id', 'charttime', 'itemid', 'value', 'valuenum', 'valueuom'],
    
    # MIMIC-IV labevents: åªéœ€è¦6åˆ—è€Œéå…¨éƒ¨16åˆ—  
    # æ³¨æ„: labeventsæ²¡æœ‰stay_idï¼Œéœ€è¦subject_id+hadm_idåç»­å…³è”
    # åŒ…å«valueuomç”¨äºå•ä½è½¬æ¢å›è°ƒï¼ˆå¦‚CRPçš„mg/dLè½¬mg/Lï¼‰
    'labevents': ['subject_id', 'hadm_id', 'charttime', 'itemid', 'valuenum', 'valueuom'],
    
    # ğŸ”§ FIX 2026-01-26: MIMIC-III labevents ä½¿ç”¨ icustay_idï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
    'labevents_mimic': ['subject_id', 'hadm_id', 'icustay_id', 'charttime', 'itemid', 'valuenum', 'valueuom'],
    
    # MIMIC-IV inputevents: è¾“å…¥äº‹ä»¶çš„æ ¸å¿ƒåˆ—
    # åŒ…å«hadm_idç”¨äºæŸäº›éœ€è¦ä½é™¢çº§åˆ«èšåˆçš„æ¦‚å¿µï¼ˆå¦‚abxï¼‰
    'inputevents': ['stay_id', 'hadm_id', 'starttime', 'endtime', 'itemid', 'amount', 'amountuom', 'rate', 'linkorderid'],
    
    # MIMIC-IV outputevents: è¾“å‡ºäº‹ä»¶çš„æ ¸å¿ƒåˆ—
    'outputevents': ['stay_id', 'charttime', 'itemid', 'value'],
    
    # MIMIC-IV procedureevents: æ“ä½œäº‹ä»¶çš„æ ¸å¿ƒåˆ—
    'procedureevents': ['stay_id', 'starttime', 'endtime', 'itemid', 'value'],
    
    # eICU vitalperiodic: ç”Ÿå‘½ä½“å¾å‘¨æœŸè¡¨
    # ğŸ”§ FIX: æ·»åŠ  sao2 åˆ—ç”¨äº o2sat å’Œ spo2 æ¦‚å¿µ
    'vitalperiodic': ['patientunitstayid', 'observationoffset', 'temperature', 'heartrate', 
                      'respiration', 'systemicsystolic', 'systemicdiastolic', 'systemicmean', 'sao2'],
    
    # eICU lab: å®éªŒå®¤æ£€æŸ¥
    # åŒ…å«labmeasurenameinterfaceç”¨äºå•ä½è½¬æ¢å›è°ƒï¼ˆå¦‚calciumçš„mmol/lè½¬mg/dLï¼‰
    'lab': ['patientunitstayid', 'labresultoffset', 'labname', 'labresult', 'labmeasurenameinterface'],
    
    # AUMC numericitems: æ•°å€¼é¡¹ç›®è¡¨ - åŒ…å« measuredat æ—¶é—´åˆ—
    # AUMC æ—¶é—´å•ä½: measuredat æ˜¯æ¯«ç§’ï¼Œéœ€è¦å‡å» admittedat å¹¶è½¬æ¢ä¸ºå°æ—¶
    # ğŸ”§ FIX: æ·»åŠ  tag åˆ—ç”¨äº aumc_bxs å›è°ƒï¼ˆbe æ¦‚å¿µéœ€è¦æ ¹æ® tag='-' å–åå€¼ï¼‰
    'numericitems': ['admissionid', 'itemid', 'value', 'unit', 'measuredat', 'tag'],
    
    # æ³¨æ„ï¼šadmissions è¡¨ä¸åŒæ•°æ®åº“åˆ—åä¸åŒï¼Œä¸çº³å…¥ä¼˜åŒ–
    # AUMC: admissionid, patientid, admittedat, dischargedat, destination
    # MIIV: hadm_id, subject_id, admittime, dischtime, deathtime, hospital_expire_flag
    # å› æ­¤ä¸åœ¨æ­¤å¤„é…ç½®ï¼Œè®©ç³»ç»ŸåŠ è½½æ‰€æœ‰åˆ—
}

# æ€§èƒ½ä¼˜åŒ–å¼€å…³ - å¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥ç¦ç”¨
USE_MINIMAL_COLUMNS = True

logger = logging.getLogger(__name__)

class ConceptLoader:
    """æ¦‚å¿µåŠ è½½å™¨ - å¤åˆ» R ricu çš„ load_concepts"""
    
    def __init__(self, src: Union[str, DataSource, DataSourceConfig], data_path: Optional[str] = None, low_memory: Optional[bool] = None):
        """
        åˆå§‹åŒ–æ¦‚å¿µåŠ è½½å™¨
        
        Args:
            src: æ•°æ®æºåç§°æˆ– DataSource å¯¹è±¡
            data_path: æ•°æ®è·¯å¾„
            low_memory: ä½å†…å­˜æ¨¡å¼ï¼ˆNone=è‡ªåŠ¨æ£€æµ‹ï¼ŒTrue=å¼ºåˆ¶å¯ç”¨ï¼ŒFalse=ç¦ç”¨ï¼‰
                        ä½å†…å­˜æ¨¡å¼ä½¿ç”¨ DuckDB filter pushdownï¼Œé¿å…åŠ è½½å…¨è¡¨
        """
        self._data_source: Optional[ICUDataSource] = None
        if isinstance(src, ICUDataSource):
            self._data_source = src
            self.src = src.config
        elif isinstance(src, DataSourceConfig):
            self.src = src
        elif isinstance(src, str):
            self.src = load_src_cfg(src)
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {type(src)}")
        self._src_name = self.src.name
        self.data_path = data_path
        
        # ğŸš€ ä½å†…å­˜æ¨¡å¼ï¼šè‡ªåŠ¨æ£€æµ‹æˆ–æ‰‹åŠ¨æŒ‡å®š
        # HiRID å¼ºåˆ¶ä½¿ç”¨ä½å†…å­˜æ¨¡å¼ï¼ˆobservations è¡¨æœ‰ 7.77 äº¿è¡Œï¼‰
        if self._src_name == 'hirid':
            self._low_memory = True
        elif low_memory is not None:
            self._low_memory = low_memory
        else:
            # è‡ªåŠ¨æ£€æµ‹ï¼šå¯ç”¨å†…å­˜ < 24GB æ—¶å¯ç”¨ä½å†…å­˜æ¨¡å¼
            try:
                import psutil
                available_gb = psutil.virtual_memory().available / (1024 ** 3)
                self._low_memory = available_gb < 24
            except ImportError:
                self._low_memory = False
        
        # ğŸš€ ä½å†…å­˜æ¨¡å¼ä¸‹ï¼Œè‡ªåŠ¨åˆ›å»º ICUDataSource ä»¥å¯ç”¨ filter pushdown
        if self._low_memory and self._data_source is None and data_path:
            try:
                self._data_source = ICUDataSource(self.src, base_path=data_path)
                logger.info(f"ğŸ§  ä½å†…å­˜æ¨¡å¼å¯ç”¨ for {self._src_name}")
            except Exception as e:
                logger.warning(f"æ— æ³•åˆ›å»º ICUDataSource: {e}")
        
        self._id_lookup_cache: Optional[pd.DataFrame] = None
        self._table_cache: Dict[str, pd.DataFrame] = {}
    
    def _get_table_config(self, table_name: Optional[str]) -> Optional[TableConfig]:
        """æ ¹æ®è¡¨åè·å–é…ç½®ã€‚"""
        if not table_name or not hasattr(self.src, 'tables'):
            return None
        return self.src.tables.get(table_name)
    
    def _infer_required_columns(
        self,
        table_name: Optional[str],
        id_type: str,
        extra_candidates: Optional[Sequence[str]] = None,
    ) -> Optional[List[str]]:
        """æ ¹æ®è¡¨é…ç½®å’Œæ¦‚å¿µéœ€æ±‚æ¨æ–­éœ€è¦åŠ è½½çš„åˆ— - ä¼˜åŒ–ç‰ˆï¼ŒåªåŠ è½½å¿…è¦åˆ—"""
        
        # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨æœ€å°åˆ—é›†ï¼ˆå‡å°‘50-70%çš„I/Oï¼‰
        if USE_MINIMAL_COLUMNS and table_name in MINIMAL_COLUMNS_MAP:
            base_cols = list(MINIMAL_COLUMNS_MAP[table_name])
            
            # æ·»åŠ é¢å¤–éœ€è¦çš„åˆ—ï¼ˆå¦‚sub_var, val_varç­‰ï¼‰
            if extra_candidates:
                for col in extra_candidates:
                    if col and col not in base_cols:
                        base_cols.append(col)
            
            # ç¡®ä¿æœ‰IDåˆ— - åŒ…æ‹¬ AUMC çš„ admissionid
            has_id = any(id_col in base_cols for id_col in 
                        ['stay_id', 'icustay_id', 'subject_id', 'patientunitstayid', 'hadm_id', 'admissionid'])
            if not has_id:
                # æ·»åŠ IDç±»å‹å¯¹åº”çš„åˆ—
                id_candidates = ID_TYPE_HINTS.get(id_type, ['stay_id'])
                base_cols.insert(0, id_candidates[0])
            
            return base_cols
        
        # å›é€€åˆ°åŸæœ‰é€»è¾‘ï¼ˆç”¨äºä¸åœ¨æœ€å°åˆ—é›†æ˜ å°„ä¸­çš„è¡¨ï¼Œå¦‚icustaysç­‰ï¼‰
        table_cfg = self._get_table_config(table_name)
        defaults = table_cfg.defaults if table_cfg else None
        available = (
            set(table_cfg.columns.keys())
            if table_cfg and table_cfg.columns
            else None
        )
        
        candidates: List[str] = []
        if defaults:
            if defaults.id_var:
                candidates.append(defaults.id_var)
            if defaults.index_var:
                candidates.append(defaults.index_var)
            if defaults.val_var:
                candidates.append(defaults.val_var)
            if defaults.unit_var:
                candidates.append(defaults.unit_var)
            candidates.extend(defaults.time_vars or [])
        
        if extra_candidates:
            candidates.extend(extra_candidates)
        
        # ID åˆ—å’Œé€šç”¨åˆ—å€™é€‰
        candidates.extend(ID_TYPE_HINTS.get(id_type, []))
        candidates.extend(COMMON_ID_COLUMNS)
        candidates.extend(COMMON_TIME_COLUMNS)
        candidates.extend(COMMON_VALUE_COLUMNS)
        
        filtered: List[str] = []
        seen: set[str] = set()
        for col in candidates:
            if not col or col in seen:
                continue
            if available is not None and col not in available:
                continue
            filtered.append(col)
            seen.add(col)
        
        return filtered or None
    
    def _safe_load_table(
        self,
        table_name: str,
        columns: Optional[Iterable[str]],
    ) -> pd.DataFrame:
        """åœ¨åˆ—è¿‡æ»¤å¤±è´¥æ—¶å›é€€åˆ°å…¨è¡¨åŠ è½½ã€‚"""
        # Check cache first
        if table_name in self._table_cache:
            return self._table_cache[table_name]

        # ğŸš€ åŠ è½½è¡¨å¹¶å­˜å…¥ç¼“å­˜
        df = None
        if columns:
            try:
                df = load_table(self._src_name, table_name, columns=list(columns), path=self.data_path)
            except Exception:
                # å›é€€åˆ°åŠ è½½å…¨éƒ¨åˆ—ï¼Œç¡®ä¿å…¼å®¹ç¼ºå°‘åˆ—æè¿°çš„è¡¨
                df = load_table(self._src_name, table_name, path=self.data_path)
        else:
            df = load_table(self._src_name, table_name, path=self.data_path)
        
        # ğŸš€ å­˜å…¥ç¼“å­˜ä»¥ä¾›åç»­å¤ç”¨
        if df is not None:
            self._table_cache[table_name] = df
        
        return df
    
    def _columns_for_source(self, source, id_type: str) -> Optional[List[str]]:
        """æå– ConceptSource æ‰€éœ€çš„åˆ—ã€‚"""
        extra: List[str] = []
        if getattr(source, 'sub_var', None):
            extra.append(source.sub_var)
        if getattr(source, 'value_var', None):
            extra.append(source.value_var)
        if getattr(source, 'index_var', None):
            extra.append(source.index_var)
        if getattr(source, 'unit_var', None):
            extra.append(source.unit_var)
        
        # DEBUG: è¾“å‡ºæå–çš„åˆ—ä¿¡æ¯
        result = self._infer_required_columns(source.table, id_type, extra)
        logger.debug(f"_columns_for_source: table={source.table}, sub_var={getattr(source, 'sub_var', None)}, extra={extra}, result={result}")
        return result
    
    def _columns_for_item(self, item: Mapping[str, Any], id_type: str) -> Optional[List[str]]:
        """æå–æ—§å¼ item é…ç½®æ‰€éœ€åˆ—ã€‚"""
        extra: List[str] = []
        for key in ['sub_var', 'val_var', 'value_var', 'time_var', 'index_var']:
            value = item.get(key)
            if isinstance(value, str):
                extra.append(value)
        return self._infer_required_columns(item.get('table'), id_type, extra)

    def _canonical_id_column(self, id_type: str) -> str:
        """æ ¹æ®æ•°æ®æºé…ç½®è¿”å›æŒ‡å®šIDç±»å‹çš„æ ‡å‡†åˆ—åã€‚"""
        cfg = self.src.id_configs.get(id_type) if hasattr(self.src, 'id_configs') else None
        if cfg and getattr(cfg, 'id', None):
            return cfg.id
        fallback = {
            'icustay': 'stay_id',
            'hadm': 'hadm_id',
            'patient': 'subject_id',
        }
        return fallback.get(id_type, id_type)

    def _coerce_patient_list(self, patient_ids: Union[List, Sequence, set, pd.Series, pd.DataFrame, None]) -> List[Any]:
        """å°† patient_ids å½’ä¸€åŒ–ä¸ºç®€å•åˆ—è¡¨ã€‚"""
        if patient_ids is None:
            return []
        values: List[Any] = []
        if isinstance(patient_ids, pd.DataFrame):
            for column in patient_ids.columns:
                col_vals = patient_ids[column].tolist()
                for value in col_vals:
                    if pd.isna(value):
                        continue
                    values.append(value)
            return values
        if isinstance(patient_ids, pd.Series):
            return [value for value in patient_ids.tolist() if not pd.isna(value)]
        if isinstance(patient_ids, (list, tuple, set)):
            return [value for value in patient_ids if not pd.isna(value)]
        return [patient_ids] if not pd.isna(patient_ids) else []

    def _load_id_lookup(self) -> pd.DataFrame:
        """åŠ è½½åŒ…å« stay/hadm/subject æ˜ å°„çš„å‚è€ƒè¡¨ï¼Œç”¨äºIDè½¬æ¢ã€‚"""
        if self._id_lookup_cache is not None:
            return self._id_lookup_cache

        cfg = getattr(self.src, 'id_configs', {}).get('icustay') if hasattr(self.src, 'id_configs') else None
        table_name = cfg.table if cfg and getattr(cfg, 'table', None) else None
        if not table_name:
            self._id_lookup_cache = pd.DataFrame()
            return self._id_lookup_cache

        desired_cols = {
            'stay_id', 'icustay_id', 'patientunitstayid', 'hadm_id', 'subject_id',
            'admissionid', 'patientid', 'patient_id', 'admission_id'
        }
        for id_cfg in getattr(self.src, 'id_configs', {}).values():
            if getattr(id_cfg, 'id', None):
                desired_cols.add(id_cfg.id)

        table_cfg = self._get_table_config(table_name)
        available = set(table_cfg.columns.keys()) if table_cfg and table_cfg.columns else None
        columns = [col for col in desired_cols if (available is None or col in available)]
        columns = columns or None

        try:
            lookup = self._safe_load_table(table_name, columns)
        except Exception as exc:
            logger.warning("æ— æ³•åŠ è½½IDæ˜ å°„è¡¨ %s: %s", table_name, exc)
            lookup = pd.DataFrame()

        self._id_lookup_cache = lookup
        return lookup

    def _map_patient_ids_to_column(
        self,
        patient_ids: List[Any],
        id_type: str,
        target_column: Optional[str],
    ) -> Optional[List[Any]]:
        """å°†åŸºäº id_type çš„ patient_ids æ˜ å°„åˆ°ç›®æ ‡åˆ—çš„å–å€¼é›†åˆã€‚"""
        if target_column is None:
            return patient_ids
        canonical_col = self._canonical_id_column(id_type)
        if canonical_col.lower() == target_column.lower():
            return patient_ids
        lookup = self._load_id_lookup()
        if lookup.empty or canonical_col not in lookup.columns or target_column not in lookup.columns:
            return None
        if not patient_ids:
            return []
        subset = lookup[lookup[canonical_col].isin(patient_ids)]
        if subset.empty:
            return []
        mapped = subset[target_column].dropna().unique().tolist()
        return mapped
            
    def load_concepts(
        self,
        concepts: Union[str, List[str], Concept, List[Concept]],
        patient_ids: Optional[Union[List, pd.DataFrame]] = None,
        id_type: str = 'icustay',
        interval: Optional[timedelta] = None,
        aggregate: Optional[Union[str, Dict[str, str]]] = None,
        merge_data: bool = True,
        verbose: bool = True,
        **kwargs
    ) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
        """
        åŠ è½½æ¦‚å¿µæ•°æ®
        
        Args:
            concepts: æ¦‚å¿µåç§°ã€IDæˆ–Conceptå¯¹è±¡
            patient_ids: æ‚£è€…IDåˆ—è¡¨æˆ–åŒ…å«IDçš„DataFrame
            id_type: IDç±»å‹ (patient, hadm, icustayç­‰)
            interval: æ—¶é—´é—´éš” (å¦‚ timedelta(hours=1))
            aggregate: èšåˆå‡½æ•° ('mean', 'sum', 'min', 'max' æˆ–å­—å…¸)
            merge_data: æ˜¯å¦åˆå¹¶ä¸ºå®½æ ¼å¼è¡¨
            verbose: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
            
        Returns:
            DataFrame æˆ–å­—å…¸ (å–å†³äº merge_data)
        """
        # 1. è§£ææ¦‚å¿µ
        if isinstance(concepts, str):
            concepts = [concepts]
        
        if isinstance(concepts, list) and all(isinstance(c, str) for c in concepts):
            # ä»å­—å…¸åŠ è½½æ¦‚å¿µ
            # å¦‚æœè¯·æ±‚çš„æ¦‚å¿µä¸­åŒ…å« SOFA-2 ç›¸å…³æ¦‚å¿µï¼Œè‡ªåŠ¨åŠ è½½ sofa2-dict
            sofa2_concepts = {'sofa2', 'sofa2_resp', 'sofa2_coag', 'sofa2_liver', 
                              'sofa2_cardio', 'sofa2_cns', 'sofa2_renal',
                              'uo_6h', 'uo_12h', 'uo_24h', 'rrt_criteria', 'rrt',
                              'adv_resp', 'ecmo', 'ecmo_indication', 'sedated_gcs',
                              'mech_circ_support', 'other_vaso', 'delirium_tx',
                              'motor_response', 'delirium_positive'}
            include_sofa2 = any(c in sofa2_concepts for c in concepts)
            
            concept_dict = load_dictionary(self._src_name, include_sofa2=include_sofa2)
            concept_objs = [concept_dict[name] for name in concepts]
        elif isinstance(concepts, Concept):
            concept_objs = [concepts]
        elif isinstance(concepts, list) and all(isinstance(c, Concept) for c in concepts):
            concept_objs = concepts
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¦‚å¿µç±»å‹: {type(concepts)}")
        
        # 2. è®¾ç½®é»˜è®¤å€¼
        if interval is None:
            interval = timedelta(hours=1)
        
        # ğŸš€ æ™ºèƒ½å¹¶è¡Œé…ç½®ï¼šæ ¹æ®æ¦‚å¿µæ•°é‡è‡ªåŠ¨ä¼˜åŒ–
        user_concept_workers = kwargs.get('concept_workers')
        if user_concept_workers is None:
            # è‡ªåŠ¨è®¡ç®—æœ€ä½³å¹¶è¡Œæ•°
            import os
            num_concepts = len(concept_objs)
            if num_concepts >= 3:
                cpu_count = os.cpu_count() or 4
                parallel_workers = min(num_concepts, max(2, cpu_count // 2))
            elif num_concepts == 2:
                parallel_workers = 2
            else:
                parallel_workers = 1
        else:
            parallel_workers = user_concept_workers
            
        enable_parallel = len(concept_objs) > 1 and parallel_workers > 1
        
        # ğŸš€ Preload tablesï¼ˆä¼˜åŒ–ï¼šå¹¶è¡Œæ¨¡å¼ä¸‹æ›´æ¿€è¿›çš„é¢„åŠ è½½ï¼‰
        self._preload_tables(concept_objs, patient_ids, id_type, verbose=verbose, 
                             parallel_mode=enable_parallel)
        
        # 3. åŠ è½½æ¯ä¸ªæ¦‚å¿µ - æ”¯æŒå¹¶è¡ŒåŠ è½½
        results = {}
        
        if enable_parallel:
            # ğŸš€ å¹¶è¡ŒåŠ è½½æ¦‚å¿µ
            max_workers = min(parallel_workers, len(concept_objs))
            if verbose:
                print(f"ğŸš€ å¹¶è¡ŒåŠ è½½ {len(concept_objs)} ä¸ªæ¦‚å¿µ (å·¥ä½œçº¿ç¨‹: {max_workers})...")
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_concept = {
                    executor.submit(
                        self._load_one_concept,
                        concept=concept,
                        patient_ids=patient_ids,
                        id_type=id_type,
                        interval=interval,
                        aggregate=aggregate if not isinstance(aggregate, dict) else aggregate.get(concept.name),
                        **kwargs
                    ): concept
                    for concept in concept_objs
                }
                
                for future in as_completed(future_to_concept):
                    concept = future_to_concept[future]
                    try:
                        data = future.result()
                        if verbose:
                            print(f"  âœ… {concept.name}")
                        if data is not None and len(data) > 0:
                            results[concept.name] = data
                    except Exception as e:
                        if verbose:
                            print(f"  âŒ {concept.name}: {e}")
                        logger.error(f"åŠ è½½æ¦‚å¿µ {concept.name} å¤±è´¥", exc_info=True)
        else:
            # ä¸²è¡ŒåŠ è½½ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
            for concept in concept_objs:
                if verbose:
                    print(f"åŠ è½½æ¦‚å¿µ: {concept.name}")
                
                # åŠ è½½å•ä¸ªæ¦‚å¿µ
                data = self._load_one_concept(
                    concept=concept,
                    patient_ids=patient_ids,
                    id_type=id_type,
                    interval=interval,
                    aggregate=aggregate if not isinstance(aggregate, dict) else aggregate.get(concept.name),
                    **kwargs
                )
                
                if data is not None and len(data) > 0:
                    results[concept.name] = data
        
        # 4. åˆå¹¶æˆ–è¿”å›
        if not merge_data:
            # è½¬æ¢æ—¶é—´åˆ—ä¸ºç›¸å¯¹å°æ—¶æ•°
            for name in results:
                results[name] = self._convert_time_to_hours(results[name], id_type)
            return results
        
        if len(results) == 0:
            return pd.DataFrame()
        
        if len(results) == 1:
            single_result = list(results.values())[0]
            return self._convert_time_to_hours(single_result, id_type)
        
        # åˆå¹¶å¤šä¸ªæ¦‚å¿µä¸ºå®½æ ¼å¼
        merged = self._merge_concepts(results, id_type)
        return self._convert_time_to_hours(merged, id_type)
    
    def _load_one_concept(
        self,
        concept: Concept,
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        interval: timedelta,
        aggregate: Optional[str],
        **kwargs
    ) -> pd.DataFrame:
        """
        åŠ è½½å•ä¸ªæ¦‚å¿µ
        
        Args:
            concept: Concept å¯¹è±¡
            patient_ids: æ‚£è€…ID
            id_type: IDç±»å‹
            interval: æ—¶é—´é—´éš”
            aggregate: èšåˆå‡½æ•°
            
        Returns:
            DataFrame
        """
        # ğŸš€ ä¼˜åŒ–ï¼šå¯¹äº rec_cncpt ç±»å‹çš„æ¦‚å¿µï¼ˆå¦‚ vent_indï¼‰ï¼Œ
        # ç›´æ¥ä½¿ç”¨ ConceptResolverï¼Œå› ä¸ºå®ƒä»¬éœ€è¦concept_callbacksä¸­çš„å›è°ƒå‡½æ•°
        if hasattr(concept, 'class_name') and concept.class_name == 'rec_cncpt':
            from .concept import ConceptResolver
            from .ts_utils import ICUTable
            
            # ğŸš€ é‡è¦ï¼šå¿…é¡»é‡ç”¨ ConceptLoader çš„æ•°æ®æºï¼Œä»¥ä¾¿å…±äº«è¡¨ç¼“å­˜å’Œé¢„åŠ è½½çš„æ•°æ®
            # å¦‚æœåˆ›å»ºæ–°çš„æ•°æ®æºï¼Œé¢„åŠ è½½çš„è¡¨ä¼šä¸¢å¤±
            if self._data_source is None:
                raise RuntimeError("rec_cncpt concepts require a data source, but none is available")
            
            data_source = self._data_source
            
            # åˆ›å»º ConceptResolverï¼ˆå®ƒä¼šä»æ•°æ®æºåŠ è½½è¡¨ï¼‰
            resolver = ConceptResolver(load_dictionary(self._src_name))
            
            # ä½¿ç”¨ ConceptResolver åŠ è½½
            # è¿‡æ»¤æ‰ ConceptLoader ç‰¹æœ‰çš„å‚æ•°å’Œå·²ç»æ˜¾å¼ä¼ é€’çš„å‚æ•°
            excluded_kwargs = {'verbose', 'merge_data', 'id_type', 'merge', 'patient_ids', 'interval', 'aggregate', 'ricu_compatible'}
            resolver_kwargs = {k: v for k, v in kwargs.items() if k not in excluded_kwargs}
            
            result = resolver.load_concepts(
                [concept.name],
                data_source=data_source,
                merge=False,
                patient_ids=patient_ids,
                interval=interval,
                aggregate=aggregate,
                verbose=kwargs.get('verbose', False),
                ricu_compatible=False,  # ğŸ”§ FIX: å¼ºåˆ¶è¿”å› dict[str, ICUTable]ï¼Œä»¥ä¾¿æ­£ç¡®æå–æ•°æ®
                **resolver_kwargs
            )
            
            # æå–DataFrame
            if isinstance(result, dict) and concept.name in result:
                result_table = result[concept.name]
                if isinstance(result_table, ICUTable):
                    return result_table.data
                return result_table
            # ğŸ”§ FIX: å¦‚æœè¿”å›çš„æ˜¯ DataFrameï¼ˆricu_compatible=True çš„æƒ…å†µï¼‰ï¼Œç›´æ¥è¿”å›
            elif isinstance(result, pd.DataFrame):
                return result
            return pd.DataFrame()
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºé€’å½’æ¦‚å¿µï¼ˆæœ‰å­æ¦‚å¿µï¼‰- è¿™ä¸ªåˆ†æ”¯ç°åœ¨ä¸»è¦ç”¨äºé rec_cncpt ç±»å‹
        if concept.sub_concepts and len(concept.sub_concepts) > 0:
            # é€’å½’æ¦‚å¿µ - ä½¿ç”¨å›è°ƒ
            return self._load_recursive_concept(
                concept, patient_ids, id_type, interval, aggregate, **kwargs
            )
        
        # 2. æ™®é€šæ¦‚å¿µ - ä»è¡¨ä¸­åŠ è½½
        # è·å–å½“å‰æ•°æ®æºçš„ ConceptSource é…ç½®
        sources = concept.for_data_source(self.src)
        if not sources:
            return pd.DataFrame()
        
        all_data = []
        
        for source in sources:
            # åŠ è½½sourceæ•°æ®
            df = self._load_concept_source(
                source=source,
                concept_name=concept.name,
                patient_ids=patient_ids,
                id_type=id_type,
                interval=interval
            )
            
            if df is not None and len(df) > 0:
                all_data.append(df)
        
        if not all_data:
            return pd.DataFrame()
        
        # 3. åˆå¹¶æ‰€æœ‰sourceæ•°æ®
        data = pd.concat(all_data, ignore_index=True)
        
        # 4. è¿‡æ»¤å’Œè½¬æ¢
        data = self._filter_concept_data(data, concept)
        
        # 5. é‡å‘½ååˆ—
        if 'value' in data.columns:
            data = data.rename(columns={'value': concept.name})
        
        # 6. èšåˆ
        if aggregate and len(data) > 0:
            data = self._aggregate_concept(data, concept, aggregate, id_type, interval)
        
        return data
    
    def _load_item(
        self,
        item: Dict[str, Any],
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        interval: timedelta
    ) -> pd.DataFrame:
        """
        åŠ è½½å•ä¸ªitem
        
        Args:
            item: itemå­—å…¸
            patient_ids: æ‚£è€…ID
            id_type: IDç±»å‹
            interval: æ—¶é—´é—´éš”
            
        Returns:
            DataFrame
        """
        # 1. åŠ è½½è¡¨
        table_name = item.get('table')
        if not table_name:
            return pd.DataFrame()
        
        required_columns = self._columns_for_item(item, id_type)
        
        # ğŸ” è°ƒè¯•ï¼šæ˜¾ç¤ºæ¨æ–­çš„åˆ—
        if required_columns:
            import logging
            logger = logging.getLogger('pyricu.load_concepts')
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(f"   ğŸ”¹ è¡¨ {table_name} æ¨æ–­çš„åˆ—: {required_columns}")
        
        try:
            df = self._safe_load_table(table_name, required_columns)
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½è¡¨ {table_name}: {e}")
            return pd.DataFrame()
        
        # 2. è¿‡æ»¤æ‚£è€…
        if patient_ids is not None:
            id_col = self._get_id_column(df, id_type)
            if id_col:
                filter_values: Optional[List[Any]] = None
                if isinstance(patient_ids, pd.DataFrame):
                    if id_col in patient_ids.columns:
                        filter_values = [val for val in patient_ids[id_col].tolist() if not pd.isna(val)]
                    else:
                        canonical_col = self._canonical_id_column(id_type)
                        if canonical_col in patient_ids.columns:
                            base_values = [val for val in patient_ids[canonical_col].tolist() if not pd.isna(val)]
                            filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)
                else:
                    base_values = self._coerce_patient_list(patient_ids)
                    filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)

                if filter_values is not None:
                    if not filter_values:
                        return pd.DataFrame()
                    df = df[df[id_col].isin(filter_values)]
        
        # 3. è¿‡æ»¤itemå€¼
        val_col = item.get('val_var', 'value')
        sub_col = item.get('sub_var')
        
        if sub_col and sub_col in df.columns:
            # è¿‡æ»¤ç‰¹å®šå€¼
            target_vals = item.get('target', [])
            if target_vals:
                df = df[df[sub_col].isin(target_vals)]
        
        # 4. é€‰æ‹©éœ€è¦çš„åˆ—
        required_cols = [self._get_id_column(df, id_type)]
        
        # æ—¶é—´åˆ—
        time_col = self._get_time_column(df)
        if time_col:
            required_cols.append(time_col)
        
        # å€¼åˆ—
        if val_col in df.columns:
            required_cols.append(val_col)
        
        # è¿‡æ»¤åˆ—
        required_cols = [c for c in required_cols if c and c in df.columns]
        df = df[required_cols].copy()
        
        # 5. é‡å‘½åä¸ºæ ‡å‡†åˆ—å
        rename_map = {}
        if time_col and time_col != 'time':
            rename_map[time_col] = 'time'
        if val_col and val_col != 'value':
            rename_map[val_col] = 'value'
        
        if rename_map:
            df = df.rename(columns=rename_map)
        
        # 6. å¯¹é½æ—¶é—´é—´éš”
        if 'time' in df.columns and interval:
            df = change_interval(df, interval=interval, time_col='time')
        
        return df
    
    def _load_concept_source(
        self,
        source,  # ConceptSource object
        concept_name: str,
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        interval: timedelta
    ) -> pd.DataFrame:
        """
        ä» ConceptSource åŠ è½½æ•°æ®
        
        Args:
            source: ConceptSource å¯¹è±¡
            concept_name: æ¦‚å¿µåç§°
            patient_ids: æ‚£è€…ID
            id_type: IDç±»å‹
            interval: æ—¶é—´é—´éš”
            
        Returns:
            DataFrame
        """
        # 1. åŠ è½½è¡¨
        table_name = source.table
        if not table_name:
            return pd.DataFrame()
        
        # ğŸ”§ FIX: å¯¹äºæœ‰callbackçš„æ¦‚å¿µï¼Œéœ€è¦åŠ è½½callbackæ‰€éœ€çš„æ‰€æœ‰åˆ—
        # ä¾‹å¦‚ hirid_rate_kg éœ€è¦ givendose, doseunit, infusionid ç­‰
        has_callback = getattr(source, 'callback', None) is not None
        
        if has_callback:
            # å¯¹äºæœ‰callbackçš„æ¦‚å¿µï¼ŒåŠ è½½è¡¨ä¸­æ‰€æœ‰ç›¸å…³åˆ—è€Œä¸æ˜¯åªåŠ è½½æ ‡å‡†åˆ—
            # å› ä¸ºcallbackå‡½æ•°éœ€è¦è®¿é—®æ›´å¤šçš„åˆ—ï¼ˆå¦‚ givendose, doseunit, infusionidï¼‰
            required_columns = self._columns_for_source(source, id_type)
            # æ·»åŠ callbackå¯èƒ½éœ€è¦çš„é¢å¤–åˆ—
            callback_extra_cols = []
            if source.callback in ('hirid_rate_kg', 'hirid_rate', 'hirid_duration'):
                callback_extra_cols = ['givendose', 'doseunit', 'infusionid', 'givenat']
            elif source.callback in ('aumc_rate_kg', 'aumc_rate'):
                callback_extra_cols = ['dose', 'doseunit', 'doseunitid', 'rate', 'rateunit', 'infusionid', 'start', 'stop']
            elif source.callback in ('mimic_rate_cv', 'mimic_rate_mv'):
                callback_extra_cols = ['amount', 'amountuom', 'rate', 'rateuom', 'ordercategorydescription']
            
            if required_columns is None:
                required_columns = callback_extra_cols
            else:
                for col in callback_extra_cols:
                    if col not in required_columns:
                        required_columns.append(col)
        else:
            required_columns = self._columns_for_source(source, id_type)
        
        try:
            df = self._safe_load_table(table_name, required_columns)
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½è¡¨ {table_name}: {e}")
            return pd.DataFrame()
        
        # 2. è¿‡æ»¤ sub_var (å¦‚ itemid)
        if source.sub_var and source.ids:
            if source.sub_var not in df.columns:
                print(f"è­¦å‘Š: è¡¨ {table_name} ä¸­æ‰¾ä¸åˆ°åˆ— {source.sub_var}")
                return pd.DataFrame()
            df = df[df[source.sub_var].isin(source.ids)]
        
        if len(df) == 0:
            return pd.DataFrame()
        
        # 3. è¿‡æ»¤æ‚£è€…
        id_col = self._get_id_column(df, id_type)
        if patient_ids is not None:
            if id_col:
                filter_values: Optional[List[Any]] = None
                if isinstance(patient_ids, pd.DataFrame):
                    if id_col in patient_ids.columns:
                        filter_values = [val for val in patient_ids[id_col].tolist() if not pd.isna(val)]
                    else:
                        canonical_col = self._canonical_id_column(id_type)
                        if canonical_col in patient_ids.columns:
                            base_values = [val for val in patient_ids[canonical_col].tolist() if not pd.isna(val)]
                            filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)
                else:
                    base_values = self._coerce_patient_list(patient_ids)
                    filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)

                if filter_values is not None:
                    if not filter_values:
                        return pd.DataFrame()
                    df = df[df[id_col].isin(filter_values)]
        
        # ğŸ”§ FIX: å¯¹äºæœ‰callbackçš„æ¦‚å¿µï¼Œè°ƒç”¨callbackå¤„ç†æ•°æ®
        # callbackä¼šå¤„ç†åˆ—é€‰æ‹©ã€å€¼è½¬æ¢ã€æ—¶é—´æ‰©å±•ç­‰é€»è¾‘
        if has_callback:
            from .concept import _apply_callback
            
            # è·å–patient weightï¼ˆå¦‚æœcallbackéœ€è¦ï¼‰
            if source.callback in ('hirid_rate_kg', 'aumc_rate_kg', 'sic_rate_kg') and 'weight' not in df.columns:
                weight_df = self._get_patient_weights(df, id_col, id_type)
                if weight_df is not None and not weight_df.empty:
                    df = df.merge(weight_df, on=id_col, how='left')
            
            # è½¬æ¢æ—¶é—´åˆ—ä¸ºæ•°å€¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
            time_col = source.index_var or self._get_time_column(df)
            if time_col and time_col in df.columns:
                df = self._convert_time_column_to_hours(df, time_col, id_col)
            
            # è°ƒç”¨callback
            df = _apply_callback(
                frame=df,
                source=source,
                concept_name=concept_name,
                unit_column=source.unit_var,
                resolver=None,  # ConceptLoaderä¸ä½¿ç”¨resolver
                patient_ids=patient_ids,
                data_source=self._data_source,
                interval=interval,
            )
            
            return df
        
        # 4. ç¡®å®šå€¼åˆ—ï¼ˆæ— callbackæ—¶çš„åŸæœ‰é€»è¾‘ï¼‰
        val_col = source.value_var or 'valuenum'  # é»˜è®¤ä½¿ç”¨ valuenum
        if val_col not in df.columns:
            # å°è¯•å…¶ä»–å¯èƒ½çš„å€¼åˆ—
            for candidate in ['valuenum', 'value', 'amount']:
                if candidate in df.columns:
                    val_col = candidate
                    break
        
        # 5. é€‰æ‹©éœ€è¦çš„åˆ—
        required_cols = [id_col] if id_col else []
        
        # æ—¶é—´åˆ—
        time_col = source.index_var or self._get_time_column(df)
        if time_col and time_col in df.columns:
            required_cols.append(time_col)
        
        # å€¼åˆ—
        if val_col and val_col in df.columns:
            required_cols.append(val_col)
        
        # è¿‡æ»¤åˆ—
        required_cols = [c for c in required_cols if c and c in df.columns]
        if not required_cols:
            return pd.DataFrame()
        
        df = df[required_cols].copy()
        
        # 6. é‡å‘½åä¸ºæ ‡å‡†åˆ—å
        rename_map = {}
        if time_col and time_col != 'time' and time_col in df.columns:
            rename_map[time_col] = 'time'
        if val_col and val_col != 'value' and val_col in df.columns:
            rename_map[val_col] = 'value'
        
        if rename_map:
            df = df.rename(columns=rename_map)
        
        # 7. å¯¹é½æ—¶é—´é—´éš”
        if 'time' in df.columns and interval:
            df = change_interval(df, interval=interval, time_col='time')
        
        return df
    
    def _get_patient_weights(
        self,
        df: pd.DataFrame,
        id_col: str,
        id_type: str
    ) -> Optional[pd.DataFrame]:
        """è·å–æ‚£è€…ä½“é‡æ•°æ®"""
        try:
            from .concept import load_dictionary
            concept_dict = load_dictionary(self._src_name)
            if 'weight' not in concept_dict:
                return None
            
            unique_ids = df[id_col].unique().tolist()
            weight_data = self._load_one_concept(
                concept=concept_dict['weight'],
                patient_ids=unique_ids,
                id_type=id_type,
                interval=timedelta(hours=1),
                aggregate='median'
            )
            
            if weight_data is not None and not weight_data.empty:
                # ç¡®ä¿åªè¿”å›idå’Œweightåˆ—
                if 'value' in weight_data.columns and 'weight' not in weight_data.columns:
                    weight_data = weight_data.rename(columns={'value': 'weight'})
                
                # å–æ¯ä¸ªæ‚£è€…çš„ä¸­ä½æ•°ä½“é‡
                if 'weight' in weight_data.columns:
                    weight_data['weight'] = pd.to_numeric(weight_data['weight'], errors='coerce')
                    weight_data = weight_data.groupby(id_col)['weight'].median().reset_index()
                    return weight_data
            return None
        except Exception as e:
            logger.debug(f"è·å–ä½“é‡æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _convert_time_column_to_hours(
        self,
        df: pd.DataFrame,
        time_col: str,
        id_col: str
    ) -> pd.DataFrame:
        """å°†æ—¶é—´åˆ—ä»datetimeè½¬æ¢ä¸ºç›¸å¯¹ICUå…¥é™¢çš„å°æ—¶æ•°"""
        if time_col not in df.columns:
            return df
        
        time_series = df[time_col]
        if pd.api.types.is_numeric_dtype(time_series):
            # å·²ç»æ˜¯æ•°å€¼ï¼Œä¸éœ€è¦è½¬æ¢
            return df
        
        # å°è¯•è½¬æ¢ä¸ºdatetime
        try:
            df = df.copy()
            df[time_col] = pd.to_datetime(df[time_col], errors='coerce')
            
            # è·å–ICUå…¥é™¢æ—¶é—´
            from .table import load_id_tbl
            icu_times = load_id_tbl(self._src_name, 'icustay', path=self.data_path)
            
            # ğŸ”§ FIX: æ”¯æŒä¸åŒæ•°æ®åº“çš„å…¥é™¢æ—¶é—´åˆ—å
            # MIMIC-IV: intime, HiRID: admissiontime, eICU: hospitaladmittime, AUMC: admittedat
            intime_candidates = ['intime', 'admissiontime', 'hospitaladmittime', 'admittedat']
            intime_col = None
            for cand in intime_candidates:
                if cand in icu_times.columns:
                    intime_col = cand
                    break
            
            if not icu_times.empty and intime_col:
                if id_col and id_col in df.columns and id_col in icu_times.columns:
                    df = df.merge(icu_times[[id_col, intime_col]], on=id_col, how='left')
                    df[intime_col] = pd.to_datetime(df[intime_col], errors='coerce')
                    
                    time_diff = (df[time_col] - df[intime_col]).dt.total_seconds() / 3600
                    df[time_col] = time_diff
                    df = df.drop(columns=[intime_col])
        except Exception as e:
            logger.debug(f"æ—¶é—´è½¬æ¢å¤±è´¥: {e}")
        
        return df
    
    def _load_recursive_concept(
        self,
        concept: Concept,
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        interval: timedelta,
        aggregate: Optional[str],
        **kwargs
    ) -> pd.DataFrame:
        """
        åŠ è½½é€’å½’æ¦‚å¿µï¼ˆä½¿ç”¨å›è°ƒï¼‰- ä¿®å¤å¾ªç¯ä¾èµ–æ£€æµ‹
        
        å®Œå…¨å¤åˆ» R ricu çš„é€’å½’æ¦‚å¿µåŠ è½½é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
        1. å¾ªç¯ä¾èµ–æ£€æµ‹
        2. ä¾èµ–è§£æç¼“å­˜
        3. æ­£ç¡®çš„å­æ¦‚å¿µåŠ è½½é¡ºåº
        
        Args:
            concept: Conceptå¯¹è±¡
            patient_ids: æ‚£è€…ID
            id_type: IDç±»å‹
            interval: æ—¶é—´é—´éš”
            aggregate: èšåˆå‡½æ•°
            
        Returns:
            DataFrame
            
        Raises:
            ValueError: å¦‚æœæ£€æµ‹åˆ°å¾ªç¯ä¾èµ–
        """
        # åˆå§‹åŒ–åŠ è½½æ ˆï¼ˆç”¨äºæ£€æµ‹å¾ªç¯ä¾èµ–ï¼‰
        if not hasattr(self, '_loading_stack'):
            self._loading_stack = set()
        
        # åˆå§‹åŒ–ç¼“å­˜ï¼ˆé¿å…é‡å¤åŠ è½½ç›¸åŒæ¦‚å¿µï¼‰
        if not hasattr(self, '_concept_cache'):
            self._concept_cache = {}
        
        # æ£€æŸ¥å¾ªç¯ä¾èµ–
        if concept.name in self._loading_stack:
            chain = ' -> '.join(self._loading_stack) + f' -> {concept.name}'
            raise ValueError(f"æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–: {chain}")
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = (
            concept.name, 
            str(patient_ids) if patient_ids is not None else None,
            id_type,
            str(interval),
            aggregate
        )
        if cache_key in self._concept_cache:
            return self._concept_cache[cache_key].copy()
        
        # å°†å½“å‰æ¦‚å¿µåŠ å…¥åŠ è½½æ ˆ
        self._loading_stack.add(concept.name)
        
        try:
            # 1. åŠ è½½å­æ¦‚å¿µ
            # ä½¿ç”¨ sub_concepts å±æ€§ï¼ˆè€Œé itemsï¼‰ï¼Œè¿™æ˜¯ ConceptDefinition çš„æ ‡å‡†å­—æ®µ
            sub_concept_names = concept.sub_concepts if hasattr(concept, 'sub_concepts') else []
            sub_data = {}
            
            # æŒ‰ç…§ä¾èµ–é¡ºåºåŠ è½½å­æ¦‚å¿µ
            for sub_name in sub_concept_names:
                try:
                    # ä»å­—å…¸ä¸­åŠ è½½å­æ¦‚å¿µå®šä¹‰
                    concept_dict = load_dictionary(self._src_name)
                    if sub_name not in concept_dict:
                        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°å­æ¦‚å¿µ {sub_name}")
                        continue
                    sub_concept = concept_dict[sub_name]
                    
                    # é€’å½’åŠ è½½å­æ¦‚å¿µ
                    data = self._load_one_concept(
                        sub_concept, patient_ids, id_type, interval, aggregate, **kwargs
                    )
                    
                    if data is not None and len(data) > 0:
                        sub_data[sub_name] = data
                        
                except Exception as e:
                    print(f"è­¦å‘Š: åŠ è½½å­æ¦‚å¿µ {sub_name} å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    continue
            
            if not sub_data:
                result = pd.DataFrame()
            else:
                # 2. åº”ç”¨å›è°ƒå‡½æ•°
                # rec_cncpt ç±»å‹çš„æ¦‚å¿µéœ€è¦é€šè¿‡å›è°ƒå‡½æ•°å¤„ç†å­æ¦‚å¿µ
                # ä½†æ˜¯ ConceptLoader æ¶æ„ä¸ ConceptResolver ä¸åŒ
                # æˆ‘ä»¬éœ€è¦å§”æ‰˜ç»™ ConceptResolver æ¥å¤„ç†å›è°ƒ
                
                # å¦‚æœæ²¡æœ‰å›è°ƒå‡½æ•°ï¼Œç®€å•åˆå¹¶å­æ¦‚å¿µ
                callback_name = concept.callback if hasattr(concept, 'callback') else None
                
                if not callback_name:
                    # æ²¡æœ‰å›è°ƒï¼Œå°è¯•ç®€å•åˆå¹¶
                    if len(sub_data) == 1:
                        result = list(sub_data.values())[0]
                    else:
                        result = self._merge_sub_concepts(sub_data, id_type, interval)
                else:
                    # æœ‰å›è°ƒï¼Œéœ€è¦é€šè¿‡ ConceptResolver å¤„ç†
                    # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸åŒçš„è·¯å¾„ï¼šç›´æ¥å§”æ‰˜ç»™ ConceptResolver
                    from .concept import ConceptResolver
                    from .datasource import ICUDataSource
                    from .config import load_src_cfg
                    from pathlib import Path
                    
                    # åˆ›å»ºæˆ–è·å–æ•°æ®æº
                    if self._data_source is not None:
                        data_source = self._data_source
                    else:
                        # åˆ›å»ºæ–°çš„æ•°æ®æº
                        config = load_src_cfg(self._src_name)
                        data_source = ICUDataSource(config, base_path=Path(self.data_path) if self.data_path else None)
                    
                    # åˆ›å»º ConceptResolver
                    resolver = ConceptResolver(load_dictionary(self._src_name))
                    
                    # ä½¿ç”¨ ConceptResolver åŠ è½½è¿™ä¸ªæ¦‚å¿µ
                    result_dict = resolver.load_concepts(
                        [concept.name],
                        data_source=data_source,
                        merge=False,
                        patient_ids=patient_ids,
                        interval=interval,
                        aggregate=aggregate,
                        verbose=kwargs.get('verbose', False),
                        **kwargs
                    )
                    
                    # æå–ç»“æœ
                    if isinstance(result_dict, dict) and concept.name in result_dict:
                        from .ts_utils import ICUTable
                        result_table = result_dict[concept.name]
                        if isinstance(result_table, ICUTable):
                            result = result_table.data
                        else:
                            result = result_table
                    else:
                        result = pd.DataFrame()
            
            # ç¼“å­˜ç»“æœ
            self._concept_cache[cache_key] = result.copy() if len(result) > 0 else result
            
            return result
            
        finally:
            # ä»åŠ è½½æ ˆä¸­ç§»é™¤å½“å‰æ¦‚å¿µ
            self._loading_stack.discard(concept.name)
    
    def _filter_concept_data(self, data: pd.DataFrame, concept: Concept) -> pd.DataFrame:
        """
        æ ¹æ®æ¦‚å¿µå®šä¹‰è¿‡æ»¤æ•°æ®
        
        Args:
            data: åŸå§‹æ•°æ®
            concept: æ¦‚å¿µå¯¹è±¡
            
        Returns:
            è¿‡æ»¤åçš„æ•°æ®
        """
        if 'value' not in data.columns:
            return data
        
        # 1. è¿‡æ»¤NA
        data = data.dropna(subset=['value'])
        
        # 2. æ•°å€¼èŒƒå›´è¿‡æ»¤
        if hasattr(concept, 'min') and concept.min is not None:
            data = data[data['value'] >= concept.min]
        
        if hasattr(concept, 'max') and concept.max is not None:
            data = data[data['value'] <= concept.max]
        
        # 3. åˆ†ç±»å€¼è¿‡æ»¤
        if hasattr(concept, 'levels') and concept.levels:
            data = data[data['value'].isin(concept.levels)]
        
        # 4. å•ä½è½¬æ¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if hasattr(concept, 'unit') and concept.unit and 'unit' in data.columns:
            data = self._convert_units(data, concept.unit)
        
        return data
    
    def _convert_units(self, data: pd.DataFrame, target_unit: str) -> pd.DataFrame:
        """
        å•ä½è½¬æ¢
        
        Args:
            data: æ•°æ®
            target_unit: ç›®æ ‡å•ä½
            
        Returns:
            è½¬æ¢åçš„æ•°æ®
        """
        # TODO: å®ç°å®Œæ•´çš„å•ä½è½¬æ¢ç³»ç»Ÿ
        # è¿™é‡Œå…ˆåšç®€å•å¤„ç†
        return data
    
    def _aggregate_concept(
        self,
        data: pd.DataFrame,
        concept: Concept,
        aggregate: str,
        id_type: str,
        interval: timedelta
    ) -> pd.DataFrame:
        """
        èšåˆæ¦‚å¿µæ•°æ®
        
        Args:
            data: æ•°æ®
            concept: æ¦‚å¿µ
            aggregate: èšåˆå‡½æ•°å
            id_type: IDç±»å‹
            interval: æ—¶é—´é—´éš”
            
        Returns:
            èšåˆåçš„æ•°æ®
        """
        id_col = self._get_id_column(data, id_type)
        
        group_cols = [id_col]
        if 'time' in data.columns:
            group_cols.append('time')
        
        value_col = concept.name
        
        # æ‰§è¡Œèšåˆ
        agg_dict = {value_col: aggregate}
        result = data.groupby(group_cols, as_index=False).agg(agg_dict)
        
        return result
    
    def _convert_time_to_hours(self, df: pd.DataFrame, id_type: str) -> pd.DataFrame:
        """
        å°†timeåˆ—ä»datetimeè½¬æ¢ä¸ºç›¸å¯¹ICUå…¥é™¢çš„å°æ—¶æ•°,å¹¶æ¸…ç†åˆ—æ ¼å¼ä»¥åŒ¹é…ricuè¾“å‡º
        
        Args:
            df: åŒ…å«timeåˆ—çš„DataFrame
            id_type: IDç±»å‹
            
        Returns:
            timeåˆ—è½¬æ¢ä¸ºæ•°å€¼ã€åˆ—æ ¼å¼ä¸ricuä¸€è‡´çš„DataFrame
        """
        print(f"[DEBUG _convert_time_to_hours] Input: shape={df.shape}, columns={df.columns.tolist()}, id_type={id_type}")
        
        if df.empty:
            return df
        
        df = df.copy()
        
        # æ£€æµ‹æ—¶é—´åˆ—å(å¯èƒ½æ˜¯timeæˆ–charttime)
        time_col_name = None
        if 'time' in df.columns:
            time_col_name = 'time'
        elif 'charttime' in df.columns:
            time_col_name = 'charttime'
        
        # 1. è½¬æ¢æ—¶é—´åˆ—ä¸ºç›¸å¯¹å°æ—¶æ•°
        if time_col_name and not pd.api.types.is_numeric_dtype(df[time_col_name]):
            # åŠ è½½ICUå…¥é™¢æ—¶é—´
            from pyricu.table import load_id_tbl
            icu_times = load_id_tbl(self._src_name, id_type, path=self.data_path)
            
            if not icu_times.empty and 'intime' in icu_times.columns:
                # ç¡®å®šIDåˆ—å
                id_col = self._get_id_column(df, id_type)
                if id_col and id_col in df.columns:
                    # åˆå¹¶å…¥é™¢æ—¶é—´
                    df = df.merge(icu_times[[id_col, 'intime']], on=id_col, how='left')
                    
                    # è½¬æ¢æ—¶é—´åˆ—ä¸ºç›¸å¯¹å°æ—¶æ•°
                    df[time_col_name] = pd.to_datetime(df[time_col_name], errors='coerce')
                    df['intime'] = pd.to_datetime(df['intime'], errors='coerce')
                    
                    # è®¡ç®—æ—¶é—´å·®(å°æ—¶)
                    time_diff = (df[time_col_name] - df['intime']).dt.total_seconds() / 3600
                    df[time_col_name] = time_diff.round(2)
                    
                    # åˆ é™¤intimeè¾…åŠ©åˆ—
                    df = df.drop(columns=['intime'])
        
        # 2. æ¸…ç†åˆ—æ ¼å¼ä»¥åŒ¹é…ricuè¾“å‡º
        # ç¡®å®šä¸»IDåˆ—(æ ¹æ®id_type)
        id_mappings = {
            'patient': ['subject_id', 'patientid', 'patient_id'],
            'hadm': ['hadm_id', 'admissionid', 'admission_id'],
            'icustay': ['stay_id', 'icustay_id', 'patientunitstayid', 'admissionid'],
        }
        
        # æ‰¾åˆ°ä¸»IDåˆ—
        id_col = None
        possible_names = id_mappings.get(id_type, [id_type])
        for name in possible_names:
            if name in df.columns:
                id_col = name
                break
        
        if not id_col:
            # å›é€€åˆ°_get_id_column
            id_col = self._get_id_column(df, id_type)
        
        print(f"[DEBUG _convert_time_to_hours] id_col={id_col}, all columns={df.columns.tolist()}")
        
        # ç§»é™¤å¤šä½™çš„IDåˆ—(ä¿ç•™ä¸»IDåˆ—)
        all_id_cols = set()
        for names in id_mappings.values():
            all_id_cols.update(names)
        
        extra_id_cols = [col for col in df.columns if col in all_id_cols and col != id_col]
        
        print(f"[DEBUG _convert_time_to_hours] all_id_cols={all_id_cols}, extra_id_cols={extra_id_cols}")
        
        if extra_id_cols:
            df = df.drop(columns=extra_id_cols)
            print(f"[DEBUG _convert_time_to_hours] After drop: columns={df.columns.tolist()}")
        
        # 3. ç»Ÿä¸€æ—¶é—´åˆ—åä¸ºcharttime(ricuä½¿ç”¨charttime)
        if 'time' in df.columns:
            df = df.rename(columns={'time': 'charttime'})
            time_col_name = 'charttime'
        
        # 4. è°ƒæ•´åˆ—é¡ºåº: [id_col, charttime, concept1, concept2, ...]
        cols = [id_col]
        if time_col_name and time_col_name in df.columns:
            cols.append(time_col_name)
        
        # æ·»åŠ å…¶ä»–åˆ—(æ¦‚å¿µå€¼ã€è¾…åŠ©åˆ—ç­‰)
        other_cols = [col for col in df.columns if col not in cols]
        cols.extend(other_cols)
        
        df = df[cols]
        
        return df
    
    def _merge_concepts(
        self,
        results: Dict[str, pd.DataFrame],
        id_type: str
    ) -> pd.DataFrame:
        """
        åˆå¹¶å¤šä¸ªæ¦‚å¿µä¸ºå®½æ ¼å¼
        
        Args:
            results: æ¦‚å¿µå -> DataFrame å­—å…¸
            id_type: IDç±»å‹
            
        Returns:
            åˆå¹¶åçš„å®½æ ¼å¼DataFrame
        """
        if not results:
            return pd.DataFrame()
        
        # æ‰¾å‡ºå…¬å…±åˆ—
        first_df = list(results.values())[0]
        id_col = self._get_id_column(first_df, id_type)
        
        merge_cols = [id_col]
        if 'time' in first_df.columns:
            merge_cols.append('time')
        
        # é€æ­¥åˆå¹¶
        merged = None
        for name, df in results.items():
            if merged is None:
                merged = df
            else:
                merged = merged.merge(df, on=merge_cols, how='outer')
        
        return merged
    
    def _merge_sub_concepts(
        self,
        sub_data: Dict[str, pd.DataFrame],
        id_type: str,
        interval: timedelta
    ) -> pd.DataFrame:
        """
        åˆå¹¶å¤šä¸ªå­æ¦‚å¿µæ•°æ®
        
        Args:
            sub_data: å­æ¦‚å¿µæ•°æ®å­—å…¸
            id_type: IDç±»å‹
            interval: æ—¶é—´é—´éš”
            
        Returns:
            åˆå¹¶åçš„DataFrame
        """
        if not sub_data:
            return pd.DataFrame()
        
        if len(sub_data) == 1:
            return list(sub_data.values())[0]
        
        # ç¡®å®šIDåˆ—å’Œæ—¶é—´åˆ—
        id_col = self._determine_id_column(id_type)
        merge_cols = [id_col]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åˆ—
        first_df = list(sub_data.values())[0]
        if 'time' in first_df.columns:
            merge_cols.append('time')
        
        # é€æ­¥åˆå¹¶
        result = None
        for name, df in sub_data.items():
            if result is None:
                result = df.copy()
            else:
                result = result.merge(df, on=merge_cols, how='outer', suffixes=('', f'_{name}'))
        
        return result
    
    def _determine_id_column(self, id_type: str) -> str:
        """
        æ ¹æ®IDç±»å‹ç¡®å®šIDåˆ—å
        
        Args:
            id_type: IDç±»å‹
            
        Returns:
            IDåˆ—å
        """
        # æ•°æ®æºç‰¹å®šçš„IDåˆ—åæ˜ å°„
        id_mappings = {
            'mimic_demo': {
                'icustay': 'stay_id',
                'hadm': 'hadm_id',
                'subject': 'subject_id',
            },
            'mimic': {
                'icustay': 'stay_id',
                'hadm': 'hadm_id',
                'subject': 'subject_id',
            },
            'eicu_demo': {
                'icustay': 'patientunitstayid',
                'hadm': 'patienthealthsystemstayid',
                'subject': 'uniquepid',
            },
            'eicu': {
                'icustay': 'patientunitstayid',
                'hadm': 'patienthealthsystemstayid',
                'subject': 'uniquepid',
            },
        }
        
        src_name = self._src_name
        
        if src_name in id_mappings and id_type in id_mappings[src_name]:
            return id_mappings[src_name][id_type]
        
        # é»˜è®¤è¿”å› stay_id
        return 'stay_id'
    
    def clear_cache(self):
        """æ¸…é™¤æ¦‚å¿µåŠ è½½ç¼“å­˜"""
        if hasattr(self, '_concept_cache'):
            self._concept_cache.clear()
        if hasattr(self, '_loading_stack'):
            self._loading_stack.clear()
    
    def _get_id_column(self, df: pd.DataFrame, id_type: str) -> Optional[str]:
        """
        è·å–IDåˆ—å
        
        Args:
            df: DataFrame
            id_type: IDç±»å‹
            
        Returns:
            åˆ—åæˆ–None
        """
        # å¸¸è§çš„IDåˆ—åæ˜ å°„
        id_mappings = {
            'patient': ['subject_id', 'patientid', 'patient_id'],
            'hadm': ['hadm_id', 'admissionid', 'admission_id'],
            'icustay': ['icustay_id', 'stay_id', 'patientunitstayid'],
        }
        
        possible_names = id_mappings.get(id_type, [id_type])
        
        for col in df.columns:
            if col.lower() in [n.lower() for n in possible_names]:
                return col
        
        # è¿”å›ç¬¬ä¸€ä¸ªåŒ…å«'id'çš„åˆ—
        for col in df.columns:
            if 'id' in col.lower():
                return col
        
        return None
    
    def _get_time_column(self, df: pd.DataFrame) -> Optional[str]:
        """
        è·å–æ—¶é—´åˆ—å
        
        Args:
            df: DataFrame
            
        Returns:
            åˆ—åæˆ–None
        """
        # ğŸ”§ FIX: Added more time column candidates for different databases
        # - givenat: HiRID pharma table
        # - infusionoffset: eICU inputOutput table
        # - start, stop: AUMC tables
        time_cols = ['charttime', 'time', 'datetime', 'timestamp', 
                     'starttime', 'observationoffset', 'givenat',
                     'infusionoffset', 'start', 'stop', 'entertime']
        
        for col in df.columns:
            if col.lower() in [t.lower() for t in time_cols]:
                return col
        
        return None

    def _ensure_id_column(self, df: pd.DataFrame, id_type: str) -> pd.DataFrame:
        """Ensure the dataframe has the target ID column, augmenting if necessary."""
        target_col = self._canonical_id_column(id_type)
        
        # Check if target column already exists
        existing_col = self._get_id_column(df, id_type)
        if existing_col:
            return df
            
        # If not exists, try to map from other ID columns
        available_ids = []
        for col in df.columns:
            if col in ['hadm_id', 'subject_id', 'stay_id', 'icustay_id', 'patientunitstayid', 'admissionid', 'patientid']:
                available_ids.append(col)
        
        if not available_ids:
            return df
            
        # Load ID lookup table
        lookup = self._load_id_lookup()
        if lookup.empty:
            return df
            
        if target_col not in lookup.columns:
            return df
            
        for avail_id in available_ids:
            if avail_id in lookup.columns:
                # Merge
                subset = lookup[[avail_id, target_col]].dropna().drop_duplicates()
                # Use left merge to preserve data rows
                df = df.merge(subset, on=avail_id, how='left')
                return df
                
        return df

    def _filter_by_patient(
        self, 
        df: pd.DataFrame, 
        patient_ids: Union[List, pd.DataFrame], 
        id_type: str
    ) -> pd.DataFrame:
        """Filter dataframe by patient IDs."""
        if patient_ids is None:
            return df
            
        id_col = self._get_id_column(df, id_type)
        if id_col:
            filter_values: Optional[List[Any]] = None
            if isinstance(patient_ids, pd.DataFrame):
                if id_col in patient_ids.columns:
                    filter_values = [val for val in patient_ids[id_col].tolist() if not pd.isna(val)]
                else:
                    canonical_col = self._canonical_id_column(id_type)
                    if canonical_col in patient_ids.columns:
                        base_values = [val for val in patient_ids[canonical_col].tolist() if not pd.isna(val)]
                        filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)
            else:
                base_values = self._coerce_patient_list(patient_ids)
                filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)

            if filter_values is not None:
                if not filter_values:
                    return df.iloc[0:0] # Empty dataframe with same columns
                df = df[df[id_col].isin(filter_values)]
        
        return df

    def _preload_tables(
        self,
        concept_objs: List[Concept],
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        verbose: bool = False,
        parallel_mode: bool = False
    ):
        """Preload and filter tables for all concepts.
        
        Args:
            parallel_mode: If True, use more aggressive caching strategy for parallel execution
        """
        if verbose:
            mode_str = "å¹¶è¡Œ" if parallel_mode else "ä¸²è¡Œ"
            print(f"âš¡ é¢„åŠ è½½è¡¨ ({mode_str}æ¨¡å¼)...")
        
        # ğŸš€ åˆå§‹åŒ– ICUDataSourceï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
        # è¿™å¯¹ rec_cncpt æ¦‚å¿µè‡³å…³é‡è¦ï¼Œå› ä¸º ConceptResolver éœ€è¦æ•°æ®æºå¯¹è±¡
        if self._data_source is None:
            from .datasource import ICUDataSource
            from pathlib import Path
            self._data_source = ICUDataSource(
                self.src,
                base_path=Path(self.data_path) if self.data_path else None
            )
            if verbose:
                print(f"  åˆå§‹åŒ–æ•°æ®æº: {self._src_name}")
            
        # 1. Identify required tables and columns - é€’å½’æ”¶é›†æ‰€æœ‰ä¾èµ–
        table_columns = {} # table_name -> set of columns
        
        # ğŸš€ ä¼˜åŒ–ï¼šé€’å½’æ”¶é›†æ‰€æœ‰ä¾èµ–æ¦‚å¿µçš„è¡¨ï¼ˆç‰¹åˆ«æ˜¯SOFAç»„ä»¶ï¼‰
        def collect_dependencies(concept_name: str, visited: set = None):
            """é€’å½’æ”¶é›†æ¦‚å¿µçš„æ‰€æœ‰ä¾èµ–è¡¨"""
            if visited is None:
                visited = set()
            if concept_name in visited:
                return
            visited.add(concept_name)
            
            try:
                from .concept import load_dictionary
                dict_obj = load_dictionary(self._src_name, include_sofa2='sofa2' in concept_name)
                if concept_name not in dict_obj._concepts:
                    return
                    
                concept = dict_obj._concepts[concept_name]
                
                # å¤„ç†å½“å‰æ¦‚å¿µ
                sources = concept.for_data_source(self.src)
                for source in sources:
                    if not source.table:
                        continue
                    cols = self._columns_for_source(source, id_type)
                    if cols:
                        if source.table not in table_columns:
                            table_columns[source.table] = set()
                        table_columns[source.table].update(cols)
                
                # é€’å½’å¤„ç†ä¾èµ–
                if hasattr(concept, 'items') and concept.items:
                    for dep_name in concept.items.keys():
                        collect_dependencies(dep_name, visited)
                        
            except Exception as e:
                if verbose:
                    print(f"  âš ï¸  æ”¶é›†ä¾èµ– {concept_name} å¤±è´¥: {e}")
        
        # Helper to process a concept
        def process_concept(c):
            sources = c.for_data_source(self.src)
            for source in sources:
                if not source.table:
                    continue
                
                cols = self._columns_for_source(source, id_type)
                if cols:
                    if source.table not in table_columns:
                        table_columns[source.table] = set()
                    table_columns[source.table].update(cols)
            
            # ğŸš€ å¹¶è¡Œæ¨¡å¼ï¼šé€’å½’æ”¶é›†ä¾èµ–ä»¥é¿å…åç»­é‡å¤åŠ è½½
            if parallel_mode and hasattr(c, 'name'):
                collect_dependencies(c.name)
            elif hasattr(c, 'items') and c.items:
                # ä¸²è¡Œæ¨¡å¼ï¼šåªå¤„ç†ç›´æ¥å­æ¦‚å¿µ
                for sub in c.items.values():
                    if isinstance(sub, Concept):
                        process_concept(sub)

        for concept in concept_objs:
            process_concept(concept)
        
        if verbose and table_columns:
            print(f"  éœ€è¦åŠ è½½ {len(table_columns)} å¼ è¡¨")
        
        # ğŸš€ HiRID observations ç­‰è¶…å¤§è¡¨ä¸åº”è¯¥åœ¨é¢„åŠ è½½é˜¶æ®µåŠ è½½
        # è¿™äº›è¡¨éœ€è¦æ¦‚å¿µç‰¹å®šçš„ variableid è¿‡æ»¤ï¼Œé¢„åŠ è½½æ—¶æ— æ³•æä¾›
        # è·³è¿‡è¿™äº›è¡¨ï¼Œè®©æ¯ä¸ªæ¦‚å¿µå•ç‹¬åŠ è½½æ—¶ä½¿ç”¨ç²¾ç¡®è¿‡æ»¤
        skip_preload_tables = set()
        if self._src_name == 'hirid':
            # HiRID observations: 7.77äº¿è¡Œï¼Œå¿…é¡»æŒ‰æ¦‚å¿µç²¾ç¡®è¿‡æ»¤
            skip_preload_tables.add('observations')
        
        # 2. Load and filter
        for table_name, columns in table_columns.items():
            if table_name in self._table_cache:
                continue
            
            # ğŸš€ è·³è¿‡éœ€è¦æ¦‚å¿µç‰¹å®šè¿‡æ»¤çš„è¶…å¤§è¡¨
            if table_name in skip_preload_tables:
                if verbose:
                    print(f"  â­ï¸  è·³è¿‡é¢„åŠ è½½ {table_name} (å°†æŒ‰æ¦‚å¿µç²¾ç¡®è¿‡æ»¤)")
                continue
                
            if verbose:
                print(f"  Loading {table_name} with {len(columns)} columns...")
            
            try:
                # ğŸš€ ä¼˜åŒ–ï¼šå¦‚æœæœ‰ data_sourceï¼Œä½¿ç”¨å®ƒå¹¶ä¼ é€’æ‚£è€…è¿‡æ»¤å™¨ä»¥åœ¨è¯»å–æ—¶å°±è¿‡æ»¤
                if self._data_source is not None and patient_ids is not None:
                    # æ„é€ æ‚£è€…è¿‡æ»¤å™¨
                    from .datasource import FilterSpec, FilterOp
                    # ç¡®å®šIDåˆ—å
                    id_col = self._canonical_id_column(id_type)
                    # è½¬æ¢æ‚£è€…IDåˆ—è¡¨
                    if isinstance(patient_ids, pd.DataFrame):
                        if id_col in patient_ids.columns:
                            patient_list = patient_ids[id_col].dropna().unique().tolist()
                        else:
                            patient_list = None
                    else:
                        patient_list = self._coerce_patient_list(patient_ids)
                    
                    if patient_list:
                        patient_filter = FilterSpec(column=id_col, op=FilterOp.IN, value=patient_list)
                        icu_table = self._data_source.load_table(
                            table_name,
                            columns=list(columns),
                            filters=[patient_filter],
                            verbose=verbose
                        )
                        df = icu_table.data
                    else:
                        # æ²¡æœ‰æœ‰æ•ˆçš„æ‚£è€…IDï¼Œå›é€€åˆ°æ™®é€šåŠ è½½
                        try:
                            df = load_table(self._src_name, table_name, columns=list(columns), path=self.data_path)
                        except Exception:
                            df = load_table(self._src_name, table_name, path=self.data_path)
                        df = self._ensure_id_column(df, id_type)
                        if patient_ids is not None:
                            df = self._filter_by_patient(df, patient_ids, id_type)
                else:
                    # æ²¡æœ‰ data_source æˆ– patient_idsï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
                    try:
                        df = load_table(self._src_name, table_name, columns=list(columns), path=self.data_path)
                    except Exception:
                        df = load_table(self._src_name, table_name, path=self.data_path)
                    
                    df = self._ensure_id_column(df, id_type)
                    if patient_ids is not None:
                        df = self._filter_by_patient(df, patient_ids, id_type)
                
                # Store in cache
                self._table_cache[table_name] = df
                
            except Exception as e:
                if verbose:
                    print(f"  âš ï¸  Failed to preload {table_name}: {e}")

def load_concepts(
    concepts: Union[str, List[str]],
    src: Union[str, DataSource],
    **kwargs
) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåŠ è½½æ¦‚å¿µ
    
    Args:
        concepts: æ¦‚å¿µåç§°æˆ–åˆ—è¡¨
        src: æ•°æ®æº
        **kwargs: ä¼ é€’ç»™ ConceptLoader.load_concepts
        
    Returns:
        DataFrame æˆ–å­—å…¸
    
    Examples:
        >>> # åŠ è½½å•ä¸ªæ¦‚å¿µ
        >>> hr = load_concepts('hr', 'mimic')
        >>> 
        >>> # åŠ è½½å¤šä¸ªæ¦‚å¿µå¹¶åˆå¹¶
        >>> vitals = load_concepts(['hr', 'sbp', 'dbp'], 'mimic', 
        ...                        interval=timedelta(hours=1))
    
    .. deprecated::
        æ­¤å‡½æ•°å·²è¢«åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ `pyricu.api.load_concepts` ä»£æ›¿ã€‚
        è¯¥å‡½æ•°ä»…ä¿ç•™ç”¨äºå‘åå…¼å®¹ã€‚
    """
    import warnings
    warnings.warn(
        "load_concepts from pyricu.load_concepts is deprecated. "
        "Use pyricu.load_concepts (from api module) instead.",
        DeprecationWarning,
        stacklevel=2
    )
    data_path = kwargs.pop('data_path', None)
    loader = ConceptLoader(src, data_path=data_path)
    return loader.load_concepts(concepts, **kwargs)


# å‘åå…¼å®¹åˆ«å - å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ pyricu.api.load_concept
load_concept = load_concepts
