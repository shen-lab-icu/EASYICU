"""
å®Œæ•´çš„æ¦‚å¿µåŠ è½½ç³»ç»Ÿ
å®žçŽ° R ricu çš„ load_concepts åŠŸèƒ½
"""
from typing import List, Optional, Union, Dict, Any, Callable, Iterable, Sequence, Mapping
import logging
from datetime import timedelta

import pandas as pd

from .concept import Concept, load_dictionary
from .config import DataSourceConfig, TableConfig, load_src_cfg
from .datasource import ICUDataSource
from .table import load_table
from .ts_utils import change_interval, aggregate_data
from .callback_utils import combine_callbacks

# DataSource åˆ«åç”¨äºŽå‘åŽå…¼å®¹
DataSource = ICUDataSource

# å¸¸è§åˆ—åé›†åˆï¼Œç”¨äºŽæŽ¨æµ‹å¯èƒ½éœ€è¦çš„åˆ—
COMMON_ID_COLUMNS = [
    'stay_id', 'icustay_id', 'subject_id', 'hadm_id',
    'patientunitstayid', 'patientid', 'patient_id', 'admissionid',
    'admission_id', 'patienthealthsystemstayid', 'uniquepid',
    'encounter', 'encounter_id', 'visit_id', 'visitid', 'episode_id',
]

ID_TYPE_HINTS = {
    'patient': ['subject_id', 'patientid', 'patient_id', 'uniquepid'],
    'hadm': ['hadm_id', 'admissionid', 'admission_id', 'visit_id', 'encounter_id'],
    'icustay': ['stay_id', 'icustay_id', 'patientunitstayid'],
}

COMMON_TIME_COLUMNS = [
    'charttime', 'time', 'datetime', 'timestamp', 'starttime', 'endtime',
    'intime', 'outtime', 'admittime', 'dischtime', 'createtime',
    'observationoffset', 'chartoffset', 'eventtime', 'realtime'
]

COMMON_VALUE_COLUMNS = [
    'valuenum', 'value', 'valuetext', 'valueasnumber', 'value_as_number',
    'amount', 'totalamount', 'rate', 'dose', 'doseamount', 'dose_val_rx',
    'volume', 'chartvalue', 'resultvalue', 'value1', 'value2', 'value3',
    'drugname', 'amountuom'
]

# ðŸš€ è¡¨ç‰¹å®šçš„æœ€å°åˆ—é›† - åªåŠ è½½å¿…è¦çš„åˆ—ä»¥æå‡æ€§èƒ½
MINIMAL_COLUMNS_MAP = {
    # MIMIC-IV chartevents: åªéœ€è¦6åˆ—è€Œéžå…¨éƒ¨11åˆ—
    # åŒ…å«valueåˆ—ä»¥æ”¯æŒå­—ç¬¦ä¸²åž‹æ•°æ®ï¼ˆå¦‚è¯ç‰©åç§°ç­‰ï¼‰
    'chartevents': ['stay_id', 'charttime', 'itemid', 'value', 'valuenum', 'valueuom'],
    
    # MIMIC-IV labevents: åªéœ€è¦5åˆ—è€Œéžå…¨éƒ¨16åˆ—  
    # æ³¨æ„: labeventsæ²¡æœ‰stay_idï¼Œéœ€è¦subject_id+hadm_idåŽç»­å…³è”
    'labevents': ['subject_id', 'hadm_id', 'charttime', 'itemid', 'valuenum'],
    
    # MIMIC-IV inputevents: è¾“å…¥äº‹ä»¶çš„æ ¸å¿ƒåˆ—
    # åŒ…å«hadm_idç”¨äºŽæŸäº›éœ€è¦ä½é™¢çº§åˆ«èšåˆçš„æ¦‚å¿µï¼ˆå¦‚abxï¼‰
    'inputevents': ['stay_id', 'hadm_id', 'starttime', 'endtime', 'itemid', 'amount', 'amountuom', 'rate', 'linkorderid'],
    
    # MIMIC-IV outputevents: è¾“å‡ºäº‹ä»¶çš„æ ¸å¿ƒåˆ—
    'outputevents': ['stay_id', 'charttime', 'itemid', 'value'],
    
    # MIMIC-IV procedureevents: æ“ä½œäº‹ä»¶çš„æ ¸å¿ƒåˆ—
    'procedureevents': ['stay_id', 'starttime', 'endtime', 'itemid', 'value'],
    
    # eICU vitalperiodic: ç”Ÿå‘½ä½“å¾å‘¨æœŸè¡¨
    'vitalperiodic': ['patientunitstayid', 'observationoffset', 'temperature', 'heartrate', 
                      'respiration', 'systemicsystolic', 'systemicdiastolic', 'systemicmean'],
    
    # eICU lab: å®žéªŒå®¤æ£€æŸ¥
    'lab': ['patientunitstayid', 'labresultoffset', 'labname', 'labresult'],
}

# æ€§èƒ½ä¼˜åŒ–å¼€å…³ - å¦‚æžœé‡åˆ°é—®é¢˜å¯ä»¥ç¦ç”¨
USE_MINIMAL_COLUMNS = True


logger = logging.getLogger(__name__)


class ConceptLoader:
    """æ¦‚å¿µåŠ è½½å™¨ - å¤åˆ» R ricu çš„ load_concepts"""
    
    def __init__(self, src: Union[str, DataSource, DataSourceConfig]):
        """
        åˆå§‹åŒ–æ¦‚å¿µåŠ è½½å™¨
        
        Args:
            src: æ•°æ®æºåç§°æˆ– DataSource å¯¹è±¡
        """
        self._data_source: Optional[ICUDataSource] = None
        if isinstance(src, ICUDataSource):
            self._data_source = src
            self.src = src.config
        elif isinstance(src, DataSourceConfig):
            self.src = src
        elif isinstance(src, str):
            self.src = load_src_cfg(src)
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»åž‹: {type(src)}")
        self._src_name = self.src.name
        self._id_lookup_cache: Optional[pd.DataFrame] = None
    
    def _get_table_config(self, table_name: Optional[str]) -> Optional[TableConfig]:
        """æ ¹æ®è¡¨åèŽ·å–é…ç½®ã€‚"""
        if not table_name or not hasattr(self.src, 'tables'):
            return None
        return self.src.tables.get(table_name)
    
    def _infer_required_columns(
        self,
        table_name: Optional[str],
        id_type: str,
        extra_candidates: Optional[Sequence[str]] = None,
    ) -> Optional[List[str]]:
        """æ ¹æ®è¡¨é…ç½®å’Œæ¦‚å¿µéœ€æ±‚æŽ¨æ–­éœ€è¦åŠ è½½çš„åˆ— - ä¼˜åŒ–ç‰ˆï¼ŒåªåŠ è½½å¿…è¦åˆ—"""
        
        # ðŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨æœ€å°åˆ—é›†ï¼ˆå‡å°‘50-70%çš„I/Oï¼‰
        if USE_MINIMAL_COLUMNS and table_name in MINIMAL_COLUMNS_MAP:
            base_cols = list(MINIMAL_COLUMNS_MAP[table_name])
            
            # æ·»åŠ é¢å¤–éœ€è¦çš„åˆ—ï¼ˆå¦‚sub_var, val_varç­‰ï¼‰
            if extra_candidates:
                for col in extra_candidates:
                    if col and col not in base_cols:
                        base_cols.append(col)
            
            # ç¡®ä¿æœ‰IDåˆ—
            has_id = any(id_col in base_cols for id_col in 
                        ['stay_id', 'icustay_id', 'subject_id', 'patientunitstayid', 'hadm_id'])
            if not has_id:
                # æ·»åŠ IDç±»åž‹å¯¹åº”çš„åˆ—
                id_candidates = ID_TYPE_HINTS.get(id_type, ['stay_id'])
                base_cols.insert(0, id_candidates[0])
            
            return base_cols
        
        # å›žé€€åˆ°åŽŸæœ‰é€»è¾‘ï¼ˆç”¨äºŽä¸åœ¨æœ€å°åˆ—é›†æ˜ å°„ä¸­çš„è¡¨ï¼Œå¦‚icustaysç­‰ï¼‰
        table_cfg = self._get_table_config(table_name)
        defaults = table_cfg.defaults if table_cfg else None
        available = (
            set(table_cfg.columns.keys())
            if table_cfg and table_cfg.columns
            else None
        )
        
        candidates: List[str] = []
        if defaults:
            if defaults.id_var:
                candidates.append(defaults.id_var)
            if defaults.index_var:
                candidates.append(defaults.index_var)
            if defaults.val_var:
                candidates.append(defaults.val_var)
            if defaults.unit_var:
                candidates.append(defaults.unit_var)
            candidates.extend(defaults.time_vars or [])
        
        if extra_candidates:
            candidates.extend(extra_candidates)
        
        # ID åˆ—å’Œé€šç”¨åˆ—å€™é€‰
        candidates.extend(ID_TYPE_HINTS.get(id_type, []))
        candidates.extend(COMMON_ID_COLUMNS)
        candidates.extend(COMMON_TIME_COLUMNS)
        candidates.extend(COMMON_VALUE_COLUMNS)
        
        filtered: List[str] = []
        seen: set[str] = set()
        for col in candidates:
            if not col or col in seen:
                continue
            if available is not None and col not in available:
                continue
            filtered.append(col)
            seen.add(col)
        
        return filtered or None
    
    def _safe_load_table(
        self,
        table_name: str,
        columns: Optional[Iterable[str]],
    ) -> pd.DataFrame:
        """åœ¨åˆ—è¿‡æ»¤å¤±è´¥æ—¶å›žé€€åˆ°å…¨è¡¨åŠ è½½ã€‚"""
        if columns:
            try:
                return load_table(self._src_name, table_name, columns=list(columns))
            except Exception:
                # å›žé€€åˆ°åŠ è½½å…¨éƒ¨åˆ—ï¼Œç¡®ä¿å…¼å®¹ç¼ºå°‘åˆ—æè¿°çš„è¡¨
                return load_table(self._src_name, table_name)
        return load_table(self._src_name, table_name)
    
    def _columns_for_source(self, source, id_type: str) -> Optional[List[str]]:
        """æå– ConceptSource æ‰€éœ€çš„åˆ—ã€‚"""
        extra: List[str] = []
        if getattr(source, 'sub_var', None):
            extra.append(source.sub_var)
        if getattr(source, 'value_var', None):
            extra.append(source.value_var)
        if getattr(source, 'index_var', None):
            extra.append(source.index_var)
        if getattr(source, 'unit_var', None):
            extra.append(source.unit_var)
        
        result = self._infer_required_columns(source.table, id_type, extra)
        return result
    
    def _columns_for_item(self, item: Mapping[str, Any], id_type: str) -> Optional[List[str]]:
        """æå–æ—§å¼ item é…ç½®æ‰€éœ€åˆ—ã€‚"""
        extra: List[str] = []
        for key in ['sub_var', 'val_var', 'value_var', 'time_var', 'index_var']:
            value = item.get(key)
            if isinstance(value, str):
                extra.append(value)
        return self._infer_required_columns(item.get('table'), id_type, extra)

    def _canonical_id_column(self, id_type: str) -> str:
        """æ ¹æ®æ•°æ®æºé…ç½®è¿”å›žæŒ‡å®šIDç±»åž‹çš„æ ‡å‡†åˆ—åã€‚"""
        cfg = self.src.id_configs.get(id_type) if hasattr(self.src, 'id_configs') else None
        if cfg and getattr(cfg, 'id', None):
            return cfg.id
        fallback = {
            'icustay': 'stay_id',
            'hadm': 'hadm_id',
            'patient': 'subject_id',
        }
        return fallback.get(id_type, id_type)

    def _coerce_patient_list(self, patient_ids: Union[List, Sequence, set, pd.Series, pd.DataFrame, None]) -> List[Any]:
        """å°† patient_ids å½’ä¸€åŒ–ä¸ºç®€å•åˆ—è¡¨ã€‚"""
        if patient_ids is None:
            return []
        values: List[Any] = []
        if isinstance(patient_ids, pd.DataFrame):
            for column in patient_ids.columns:
                col_vals = patient_ids[column].tolist()
                for value in col_vals:
                    if pd.isna(value):
                        continue
                    values.append(value)
            return values
        if isinstance(patient_ids, pd.Series):
            return [value for value in patient_ids.tolist() if not pd.isna(value)]
        if isinstance(patient_ids, (list, tuple, set)):
            return [value for value in patient_ids if not pd.isna(value)]
        return [patient_ids] if not pd.isna(patient_ids) else []

    def _load_id_lookup(self) -> pd.DataFrame:
        """åŠ è½½åŒ…å« stay/hadm/subject æ˜ å°„çš„å‚è€ƒè¡¨ï¼Œç”¨äºŽIDè½¬æ¢ã€‚"""
        if self._id_lookup_cache is not None:
            return self._id_lookup_cache

        cfg = getattr(self.src, 'id_configs', {}).get('icustay') if hasattr(self.src, 'id_configs') else None
        table_name = cfg.table if cfg and getattr(cfg, 'table', None) else None
        if not table_name:
            self._id_lookup_cache = pd.DataFrame()
            return self._id_lookup_cache

        desired_cols = {
            'stay_id', 'icustay_id', 'patientunitstayid', 'hadm_id', 'subject_id',
            'admissionid', 'patientid', 'patient_id', 'admission_id'
        }
        for id_cfg in getattr(self.src, 'id_configs', {}).values():
            if getattr(id_cfg, 'id', None):
                desired_cols.add(id_cfg.id)

        table_cfg = self._get_table_config(table_name)
        available = set(table_cfg.columns.keys()) if table_cfg and table_cfg.columns else None
        columns = [col for col in desired_cols if (available is None or col in available)]
        columns = columns or None

        try:
            lookup = self._safe_load_table(table_name, columns)
        except Exception as exc:
            logger.warning("æ— æ³•åŠ è½½IDæ˜ å°„è¡¨ %s: %s", table_name, exc)
            lookup = pd.DataFrame()

        self._id_lookup_cache = lookup
        return lookup

    def _map_patient_ids_to_column(
        self,
        patient_ids: List[Any],
        id_type: str,
        target_column: Optional[str],
    ) -> Optional[List[Any]]:
        """å°†åŸºäºŽ id_type çš„ patient_ids æ˜ å°„åˆ°ç›®æ ‡åˆ—çš„å–å€¼é›†åˆã€‚"""
        if target_column is None:
            return patient_ids
        canonical_col = self._canonical_id_column(id_type)
        if canonical_col.lower() == target_column.lower():
            return patient_ids
        lookup = self._load_id_lookup()
        if lookup.empty or canonical_col not in lookup.columns or target_column not in lookup.columns:
            return None
        if not patient_ids:
            return []
        subset = lookup[lookup[canonical_col].isin(patient_ids)]
        if subset.empty:
            return []
        mapped = subset[target_column].dropna().unique().tolist()
        return mapped
            
    def load_concepts(
        self,
        concepts: Union[str, List[str], Concept, List[Concept]],
        patient_ids: Optional[Union[List, pd.DataFrame]] = None,
        id_type: str = 'icustay',
        interval: Optional[timedelta] = None,
        aggregate: Optional[Union[str, Dict[str, str]]] = None,
        merge_data: bool = True,
        verbose: bool = True,
        **kwargs
    ) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
        """
        åŠ è½½æ¦‚å¿µæ•°æ®
        
        Args:
            concepts: æ¦‚å¿µåç§°ã€IDæˆ–Conceptå¯¹è±¡
            patient_ids: æ‚£è€…IDåˆ—è¡¨æˆ–åŒ…å«IDçš„DataFrame
            id_type: IDç±»åž‹ (patient, hadm, icustayç­‰)
            interval: æ—¶é—´é—´éš” (å¦‚ timedelta(hours=1))
            aggregate: èšåˆå‡½æ•° ('mean', 'sum', 'min', 'max' æˆ–å­—å…¸)
            merge_data: æ˜¯å¦åˆå¹¶ä¸ºå®½æ ¼å¼è¡¨
            verbose: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
            
        Returns:
            DataFrame æˆ–å­—å…¸ (å–å†³äºŽ merge_data)
        """
        # 1. è§£æžæ¦‚å¿µ
        if isinstance(concepts, str):
            concepts = [concepts]
        
        if isinstance(concepts, list) and all(isinstance(c, str) for c in concepts):
            # ä»Žå­—å…¸åŠ è½½æ¦‚å¿µ
            # å¦‚æžœè¯·æ±‚çš„æ¦‚å¿µä¸­åŒ…å« SOFA-2 ç›¸å…³æ¦‚å¿µï¼Œè‡ªåŠ¨åŠ è½½ sofa2-dict
            sofa2_concepts = {'sofa2', 'sofa2_resp', 'sofa2_coag', 'sofa2_liver', 
                              'sofa2_cardio', 'sofa2_cns', 'sofa2_renal',
                              'uo_6h', 'uo_12h', 'uo_24h', 'rrt_criteria',
                              'adv_resp', 'ecmo', 'ecmo_indication', 'sedated_gcs',
                              'mech_circ_support', 'other_vaso', 'delirium_tx'}
            include_sofa2 = any(c in sofa2_concepts for c in concepts)
            
            concept_dict = load_dictionary(self._src_name, include_sofa2=include_sofa2)
            concept_objs = [concept_dict[name] for name in concepts]
        elif isinstance(concepts, Concept):
            concept_objs = [concepts]
        elif isinstance(concepts, list) and all(isinstance(c, Concept) for c in concepts):
            concept_objs = concepts
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¦‚å¿µç±»åž‹: {type(concepts)}")
        
        # 2. è®¾ç½®é»˜è®¤å€¼
        if interval is None:
            interval = timedelta(hours=1)
        
        # 3. åŠ è½½æ¯ä¸ªæ¦‚å¿µ
        results = {}
        for concept in concept_objs:
            if verbose:
                print(f"åŠ è½½æ¦‚å¿µ: {concept.name}")
            
            # åŠ è½½å•ä¸ªæ¦‚å¿µ
            data = self._load_one_concept(
                concept=concept,
                patient_ids=patient_ids,
                id_type=id_type,
                interval=interval,
                aggregate=aggregate if not isinstance(aggregate, dict) else aggregate.get(concept.name),
                **kwargs
            )
            
            if data is not None and len(data) > 0:
                results[concept.name] = data
        
        # 4. åˆå¹¶æˆ–è¿”å›ž
        if not merge_data:
            return results
        
        if len(results) == 0:
            return pd.DataFrame()
        
        if len(results) == 1:
            return list(results.values())[0]
        
        # åˆå¹¶å¤šä¸ªæ¦‚å¿µä¸ºå®½æ ¼å¼
        return self._merge_concepts(results, id_type)
    
    def _load_one_concept(
        self,
        concept: Concept,
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        interval: timedelta,
        aggregate: Optional[str],
        **kwargs
    ) -> pd.DataFrame:
        """
        åŠ è½½å•ä¸ªæ¦‚å¿µ
        
        Args:
            concept: Concept å¯¹è±¡
            patient_ids: æ‚£è€…ID
            id_type: IDç±»åž‹
            interval: æ—¶é—´é—´éš”
            aggregate: èšåˆå‡½æ•°
            
        Returns:
            DataFrame
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºé€’å½’æ¦‚å¿µï¼ˆæœ‰å­æ¦‚å¿µï¼‰
        if concept.sub_concepts and len(concept.sub_concepts) > 0:
            # é€’å½’æ¦‚å¿µ - ä½¿ç”¨å›žè°ƒ
            return self._load_recursive_concept(
                concept, patient_ids, id_type, interval, aggregate, **kwargs
            )
        
        # 2. æ™®é€šæ¦‚å¿µ - ä»Žè¡¨ä¸­åŠ è½½
        # èŽ·å–å½“å‰æ•°æ®æºçš„ ConceptSource é…ç½®
        sources = concept.for_data_source(self.src)
        if not sources:
            return pd.DataFrame()
        
        all_data = []
        
        for source in sources:
            # åŠ è½½sourceæ•°æ®
            df = self._load_concept_source(
                source=source,
                concept_name=concept.name,
                patient_ids=patient_ids,
                id_type=id_type,
                interval=interval
            )
            
            if df is not None and len(df) > 0:
                all_data.append(df)
        
        if not all_data:
            return pd.DataFrame()
        
        # 3. åˆå¹¶æ‰€æœ‰sourceæ•°æ®
        data = pd.concat(all_data, ignore_index=True)
        
        # 4. è¿‡æ»¤å’Œè½¬æ¢
        data = self._filter_concept_data(data, concept)
        
        # 5. é‡å‘½ååˆ—
        if 'value' in data.columns:
            data = data.rename(columns={'value': concept.name})
        
        # 6. èšåˆ
        if aggregate and len(data) > 0:
            data = self._aggregate_concept(data, concept, aggregate, id_type, interval)
        
        return data
    
    def _load_item(
        self,
        item: Dict[str, Any],
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        interval: timedelta
    ) -> pd.DataFrame:
        """
        åŠ è½½å•ä¸ªitem
        
        Args:
            item: itemå­—å…¸
            patient_ids: æ‚£è€…ID
            id_type: IDç±»åž‹
            interval: æ—¶é—´é—´éš”
            
        Returns:
            DataFrame
        """
        # 1. åŠ è½½è¡¨
        table_name = item.get('table')
        if not table_name:
            return pd.DataFrame()
        
        required_columns = self._columns_for_item(item, id_type)
        
        # ðŸ” è°ƒè¯•ï¼šæ˜¾ç¤ºæŽ¨æ–­çš„åˆ—
        if required_columns:
            import logging
            logger = logging.getLogger('pyricu.load_concepts')
            if logger.isEnabledFor(logging.DEBUG):
        
        try:
            df = self._safe_load_table(table_name, required_columns)
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½è¡¨ {table_name}: {e}")
            return pd.DataFrame()
        
        # 2. è¿‡æ»¤æ‚£è€…
        if patient_ids is not None:
            id_col = self._get_id_column(df, id_type)
            if id_col:
                filter_values: Optional[List[Any]] = None
                if isinstance(patient_ids, pd.DataFrame):
                    if id_col in patient_ids.columns:
                        filter_values = [val for val in patient_ids[id_col].tolist() if not pd.isna(val)]
                    else:
                        canonical_col = self._canonical_id_column(id_type)
                        if canonical_col in patient_ids.columns:
                            base_values = [val for val in patient_ids[canonical_col].tolist() if not pd.isna(val)]
                            filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)
                else:
                    base_values = self._coerce_patient_list(patient_ids)
                    filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)

                if filter_values is not None:
                    if not filter_values:
                        return pd.DataFrame()
                    df = df[df[id_col].isin(filter_values)]
        
        # 3. è¿‡æ»¤itemå€¼
        val_col = item.get('val_var', 'value')
        sub_col = item.get('sub_var')
        
        if sub_col and sub_col in df.columns:
            # è¿‡æ»¤ç‰¹å®šå€¼
            target_vals = item.get('target', [])
            if target_vals:
                df = df[df[sub_col].isin(target_vals)]
        
        # 4. é€‰æ‹©éœ€è¦çš„åˆ—
        required_cols = [self._get_id_column(df, id_type)]
        
        # æ—¶é—´åˆ—
        time_col = self._get_time_column(df)
        if time_col:
            required_cols.append(time_col)
        
        # å€¼åˆ—
        if val_col in df.columns:
            required_cols.append(val_col)
        
        # è¿‡æ»¤åˆ—
        required_cols = [c for c in required_cols if c and c in df.columns]
        df = df[required_cols].copy()
        
        # 5. é‡å‘½åä¸ºæ ‡å‡†åˆ—å
        rename_map = {}
        if time_col and time_col != 'time':
            rename_map[time_col] = 'time'
        if val_col and val_col != 'value':
            rename_map[val_col] = 'value'
        
        if rename_map:
            df = df.rename(columns=rename_map)
        
        # 6. å¯¹é½æ—¶é—´é—´éš”
        if 'time' in df.columns and interval:
            df = change_interval(df, interval=interval, time_col='time')
        
        return df
    
    def _load_concept_source(
        self,
        source,  # ConceptSource object
        concept_name: str,
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        interval: timedelta
    ) -> pd.DataFrame:
        """
        ä»Ž ConceptSource åŠ è½½æ•°æ®
        
        Args:
            source: ConceptSource å¯¹è±¡
            concept_name: æ¦‚å¿µåç§°
            patient_ids: æ‚£è€…ID
            id_type: IDç±»åž‹
            interval: æ—¶é—´é—´éš”
            
        Returns:
            DataFrame
        """
        # 1. åŠ è½½è¡¨
        table_name = source.table
        if not table_name:
            return pd.DataFrame()
        
        required_columns = self._columns_for_source(source, id_type)
        try:
            df = self._safe_load_table(table_name, required_columns)
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½è¡¨ {table_name}: {e}")
            return pd.DataFrame()
        
        # 2. è¿‡æ»¤ sub_var (å¦‚ itemid)
        if source.sub_var and source.ids:
            if source.sub_var not in df.columns:
                print(f"è­¦å‘Š: è¡¨ {table_name} ä¸­æ‰¾ä¸åˆ°åˆ— {source.sub_var}")
                return pd.DataFrame()
            df = df[df[source.sub_var].isin(source.ids)]
        
        if len(df) == 0:
            return pd.DataFrame()
        
        # 3. è¿‡æ»¤æ‚£è€…
        if patient_ids is not None:
            id_col = self._get_id_column(df, id_type)
            if id_col:
                filter_values: Optional[List[Any]] = None
                if isinstance(patient_ids, pd.DataFrame):
                    if id_col in patient_ids.columns:
                        filter_values = [val for val in patient_ids[id_col].tolist() if not pd.isna(val)]
                    else:
                        canonical_col = self._canonical_id_column(id_type)
                        if canonical_col in patient_ids.columns:
                            base_values = [val for val in patient_ids[canonical_col].tolist() if not pd.isna(val)]
                            filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)
                else:
                    base_values = self._coerce_patient_list(patient_ids)
                    filter_values = self._map_patient_ids_to_column(base_values, id_type, id_col)

                if filter_values is not None:
                    if not filter_values:
                        return pd.DataFrame()
                    df = df[df[id_col].isin(filter_values)]
        
        # 4. ç¡®å®šå€¼åˆ—
        val_col = source.value_var or 'valuenum'  # é»˜è®¤ä½¿ç”¨ valuenum
        if val_col not in df.columns:
            # å°è¯•å…¶ä»–å¯èƒ½çš„å€¼åˆ—
            for candidate in ['valuenum', 'value', 'amount']:
                if candidate in df.columns:
                    val_col = candidate
                    break
        
        # 5. é€‰æ‹©éœ€è¦çš„åˆ—
        id_col = self._get_id_column(df, id_type)
        required_cols = [id_col] if id_col else []
        
        # æ—¶é—´åˆ—
        time_col = source.index_var or self._get_time_column(df)
        if time_col and time_col in df.columns:
            required_cols.append(time_col)
        
        # å€¼åˆ—
        if val_col and val_col in df.columns:
            required_cols.append(val_col)
        
        # è¿‡æ»¤åˆ—
        required_cols = [c for c in required_cols if c and c in df.columns]
        if not required_cols:
            return pd.DataFrame()
        
        df = df[required_cols].copy()
        
        # 6. é‡å‘½åä¸ºæ ‡å‡†åˆ—å
        rename_map = {}
        if time_col and time_col != 'time' and time_col in df.columns:
            rename_map[time_col] = 'time'
        if val_col and val_col != 'value' and val_col in df.columns:
            rename_map[val_col] = 'value'
        
        if rename_map:
            df = df.rename(columns=rename_map)
        
        # 7. å¯¹é½æ—¶é—´é—´éš”
        if 'time' in df.columns and interval:
            df = change_interval(df, interval=interval, time_col='time')
        
        return df
    
    def _load_recursive_concept(
        self,
        concept: Concept,
        patient_ids: Optional[Union[List, pd.DataFrame]],
        id_type: str,
        interval: timedelta,
        aggregate: Optional[str],
        **kwargs
    ) -> pd.DataFrame:
        """
        åŠ è½½é€’å½’æ¦‚å¿µï¼ˆä½¿ç”¨å›žè°ƒï¼‰- ä¿®å¤å¾ªçŽ¯ä¾èµ–æ£€æµ‹
        
        å®Œå…¨å¤åˆ» R ricu çš„é€’å½’æ¦‚å¿µåŠ è½½é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
        1. å¾ªçŽ¯ä¾èµ–æ£€æµ‹
        2. ä¾èµ–è§£æžç¼“å­˜
        3. æ­£ç¡®çš„å­æ¦‚å¿µåŠ è½½é¡ºåº
        
        Args:
            concept: Conceptå¯¹è±¡
            patient_ids: æ‚£è€…ID
            id_type: IDç±»åž‹
            interval: æ—¶é—´é—´éš”
            aggregate: èšåˆå‡½æ•°
            
        Returns:
            DataFrame
            
        Raises:
            ValueError: å¦‚æžœæ£€æµ‹åˆ°å¾ªçŽ¯ä¾èµ–
        """
        # åˆå§‹åŒ–åŠ è½½æ ˆï¼ˆç”¨äºŽæ£€æµ‹å¾ªçŽ¯ä¾èµ–ï¼‰
        if not hasattr(self, '_loading_stack'):
            self._loading_stack = set()
        
        # åˆå§‹åŒ–ç¼“å­˜ï¼ˆé¿å…é‡å¤åŠ è½½ç›¸åŒæ¦‚å¿µï¼‰
        if not hasattr(self, '_concept_cache'):
            self._concept_cache = {}
        
        # æ£€æŸ¥å¾ªçŽ¯ä¾èµ–
        if concept.name in self._loading_stack:
            chain = ' -> '.join(self._loading_stack) + f' -> {concept.name}'
            raise ValueError(f"æ£€æµ‹åˆ°å¾ªçŽ¯ä¾èµ–: {chain}")
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = (
            concept.name, 
            str(patient_ids) if patient_ids is not None else None,
            id_type,
            str(interval),
            aggregate
        )
        if cache_key in self._concept_cache:
            return self._concept_cache[cache_key].copy()
        
        # å°†å½“å‰æ¦‚å¿µåŠ å…¥åŠ è½½æ ˆ
        self._loading_stack.add(concept.name)
        
        try:
            # 1. åŠ è½½å­æ¦‚å¿µ
            sub_concepts = concept.items if hasattr(concept, 'items') else {}
            sub_data = {}
            
            # æŒ‰ç…§ä¾èµ–é¡ºåºåŠ è½½å­æ¦‚å¿µ
            for sub_name in sub_concepts:
                try:
                    # èŽ·å–å­æ¦‚å¿µå®šä¹‰
                    if isinstance(sub_concepts[sub_name], Concept):
                        sub_concept = sub_concepts[sub_name]
                    else:
                        # ä»Žå­—å…¸ä¸­åŠ è½½
                        concept_dict = load_dictionary(self._src_name)
                        if sub_name not in concept_dict:
                            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°å­æ¦‚å¿µ {sub_name}")
                            continue
                        sub_concept = concept_dict[sub_name]
                    
                    # é€’å½’åŠ è½½å­æ¦‚å¿µ
                    data = self._load_one_concept(
                        sub_concept, patient_ids, id_type, interval, aggregate, **kwargs
                    )
                    
                    if data is not None and len(data) > 0:
                        sub_data[sub_name] = data
                        
                except Exception as e:
                    print(f"è­¦å‘Š: åŠ è½½å­æ¦‚å¿µ {sub_name} å¤±è´¥: {e}")
                    continue
            
            if not sub_data:
                result = pd.DataFrame()
            else:
                # 2. åº”ç”¨å›žè°ƒå‡½æ•°
                callback = concept.callback if hasattr(concept, 'callback') else None
                
                if callback:
                    # æž„å»ºå›žè°ƒå‡½æ•°å¹¶åº”ç”¨
                    if callable(callback):
                        result = callback(sub_data, interval=interval, src=self.src, **kwargs)
                    else:
                        # å¦‚æžœæ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»åž‹ï¼Œå°è¯•ä»Žcallback_utilsæž„å»º
                        from .callback_utils import build_callback
                        cb_func = build_callback(callback)
                        result = cb_func(sub_data, interval=interval, src=self.src, **kwargs)
                else:
                    # å¦‚æžœæ²¡æœ‰å›žè°ƒï¼Œå°è¯•ç®€å•åˆå¹¶
                    if len(sub_data) == 1:
                        result = list(sub_data.values())[0]
                    else:
                        # å¤šä¸ªå­æ¦‚å¿µï¼Œéœ€è¦åˆå¹¶
                        result = self._merge_sub_concepts(sub_data, id_type, interval)
            
            # ç¼“å­˜ç»“æžœ
            self._concept_cache[cache_key] = result.copy() if len(result) > 0 else result
            
            return result
            
        finally:
            # ä»ŽåŠ è½½æ ˆä¸­ç§»é™¤å½“å‰æ¦‚å¿µ
            self._loading_stack.discard(concept.name)
    
    def _filter_concept_data(self, data: pd.DataFrame, concept: Concept) -> pd.DataFrame:
        """
        æ ¹æ®æ¦‚å¿µå®šä¹‰è¿‡æ»¤æ•°æ®
        
        Args:
            data: åŽŸå§‹æ•°æ®
            concept: æ¦‚å¿µå¯¹è±¡
            
        Returns:
            è¿‡æ»¤åŽçš„æ•°æ®
        """
        if 'value' not in data.columns:
            return data
        
        # 1. è¿‡æ»¤NA
        data = data.dropna(subset=['value'])
        
        # 2. æ•°å€¼èŒƒå›´è¿‡æ»¤
        if hasattr(concept, 'min') and concept.min is not None:
            data = data[data['value'] >= concept.min]
        
        if hasattr(concept, 'max') and concept.max is not None:
            data = data[data['value'] <= concept.max]
        
        # 3. åˆ†ç±»å€¼è¿‡æ»¤
        if hasattr(concept, 'levels') and concept.levels:
            data = data[data['value'].isin(concept.levels)]
        
        # 4. å•ä½è½¬æ¢ï¼ˆå¦‚æžœéœ€è¦ï¼‰
        if hasattr(concept, 'unit') and concept.unit and 'unit' in data.columns:
            data = self._convert_units(data, concept.unit)
        
        return data
    
    def _convert_units(self, data: pd.DataFrame, target_unit: str) -> pd.DataFrame:
        """
        å•ä½è½¬æ¢
        
        Args:
            data: æ•°æ®
            target_unit: ç›®æ ‡å•ä½
            
        Returns:
            è½¬æ¢åŽçš„æ•°æ®
        """
        # TODO: å®žçŽ°å®Œæ•´çš„å•ä½è½¬æ¢ç³»ç»Ÿ
        # è¿™é‡Œå…ˆåšç®€å•å¤„ç†
        return data
    
    def _aggregate_concept(
        self,
        data: pd.DataFrame,
        concept: Concept,
        aggregate: str,
        id_type: str,
        interval: timedelta
    ) -> pd.DataFrame:
        """
        èšåˆæ¦‚å¿µæ•°æ®
        
        Args:
            data: æ•°æ®
            concept: æ¦‚å¿µ
            aggregate: èšåˆå‡½æ•°å
            id_type: IDç±»åž‹
            interval: æ—¶é—´é—´éš”
            
        Returns:
            èšåˆåŽçš„æ•°æ®
        """
        id_col = self._get_id_column(data, id_type)
        
        group_cols = [id_col]
        if 'time' in data.columns:
            group_cols.append('time')
        
        value_col = concept.name
        
        # æ‰§è¡Œèšåˆ
        agg_dict = {value_col: aggregate}
        result = data.groupby(group_cols, as_index=False).agg(agg_dict)
        
        return result
    
    def _merge_concepts(
        self,
        results: Dict[str, pd.DataFrame],
        id_type: str
    ) -> pd.DataFrame:
        """
        åˆå¹¶å¤šä¸ªæ¦‚å¿µä¸ºå®½æ ¼å¼
        
        Args:
            results: æ¦‚å¿µå -> DataFrame å­—å…¸
            id_type: IDç±»åž‹
            
        Returns:
            åˆå¹¶åŽçš„å®½æ ¼å¼DataFrame
        """
        if not results:
            return pd.DataFrame()
        
        # æ‰¾å‡ºå…¬å…±åˆ—
        first_df = list(results.values())[0]
        id_col = self._get_id_column(first_df, id_type)
        
        merge_cols = [id_col]
        if 'time' in first_df.columns:
            merge_cols.append('time')
        
        # é€æ­¥åˆå¹¶
        merged = None
        for name, df in results.items():
            if merged is None:
                merged = df
            else:
                merged = merged.merge(df, on=merge_cols, how='outer')
        
        return merged
    
    def _merge_sub_concepts(
        self,
        sub_data: Dict[str, pd.DataFrame],
        id_type: str,
        interval: timedelta
    ) -> pd.DataFrame:
        """
        åˆå¹¶å¤šä¸ªå­æ¦‚å¿µæ•°æ®
        
        Args:
            sub_data: å­æ¦‚å¿µæ•°æ®å­—å…¸
            id_type: IDç±»åž‹
            interval: æ—¶é—´é—´éš”
            
        Returns:
            åˆå¹¶åŽçš„DataFrame
        """
        if not sub_data:
            return pd.DataFrame()
        
        if len(sub_data) == 1:
            return list(sub_data.values())[0]
        
        # ç¡®å®šIDåˆ—å’Œæ—¶é—´åˆ—
        id_col = self._determine_id_column(id_type)
        merge_cols = [id_col]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´åˆ—
        first_df = list(sub_data.values())[0]
        if 'time' in first_df.columns:
            merge_cols.append('time')
        
        # é€æ­¥åˆå¹¶
        result = None
        for name, df in sub_data.items():
            if result is None:
                result = df.copy()
            else:
                result = result.merge(df, on=merge_cols, how='outer', suffixes=('', f'_{name}'))
        
        return result
    
    def _determine_id_column(self, id_type: str) -> str:
        """
        æ ¹æ®IDç±»åž‹ç¡®å®šIDåˆ—å
        
        Args:
            id_type: IDç±»åž‹
            
        Returns:
            IDåˆ—å
        """
        # æ•°æ®æºç‰¹å®šçš„IDåˆ—åæ˜ å°„
        id_mappings = {
            'mimic_demo': {
                'icustay': 'stay_id',
                'hadm': 'hadm_id',
                'subject': 'subject_id',
            },
            'mimic': {
                'icustay': 'stay_id',
                'hadm': 'hadm_id',
                'subject': 'subject_id',
            },
            'eicu_demo': {
                'icustay': 'patientunitstayid',
                'hadm': 'patienthealthsystemstayid',
                'subject': 'uniquepid',
            },
            'eicu': {
                'icustay': 'patientunitstayid',
                'hadm': 'patienthealthsystemstayid',
                'subject': 'uniquepid',
            },
        }
        
        src_name = self._src_name
        
        if src_name in id_mappings and id_type in id_mappings[src_name]:
            return id_mappings[src_name][id_type]
        
        # é»˜è®¤è¿”å›ž stay_id
        return 'stay_id'
    
    def clear_cache(self):
        """æ¸…é™¤æ¦‚å¿µåŠ è½½ç¼“å­˜"""
        if hasattr(self, '_concept_cache'):
            self._concept_cache.clear()
        if hasattr(self, '_loading_stack'):
            self._loading_stack.clear()
    
    def _get_id_column(self, df: pd.DataFrame, id_type: str) -> Optional[str]:
        """
        èŽ·å–IDåˆ—å
        
        Args:
            df: DataFrame
            id_type: IDç±»åž‹
            
        Returns:
            åˆ—åæˆ–None
        """
        # å¸¸è§çš„IDåˆ—åæ˜ å°„
        id_mappings = {
            'patient': ['subject_id', 'patientid', 'patient_id'],
            'hadm': ['hadm_id', 'admissionid', 'admission_id'],
            'icustay': ['icustay_id', 'stay_id', 'patientunitstayid'],
        }
        
        possible_names = id_mappings.get(id_type, [id_type])
        
        for col in df.columns:
            if col.lower() in [n.lower() for n in possible_names]:
                return col
        
        # è¿”å›žç¬¬ä¸€ä¸ªåŒ…å«'id'çš„åˆ—
        for col in df.columns:
            if 'id' in col.lower():
                return col
        
        return None
    
    def _get_time_column(self, df: pd.DataFrame) -> Optional[str]:
        """
        èŽ·å–æ—¶é—´åˆ—å
        
        Args:
            df: DataFrame
            
        Returns:
            åˆ—åæˆ–None
        """
        time_cols = ['charttime', 'time', 'datetime', 'timestamp', 
                     'starttime', 'observationoffset']
        
        for col in df.columns:
            if col.lower() in [t.lower() for t in time_cols]:
                return col
        
        return None


def load_concepts(
    concepts: Union[str, List[str]],
    src: Union[str, DataSource],
    **kwargs
) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåŠ è½½æ¦‚å¿µ
    
    Args:
        concepts: æ¦‚å¿µåç§°æˆ–åˆ—è¡¨
        src: æ•°æ®æº
        **kwargs: ä¼ é€’ç»™ ConceptLoader.load_concepts
        
    Returns:
        DataFrame æˆ–å­—å…¸
    
    Examples:
        >>> # åŠ è½½å•ä¸ªæ¦‚å¿µ
        >>> hr = load_concepts('hr', 'mimic')
        >>> 
        >>> # åŠ è½½å¤šä¸ªæ¦‚å¿µå¹¶åˆå¹¶
        >>> vitals = load_concepts(['hr', 'sbp', 'dbp'], 'mimic', 
        ...                        interval=timedelta(hours=1))
    """
    loader = ConceptLoader(src)
    return loader.load_concepts(concepts, **kwargs)
