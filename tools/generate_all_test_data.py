#!/usr/bin/env python3
"""ç»Ÿä¸€ç”Ÿæˆæ‰€æœ‰æ•°æ®åº“çš„æµ‹è¯•æ•°æ®"""

import subprocess
import sys
from pathlib import Path
import shutil
from datetime import datetime

# å·¥å…·ç›®å½•è·¯å¾„
TOOLS_DIR = Path(__file__).resolve().parent
ROOT_DIR = TOOLS_DIR.parent

# æ•°æ®åº“é…ç½®
DATABASES = {
    'miiv': {
        'script': 'create_miiv_from_db.py',
        'test_dir': ROOT_DIR / 'test_data_miiv',
        'description': 'MIMIC-IVæ•°æ®åº“'
    },
    'aumc': {
        'script': 'create_aumc_from_db.py',
        'test_dir': ROOT_DIR / 'test_data_aumc',
        'description': 'AUMCæ•°æ®åº“'
    },
    'eicu': {
        'script': 'create_eicu_from_db.py',
        'test_dir': ROOT_DIR / 'test_data_eicu',
        'description': 'eICUæ•°æ®åº“'
    },
    'hirid': {
        'script': 'create_hirid_from_db.py',
        'test_dir': ROOT_DIR / 'test_data_hirid',
        'description': 'HiRIDæ•°æ®åº“'
    }
}

def clean_existing_data(test_dir):
    """æ¸…ç†ç°æœ‰æµ‹è¯•æ•°æ®"""
    if test_dir.exists():
        print(f"  ğŸ—‘ï¸  æ¸…ç†ç°æœ‰ç›®å½•: {test_dir}")
        shutil.rmtree(test_dir)
    test_dir.mkdir(parents=True, exist_ok=True)

def run_script(script_path, description):
    """è¿è¡Œç”Ÿæˆè„šæœ¬"""
    print(f"ğŸš€ ç”Ÿæˆ {description} æµ‹è¯•æ•°æ®...")

    try:
        result = subprocess.run(
            [sys.executable, str(script_path)],
            capture_output=True,
            text=True,
            timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
        )

        if result.returncode == 0:
            print(f"  âœ… {description} æ•°æ®ç”ŸæˆæˆåŠŸ")
            # è¾“å‡ºå…³é”®ä¿¡æ¯
            for line in result.stdout.split('\n'):
                if any(keyword in line for keyword in ['âœ…', 'å®Œæˆ', 'æ€»è®¡', 'æ‚£è€…', 'è®°å½•']):
                    print(f"    {line}")
        else:
            print(f"  âŒ {description} æ•°æ®ç”Ÿæˆå¤±è´¥")
            print(f"  é”™è¯¯ä¿¡æ¯: {result.stderr}")
            return False

    except subprocess.TimeoutExpired:
        print(f"  â° {description} æ•°æ®ç”Ÿæˆè¶…æ—¶")
        return False
    except Exception as e:
        print(f"  âŒ {description} æ•°æ®ç”Ÿæˆå‡ºé”™: {e}")
        return False

    return True

def verify_generated_data(test_dir, description):
    """éªŒè¯ç”Ÿæˆçš„æ•°æ®"""
    print(f"ğŸ” éªŒè¯ {description} æ•°æ®...")

    if not test_dir.exists():
        print(f"  âŒ ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        return False

    # ç»Ÿè®¡parquetæ–‡ä»¶
    parquet_files = list(test_dir.rglob("*.parquet"))
    csv_files = list(test_dir.rglob("*.csv"))
    py_files = list(test_dir.rglob("*.py"))

    print(f"  ğŸ“ ç›®å½•ç»“æ„:")
    print(f"    - Parquetæ–‡ä»¶: {len(parquet_files)} ä¸ª")
    print(f"    - CSVæ–‡ä»¶: {len(csv_files)} ä¸ª")
    print(f"    - Pythonæ–‡ä»¶: {len(py_files)} ä¸ª")

    # æ£€æŸ¥æ‚£è€…IDæ–‡ä»¶
    patient_ids_file = test_dir / "test_patient_ids.py"
    if patient_ids_file.exists():
        print(f"  âœ… æ‚£è€…IDæ–‡ä»¶å·²ç”Ÿæˆ: test_patient_ids.py")
    else:
        print(f"  âš ï¸  æ‚£è€…IDæ–‡ä»¶ç¼ºå¤±")

    # è®¡ç®—æ€»æ•°æ®é‡
    total_rows = 0
    total_size = 0

    for parquet_file in parquet_files:
        try:
            # ä½¿ç”¨pandasè¯»å–è·å–è¡Œæ•°
            import pandas as pd
            df = pd.read_parquet(parquet_file)
            total_rows += len(df)
            total_size += parquet_file.stat().st_size
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•è¯»å– {parquet_file.name}: {e}")

    if total_size > 0:
        size_mb = total_size / (1024 * 1024)
        print(f"  ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"    - æ€»è®°å½•æ•°: {total_rows:,}")
        print(f"    - æ€»å¤§å°: {size_mb:.1f} MB")

    return len(parquet_files) > 0

def generate_summary_report(results):
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ æµ‹è¯•æ•°æ®ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š")
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}")

    success_count = sum(1 for r in results.values() if r['success'])
    total_count = len(results)

    print(f"\nğŸ“Š æ€»ä½“ç»“æœ: {success_count}/{total_count} æ•°æ®åº“æˆåŠŸ")

    print(f"\nğŸ“ˆ è¯¦ç»†ç»“æœ:")
    for db, result in results.items():
        status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"
        print(f"  {DATABASES[db]['description']:15} : {status}")
        if result['error']:
            print(f"    é”™è¯¯: {result['error']}")

    if success_count == total_count:
        print(f"\nğŸ‰ æ‰€æœ‰æ•°æ®åº“æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆï¼")
        print(f"\nğŸ“‚ ç”Ÿæˆçš„æ•°æ®ç›®å½•:")
        for db in results:
            test_dir = DATABASES[db]['test_dir']
            if test_dir.exists():
                parquet_count = len(list(test_dir.rglob("*.parquet")))
                print(f"  - {test_dir.name}: {parquet_count} ä¸ªparquetæ–‡ä»¶")
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†æ•°æ®åº“ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    print(f"\nğŸ”§ ä½¿ç”¨æ–¹æ³•:")
    print(f"  # å¯¼å…¥æ‚£è€…ID")
    print(f"  from test_data_miiv.test_patient_ids import SELECTED_STAY_IDS")
    print(f"  # åŠ è½½æµ‹è¯•æ•°æ®")
    print(f"  python test_main.py --database miiv --data-source test")

def main():
    import argparse

    parser = argparse.ArgumentParser(description='pyricuæµ‹è¯•æ•°æ®ç»Ÿä¸€ç”Ÿæˆå·¥å…·')
    parser.add_argument(
        'databases',
        nargs='*',
        help='è¦ç”Ÿæˆçš„æ•°æ®åº“åˆ—è¡¨ (ä¾‹å¦‚: miiv eicu)ï¼Œé»˜è®¤: all'
    )
    parser.add_argument(
        '--auto-confirm',
        action='store_true',
        help='è‡ªåŠ¨ç¡®è®¤æ“ä½œï¼Œä¸è¯¢é—®ç”¨æˆ·'
    )

    args = parser.parse_args()

    print(f"ğŸ¥ pyricu æµ‹è¯•æ•°æ®ç»Ÿä¸€ç”Ÿæˆå·¥å…·")
    print(f"{'='*60}")

    # ç¡®å®šè¦ç”Ÿæˆçš„æ•°æ®åº“
    if not args.databases:
        selected_dbs = list(DATABASES.keys())  # é»˜è®¤ç”Ÿæˆæ‰€æœ‰æ•°æ®åº“
    else:
        if args.databases[0].lower() == 'all':
            selected_dbs = list(DATABASES.keys())
        else:
            selected_dbs = args.databases

    # éªŒè¯è¾“å…¥
    invalid_dbs = [db for db in selected_dbs if db not in DATABASES]
    if invalid_dbs:
        print(f"âŒ æ— æ•ˆçš„æ•°æ®åº“: {invalid_dbs}")
        print(f"å¯ç”¨çš„æ•°æ®åº“: {', '.join(DATABASES.keys())}")
        return

    print(f"\nğŸ¯ å°†ä¸ºä»¥ä¸‹æ•°æ®åº“ç”Ÿæˆæµ‹è¯•æ•°æ®: {', '.join(selected_dbs)}")

    # æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
    print(f"\nğŸ“‹ æ•°æ®åº“ä¿¡æ¯:")
    for db in selected_dbs:
        config = DATABASES[db]
        print(f"  {db}: {config['description']}")

    # ç¡®è®¤æ“ä½œ
    if not args.auto_confirm:
        print(f"\nâš ï¸  è¿™å°†åˆ é™¤ç°æœ‰æµ‹è¯•æ•°æ®å¹¶é‡æ–°ç”Ÿæˆ")
        print(f"å¦‚æœç¡®è®¤ï¼Œè¯·ä½¿ç”¨ --auto-confirm å‚æ•°")
        return

    # æ‰§è¡Œç”Ÿæˆ
    results = {}

    for db in selected_dbs:
        config = DATABASES[db]
        print(f"\n{'-'*40}")

        results[db] = {'success': False, 'error': None}

        try:
            # 1. æ¸…ç†ç°æœ‰æ•°æ®
            clean_existing_data(config['test_dir'])

            # 2. è¿è¡Œç”Ÿæˆè„šæœ¬
            script_path = TOOLS_DIR / config['script']
            if not script_path.exists():
                results[db]['error'] = f"è„šæœ¬ä¸å­˜åœ¨: {script_path}"
                continue

            success = run_script(script_path, config['description'])
            if not success:
                results[db]['error'] = "è„šæœ¬æ‰§è¡Œå¤±è´¥"
                continue

            # 3. éªŒè¯ç”Ÿæˆç»“æœ
            if verify_generated_data(config['test_dir'], config['description']):
                results[db]['success'] = True
            else:
                results[db]['error'] = "æ•°æ®éªŒè¯å¤±è´¥"

        except Exception as e:
            results[db]['error'] = str(e)
            print(f"  âŒ å¤„ç† {config['description']} æ—¶å‡ºé”™: {e}")

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    generate_summary_report(results)

if __name__ == "__main__":
    main()